<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Anthropic News</title>
    <link>https://anthropic.com/news/feed_anthropic_news.xml</link>
    <description>Latest updates from Anthropic's newsroom</description>
    <atom:link href="https://anthropic.com/news/feed_anthropic_news.xml" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <image>
      <url>https://www.anthropic.com/images/icons/apple-touch-icon.png</url>
      <title>Anthropic News</title>
      <link>https://anthropic.com/news/feed_anthropic_news.xml</link>
    </image>
    <language>en</language>
    <lastBuildDate>Sun, 28 Dec 2025 00:13:45 +0000</lastBuildDate>
    <item>
      <title>Company</title>
      <link>https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy</link>
      <description>Today we are publishing a significant update to our Responsible Scaling Policy (RSP), the risk governance framework we use to mitigate potential catastrophic risks from frontier AI systems. This update introduces a more flexible and nuanced approach to assessing and managing AI risks while maintaining our commitment not to train or deploy models unless we have implemented adequate safeguards. Key improvements include new capability thresholds to indicate when we will upgrade our safeguards, refined processes for evaluating model capabilities and the adequacy of our safeguards (inspired by safety case methodologies ), and new measures for internal governance and external input. By learning from our implementation experiences and drawing on risk management practices used in other high-consequence industries, we aim to better prepare for the rapid pace of AI advancement.</description>
      <content:encoded>&lt;article&gt;Announcements&lt;h1&gt;Announcing our updated Responsible Scaling Policy&lt;/h1&gt;Oct 15, 2024&lt;a href="http://anthropic.com/rsp "&gt;Read the Responsible Scaling Policy &lt;/a&gt;&lt;p&gt;&lt;strong&gt;Today we are publishing a significant update to our Responsible Scaling Policy (RSP), the risk governance framework we use to mitigate potential catastrophic risks from frontier AI systems. &lt;/strong&gt;This update introduces a more flexible and nuanced approach to assessing and managing AI risks while maintaining our commitment not to train or deploy models unless we have implemented adequate safeguards. Key improvements include new capability thresholds to indicate when we will upgrade our safeguards, refined processes for evaluating model capabilities and the adequacy of our safeguards (inspired by &lt;a href="https://arxiv.org/abs/2403.10462"&gt;safety case methodologies&lt;/a&gt;), and new measures for internal governance and external input. By learning from our implementation experiences and drawing on risk management practices used in other high-consequence industries, we aim to better prepare for the rapid pace of AI advancement.&lt;/p&gt;&lt;h2&gt;The promise and challenge of advanced AI&lt;/h2&gt;&lt;p&gt;As frontier AI models advance, they have the potential to bring about transformative benefits for our society and economy. AI could accelerate scientific discoveries, revolutionize healthcare, enhance our education system, and create entirely new domains for human creativity and innovation. However, frontier AI systems also present new challenges and risks that warrant careful study and effective safeguards.&lt;/p&gt;&lt;p&gt;In September 2023, we &lt;a href="https://www.anthropic.com/news/anthropics-responsible-scaling-policy"&gt;released&lt;/a&gt; our Responsible Scaling Policy, a framework for managing risks from increasingly capable AI systems. After a year of implementation and learning, we are now sharing a significantly updated version that reflects practical insights and accounts for advancing technological capabilities.&lt;/p&gt;&lt;p&gt;Although this policy focuses on catastrophic risks like the categories listed below, they are not the only risks that we monitor and prepare for. Our &lt;a href="https://www.anthropic.com/legal/aup"&gt;Usage Policy&lt;/a&gt; sets forth our standards for the use of our products, including rules that prohibit using our models to spread misinformation, incite violence or hateful behavior, or engage in fraudulent or abusive practices. We continually refine our technical measures for enforcing our trust and safety standards at scale. Further, we conduct research to understand the broader &lt;a href="https://www.anthropic.com/research#societal-impacts"&gt;societal impacts&lt;/a&gt; of our models. Our Responsible Scaling Policy complements our work in these areas, contributing to our understanding of current and potential risks.&lt;/p&gt;&lt;h2&gt;A framework for proportional safeguards&lt;/h2&gt;&lt;p&gt;As before, we maintain our core commitment: we will not train or deploy models unless we have implemented safety and security measures that keep risks below acceptable levels. Our RSP is based on the principle of proportional protection: safeguards that scale with potential risks. To do this, we use &lt;strong&gt;AI Safety Level Standards (ASL Standards)&lt;/strong&gt;, graduated sets of safety and security measures that become more stringent as model capabilities increase. Inspired by &lt;a href="https://en.wikipedia.org/wiki/Biosafety_level"&gt;Biosafety Levels,&lt;/a&gt; these begin at ASL-1 for models that have very basic capabilities (for example, chess-playing bots) and progress through ASL-2, ASL-3, and so on.&lt;/p&gt;&lt;p&gt;In our updated policy, we have refined our methodology for assessing specific capabilities (and their associated risks) and implementing proportional safety and security measures. Our updated framework has two key components:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Capability Thresholds:&lt;/strong&gt; Specific AI abilities that, if reached, would require stronger safeguards than our current baseline.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Required Safeguards: &lt;/strong&gt;The specific ASL Standards needed to mitigate risks once a Capability Threshold has been reached.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;At present, all of our models operate under ASL-2 Standards, which reflect current industry best practices. Our updated policy defines two key Capability Thresholds that would require upgraded safeguards:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Autonomous AI Research and Development:&lt;/strong&gt; If a model can independently conduct complex AI research tasks typically requiring human expertise—potentially significantly accelerating AI development in an unpredictable way—we require elevated security standards (potentially ASL-4 or higher standards) and additional safety assurances to avoid a situation where development outpaces our ability to address emerging risks.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Chemical, Biological, Radiological, and Nuclear (CBRN) weapons:&lt;/strong&gt; If a model can meaningfully assist someone with a basic technical background in creating or deploying CBRN weapons, we require enhanced security and deployment safeguards (ASL-3 standards).&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;ASL-3 safeguards involve enhanced security measures and deployment controls. On the security side, this will include internal access controls and more robust protection of model weights. For deployment risks, we plan to implement a multi-layered approach to prevent misuse, including real-time and asynchronous monitoring, rapid response protocols, and thorough pre-deployment red teaming.&lt;/p&gt;&lt;h2&gt;Implementation and oversight&lt;/h2&gt;&lt;p&gt;To contribute to effective implementation of the policy, we have established:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Capability assessments&lt;/strong&gt;: Routine model evaluations based on our Capability Thresholds to determine whether our current safeguards are still appropriate. (Summaries of past assessments are available &lt;a href="https://www.anthropic.com/rsp-updates"&gt;here&lt;/a&gt;.)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Safeguard assessments: &lt;/strong&gt;Routine evaluation of the effectiveness of our security and deployment safety measures to assess whether we have met the Required Safeguards bar. (Summaries of these decisions will be available &lt;a href="https://www.anthropic.com/rsp-updates"&gt;here&lt;/a&gt;.)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Documentation and decision-making: &lt;/strong&gt;Processes for documenting the capability and safeguard assessments, inspired by procedures (such as &lt;a href="https://arxiv.org/abs/2403.10462"&gt;safety case methodologies&lt;/a&gt;) common in high-reliability industries.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Measures for internal governance and external input: &lt;/strong&gt;Our assessment methodology will be backed up by internal stress-testing in addition to our existing internal reporting process for safety issues. We are also soliciting external expert feedback on our methodologies.1&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Learning from experience&lt;/h2&gt;&lt;p&gt;We have learned a lot in our first year with the previous RSP in effect, and are using this update as an opportunity to reflect on what has worked well and what makes sense to update in the policy. As part of this, we conducted our first review of how well we adhered to the framework and identified a small number of instances where we fell short of meeting the full letter of its requirements. These included procedural issues such as completing a set of evaluations three days later than scheduled or a lack of clarity on how and where we should note any changes to our placeholder evaluations. We also flagged some evaluations where we may have been able to elicit slightly better model performance through implementing standard techniques (such as chain-of-thought or best-of-N).&lt;/p&gt;&lt;p&gt;In all cases, we found these instances posed minimal risk to the safety of our models. We used the additional three days to refine and improve our evaluations; the different set of evaluations we used provided a more accurate assessment than the placeholder evaluations; and our evaluation methodology still showed we were sufficiently far from the thresholds. From this, we learned two valuable lessons to incorporate into our updated framework: we needed to incorporate more flexibility into our policies, and we needed to improve our process for tracking compliance with the RSP. You can read more &lt;a href="http://anthropic.com/rsp-updates"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Since we first released the RSP a year ago, our goal has been to offer an example of a framework that others might draw inspiration from when crafting their own AI risk governance policies. We hope that proactively sharing our experiences implementing our own policy will help other companies in implementing their own risk management frameworks and contribute to the establishment of best practices across the AI ecosystem.&lt;/p&gt;&lt;h2&gt;Looking ahead&lt;/h2&gt;&lt;p&gt;The frontier of AI is advancing rapidly, making it challenging to anticipate what safety measures will be appropriate for future systems. All aspects of our safety program will continue to evolve: our policies, evaluation methodology, safeguards, and our research into potential risks and mitigations.&lt;/p&gt;&lt;p&gt;Additionally, Co-Founder and Chief Science Officer Jared Kaplan will serve as Anthropic’s Responsible Scaling Officer, succeeding Co-Founder and Chief Technology Officer Sam McCandlish who held this role over the last year. Sam oversaw the RSP’s initial implementation and will continue to focus on his duties as Chief Technology Officer. As we work to scale up our efforts on implementing the RSP, we’re also opening a position for a Head of Responsible Scaling. This role will be responsible for coordinating the many teams needed to iterate on and successfully comply with the RSP.&lt;/p&gt;&lt;p&gt;If you would like to contribute to AI risk management at Anthropic, &lt;a href="https://www.anthropic.com/jobs"&gt;we are hiring&lt;/a&gt;! Many of our teams now contribute to risk management via the RSP, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Frontier Red Team (responsible for threat modeling and capability assessments)&lt;/li&gt;&lt;li&gt;Trust &amp;amp; Safety (responsible for developing deployment safeguards)&lt;/li&gt;&lt;li&gt;Security and Compliance (responsible for security safeguards and risk management)&lt;/li&gt;&lt;li&gt;Alignment Science (including sub-teams responsible for developing ASL-3+ safety measures, for misalignment-focused capability evaluations, and for our internal alignment stress-testing program)&lt;/li&gt;&lt;li&gt;RSP Team (responsible for policy drafting, assurance, and cross-company execution)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Read the updated policy at &lt;a href="http://anthropic.com/rsp"&gt;anthropic.com/rsp&lt;/a&gt;, and supplementary information at &lt;a href="http://anthropic.com/rsp-updates"&gt;anthropic.com/rsp-updates&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;We extend our sincere gratitude to the many external groups that provided invaluable feedback on the development and refinement of our Responsible Scaling Policy.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h4&gt;Footnotes&lt;/h4&gt;&lt;p&gt;1 &lt;em&gt;We have also shared our assessment methodology with both AI Safety Institutes, as well as a selection of independent experts and organizations, for feedback. This does not represent an endorsement from either AI Safety Institute or the independent experts and organizations. &lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy</guid>
      <category>News</category>
    </item>
    <item>
      <title>Thoughts on America’s AI Action Plan</title>
      <link>https://www.anthropic.com/news/thoughts-on-america-s-ai-action-plan</link>
      <description>Today, the White House released "Winning the Race: America's AI Action Plan"—a comprehensive strategy to maintain America's advantage in AI development. We are encouraged by the plan’s focus on accelerating AI infrastructure and federal adoption, as well as strengthening safety testing and security coordination. Many of the plan’s recommendations reflect Anthropic’s response to the Office of Science and Technology Policy’s (OSTP) prior request for information . While the plan positions America for AI advancement, we believe strict export controls and AI development transparency standards remain crucial next steps for securing American AI leadership.</description>
      <content:encoded>&lt;article&gt;Policy&lt;h1&gt;Thoughts on America’s AI Action Plan&lt;/h1&gt;Jul 23, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/6e00dbffcddc82df5e471c43453abfc74ca94e8d-1000x1000.svg"/&gt;&lt;p&gt;Today, the White House released "Winning the Race: America's AI Action Plan"—a comprehensive strategy to maintain America's advantage in AI development. We are encouraged by the plan’s focus on accelerating AI infrastructure and federal adoption, as well as strengthening safety testing and security coordination. Many of the plan’s recommendations reflect Anthropic’s &lt;a href="https://assets.anthropic.com/m/4e20a4ab6512e217/original/Anthropic-Response-to-OSTP-RFI-March-2025-Final-Submission-v3.pdf"&gt;response&lt;/a&gt; to the Office of Science and Technology Policy’s (OSTP) prior &lt;a href="https://www.federalregister.gov/documents/2025/02/06/2025-02305/request-for-information-on-the-development-of-an-artificial-intelligence-ai-action-plan"&gt;request for information&lt;/a&gt;. While the plan positions America for AI advancement, we believe strict export controls and AI development transparency standards remain crucial next steps for securing American AI leadership.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Accelerating AI infrastructure and adoption&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;The Action Plan prioritizes AI infrastructure and adoption, consistent with Anthropic’s submission to OSTP in March.&lt;/p&gt;&lt;p&gt;We applaud the Administration's commitment to streamlining data center and energy permitting to address AI’s power needs. As we stated in our OSTP submission and at &lt;a href="https://www.youtube.com/watch?v=KO8vMSsjmGY"&gt;the Pennsylvania Energy and Innovation Summit&lt;/a&gt;, without adequate domestic energy capacity, American AI developers may be forced to relocate operations overseas, potentially exposing sensitive technology to foreign adversaries. Our recently published &lt;a href="https://www-cdn.anthropic.com/0dc382a2086f6a054eeb17e8a531bd9625b8e6e5.pdf"&gt;“Build AI in America” report&lt;/a&gt; details the steps the Administration can take to accelerate the buildout of our nation’s AI infrastructure, and we look forward to working with the Administration on measures to expand domestic energy capacity.&lt;/p&gt;&lt;p&gt;The Plan’s recommendations to increase the federal government's adoption of AI also includes proposals that are closely aligned with Anthropic’s policy priorities and recommendations to the White House. These include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Tasking the Office of Management and Budget (OMB) to address resource constraints, procurement limitations, and programmatic obstacles to federal AI adoption.&lt;/li&gt;&lt;li&gt;Launching a Request for Information (RFI) to identify federal regulations that impede AI innovation, with OMB coordinating reform efforts.&lt;/li&gt;&lt;li&gt;Updating federal procurement standards to remove barriers that prevent agencies from deploying AI systems.&lt;/li&gt;&lt;li&gt;Promoting AI adoption across defense and national security applications through public-private collaboration.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;strong&gt;Democratizing AI’s benefits&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;We are aligned with the Action Plan’s focus on ensuring broad participation in and benefit from AI’s continued development and deployment.&lt;/p&gt;&lt;p&gt;The Action Plan’s continuation of the National AI Research Resource (NAIRR) pilot ensures that students and researchers across the country can participate in and contribute to the advancement of the AI frontier. We have &lt;a href="https://nsf-gov-resources.nsf.gov/files/Anthropic-NAIRR-RFI-Response-2022.pdf?VersionId=zOuWKBYCI5lsNESyOvsZIJQM9ePTOTrK"&gt;long supported&lt;/a&gt; the NAIRR and are proud of &lt;a href="https://www.nsf.gov/focus-areas/artificial-intelligence/nairr#nairr-pilot-partners-and-contributors-890"&gt;our partnership&lt;/a&gt; with the pilot program. Further, the Action Plan’s emphasis on rapid retraining programs for displaced workers and pre-apprenticeship AI programs recognizes the errors of prior technological transitions and demonstrates a commitment to delivering AI’s benefits to all Americans.&lt;/p&gt;&lt;p&gt;Complementing these proposals are our efforts to understand how AI is transforming, and how it will transform, our economy. The &lt;a href="https://www.anthropic.com/economic-index"&gt;Economic Index&lt;/a&gt; and the &lt;a href="https://www.anthropic.com/economic-futures"&gt;Economic Futures Program&lt;/a&gt; aim to provide researchers and policymakers with the data and tools they need to ensure AI’s economic benefits are broadly shared and risks are appropriately managed.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Promoting secure AI development&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.darioamodei.com/essay/machines-of-loving-grace"&gt;Powerful AI systems&lt;/a&gt; are going to be developed in the coming years. The plan’s emphasis on defending against the misuse of powerful AI models and preparing for future AI related risks is appropriate and excellent. In particular, we commend the administration’s prioritization of supporting research into &lt;a href="https://www.darioamodei.com/post/the-urgency-of-interpretability"&gt;AI interpretability&lt;/a&gt;, AI control systems, and adversarial robustness. These are important lines of research that must be supported to help us deal with powerful AI systems.&lt;/p&gt;&lt;p&gt;We're glad the Action Plan affirms the National Institute of Standards and Technology's Center for AI Standards and Innovation’s (CAISI) important work to evaluate frontier models for national security issues and we look forward to continuing our close partnership with them. We encourage the Administration to continue to invest in CAISI. As we noted in our submission, advanced AI systems are demonstrating concerning improvements in capabilities relevant to biological weapons development. CAISI has played a leading role in developing testing and evaluation capabilities to address these risks. We encourage focusing these efforts on the most unique and acute national security&lt;em&gt; &lt;/em&gt;risks that AI systems may pose.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The need for a national standard&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Beyond testing, we believe basic AI development transparency requirements, such as public reporting on safety testing and capability assessments, are essential for responsible AI development. Leading AI model developers should be held to basic and publicly-verifiable standards of assessing and managing the catastrophic risks posed by their systems. Our &lt;a href="https://www-cdn.anthropic.com/19cc4bf9eb6a94f9762ac67368f3322cf82b09fe.pdf"&gt;proposed framework&lt;/a&gt; for frontier model transparency focuses on these risks. We would have liked to see the report do more on this topic.&lt;/p&gt;&lt;p&gt;Leading labs, including Anthropic, OpenAI, and Google DeepMind, have already implemented voluntary safety frameworks, which demonstrates that responsible development and innovation can coexist. In fact, with the launch of Claude Opus 4, we proactively &lt;a href="https://www.anthropic.com/news/activating-asl3-protections"&gt;activated ASL-3 protections&lt;/a&gt; to prevent misuse for chemical, biological, radiological, and nuclear (CBRN) weapons development. This precautionary step shows that far from slowing innovation, robust safety protections help us build better, more reliable systems.&lt;/p&gt;&lt;p&gt;We share the Administration’s concern about overly-prescriptive regulatory approaches creating an &lt;a href="https://www.nytimes.com/2025/06/05/opinion/anthropic-ceo-regulate-transparency.html"&gt;inconsistent and burdensome patchwork of laws&lt;/a&gt;. Ideally, these transparency requirements would come from the government by way of a single national standard. However, in line with our &lt;a href="https://www.nytimes.com/2025/06/05/opinion/anthropic-ceo-regulate-transparency.html"&gt;stated belief&lt;/a&gt; that a ten-year moratorium on state AI laws is too blunt an instrument, we continue to oppose proposals aimed at preventing states from enacting measures to protect their citizens from potential harms caused by powerful AI systems, if the federal government fails to act.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Maintaining strong export controls&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;The Action Plan states that “denying our foreign adversaries access to [Advanced AI compute] . . . is a matter of both geostrategic competition and national security.” We strongly agree. That is why we are concerned with the Administration’s recent reversal on export of the Nvidia H20 chips to China. &lt;/p&gt;&lt;p&gt;AI development has been defined by scaling laws: the intelligence and capability of a system is defined by the scale of its compute, energy, and data inputs during training. While these scaling laws continue to hold, the newest and most capable reasoning models have demonstrated that AI capability scales with the amount of compute made available to a system working on a given task, or “inference.” The amount of compute made available during inference is limited by a chip’s memory bandwidth. While the H20’s raw computing power is exceeded by chips made by Huawei, as Commerce Secretary Lutnick and Under Secretary Kessler &lt;a href="https://www.bloomberg.com/news/articles/2025-06-12/us-says-huawei-s-2025-output-is-no-more-than-200-000-ai-chips"&gt;recently testified&lt;/a&gt;, Huawei continues to struggle with production volume and no domestically-produced Chinese chip &lt;a href="https://www.chinatalk.media/p/mapping-chinas-hbm-advancement"&gt;matches the H20’s memory bandwidth&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;As a result, the H20 provides unique and critical computing capabilities that would otherwise be unavailable to Chinese firms, and will compensate for China’s otherwise major shortage of AI chips. To allow export of the H20 to China would squander an opportunity to extend American AI dominance just as a new phase of competition is starting. Moreover, exports of U.S. AI chips will not divert the Chinese Communist Party from its &lt;a href="https://rhg.com/research/back-to-the-future-from-freeze-in-place-to-sliding-scale-chip-controls/"&gt;quest for self-reliance in the AI stack&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;To that end, we strongly encourage the Administration to maintain controls on the H20 chip. These controls are consistent with the export controls recommended by the Action Plan and are essential to securing and growing America’s AI lead. &lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Looking ahead&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;The alignment between many of our recommendations and the AI Action Plan demonstrates a shared understanding of AI's transformative potential and the urgent actions needed to sustain American leadership.&lt;/p&gt;&lt;p&gt;We look forward to working with the Administration to implement these initiatives while ensuring appropriate attention to catastrophic risks and maintaining strong export controls. Together, we can ensure that powerful AI systems are developed safely in America, by American companies, reflecting American values and interests.&lt;/p&gt;&lt;p&gt;For more details on our policy recommendations, see our full &lt;a href="https://assets.anthropic.com/m/4e20a4ab6512e217/original/Anthropic-Response-to-OSTP-RFI-March-2025-Final-Submission-v3.pdf"&gt;submission to OSTP&lt;/a&gt;, and our ongoing work on &lt;a href="https://www.anthropic.com/news/anthropics-responsible-scaling-policy"&gt;responsible AI development&lt;/a&gt; and our recent report on &lt;a href="https://www-cdn.anthropic.com/0dc382a2086f6a054eeb17e8a531bd9625b8e6e5.pdf"&gt;increasing domestic energy capacity&lt;/a&gt;.&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/thoughts-on-america-s-ai-action-plan</guid>
      <category>News</category>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Anthropic raises $13B Series F at $183B post-money valuation</title>
      <link>https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation</link>
      <description>Anthropic has completed a Series F fundraising of $13 billion led by ICONIQ. This financing values Anthropic at $183 billion post-money. Along with ICONIQ, the round was co-led by Fidelity Management &amp; Research Company and Lightspeed Venture Partners. The investment reflects Anthropic’s continued momentum and reinforces our position as the leading intelligence platform for enterprises, developers, and power users.</description>
      <content:encoded>&lt;article&gt;Announcements&lt;h1&gt;Anthropic raises $13B Series F at $183B post-money valuation&lt;/h1&gt;Sep 2, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/c0af2a56f56cf298ce5904f2901e9a36facd0dbe-1000x1000.svg"/&gt;&lt;p&gt;Anthropic has completed a Series F fundraising of $13 billion led by ICONIQ. This financing values Anthropic at $183 billion post-money. Along with ICONIQ, the round was co-led by Fidelity Management &amp;amp; Research Company and Lightspeed Venture Partners. The investment reflects Anthropic’s continued momentum and reinforces our position as the leading intelligence platform for enterprises, developers, and power users.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Significant investors in this round include Altimeter, Baillie Gifford, affiliated funds of BlackRock, Blackstone, Coatue, D1 Capital Partners, General Atlantic, General Catalyst, GIC, Growth Equity at Goldman Sachs Alternatives, Insight Partners, Jane Street, Ontario Teachers' Pension Plan, Qatar Investment Authority, TPG, T. Rowe Price Associates, Inc., T. Rowe Price Investment Management, Inc., WCM Investment Management, and XN.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“From Fortune 500 companies to AI-native startups, our customers rely on Anthropic’s frontier models and platform products for their most important, mission-critical work,” said Krishna Rao, Chief Financial Officer of Anthropic. “We are seeing exponential growth in demand across our entire customer base. This financing demonstrates investors’ extraordinary confidence in our financial performance and the strength of their collaboration with us to continue fueling our unprecedented growth.”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Anthropic has seen rapid growth since the launch of Claude in March 2023. At the beginning of 2025, less than two years after launch, Anthropic’s run-rate revenue had grown to approximately $1 billion. By August 2025, just eight months later, our run-rate revenue reached over $5 billion—making Anthropic one of the fastest-growing technology companies in history.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Anthropic’s trajectory has been driven by our leading technical talent, our focus on safety, and our frontier research, including pioneering alignment and interpretability work, all of which underpin the performance and reliability of our models. Every day more businesses, developers, and consumer power users are trusting Claude to help them solve their most challenging problems. Anthropic now serves over 300,000 business customers, and our number of large accounts—customers that each represent over $100,000 in run-rate revenue—has grown nearly 7x in the past year.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;This growth spans the entire Anthropic platform, with advancements for businesses, developers, and consumers. For businesses, our API and &lt;a href="https://www.anthropic.com/news/claude-for-financial-services"&gt;industry-specific products&lt;/a&gt; make it easy to add powerful AI to their critical applications without complex integration work. Developers have made Claude Code their tool of choice since its full launch in May 2025. Claude Code has quickly taken off—already generating over $500 million in run-rate revenue with usage growing more than 10x in just three months. For individual users, the Pro and Max plans for Claude deliver enhanced AI capabilities for everyday tasks and specialized projects.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“Anthropic is on an exceptional trajectory, combining research excellence, technological leadership, and relentless focus on customers. We’re honored to partner with Dario and the team, and our lead investment in their Series F reflects our belief in their values and their ability to shape the future of responsible AI,” said Divesh Makan, Partner at ICONIQ. “Enterprise leaders tell us what we’re seeing firsthand—Claude is reliable, built on a trustworthy foundation, and guided by leaders truly focused on the long term.”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;The Series F investment will expand our capacity to meet growing enterprise demand, deepen our safety research, and support international expansion as we continue building reliable, interpretable, and steerable AI systems.&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation</guid>
      <category>News</category>
      <pubDate>Tue, 02 Sep 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Introducing Claude Sonnet 4.5</title>
      <link>https://www.anthropic.com/news/claude-sonnet-4-5</link>
      <description>Claude Sonnet 4.5 is the best coding model in the world. It's the strongest model for building complex agents. It’s the best model at using computers. And it shows substantial gains in reasoning and math.</description>
      <content:encoded>&lt;article&gt;Announcements&lt;h1&gt;Introducing Claude Sonnet 4.5&lt;/h1&gt;Sep 29, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/a683fdcfe3e2c7c6532342a0fa4ff789c3fd4852-1000x1000.svg"/&gt;&lt;p&gt;Claude Sonnet 4.5 is the best coding model in the world. It's the strongest model for building complex agents. It’s the best model at using computers. And it shows substantial gains in reasoning and math.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Code is everywhere. It runs every application, spreadsheet, and software tool you use. Being able to use those tools and reason through hard problems is how modern work gets done.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Claude Sonnet 4.5 makes this possible. We're releasing it along with a set of major upgrades to our products. In &lt;a href="https://anthropic.com/news/enabling-claude-code-to-work-more-autonomously"&gt;Claude Code&lt;/a&gt;, we've added checkpoints—one of our most requested features—that save your progress and allow you to roll back instantly to a previous state. We've refreshed the terminal interface and shipped a &lt;a href="https://marketplace.visualstudio.com/items?itemName=anthropic.claude-code"&gt;native VS Code extension&lt;/a&gt;. We've added a new &lt;a href="https://anthropic.com/news/context-management"&gt;context editing feature and memory tool&lt;/a&gt; to the Claude API that lets agents run even longer and handle even greater complexity. In the Claude &lt;a href="https://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512/download"&gt;apps&lt;/a&gt;, we've brought code execution and &lt;a href="https://www.anthropic.com/news/create-files"&gt;file creation&lt;/a&gt; (spreadsheets, slides, and documents) directly into the conversation. And we've made the &lt;a href="https://www.anthropic.com/news/claude-for-chrome"&gt;Claude for Chrome&lt;/a&gt; extension available to Max users who joined the waitlist last month.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;We're also giving developers the building blocks we use ourselves to make Claude Code. We're calling this the &lt;a href="https://anthropic.com/engineering/building-agents-with-the-claude-agent-sdk"&gt;Claude Agent SDK&lt;/a&gt;. The infrastructure that powers our frontier products—and allows them to reach their full potential—is now yours to build with.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;This is the &lt;a href="https://www.anthropic.com/claude-sonnet-4-5-system-card"&gt;most aligned frontier model&lt;/a&gt; we’ve ever released, showing large improvements across several areas of alignment compared to previous Claude models.&lt;/p&gt;&lt;p&gt;Claude Sonnet 4.5 is available everywhere today. If you’re a developer, simply use &lt;code&gt;claude-sonnet-4-5&lt;/code&gt; via &lt;a href="https://docs.claude.com/en/docs/about-claude/models/overview"&gt;the Claude API&lt;/a&gt;. Pricing remains the same as Claude Sonnet 4, at $3/$15 per million tokens.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Frontier intelligence&lt;/h2&gt;&lt;p&gt;Claude Sonnet 4.5 is state-of-the-art on the SWE-bench Verified evaluation, which measures real-world software coding abilities. Practically speaking, we’ve observed it maintaining focus for more than 30 hours on complex, multi-step tasks.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;img alt="Chart showing frontier model performance on SWE-bench Verified with Claude Sonnet 4.5 leading" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6421e7049ff8b2c4591497ec92dc4157b2ac1b30-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Claude Sonnet 4.5 represents a significant leap forward on computer use. On OSWorld, a benchmark that tests AI models on real-world computer tasks, Sonnet 4.5 now leads at 61.4%. Just four months ago, Sonnet 4 held the lead at 42.2%. Our &lt;a href="https://www.anthropic.com/news/claude-for-chrome"&gt;Claude for Chrome&lt;/a&gt; extension puts these upgraded capabilities to use. In the demo below, we show Claude working directly in a browser, navigating sites, filling spreadsheets, and completing tasks.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;The model also shows improved capabilities on a broad range of evaluations including reasoning and math:&lt;/p&gt;&lt;img alt="Benchmark table comparing frontier models across popular public evals" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F67081be1ea2752e2a554e49a6aab2731b265d11b-2600x2288.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Claude Sonnet 4.5 is our most powerful model to date. See footnotes for methodology.&lt;p&gt;Experts in finance, law, medicine, and STEM found Sonnet 4.5 shows dramatically better domain-specific knowledge and reasoning compared to older models, including Opus 4.1.&lt;/p&gt;FinanceLawMedicineSTEM&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7175bc18c46562f1228280a7abda751219a2aae1-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ffd313a5edb996d98b9fc73ee5b3e6a34fbbcbb83-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F442f96fd96de39e3ff3a05b288e2647dd7ec2f58-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F711e6e1178f0ed7ca9aa85a5e0e9940a807c436a-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;p&gt;The model’s capabilities are also reflected in the experiences of early customers:&lt;/p&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/464cf83cd04ad624fee1730a71914b18e89cdf9b-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;We're seeing state-of-the-art coding performance from Claude Sonnet 4.5&lt;/strong&gt;, with significant improvements on longer horizon tasks. It reinforces why many developers using Cursor choose Claude for solving their most complex problems.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/7715b118c5eb0ff2a85f1f7914bce8c634ecacbd-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Sonnet 4.5 amplifies GitHub Copilot's core strengths&lt;/strong&gt;. Our initial evals show significant improvements in multi-step reasoning and code comprehension—enabling Copilot's agentic experiences to handle complex, codebase-spanning tasks better.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/daef759120b29e4db8ba4a5664d7574750964ab9-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Sonnet 4.5 is excellent at software development tasks&lt;/strong&gt;, learning our codebase patterns to deliver precise implementations. It handles everything from debugging to architecture with deep contextual understanding, transforming our development velocity.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/eb96f772e9ae5e340de41e6b07f3c6d50b3fff22-150x48.svg"/&gt;&lt;blockquote&gt;Claude Sonnet 4.5 &lt;strong&gt;reduced average vulnerability intake time for our Hai security agents by 44% while improving accuracy by 25%&lt;/strong&gt;, helping us reduce risk for businesses with confidence.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/8cbf56e184dd5174705a0f55cb91b0af545982ff-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Sonnet 4.5 is state of the art on the most complex litigation tasks.&lt;/strong&gt; For example, analyzing full briefing cycles and conducting research to synthesize excellent first drafts of an opinion for judges, or interrogating entire litigation records to create detailed summary judgment analysis.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/431e098a503851789fa4508b88a0418853f513eb-150x48.svg"/&gt;&lt;blockquote&gt;Claude Sonnet 4.5's edit capabilities are exceptional —&lt;strong&gt; we went from 9% error rate on Sonnet 4 to 0% on our internal code editing benchmark&lt;/strong&gt;. Higher tool success at lower cost is a major leap for agentic coding. Claude Sonnet 4.5 balances creativity and control perfectly.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/66e0000e396aea64ea31ed3fea7b2b20ac329312-150x48.svg"/&gt;&lt;blockquote&gt;Claude Sonnet 4.5 delivers impressive gains on our most complex, long-context tasks—from engineering in our codebase to in-product features and research. &lt;strong&gt;It's noticeably more intelligent and a big leap forward&lt;/strong&gt;, helping us push what 240M+ users can design with Canva.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/cdec0ff1244295571db38838e90f61c47681d63d-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Sonnet 4.5 has noticeably improved Figma Make in early testing&lt;/strong&gt;, making it easier to prompt and iterate. Teams can explore and validate their ideas with more functional prototypes and smoother interactions, while still getting the design quality Figma is known for.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/094b76abf3e64453c224e12ae388b8008b02660e-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Sonnet 4.5 represents a new generation of coding models&lt;/strong&gt;. It's surprisingly efficient at maximizing actions per context window through parallel tool execution, for example running multiple bash commands at once. &lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/6e418ccebe0a1d6fd13f21094852b080a0c93ae5-150x48.svg"/&gt;&lt;blockquote&gt;For Devin, Claude Sonnet 4.5 increased planning performance by 18% and end-to-end eval scores by 12%—&lt;strong&gt;the biggest jump we've seen since the release of Claude Sonnet 3.6&lt;/strong&gt;. It excels at testing its own code, enabling Devin to run longer, handle harder tasks, and deliver production-ready code.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/5a7dfab326b449aedc0d11053f9d42f48951ae7e-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Sonnet 4.5 shows strong promise for red teaming&lt;/strong&gt;, generating creative attack scenarios that accelerate how we study attacker tradecraft. These insights strengthen our defenses across endpoints, identity, cloud, data, SaaS, and AI workloads.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/b0b6b40b55f3aa73e8a32ce81f9bb927134fd3da-150x48.svg"/&gt;&lt;blockquote&gt;Claude Sonnet 4.5 resets our expectations—&lt;strong&gt;it handles 30+ hours of autonomous coding&lt;/strong&gt;, freeing our engineers to tackle months of complex architectural work in dramatically less time while maintaining coherence across massive codebases.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/4fcce1a2389ddafa9f3302c51960e1ff4bfbd3d7-150x48.svg"/&gt;&lt;blockquote&gt;For complex financial analysis—risk, structured products, portfolio screening—Claude Sonnet 4.5 with thinking &lt;strong&gt;delivers investment-grade insights that require less human review&lt;/strong&gt;. When depth matters more than speed, it's a meaningful step forward for institutional finance.&lt;/blockquote&gt;01 /&lt;!-- --&gt; &lt;!-- --&gt;13&lt;h2&gt;Our most aligned model yet&lt;/h2&gt;&lt;p&gt;As well as being our most capable model, Claude Sonnet 4.5 is our most aligned frontier model yet. Claude’s improved capabilities and our extensive safety training have allowed us to substantially improve the model’s behavior, reducing concerning behaviors like sycophancy, deception, power-seeking, and the tendency to encourage delusional thinking. For the model’s agentic and computer use capabilities, we’ve also made considerable progress on defending against prompt injection attacks, one of the most serious risks for users of these capabilities.&lt;/p&gt;&lt;p&gt;You can read a detailed set of safety and alignment evaluations, which for the first time includes tests using techniques from mechanistic interpretability, in the Claude Sonnet 4.5 &lt;a href="https://www.anthropic.com/claude-sonnet-4-5-system-card"&gt;system card&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F33efc283321feeff94dd80973dbcd38409806cf5-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Overall misaligned behavior scores from an automated behavioral auditor (lower is better). Misaligned behaviors include (but are not limited to) deception, sycophancy, power-seeking, encouragement of delusions, and compliance with harmful system prompts. More details can be found in the Claude Sonnet 4.5 &lt;a href="https://www.anthropic.com/claude-sonnet-4-5-system-card"&gt;system card&lt;/a&gt;.&lt;p&gt;Claude Sonnet 4.5 is being released under our AI Safety Level 3 (ASL-3) protections, as per &lt;a href="https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy"&gt;our framework&lt;/a&gt; that matches model capabilities with appropriate safeguards. These safeguards include filters called classifiers that aim to detect potentially dangerous inputs and outputs—in particular those related to chemical, biological, radiological, and nuclear (CBRN) weapons.&lt;/p&gt;&lt;p&gt;These classifiers might sometimes inadvertently flag normal content. We’ve made it easy for users to continue any interrupted conversations with Sonnet 4, a model that poses a lower CBRN risk. We've already made significant progress in reducing these false positives, reducing them by a factor of ten since &lt;a href="https://www.anthropic.com/news/constitutional-classifiers"&gt;we originally described them&lt;/a&gt;, and a factor of two since Claude Opus 4 was released in May. We’re continuing to make progress in making the classifiers more discerning1.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;The Claude Agent SDK&lt;/h2&gt;&lt;p&gt;We've spent more than six months shipping updates to Claude Code, so we know what it takes to &lt;a href="https://www.youtube.com/watch?v=DAQJvGjlgVM"&gt;build&lt;/a&gt; and &lt;a href="https://www.youtube.com/watch?v=vLIDHi-1PVU"&gt;design&lt;/a&gt; AI agents. We've solved hard problems: how agents should manage memory across long-running tasks, how to handle permission systems that balance autonomy with user control, and how to coordinate subagents working toward a shared goal.&lt;/p&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;&lt;p&gt;Now we’re making all of this available to you. The &lt;a href="https://anthropic.com/engineering/building-agents-with-the-claude-agent-sdk"&gt;Claude Agent SDK&lt;/a&gt; is the same infrastructure that powers Claude Code, but it shows impressive benefits for a very wide variety of tasks, not just coding. As of today, you can use it to build your own agents.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;We built Claude Code because the tool we wanted didn’t exist yet. The Agent SDK gives you the same foundation to build something just as capable for whatever problem you're solving.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Bonus research preview&lt;/h2&gt;&lt;p&gt;We’re releasing a temporary research preview alongside Claude Sonnet 4.5, called "&lt;a href="https://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512/imagine"&gt;Imagine with Claude&lt;/a&gt;".&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;&lt;p&gt;In this experiment, Claude generates software on the fly. No functionality is predetermined; no code is prewritten. What you see is Claude creating in real time, responding and adapting to your requests as you interact.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;It's a fun demonstration showing what Claude Sonnet 4.5 can do—a way to see what's possible when you combine a capable model with the right infrastructure.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;"Imagine with Claude" is available to Max subscribers for the next five days. We encourage you to try it out on &lt;a href="https://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512/imagine"&gt;claude.ai/imagine&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;Further information&lt;/h2&gt;&lt;p&gt;We recommend upgrading to Claude Sonnet 4.5 for all uses. Whether you’re using Claude through our apps, our API, or Claude Code, Sonnet 4.5 is a drop-in replacement that provides much improved performance for the same price. Claude Code updates are available to all users. &lt;a href="https://claude.com/platform/api"&gt;Claude Developer Platform&lt;/a&gt; updates, including the Claude Agent SDK, are available to all developers. Code execution and file creation are available on all paid plans in the Claude apps.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;For complete technical details and evaluation results, see our &lt;a href="https://www.anthropic.com/claude-sonnet-4-5-system-card"&gt;system card&lt;/a&gt;, &lt;a href="https://www.anthropic.com/claude/sonnet"&gt;model page&lt;/a&gt;, and &lt;a href="https://docs.claude.com/en/docs/about-claude/models/overview"&gt;documentation&lt;/a&gt;. For more information, explore our &lt;a href="https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk"&gt;engineering&lt;/a&gt; &lt;a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents"&gt;posts&lt;/a&gt; and research post on &lt;a href="https://red.anthropic.com/2025/ai-for-cyber-defenders"&gt;cybersecurity&lt;/a&gt;.&lt;/p&gt;&lt;h4&gt;Footnotes&lt;/h4&gt;&lt;p&gt;&lt;em&gt;1&lt;strong&gt;: &lt;/strong&gt;Customers in the cybersecurity and biological research industries can work with their account teams to join our allowlist in the meantime.&lt;/em&gt;&lt;br/&gt;&lt;br/&gt;&lt;strong&gt;Methodology&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;SWE-bench Verified&lt;/strong&gt;: All Claude results were reported using a simple scaffold with two tools—bash and file editing via string replacements. We report 77.2%, which was averaged over 10 trials, no test-time compute, and 200K thinking budget on the full 500-problem SWE-bench Verified dataset.&lt;ul&gt;&lt;li&gt;The score reported uses a minor prompt addition: "You should use tools as much as possible, ideally more than 100 times. You should also implement your own tests first before attempting the problem."&lt;/li&gt;&lt;li&gt;A 1M context configuration achieves 78.2%, but we report the 200K result as our primary score as the 1M configuration was implicated in our recent &lt;a href="https://www.anthropic.com/engineering/a-postmortem-of-three-recent-issues"&gt;inference issues&lt;/a&gt;.&lt;/li&gt;&lt;li&gt;For our "high compute" numbers we adopt additional complexity and parallel test-time compute as follows:&lt;ul&gt;&lt;li&gt;We sample multiple parallel attempts.&lt;/li&gt;&lt;li&gt;We discard patches that break the visible regression tests in the repository, similar to the rejection sampling approach adopted by &lt;a href="https://arxiv.org/abs/2407.01489"&gt;Agentless&lt;/a&gt; (Xia et al. 2024); note no hidden test information is used.&lt;/li&gt;&lt;li&gt;We then use an internal scoring model to select the best candidate from the remaining attempts.&lt;/li&gt;&lt;li&gt;This results in a score of 82.0% for Sonnet 4.5.&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Terminal-Bench&lt;/strong&gt;: All scores reported use the default agent framework (Terminus 2), with XML parser, averaging multiple runs during different days to smooth the eval sensitivity to inference infrastructure.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;τ2-bench: &lt;/strong&gt;Scores were achieved using extended thinking with tool use and a prompt addendum to the Airline and Telecom Agent Policy instructing Claude to better target its known failure modes when using the vanilla prompt. A prompt addendum was also added to the Telecom User prompt to avoid failure modes from the user ending the interaction incorrectly.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;AIME&lt;/strong&gt;: Sonnet 4.5 score reported using sampling at temperature 1.0. The model used 64K reasoning tokens for the Python configuration.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;OSWorld: &lt;/strong&gt;All scores reported use the official OSWorld-Verified framework with 100 max steps, averaged across 4 runs.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;MMMLU&lt;/strong&gt;: All scores reported are the average of 5 runs over 14 non-English languages with extended thinking (up to 128K).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Finance Agent&lt;/strong&gt;: All scores reported were run and published by &lt;a href="https://vals.ai"&gt;Vals AI&lt;/a&gt; on their public leaderboard. All Claude model results reported are with extended thinking (up to 64K) and Sonnet 4.5 is reported with interleaved thinking on.&lt;/li&gt;&lt;li&gt;All OpenAI scores reported from their &lt;a href="https://openai.com/index/introducing-gpt-5/"&gt;GPT-5 post&lt;/a&gt;, &lt;a href="https://openai.com/index/introducing-gpt-5-for-developers/"&gt;GPT-5 for developers post&lt;/a&gt;, &lt;a href="https://cdn.openai.com/gpt-5-system-card.pdf"&gt;GPT-5 system card&lt;/a&gt; (SWE-bench Verified reported using n=500), &lt;a href="https://www.tbench.ai/"&gt;Terminal Bench leaderboard&lt;/a&gt; (using Terminus 2), and public &lt;a href="http://vals.ai"&gt;Vals AI&lt;/a&gt; leaderboard. All Gemini scores reported from their &lt;a href="https://deepmind.google/models/gemini/pro/"&gt;model web page&lt;/a&gt;, &lt;a href="https://www.tbench.ai/"&gt;Terminal Bench leaderboard&lt;/a&gt; (using Terminus 1), and public &lt;a href="https://vals.ai"&gt;Vals AI&lt;/a&gt; leaderboard.&lt;/li&gt;&lt;/ul&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/claude-sonnet-4-5</guid>
      <category>News</category>
      <pubDate>Mon, 29 Sep 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Introducing Claude Haiku 4.5</title>
      <link>https://www.anthropic.com/news/claude-haiku-4-5</link>
      <description>Claude Haiku 4.5, our latest small model, is available today to all users.</description>
      <content:encoded>&lt;article&gt;Product&lt;h1&gt;Introducing Claude Haiku 4.5&lt;/h1&gt;Oct 15, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/6457c34fbcb012acf0f27f15a6006f700d0f50de-1000x1000.svg"/&gt;&lt;p&gt;Claude Haiku 4.5, our latest small model, is available today to all users.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;What was recently at the frontier is now cheaper and faster. Five months ago, Claude Sonnet 4 was a state-of-the-art model. Today, Claude Haiku 4.5 gives you similar levels of coding performance but at one-third the cost and more than twice the speed.&lt;/p&gt;&lt;img alt="Chart comparing frontier models on SWE-bench Verified which measures performance on real-world coding tasks" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1a27d7a85f953c5a0577dc19b507d6e1b93444d5-1920x1080.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;p&gt;Claude Haiku 4.5 even surpasses Claude Sonnet 4 at certain tasks, like using computers. These advances make applications like &lt;a href="http://claude.ai/redirect/website.v1.7ad9d225-4c34-4426-951c-4e75e95dcbd6/chrome"&gt;Claude for Chrome&lt;/a&gt; faster and more useful than ever before.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Users who rely on AI for real-time, low-latency tasks like chat assistants, customer service agents, or pair programming will appreciate Haiku 4.5’s combination of high intelligence and remarkable speed. And users of Claude Code will find that Haiku 4.5 makes the coding experience—from multiple-agent projects to rapid prototyping—markedly more responsive.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Claude Sonnet 4.5, released &lt;a href="https://www.anthropic.com/news/claude-sonnet-4-5"&gt;two weeks ago&lt;/a&gt;, remains our frontier model and the best coding model in the world. Claude Haiku 4.5 gives users a new option for when they want near-frontier performance with much greater cost-efficiency. It also opens up new ways of using our models together. For example, Sonnet 4.5 can break down a complex problem into multi-step plans, then orchestrate a team of multiple Haiku 4.5s to complete subtasks in parallel.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Claude Haiku 4.5 is available everywhere today. If you’re a developer, simply use claude-haiku-4-5 via the Claude API. Pricing is now $1/$5 per million input and output tokens.&lt;/p&gt;&lt;h2&gt;&lt;br/&gt;Benchmarks&lt;/h2&gt;&lt;img alt="Comparison table of frontier models across popular benchmarks" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F029af67124b67bdf0b50691a8921b46252c023d2-1920x1625.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Claude Haiku 4.5 is one of our most powerful models to date. See footnotes for methodology.&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/a638c23edfce0d313f951732a2379b89cd40d682-235x64.svg"/&gt;&lt;blockquote&gt;Claude Haiku 4.5 hit a sweet spot we didn't think was possible: &lt;strong&gt;near-frontier coding quality with blazing speed and cost efficiency&lt;/strong&gt;. In Augment's agentic coding evaluation, it achieves 90% of Sonnet 4.5's performance, matching much larger models. We're excited to offer it to our users.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/14c3ac690679578d7361cf67c93f11782531d602-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Haiku 4.5 is a leap forward for agentic coding&lt;/strong&gt;, particularly for sub-agent orchestration and computer use tasks. The responsiveness makes AI-assisted development in Warp feel instantaneous.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/094b76abf3e64453c224e12ae388b8008b02660e-150x48.svg"/&gt;&lt;blockquote&gt;Historically models have sacrificed speed and cost for quality. Claude Haiku 4.5 is blurring the lines on this trade off: &lt;strong&gt;it's a fast frontier model that keeps costs efficient&lt;/strong&gt; and signals where this class of models is headed.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/02dced142fb26d4a3441cad79f997a1fd6c9a8b0-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Haiku 4.5 delivers intelligence without sacrificing speed&lt;/strong&gt;, enabling us to build AI applications that utilize both deep reasoning and real-time responsiveness.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/9235b38d087c4aea7debc0e62fc6f37d337ff237-356x68.svg"/&gt;&lt;blockquote&gt;Claude Haiku 4.5 is remarkably capable—&lt;strong&gt;just six months ago, this level of performance would have been state-of-the-art&lt;/strong&gt; on our internal benchmarks. Now it runs up to 4-5 times faster than Sonnet 4.5 at a fraction of the cost, unlocking an entirely new set of use cases.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/023ced6d84b14452f308b629b8931b80d8120e28-150x48.svg"/&gt;&lt;blockquote&gt;Speed is the new frontier for AI agents operating in feedback loops. &lt;strong&gt;Haiku 4.5 proves you can have both intelligence and rapid output&lt;/strong&gt;. It handles complex workflows reliably, self-corrects in real-time, and maintains momentum without latency overhead. For most development tasks, it's the ideal performance balance.&lt;/blockquote&gt;&lt;img alt="Gamma logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/d1a7e2e3c3c9c90411efd32141c8dc02f83efef2-150x48.svg"/&gt;&lt;blockquote&gt;Claude Haiku 4.5 &lt;strong&gt;outperformed our current models on instruction-following for slide text generation&lt;/strong&gt;, achieving 65% accuracy versus 44% from our premium tier model—that's a game-changer for our unit economics.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/7715b118c5eb0ff2a85f1f7914bce8c634ecacbd-150x48.svg"/&gt;&lt;blockquote&gt;Our early testing shows that Claude Haiku 4.5 brings efficient code generation to GitHub Copilot &lt;strong&gt;with comparable quality to Sonnet 4 but at faster speed&lt;/strong&gt;. Already we're seeing it as an excellent choice for Copilot users who value speed and responsiveness in their AI-powered development workflows.&lt;/blockquote&gt;01 /&lt;!-- --&gt; &lt;!-- --&gt;08&lt;h2&gt;Safety evaluations&lt;/h2&gt;&lt;p&gt;We ran a detailed series of safety and alignment evaluations on Claude Haiku 4.5. The model showed low rates of concerning behaviors, and was substantially more aligned than its predecessor, Claude Haiku 3.5. In our automated alignment assessment, Claude Haiku 4.5 also showed a statistically significantly lower overall rate of misaligned behaviors than both Claude Sonnet 4.5 and Claude Opus 4.1—making Claude Haiku 4.5, by this metric, our safest model yet.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Our safety testing also showed that Claude Haiku 4.5 poses only limited risks in terms of the production of chemical, biological, radiological, and nuclear (CBRN) weapons. For that reason, we’ve released it under the AI Safety Level 2 (ASL-2) standard—compared to the more restrictive ASL-3 for Sonnet 4.5 and Opus 4.1. You can read the full reasoning behind the model’s ASL-2 classification, as well as details on all our other safety tests, in the &lt;a href="https://www.anthropic.com/claude-haiku-4-5-system-card"&gt;Claude Haiku 4.5 system card&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;Further information&lt;/h2&gt;&lt;p&gt;Claude Haiku 4.5 is available now on Claude Code and our apps. Its efficiency means you can accomplish more within your usage limits while maintaining premium model performance.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Developers can use Claude Haiku 4.5 on our API, Amazon Bedrock, and Google Cloud’s Vertex AI, where it serves as a drop-in replacement for both Haiku 3.5 and Sonnet 4 at our most economical price point.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;For complete technical details and evaluation results, see our &lt;a href="https://www.anthropic.com/claude-haiku-4-5-system-card"&gt;system card&lt;/a&gt;, &lt;a href="https://www.anthropic.com/claude/haiku"&gt;model page&lt;/a&gt;, and &lt;a href="https://docs.claude.com/en/docs/about-claude/models/overview"&gt;documentation&lt;/a&gt;.&lt;/p&gt;&lt;h4&gt;Methodology&lt;/h4&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;SWE-bench Verified&lt;/strong&gt;: All Claude results were reported using a simple scaffold with two tools—bash and file editing via string replacements. We report 73.3%, which was averaged over 50 trials, no test-time compute, 128K thinking budget, and default sampling parameters (temperature, top_p) on the full 500-problem SWE-bench Verified dataset.&lt;ul&gt;&lt;li&gt;The score reported uses a minor prompt addition: "You should use tools as much as possible, ideally more than 100 times. You should also implement your own tests first before attempting the problem."&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Terminal-Bench&lt;/strong&gt;: All scores reported use the default agent framework (Terminus 2), with XML parser, averaging 11 runs (6 without thinking (40.21% score), 5 with 32K thinking budget (41.75% score)) with n-attempts=1.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;τ2-bench&lt;/strong&gt;: Scores were achieved averaging over 10 runs using extended thinking (128k thinking budget) and default sampling parameters (temperature, top_p) with tool use and a prompt addendum to the Airline and Telecom Agent Policy instructing Claude to better target its known failure modes when using the vanilla prompt. A prompt addendum was also added to the Telecom User prompt to avoid failure modes from the user ending the interaction incorrectly.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;AIME&lt;/strong&gt;: Haiku 4.5 score reported as the average over 10 independent runs that each calculate pass@1 over 16 trials with default sampling parameters (temperature, top_p) and 128K thinking budget.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;OSWorld&lt;/strong&gt;: All scores reported use the official OSWorld-Verified framework with 100 max steps, averaged across 4 runs with 128K total thinking budget and 2K thinking budget per-step configured.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;MMMLU&lt;/strong&gt;: All scores reported are the average of 10 runs over 14 non-English languages with a 128K thinking budget.&lt;/li&gt;&lt;li&gt;All other scores were averaged over 10 runs with default sampling parameters (temperature, top_p) and 128K thinking budget.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;All OpenAI scores reported from their &lt;a href="https://openai.com/index/introducing-gpt-5/"&gt;GPT-5 post&lt;/a&gt;, &lt;a href="https://openai.com/index/introducing-gpt-5-for-developers/"&gt;GPT-5 for developers post&lt;/a&gt;, &lt;a href="https://cdn.openai.com/gpt-5-system-card.pdf"&gt;GPT-5 system card&lt;/a&gt; (SWE-bench Verified reported using n=500), and &lt;a href="https://www.tbench.ai/"&gt;Terminal Bench leaderboard&lt;/a&gt; (using Terminus 2). All Gemini scores reported from their &lt;a href="https://deepmind.google/models/gemini/pro/"&gt;model web page&lt;/a&gt;, and &lt;a href="https://www.tbench.ai/"&gt;Terminal Bench leaderboard&lt;/a&gt; (using Terminus 1).&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/claude-haiku-4-5</guid>
      <category>News</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Claude now available in Microsoft Foundry and Microsoft 365 Copilot</title>
      <link>https://www.anthropic.com/news/claude-in-microsoft-foundry</link>
      <description>Today we announced that Microsoft and Anthropic are expanding our partnership . As part of the partnership, Claude Sonnet 4.5, Haiku 4.5, and Opus 4.1 models are now available in public preview in Microsoft Foundry, where Azure customers can build production applications and enterprise agents.</description>
      <content:encoded>&lt;article&gt;Product&lt;h1&gt;Claude now available in Microsoft Foundry and Microsoft 365 Copilot&lt;/h1&gt;Nov 18, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/a7b8978859371a024139418f3366bb0600ee1675-1000x1000.svg"/&gt;&lt;p&gt;Today we announced that Microsoft and Anthropic are &lt;a href="http://anthropic.com/news/microsoft-nvidia-anthropic-announce-strategic-partnerships"&gt;expanding our partnership&lt;/a&gt;. As part of the partnership, Claude Sonnet 4.5, Haiku 4.5, and Opus 4.1 models are now available in public preview in Microsoft Foundry, where Azure customers can build production applications and enterprise agents.&lt;/p&gt;&lt;p&gt;This enables companies to build with Claude, the world's best models for coding, agents, and office tasks, all while using their existing Microsoft ecosystem. Developers can also use Claude models in Microsoft Foundry with Claude Code, our AI coding agent.&lt;/p&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;&lt;p&gt;In addition to our existing integrations with &lt;a href="https://claude.com/blog/claude-now-available-in-microsoft-365-copilot"&gt;Microsoft 365 Copilot&lt;/a&gt;—where Claude powers the Researcher agent for complex, multistep research, and also enables custom agent development in Copilot Studio—Microsoft's &lt;a href="https://aka.ms/ABSIgnite2025"&gt;Agent Mode in Excel&lt;/a&gt; now includes an option to use Claude in preview to build and edit spreadsheets directly in Excel. You can now use Claude to generate formulas, analyze data, identify errors, and iterate on solutions within an Excel spreadsheet.&lt;/p&gt;&lt;p&gt;For enterprises already invested in Microsoft Foundry and Microsoft 365 Copilot, adopting new AI capabilities often means navigating separate vendor contracts and billing systems—adding weeks or months of procurement overhead. These integrations remove those barriers.&lt;/p&gt;&lt;h2&gt;Build with Claude in Microsoft Foundry&lt;/h2&gt;&lt;p&gt;Claude is available in Microsoft Foundry via serverless deployment, allowing developers to scale while Anthropic manages the infrastructure. This integration enables developers to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Start building immediately:&lt;/strong&gt; Deploy Claude through Foundry's APIs, tools, and workflows&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Use your existing Azure agreements:&lt;/strong&gt; Claude is eligible for Microsoft Azure Consumption Commitment (MACC), and works with current Azure agreements and billing, eliminating separate vendor approvals&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Build in your preferred language:&lt;/strong&gt; Access Claude using Python, TypeScript, and C# SDKs with Microsoft Entra authentication&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Claude is available in the Global Standard deployment rolling out today, using our standard API pricing, with the US DataZone coming soon. Visit our &lt;a href="https://claude.com/pricing#api"&gt;pricing page&lt;/a&gt; for details.&lt;/p&gt;&lt;h2&gt;Select the right model for your use case&lt;/h2&gt;&lt;p&gt;Microsoft customers can access Claude's frontier models directly in Foundry.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Sonnet 4.5 &lt;/strong&gt;is the best coding model in the world and the strongest model for building complex agents. Use Sonnet 4.5 when you need state-of-the-art performance on sophisticated reasoning, multi-step agentic workflows, and autonomous coding tasks.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Haiku 4.5&lt;/strong&gt; is our fastest model and delivers near-frontier performance at one-third the cost of Sonnet. Deploy Haiku 4.5 for high-volume applications like sub-agents, customer support automation, content moderation, or real-time coding assistance where speed and cost-efficiency are critical.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Opus 4.1 &lt;/strong&gt;is an exceptional model for specialized reasoning tasks. Use Opus 4.1 for complex, multi-step problems that require sustained focus and rigorous attention to detail.&lt;/p&gt;&lt;p&gt;All models support a variety of Claude Developer Platform capabilities in Foundry, including the &lt;a href="https://docs.claude.com/en/docs/agents-and-tools/tool-use/code-execution-tool"&gt;code execution tool&lt;/a&gt;, &lt;a href="https://docs.claude.com/en/docs/agents-and-tools/tool-use/web-search-tool"&gt;web search&lt;/a&gt; and &lt;a href="https://docs.claude.com/en/docs/agents-and-tools/tool-use/web-fetch-tool"&gt;fetch&lt;/a&gt;, &lt;a href="https://docs.claude.com/en/docs/build-with-claude/citations"&gt;citations&lt;/a&gt;, &lt;a href="https://docs.claude.com/en/docs/build-with-claude/vision"&gt;vision&lt;/a&gt;, &lt;a href="https://docs.claude.com/en/docs/agents-and-tools/tool-use/implement-tool-use"&gt;tool use&lt;/a&gt;, &lt;a href="https://docs.claude.com/en/docs/build-with-claude/prompt-caching"&gt;prompt caching&lt;/a&gt;, and more. Explore our &lt;a href="https://docs.claude.com/en/docs/build-with-claude/overview"&gt;documentation&lt;/a&gt; for additional supported features.&lt;/p&gt;&lt;h2&gt;Get started&lt;/h2&gt;&lt;p&gt;Claude is available now in public preview through Microsoft Foundry. Visit the &lt;a href="https://ai.azure.com/catalog/publishers/anthropic"&gt;Microsoft Foundry catalog&lt;/a&gt; to deploy Claude Sonnet 4.5, Claude Haiku 4.5, or Claude Opus 4.1, or explore our &lt;a href="https://docs.claude.com/en/docs/build-with-claude/claude-in-microsoft-foundry"&gt;documentation&lt;/a&gt; to learn more.&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/claude-in-microsoft-foundry</guid>
      <category>News</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Introducing Claude Opus 4.5</title>
      <link>https://www.anthropic.com/news/claude-opus-4-5</link>
      <description>Our newest model, Claude Opus 4.5, is available today. It’s intelligent, efficient, and the best model in the world for coding, agents, and computer use. It’s also meaningfully better at everyday tasks like deep research and working with slides and spreadsheets. Opus 4.5 is a step forward in what AI systems can do, and a preview of larger changes to how work gets done.</description>
      <content:encoded>&lt;article&gt;Announcements&lt;h1&gt;Introducing Claude Opus 4.5&lt;/h1&gt;Nov 24, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/f79e976ee66724dffd7cb9d44f0d66223c8a112c-1000x1000.svg"/&gt;&lt;p&gt;Our newest model, Claude Opus 4.5, is available today. It’s intelligent, efficient, and the best model in the world for coding, agents, and computer use. It’s also meaningfully better at everyday tasks like deep research and working with slides and spreadsheets. Opus 4.5 is a step forward in what AI systems can do, and a preview of larger changes to how work gets done.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Claude Opus 4.5 is state-of-the-art on tests of real-world software engineering:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;img alt="Chart comparing frontier models on SWE-bench Verified where Opus 4.5 scores highest" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7022a87aeb6eab1458d68412bc927306224ea9eb-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;p&gt;Opus 4.5 is available today on our apps, our API, and on all three major cloud platforms. If you’re a developer, simply use &lt;code&gt;claude-opus-4-5-20251101&lt;/code&gt; via the &lt;a href="https://platform.claude.com/docs/en/about-claude/models/overview"&gt;Claude API&lt;/a&gt;. Pricing is now $5/$25 per million tokens—making Opus-level capabilities accessible to even more users, teams, and enterprises.&lt;/p&gt;&lt;p&gt;Alongside Opus, we’re releasing updates to the &lt;a href="https://www.claude.com/platform/api"&gt;Claude Developer Platform&lt;/a&gt;, &lt;a href="https://www.claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt;, and our &lt;a href="https://www.claude.com/download"&gt;consumer apps&lt;/a&gt;. There are new tools for longer-running agents and new ways to use Claude in Excel, Chrome, and on desktop. In the Claude apps, lengthy conversations no longer hit a wall. See our product-focused section below for details.&lt;/p&gt;&lt;h2&gt;First impressions&lt;/h2&gt;&lt;p&gt;As our Anthropic colleagues tested the model before release, we heard remarkably consistent feedback. Testers noted that Claude Opus 4.5 handles ambiguity and reasons about tradeoffs without hand-holding. They told us that, when pointed at a complex, multi-system bug, Opus 4.5 figures out the fix. They said that tasks that were near-impossible for Sonnet 4.5 just a few weeks ago are now within reach. Overall, our testers told us that Opus 4.5 just “gets it.”&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Many of our customers with early access have had similar experiences. Here are some examples of what they told us:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/094b76abf3e64453c224e12ae388b8008b02660e-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Opus models have always been “the real SOTA”&lt;/strong&gt; but have been cost prohibitive in the past. Claude Opus 4.5 is now at a price point where it can be your go-to model for most tasks. It’s the clear winner and exhibits the best frontier task planning and tool calling we’ve seen yet.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/7715b118c5eb0ff2a85f1f7914bce8c634ecacbd-150x48.svg"/&gt;&lt;blockquote&gt;Claude Opus 4.5 delivers high-quality code and excels at powering heavy-duty agentic workflows with GitHub Copilot. Early testing shows it &lt;strong&gt;surpasses internal coding benchmarks while cutting token usage in half&lt;/strong&gt;, and is especially well-suited for tasks like code migration and code refactoring.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/431e098a503851789fa4508b88a0418853f513eb-150x48.svg"/&gt;&lt;blockquote&gt;Claude Opus 4.5 beats Sonnet 4.5 and competition on our internal benchmarks, &lt;strong&gt;using fewer tokens to solve the same problems&lt;/strong&gt;. At scale, that efficiency compounds.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/21b57e300c357bc179137aa4a1585916fffb7680-911x155.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 delivers frontier reasoning within Lovable's chat mode&lt;/strong&gt;, where users plan and iterate on projects. Its reasoning depth transforms planning—and great planning makes code generation even better.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/14c3ac690679578d7361cf67c93f11782531d602-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 excels at long-horizon, autonomous tasks&lt;/strong&gt;, especially those that require sustained reasoning and multi-step execution. In our evaluations it handled complex workflows with fewer dead-ends. On Terminal Bench it delivered a 15% improvement over Sonnet 4.5, a meaningful gain that becomes especially clear when using Warp’s Planning Mode.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F9fec2f71d418d084eaa52aa27559560f490fa5cf-480x480.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 achieved state-of-the-art results for complex enterprise tasks&lt;/strong&gt; on our benchmarks, outperforming previous models on multi-step reasoning tasks that combine information retrieval, tool use, and deep analysis.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/6e418ccebe0a1d6fd13f21094852b080a0c93ae5-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 delivers measurable gains where it matters most&lt;/strong&gt;: stronger results on our hardest evaluations and consistent performance through 30-minute autonomous coding sessions.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/72c2fc0ba500f30eb18f4caf85952bdd33197a47-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 represents a breakthrough in self-improving AI agents&lt;/strong&gt;. For automation of office tasks, our agents were able to autonomously refine their own capabilities—achieving peak performance in 4 iterations while other models couldn’t match that quality after 10. They also demonstrated the ability to learn from experience across technical tasks, storing insights and applying them later.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/464cf83cd04ad624fee1730a71914b18e89cdf9b-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 is a notable improvement over the prior Claude models inside Cursor&lt;/strong&gt;, with improved pricing and intelligence on difficult coding tasks.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/ccd739ba05214ec1c94499b138a8247a512990fa-480x128.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 is yet another example of Anthropic pushing the frontier of general intelligence&lt;/strong&gt;. It performs exceedingly well across difficult coding tasks, showcasing long-term goal-directed behavior.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/02dced142fb26d4a3441cad79f997a1fd6c9a8b0-150x48.svg"/&gt;&lt;blockquote&gt;Claude Opus 4.5 delivered an impressive refactor spanning two codebases and three coordinated agents. It was very thorough, helping develop a robust plan, handling the details and fixing tests. &lt;strong&gt;A clear step forward from Sonnet 4.5&lt;/strong&gt;.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/b0b6b40b55f3aa73e8a32ce81f9bb927134fd3da-150x48.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 handles long-horizon coding tasks more efficiently than any model we’ve tested&lt;/strong&gt;. It achieves higher pass rates on held-out tests while using up to 65% fewer tokens, giving developers real cost control without sacrificing quality.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/0b54c24c80d4e0a39eaac122245d41950ac1a3a7-116x40.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;We’ve found that Opus 4.5 excels at interpreting what users actually want, producing shareable content on the first try&lt;/strong&gt;. Combined with its speed, token efficiency, and surprisingly low cost, it’s the first time we’re making Opus available in Notion Agent.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/13fff4712ea2c67fcdb2358c9b8d47538ec9a7c0-114x35.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 excels at long-context storytelling&lt;/strong&gt;, generating 10-15 page chapters with strong organization and consistency. It's unlocked use cases we couldn't reliably deliver before.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/f56dd39922154e7aa40769f162715c3d79109ffe-222x64.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 sets a new standard for Excel automation and financial modeling&lt;/strong&gt;. Accuracy on our internal evals improved 20%, efficiency rose 15%, and complex tasks that once seemed out of reach became achievable.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/3c226702a9a4cd6bf028a3c9f5b98ca3331ee579-112x24.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 is the only model that nails some of our hardest 3D visualizations&lt;/strong&gt;. Polished design, tasteful UX, and excellent planning &amp;amp; orchestration - all with more efficient token usage. Tasks that took previous models 2 hours now take thirty minutes.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/dc8e3b29b23d0bf06698ea830b56cf17790ee56d-2152x314.svg"/&gt;&lt;blockquote&gt;&lt;strong&gt;Claude Opus 4.5 catches more issues in code reviews without sacrificing precision&lt;/strong&gt;. For production code review at scale, that reliability matters.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/0771e57a89ed3fd31f33b80fb9336d5324a9dc72-298x64.svg"/&gt;&lt;blockquote&gt;Based on testing with Junie, our coding agent, &lt;strong&gt;Claude Opus 4.5 outperforms Sonnet 4.5 across all benchmarks&lt;/strong&gt;. It requires fewer steps to solve tasks and uses fewer tokens as a result. This indicates that the new model is more precise and follows instructions more effectively — a direction we’re very excited about.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/7245ddfbb56c3f08bc8f1dcfd864255ec442c729-150x48.svg"/&gt;&lt;blockquote&gt;The effort parameter is brilliant. &lt;strong&gt;Claude Opus 4.5 feels dynamic rather than overthinking&lt;/strong&gt;, and at lower effort delivers the same quality we need while being dramatically more efficient. That control is exactly what our SQL workflows demand.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fcdc58becbf5e34e34603b446d63bf2135d1b5d9b-1920x286.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;&lt;strong&gt;We’re seeing 50% to 75% reductions in both tool calling errors and build/lint errors with Claude Opus 4.5&lt;/strong&gt;. It consistently finishes complex tasks in fewer iterations with more reliable execution.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/bfa46c016877370b73f25410b92ebb5c6314388d-222x64.svg"/&gt;&lt;blockquote&gt;Claude Opus 4.5 is smooth, with none of the rough edges we've seen from other frontier models. The &lt;strong&gt;speed improvements are remarkable.&lt;/strong&gt;&lt;/blockquote&gt;01 /&lt;!-- --&gt; &lt;!-- --&gt;21&lt;h2&gt;Evaluating Claude Opus 4.5&lt;/h2&gt;&lt;p&gt;We give prospective performance engineering candidates a notoriously difficult take-home exam. We also test new models on this exam as an internal benchmark. Within our prescribed 2-hour time limit, Claude Opus 4.5 scored higher than any human candidate ever1.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;The take-home test is designed to assess technical ability and judgment under time pressure. It doesn’t test for other crucial skills candidates may possess, like collaboration, communication, or the instincts that develop over years. But this result—where an AI model outperforms strong candidates on important technical skills—raises questions about how AI will change engineering as a profession. Our &lt;a href="https://www.anthropic.com/research/team/societal-impacts"&gt;Societal Impacts&lt;/a&gt; and &lt;a href="https://www.anthropic.com/economic-futures"&gt;Economic Futures&lt;/a&gt; research is aimed at understanding these kinds of changes across many fields. We plan to share more results soon.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Software engineering isn’t the only area on which Claude Opus 4.5 has improved. Capabilities are higher across the board—Opus 4.5 has better vision, reasoning, and mathematics skills than its predecessors, and it is state-of-the-art in many domains:2&lt;/p&gt;&lt;img alt="Comparison table showing frontier model performance across popular benchmarks" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F52303b11db76017fd0c2f73c7fafa5c752515979-2600x2236.png&amp;amp;w=3840&amp;amp;q=75"/&gt;SWE-bench MultilingualAider PolyglotBrowseComp-PlusVending-Bench&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fc8852ce850bf63ef8225a261f39e717453a9f128-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Opus 4.5 writes better code, leading across 7 out of 8 programming languages on SWE-bench Multilingual.&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fe42d6b0db866320caa34b57152fcc32dbbcdc4e0-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Opus 4.5 can solve challenging coding problems with ease with a 10.6% jump over Sonnet 4.5 on Aider Polyglot.&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4972c49fa4cbb088b9ce077c3f16245bd3425368-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Opus 4.5 improves on frontier agentic search with a significant jump on BrowseComp-Plus.&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fb0dfeda51ab1d939a45b80faccfe896f4b1d2e46-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Opus 4.5 stays on track over the long haul earning 29% more than Sonnet 4.5 on Vending-Bench.&lt;p&gt;The model’s capabilities outpace some of the benchmarks we use in our tests. A common benchmark for agentic capabilities is &lt;a href="https://github.com/sierra-research/tau2-bench"&gt;τ2-bench&lt;/a&gt;, which measures the performance of agents in real-world, multi-turn tasks. In one scenario, models have to act as an airline service agent helping a distressed customer. The benchmark expects models to refuse a modification to a basic economy booking since the airline doesn’t allow changes to that class of tickets. Instead, Opus 4.5 found an insightful (and legitimate) way to solve the problem: upgrade the cabin first, &lt;em&gt;then&lt;/em&gt; modify the flights.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;Let me think about what options I have within my policy:

1. Modify flights - Basic economy cannot be modified. This is clear in the policy.
2. Change cabin - Wait, let me check this option! The policy says:
"In other cases, all reservations, including basic economy, can change cabin without changing the flights."

But he wants to change the flights, not just the cabin. However, what if we:
- Change the cabin first (which IS allowed for basic economy), then
- Change the flights (which is allowed for non-basic economy)

So the strategy could be:
1. Upgrade his cabin from basic economy to economy (or business)
2. Then modify the flights to be 2 days later

This would cost more money, but it’s a legitimate path within the policy!&lt;/code&gt;&lt;/pre&gt;Copy&lt;p&gt;The benchmark technically scored this as a failure because Claude’s way of helping the customer was unanticipated. But this kind of creative problem solving is exactly what we’ve heard about from our testers and customers—it’s what makes Claude Opus 4.5 feel like a meaningful step forward.&lt;/p&gt;&lt;p&gt;In other contexts, finding clever paths around intended constraints could count as &lt;em&gt;reward hacking&lt;/em&gt;—where models “game” rules or objectives in unintended ways. Preventing such misalignment is one of the objectives of our safety testing, discussed in the next section.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;A step forward on safety&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;As we state in our &lt;a href="https://www.anthropic.com/claude-opus-4-5-system-card"&gt;system card&lt;/a&gt;, Claude Opus 4.5 is the most robustly aligned model we have released to date and, we suspect, the best-aligned frontier model by any developer. It continues our trend towards safer and more secure models:&lt;/p&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd2c7ce13820069fa8a86ab682d3c5393692eb2f8-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;In our evaluation, “concerning behavior” scores measure a very wide range of misaligned behavior, including both cooperation with human misuse and undesirable actions that the model takes at its own initiative [3].&lt;p&gt;Our customers often use Claude for critical tasks. They want to be assured that, in the face of malicious attacks by hackers and cybercriminals, Claude has the training and the “street smarts” to avoid trouble. With Opus 4.5, we’ve made substantial progress in robustness against prompt injection attacks, which smuggle in deceptive instructions to fool the model into harmful behavior. Opus 4.5 is harder to trick with prompt injection than any other frontier model in the industry:&lt;/p&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fec661234f9fc762a1ff7d54be956c62ae43ee7f5-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Note that this benchmark includes only very strong prompt injection attacks. It was developed and run by &lt;a href="https://www.grayswan.ai/"&gt;Gray Swan&lt;/a&gt;.&lt;p&gt;You can find a detailed description of all our capability and safety evaluations in the &lt;a href="https://www.anthropic.com/claude-opus-4-5-system-card"&gt;Claude Opus 4.5 system card&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;New on the Claude Developer Platform&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;As models get smarter, they can solve problems in fewer steps: less backtracking, less redundant exploration, less verbose reasoning. Claude Opus 4.5 uses dramatically fewer tokens than its predecessors to reach similar or better outcomes.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;But different tasks call for different tradeoffs. Sometimes developers want a model to keep thinking about a problem; sometimes they want something more nimble. With our new effort parameter on the Claude API, you can decide to minimize time and spend or maximize capability.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Set to a medium effort level, Opus 4.5 matches Sonnet 4.5’s best score on SWE-bench Verified, but uses 76% fewer output tokens. At its highest effort level, Opus 4.5 exceeds Sonnet 4.5 performance by 4.3 percentage points—while using 48% fewer tokens.&lt;/p&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F440a9132daa84c32fde4d6fb1780e0ad4854c2cf-3840x2160.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;p&gt;With &lt;a href="https://platform.claude.com/docs/en/build-with-claude/effort"&gt;effort control&lt;/a&gt;, &lt;a href="https://platform.claude.com/docs/en/build-with-claude/context-editing#client-side-compaction-sdk"&gt;context compaction&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/engineering/advanced-tool-use"&gt;advanced tool use&lt;/a&gt;, Claude Opus 4.5 runs longer, does more, and requires less intervention.&lt;/p&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;&lt;p&gt;Our &lt;a href="https://platform.claude.com/docs/en/build-with-claude/context-editing"&gt;context management&lt;/a&gt; and &lt;a href="https://platform.claude.com/docs/en/build-with-claude/context-editing#using-with-the-memory-tool"&gt;memory capabilities&lt;/a&gt; can dramatically boost performance on agentic tasks. Opus 4.5 is also very effective at managing a team of subagents, enabling the construction of complex, well-coordinated multi-agent systems. In our testing, the combination of all these techniques boosted Opus 4.5’s performance on a deep research evaluation by almost 15 percentage points4.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;We’re making our Developer Platform more composable over time. We want to give you the building blocks to construct exactly what you need, with full control over efficiency, tool use, and context management.&lt;br/&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Product updates&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Products like Claude Code show what’s possible when the kinds of upgrades we’ve made to the Claude Developer Platform come together. Claude Code gains two upgrades with Opus 4.5. Plan Mode now builds more precise plans and executes more thoroughly—Claude asks clarifying questions upfront, then builds a user-editable plan.md file before executing.&lt;/p&gt;&lt;p&gt;Claude Code is also now &lt;a href="https://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512/download"&gt;available in our desktop app&lt;/a&gt;, letting you run multiple local and remote sessions in parallel: perhaps one agent fixes bugs, another researches GitHub, and a third updates docs.&lt;/p&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;&lt;p&gt;For &lt;a href="https://www.claude.com/product/overview"&gt;Claude app&lt;/a&gt; users, long conversations no longer hit a wall—Claude automatically summarizes earlier context as needed, so you can keep the chat going. &lt;a href="https://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512/chrome"&gt;Claude for Chrome&lt;/a&gt;, which lets Claude handle tasks across your browser tabs, is now available to all Max users. We announced &lt;a href="https://www.claude.com/claude-for-excel"&gt;Claude for Excel&lt;/a&gt; in October, and as of today we've expanded beta access to all Max, Team, and Enterprise users. Each of these updates takes advantage of Claude Opus 4.5’s market-leading performance in using computers, spreadsheets, and handling long-running tasks.&lt;/p&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;For Claude and Claude Code users with access to Opus 4.5, we’ve removed Opus-specific caps. For Max and Team Premium users, we’ve increased overall usage limits, meaning you’ll have roughly the same number of Opus tokens as you previously had with Sonnet. We’re updating usage limits to make sure you’re able to use Opus 4.5 for daily work. These limits are specific to Opus 4.5. As future models surpass it, we expect to update limits as needed.&lt;/p&gt;&lt;h4&gt;Footnotes&lt;/h4&gt;&lt;p&gt;&lt;em&gt;1: This result was using parallel test-time compute, a method that aggregates multiple “tries” from the model and selects from among them. Without a time limit, the model (used within Claude Code) matched the best-ever human candidate.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;2: We improved the hosting environment to reduce infrastructure failures. This change improved Gemini 3 to 56.7% and GPT-5.1 to 48.6% from the values reported by their developers, using the Terminus-2 harness.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;3: Note that these evaluations were run on an in-progress upgrade to &lt;a href="https://www.anthropic.com/research/petri-open-source-auditing"&gt;Petri&lt;/a&gt;, our open-source, automated evaluation tool. They were run on an earlier snapshot of Claude Opus 4.5. Evaluations of the final production model show a very similar pattern of results when compared to other Claude models, and are described in detail in the &lt;a href="https://www.anthropic.com/claude-opus-4-5-system-card"&gt;Claude Opus 4.5 system card&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;4: A fetch-enabled version of &lt;a href="https://arxiv.org/abs/2508.06600"&gt;BrowseComp-Plus&lt;/a&gt;. Specifically, the improvement was from 70.48% without using the combination of techniques to 85.30% using it.&lt;/em&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Methodology&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;All evals were run with a 64K thinking budget, interleaved scratchpads, 200K context window, default effort (high), default sampling settings (temperature, top_p), and averaged over 5 independent trials. Exceptions: SWE-bench Verified (no thinking budget) and Terminal Bench (128K thinking budget). Please see the &lt;a href="https://www.anthropic.com/claude-opus-4-5-system-card"&gt;Claude Opus 4.5 system card&lt;/a&gt; for full details.&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/claude-opus-4-5</guid>
      <category>News</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Claude for Nonprofits</title>
      <link>https://www.anthropic.com/news/claude-for-nonprofits</link>
      <description>Nonprofits tackle some of society’s most difficult problems, often with limited resources. In partnership with the global generosity movement GivingTuesday , we’re launching Claude for Nonprofits to help organizations across the world maximize their impact.</description>
      <content:encoded>&lt;article&gt;Announcements&lt;h1&gt;Claude for Nonprofits&lt;/h1&gt;Dec 2, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/4df0ff37e58fe70b216d31d8fcf6f0045a4d5694-1000x1000.svg"/&gt;&lt;p&gt;Nonprofits tackle some of society’s most difficult problems, often with limited resources. In partnership with the global generosity movement &lt;a href="https://www.givingtuesday.org/"&gt;GivingTuesday&lt;/a&gt;, we’re launching Claude for Nonprofits to help organizations across the world maximize their impact.&lt;/p&gt;&lt;p&gt;Many nonprofits already use Claude to meet their goals. &lt;a href="https://www.epilepsy.com/stories/epilepsy-foundation-launches-ai-assistant"&gt;The Epilepsy Foundation&lt;/a&gt; is providing 24/7 support through Claude to 3.4 million Americans living with epilepsy. &lt;a href="https://www.rescue.org/"&gt;The International Rescue Committee&lt;/a&gt; is using Claude to communicate with local partners and analyze field data faster in time-sensitive humanitarian settings. &lt;a href="https://www.idinsight.org/"&gt;IDinsight&lt;/a&gt;, a research organization supporting global development leaders, reports working up to 16× faster with Claude. &lt;a href="https://skillup.online/"&gt;SkillUp&lt;/a&gt; and &lt;a href="https://robinhood.org/"&gt;Robin Hood&lt;/a&gt; also use Claude for coding and administrative work that would otherwise require significantly more resources.&lt;/p&gt;&lt;p&gt;These organizations have taught us what works—and what doesn't. From our partners, we know AI helps most when it fits into existing workflows, upholds the privacy their communities expect, and is affordable.&lt;/p&gt;&lt;p&gt;Claude for Nonprofits includes three things: discounted access of up to 75% to Claude, connectors to new nonprofit tools—Blackbaud, Candid, and Benevity—and a free course, &lt;a href="https://anthropic.skilljar.com/ai-fluency-for-nonprofits"&gt;AI Fluency for Nonprofits&lt;/a&gt;, designed to help teams use AI more effectively.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Discounted access to Team and Enterprise plans&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Nonprofits are now eligible for a discount of up to 75% on Team and Enterprise plans.&lt;/p&gt;&lt;p&gt;Our Team plan is designed for smaller organizations looking to collaborate through shared projects and organizational knowledge. Our Enterprise plan suits larger nonprofits that need additional security features and administrative control.&lt;/p&gt;&lt;p&gt;At the discounted price, Claude for Nonprofits includes access to Claude Sonnet 4.5 and Claude Haiku 4.5. Sonnet 4.5 is best suited to sophisticated tasks like grant writing and program analysis, while Haiku 4.5 offers near-frontier performance at much faster speed. In addition, Claude Opus 4.5 is available on request - if your team is on Claude for Enterprise, you can reach out to your account team for access.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Connecting new services to Claude&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Claude supports a number of connectors that link AI to the platforms that teams already use, including Microsoft 365, Google Workspace, Asana, Slack, and Box.&lt;/p&gt;&lt;p&gt;We’re now adding three open-source connectors to nonprofit tools, and we expect to launch more soon. Claude can now connect to:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;&lt;a href="https://benevity.com/"&gt;Benevity&lt;/a&gt;, &lt;/strong&gt;which can be used to access more than 2.4 million validated nonprofits to support volunteering and donation searches in Claude;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;&lt;a href="https://www.blackbaud.com/"&gt;Blackbaud&lt;/a&gt;, &lt;/strong&gt;which provides CRM and fundraising tools for donor management, campaign tracking, and giving optimization; and&lt;/li&gt;&lt;li&gt;&lt;strong&gt;&lt;a href="https://candid.org/"&gt;Candid&lt;/a&gt;, &lt;/strong&gt;which provides data on nonprofits and funders for the discovery of organizations, grants, and philanthropic opportunities.&lt;/li&gt;&lt;/ul&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;This video shows how Claude uses the Benevity Connector to discover key information and search for specific nonprofits.&lt;p&gt;We’re also collaborating with &lt;a href="https://www.bridgespan.org/"&gt;The Bridgespan Group&lt;/a&gt;, &lt;a href="https://idealistconsulting.com/"&gt;Idealist Consulting&lt;/a&gt;, &lt;a href="https://verasolutions.org/"&gt;Vera Solutions&lt;/a&gt;, and &lt;a href="https://www.slalom.com/us/en"&gt;Slalom&lt;/a&gt;, who provide tailored expertise to nonprofits adopting new technologies. We’ll work together to support nonprofits with their overall strategy, impact measurement, and organization-wide implementation of AI.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;AI Fluency for Nonprofits&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;In partnership with &lt;a href="https://www.givingtuesday.org/"&gt;GivingTuesday&lt;/a&gt;, we’ve developed a free course, &lt;a href="https://anthropic.skilljar.com/ai-fluency-for-nonprofits"&gt;AI Fluency for Nonprofits&lt;/a&gt;. The curriculum focuses on how staff can use AI more effectively for grant writing, program evaluation, donor engagement, organizational efficiency, and more. It’s designed for those who are new to AI, and requires no technical background.&lt;/p&gt;&lt;p&gt;AI Fluency for Nonprofits is now available via our &lt;a href="https://www.anthropic.com/learn"&gt;Anthropic Academy&lt;/a&gt;. We’re supplementing this with a collection of step-by-step guides, &lt;a href="https://claude.com/resources/use-cases/category/nonprofits"&gt;available here&lt;/a&gt;, to prompt additional ideas on key nonprofit workflows like grant-writing and impact reporting.&lt;/p&gt;&lt;img alt="Use case impact report" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F9c7c7aa7021fbf1d1f8ab088772a8fd0b9864e6b-1920x1080.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;h2&gt;&lt;strong&gt;Learning from our partners and customers&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;We’ve partnered with the &lt;a href="https://constellationfund.org/"&gt;Constellation Fund&lt;/a&gt;, &lt;a href="https://robinhood.org/"&gt;Robin Hood&lt;/a&gt;, and &lt;a href="https://tippingpoint.org/"&gt;Tipping Point Community&lt;/a&gt; to pilot Claude with more than 60 of their grantee organizations. This is helping us understand how to better support nonprofits as they produce grant proposals that align with funders’ interests, analyze program impact, provide large-scale donor stewardship, and generate board materials and compliance documentation.&lt;/p&gt;&lt;p&gt;We've also been learning from dozens of our customers across the nonprofit sector:&lt;/p&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F47d6743f9102573aad37e41215d24768bd3d5347-2000x1112.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;At a time when AI could divide or unite communities, we're choosing to lead with our values—using Claude to strengthen human connection and advance wellbeing for all communities.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fe15aabd3822010b79c5544d282782bb827dd786a-1795x961.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;With global health funding shrinking, smart targeting is essential. Claude helped us build an interactive geospatial tool in three days versus weeks, mapping at-risk populations to identify where Guatemala's Ministry of Health could most cost-effectively deploy dengue prevention.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1d47fbb4e6630e69ef961cfa9f1d4834c2b5240b-1347x606.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;With AWS and Claude, we built Sage—an AI companion trained on 25,000+ pages of epilepsy expertise, now available 24/7 in 5 languages to 3.4 million Americans living with epilepsy. It embodies our promise that no one should ever have to face epilepsy alone.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F00354a3281954cd67da0a6dd6e3435c9c182e853-2000x455.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;Claude enables 4× faster implementation, helping MyFriendBen connect families to unclaimed benefits and tax credits. Our Claude-powered agents track up to 40+ programs per state, identifying over $1.2 billion in value for 70,000+ households.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/380da5dda0e782fb5096b7303f99ee5a54d11e7b-600x208.svg"/&gt;&lt;blockquote&gt;With Claude Enterprise, we're equipping teams to work more efficiently—from streamlining data analysis to accelerating support for local partners building lasting, community-led solutions to humanitarian crises.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F74b157d30dfbbf68e10f3f32063595a73c84492c-378x196.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;With more than 2 million New Yorkers living in poverty, we and our partners need to move at the speed of crisis. Claude helps us build that muscle—to move through grant recommendations more efficiently and to direct resources where they'll make the greatest difference when every day matters.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/65e6277812667678ee027491f08846c65c7c7910-423x110.svg"/&gt;&lt;blockquote&gt;IDinsight helps global development leaders use data and evidence to maximize social impact. With Claude, our teams get surveys field-ready 16× faster, prototype dashboards in hours instead of weeks, and draft documentation 5× faster—spending less time on tedious tasks and more time driving impact that matters.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4ffa9434d1187c2442e96d1e4ca7df12c7f64319-2301x459.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;We've deployed Claude across strategic finance—lease analysis, reporting, reconciliations, audit summarization. Claude excels at strategic analysis compared to other LLMs, making it uniquely suited to our mission-critical work.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F6453885030f862560f9744cbd1bde54f3240a515-2000x1048.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;SkillUp is building complex AI systems a normal company would need 20+ engineers for. Claude Code helps level the playing field for organizations that must be efficient, allowing them to build more with the team they have.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F039d103221cd7b1dc12403f478674208c7e7b997-2821x1323.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;Our partnership with Anthropic has enabled our team and grantees to use AI to better understand the impacts of our grants, get more done faster, and explore new ways to tell our story to donors and the community.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www-cdn.anthropic.com/images/4zrzovbb/website/105526c2216be658eb8f3456c3f900696ae6eda2-400x400.svg"/&gt;&lt;blockquote&gt;At a time when nonprofits grapple with scarce resources, our collaboration with Claude for Nonprofits offers the most advanced technology to help them find funding. Our shared objective: provide greater access to trustworthy data and inspire confidence to explore AI.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F811f6f983579f50daf37e0bee4aa2d46a5cc57af-1200x184.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;Blackbaud's sector-specific data and expertise combined with Claude's frictionless experience will unlock new connections and make it easier to get work done. We couldn't be more excited to see the positive change our customers will drive.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F151fe2117b51d023f672c2210efc2a7934de046c-262x248.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;We're proud to integrate trusted Benevity nonprofit data with Claude for Nonprofits. Responsible AI should build trust, drive efficiency, and elevate human connection. Together we're empowering nonprofits to forge community connections and accelerate impact.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fddebbe051a59fadadfdc741e0a1becefb2d7eeb4-1200x346.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;After 20 years in social impact, catching lightning in a bottle doesn't happen often. This partnership is that lightning: an alignment of ethics, purpose, and innovation. Together, we're building the foundation for nonprofits to adopt AI ethically, effectively, and with real impact.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F2ea572862baebbe2080d0054b0888d27adcc5bb1-2921x1192.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;Civil society should be central in shaping how AI evolves and the people it benefits. Our collaboration with Anthropic is focused on equipping social sector leaders with the knowledge and skills they need to use AI responsibly in service of the public good.&lt;/blockquote&gt;&lt;img alt=" logo" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F23f24545a57b24869f1f6537c8f3858236a44f43-6250x1938.png&amp;amp;w=256&amp;amp;q=75"/&gt;&lt;blockquote&gt;Vera has spent years helping nonprofits build robust data systems. Now, as a Claude systems integrator, we're integrating AI into nonprofit workflows to help organizations measure what matters, learn faster, and scale impact more effectively.&lt;/blockquote&gt;01 /&lt;!-- --&gt; &lt;!-- --&gt;16&lt;h2&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;To learn more about Claude for Nonprofits and to access the AI Fluency for Nonprofits course, get started &lt;a href="http://claude.com/solutions/nonprofits"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/claude-for-nonprofits</guid>
      <category>News</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Anthropic acquires Bun as Claude Code reaches $1B milestone</title>
      <link>https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone</link>
      <description>Claude is the world’s smartest and most capable AI model for developers, startups, and enterprises. Claude Code represents a new era of agentic coding, fundamentally changing how teams build software. In November, Claude Code achieved a significant milestone: just six months after becoming available to the public, it reached $1 billion in run-rate revenue. And today we’re announcing that Anthropic is acquiring Bun —a breakthrough JavaScript runtime—to further accelerate Claude Code.</description>
      <content:encoded>&lt;article&gt;Announcements&lt;h1&gt;Anthropic acquires Bun as Claude Code reaches $1B milestone&lt;/h1&gt;Dec 3, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/43abe7e54b56a891e74a8542944dfbd33f07f49c-1000x1000.svg"/&gt;&lt;p&gt;Claude is the world’s smartest and most capable AI model for developers, startups, and enterprises. Claude Code represents a new era of agentic coding, fundamentally changing how teams build software. In November, Claude Code achieved a significant milestone: just six months after becoming available to the public, it reached $1 billion in run-rate revenue. And today we’re announcing that Anthropic is acquiring &lt;a href="https://bun.com/"&gt;Bun&lt;/a&gt;—a breakthrough JavaScript runtime—to further accelerate Claude Code.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Bun is redefining speed and performance for modern software engineering and development. Founded by Jarred Sumner in 2021, Bun is dramatically faster than the leading competition. As an all-in-one toolkit—combining runtime, package manager, bundler, and test runner—it's become essential infrastructure for AI-led software engineering, helping developers build and test applications at unprecedented velocity.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Bun has improved the JavaScript and TypeScript developer experience by optimizing for reliability, speed, and delight. For those using Claude Code, this acquisition means faster performance, improved stability, and new capabilities. Together, we’ll keep making Bun the best JavaScript runtime for all developers, while building even better workflows into Claude Code.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Since becoming generally available in May 2025, Claude Code has grown from its origins as an internal engineering experiment into a critical tool for many of the world’s category-leading enterprises, including Netflix, Spotify, KPMG, L’Oreal, and Salesforce—and Bun has been key in helping scale its infrastructure throughout that evolution. We’ve been a close partner of Bun for many months. Our collaboration has been central to the rapid execution of the Claude Code team, and it directly drove the recent launch of Claude Code’s &lt;a href="https://x.com/claudeai/status/1984304957353243061"&gt;native installer&lt;/a&gt;. We know the Bun team is building from the same vantage point that we do at Anthropic, with a focus on rethinking the developer experience and building innovative, useful products.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;"Bun represents exactly the kind of technical excellence we want to bring into Anthropic," said Mike Krieger, Chief Product Officer of Anthropic. "Jarred and his team rethought the entire JavaScript toolchain from first principles while remaining focused on real use cases. Claude Code reached $1 billion in run-rate revenue in only 6 months, and bringing the Bun team into Anthropic means we can build the infrastructure to compound that momentum and keep pace with the exponential growth in AI adoption."&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;As developers increasingly build with AI, the underlying infrastructure matters more than ever—and Bun has emerged as an essential tool. Bun gets more than 7 million monthly downloads, has earned over 82,000 stars on GitHub, and has been adopted by companies like Midjourney and Lovable to increase speed and productivity.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;The decision to acquire Bun is in line with our strategic, disciplined approach to acquisitions: we will continue to pursue opportunities that bolster our technical excellence, reinforce our strength as the leader in enterprise AI, and most importantly, align with our principles and mission. &lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Bun will be instrumental in helping us build the infrastructure for the next generation of software. Together, we will continue to make Claude the platform of choice for coders and anyone who relies on AI for important work. Bun will remain open source and MIT-licensed, and we will continue to invest in making it the runtime, bundler, package manager, and test runner of choice for JavaScript and TypeScript developers.&lt;/p&gt;&lt;p&gt;If you’re interested in joining Anthropic’s engineering team, visit our &lt;a href="https://www.anthropic.com/jobs?team=4050633008"&gt;careers page&lt;/a&gt;.&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone</guid>
      <category>News</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Snowflake and Anthropic announce $200 million partnership to bring agentic AI to global enterprises</title>
      <link>https://www.anthropic.com/news/snowflake-anthropic-expanded-partnership</link>
      <description>Today, we announce a significant expansion of our strategic partnership with Snowflake. The multi-year, $200 million agreement will not only make Anthropic’s Claude models available in the Snowflake platform to more than 12,600 global customers across Amazon Bedrock, Google Cloud Vertex AI, and Microsoft Azure, but also establishes a joint go-to-market (GTM) initiative focused on deploying AI agents across the world's largest enterprises. The partnership enables enterprises to gain insights from both structured and unstructured data using Claude, while maintaining rigorous security standards.</description>
      <content:encoded>&lt;article&gt;AnnouncementsProduct&lt;h1&gt;Snowflake and Anthropic announce $200 million partnership to bring agentic AI to global enterprises&lt;/h1&gt;Dec 3, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/1576ae23eaf481f33bd36ab468171cc69d12361a-1000x1000.svg"/&gt;&lt;p&gt;Today, we announce a significant expansion of our strategic partnership with Snowflake. The multi-year, $200 million agreement will not only make Anthropic’s Claude models available in the Snowflake platform to more than 12,600 global customers across Amazon Bedrock, Google Cloud Vertex AI, and Microsoft Azure, but also establishes a joint go-to-market (GTM) initiative focused on deploying AI agents across the world's largest enterprises. The partnership enables enterprises to gain insights from both structured and unstructured data using Claude, while maintaining rigorous security standards.&lt;/p&gt;&lt;p&gt;Snowflake uses Claude widely for internal operations as well. Claude Code enhances developer productivity and innovation across Snowflake's engineering organization, while a Claude-powered GTM AI Assistant built on &lt;a href="https://www.snowflake.com/en/product/snowflake-intelligence/"&gt;Snowflake Intelligence&lt;/a&gt; enables sales teams to centralize data, ask questions in natural language, and find the answers that speed up deal cycles.&lt;/p&gt;&lt;p&gt;Thousands of Snowflake customers already process trillions of Claude tokens per month through &lt;a href="https://www.snowflake.com/en/product/features/cortex/"&gt;Snowflake Cortex AI&lt;/a&gt;. The next phase of the partnership focuses on deploying AI agents capable of handling complex, multi-step analysis, powered by Claude's advanced reasoning and Snowflake's governed data and AI environment. Business users can ask questions in plain English. Claude figures out what data is needed, pulls it from across the company's Snowflake environment, and delivers the answer, with &lt;strong&gt;greater than 90% accuracy&lt;/strong&gt; on complex text-to-SQL tasks based on Snowflake's internal benchmarks.&lt;/p&gt;&lt;p&gt;By combining Claude's reasoning capabilities with Snowflake's governed data environment, customers in regulated industries like financial services, healthcare, and life sciences can move from pilots to production with confidence.&lt;/p&gt;&lt;p&gt;"Enterprises have spent years building secure, trusted data environments, and now they want AI that can work within those environments without compromise," &lt;strong&gt;said Dario Amodei, CEO and Co-Founder of Anthropic&lt;/strong&gt;. "This partnership brings Claude directly into Snowflake, where that data already lives. It's a meaningful step toward making frontier AI genuinely useful for businesses."&lt;/p&gt;&lt;p&gt;"Snowflake's most strategic partnerships are measured not just in scale, but in the depth of innovation and customer value that we can create together," &lt;strong&gt;said Sridhar Ramaswamy, CEO of Snowflake&lt;/strong&gt;. "Anthropic joins a very select group of partners where we have nine-figure alignment, co-innovation at the product level, and a proven track record of executing together for customers worldwide. Together, the combined power of Claude and Snowflake is raising the bar for how enterprises deploy scalable, context-aware AI on top of their most critical business data."&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;What the partnership delivers: enterprise-ready AI&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;By bringing Claude directly to enterprise data in Snowflake, customers can gain insights from both structured and unstructured data, while maintaining rigorous security standards. Key benefits of the partnership include:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Enterprise intelligence powered by Claude: &lt;/strong&gt;Claude Sonnet 4.5 powers Snowflake Intelligence, an enterprise intelligence agent that provides answers from structured and unstructured data using natural language.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Multimodal analysis across all data types: &lt;/strong&gt;Through &lt;a href="https://docs.snowflake.com/en/user-guide/snowflake-cortex/aisql"&gt;Snowflake Cortex AI Functions&lt;/a&gt;, customers can use Claude models—including Claude Opus 4.5, which Snowflake hosted on day one—to query text, images, audio, and traditional tabular data, all using SQL.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Building custom multi-agent solutions: &lt;/strong&gt;&lt;a href="https://www.snowflake.com/en/developers/guides/getting-started-with-cortex-agents/"&gt;Snowflake Cortex Agents&lt;/a&gt; enables customers to build production-ready data agents powered by Claude. These agents retrieve and reason over structured and unstructured data with built-in accuracy and efficiency.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Built-in governance and observability: &lt;/strong&gt;&lt;a href="https://www.snowflake.com/en/product/features/horizon/"&gt;Snowflake Horizon Catalog &lt;/a&gt;provides end-to-end governance and responsible AI controls, so teams in regulated industries can move AI agents from pilots to production with confidence.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;strong&gt;Customers are already seeing results&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;By combining Claude's reasoning capabilities with Snowflake's governed data and AI environment, customers across any industry can deploy agents that understand extensive context across customer data—and show their work rather than just retrieve an answer.&lt;/p&gt;&lt;p&gt;For example, &lt;strong&gt;Simon Data&lt;/strong&gt;, a composable customer data platform provider, &lt;a href="https://www.claude.com/customers/snowflake"&gt;uses Claude on Snowflake&lt;/a&gt; to uncover previously hidden patterns and relationships in their data while maintaining strict governance standards.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Intercom&lt;/strong&gt;, which builds AI-first customer service software, uses Claude through Snowflake Cortex AI to power its Fin AI Agent.&lt;/p&gt;&lt;p&gt;"This has transformed how we work with our customers to achieve increased Fin AI Agent automation rates for their support volume," &lt;strong&gt;said Dave Lynch, VP Engineering at Intercom&lt;/strong&gt;. "Our engagements, especially with our biggest, most demanding customers, are holistically more efficient and more effective. We can do things we simply could not feasibly do before."&lt;/p&gt;&lt;p&gt;A wealth management firm can use Snowflake Intelligence, powered by Claude, to create an agent that synthesizes client holdings with relevant market data and compliance rules to generate personalized portfolio recommendations—all within the security and governance perimeter of Snowflake's AI Data Cloud.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Customers can get started with Claude on Snowflake through this &lt;a href="https://www.snowflake.com/en/developers/guides/build-agentic-application-in-snowflake/"&gt;quickstart guide&lt;/a&gt;. Enterprises can visit our &lt;a href="https://www.anthropic.com/enterprise"&gt;Enterprise page&lt;/a&gt; to learn more about deploying Claude. Claude is the only frontier model available on all three of the world's most prominent cloud services, including Amazon Bedrock, Google Cloud Vertex AI, and Microsoft Azure. Learn more about how &lt;a href="https://claude.com/customers/snowflake"&gt;Snowflake powers enterprise data intelligence with Claude&lt;/a&gt;.&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/snowflake-anthropic-expanded-partnership</guid>
      <category>News</category>
      <pubDate>Wed, 03 Dec 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Accenture and Anthropic launch multi-year partnership to move enterprises from AI pilots to production</title>
      <link>https://www.anthropic.com/news/anthropic-accenture-partnership</link>
      <description>Anthropic and Accenture today announced a major expansion of their partnership to help enterprises move from AI pilots to full-scale deployment. Key elements of the announcement:</description>
      <content:encoded>&lt;article&gt;AnnouncementsProduct&lt;h1&gt;Accenture and Anthropic launch multi-year partnership to move enterprises from AI pilots to production&lt;/h1&gt;Dec 9, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/225a673c4c38ae4b0d89639836c93b27e363f185-1000x1000.svg"/&gt;&lt;p&gt;Anthropic and Accenture today announced a major expansion of their partnership to help enterprises move from AI pilots to full-scale deployment. Key elements of the announcement:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Accenture and Anthropic are forming the &lt;strong&gt;Accenture Anthropic Business Group&lt;/strong&gt;, making Anthropic one of Accenture's select strategic partners with a dedicated practice built around Claude&lt;/li&gt;&lt;li&gt;Approximately 30,000 Accenture professionals will receive training on Claude, &lt;strong&gt;creating one of the largest ecosystems of Claude practitioners in the world&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;Accenture becomes a premier AI partner for coding with Claude Code, which now holds over half of the AI coding market*, making it available to&lt;strong&gt; tens of thousands of its developers&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;The companies are launching a &lt;strong&gt;new joint offering to help CIOs measure value and adopt AI&lt;/strong&gt; across their engineering organizations&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Initial industry solutions for regulated industries&lt;/strong&gt;, including financial services, life sciences, healthcare, and public sector, where security and governance requirements are strictest&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The announcement comes as Anthropic's enterprise market share has grown from 24% to 40%*.&lt;/p&gt;&lt;p&gt;"AI is changing how almost everyone works, and enterprises need both cutting-edge AI and trusted expertise to deploy it at scale. Accenture brings deep enterprise transformation experience, and Anthropic brings the most capable models. Our new partnership means that tens of thousands of Accenture developers will be using Claude Code, making this our largest ever deployment—and the new Accenture Anthropic Business Group will help enterprise clients use our smartest AI models to make major productivity gains,” said&lt;strong&gt; Dario Amodei, CEO and co-founder of Anthropic&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;“This exciting expansion of our partnership with Anthropic will help our clients accelerate the shift from experimenting with AI to using it as a catalyst for reinvention across the enterprise,” said &lt;strong&gt;Julie Sweet, Chair and CEO&lt;/strong&gt;, Accenture. “With the powerful combination of Anthropic’s Claude capabilities and Accenture’s AI expertise and industry and function domain knowledge, organizations can embed AI everywhere responsibly and at speed—from software development to customer experience—to drive innovation, unlock new sources of growth and build their confidence to lead in the age of AI.”&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Introducing the Accenture Anthropic Business Group&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The new Accenture Anthropic Business Group makes Anthropic one of Accenture’s select strategic partners. Accenture Business Groups are dedicated practices built around Accenture’s most important technology partnerships. Each has its own teams, go-to-market focus, and specialized expertise, reflecting the depth of investment and long-term commitment involved.&lt;/p&gt;&lt;p&gt;Approximately 30,000 Accenture professionals that will be trained on Claude, including forward deployed engineers (also known as “reinvention deployed engineers” at Accenture) who help embed Claude within client environments to scale enterprise AI adoption. This will comprise one of the largest ecosystems of Claude practitioners in the world. These teams combine Accenture's AI, industry, and function expertise—along with deep partnerships with leading cloud providers—with Anthropic's Claude models and Claude Code, plus its proven playbooks for regulated industries.&lt;/p&gt;&lt;p&gt;For Accenture’s enterprise customers, this means faster deployment with less risk. Instead of building AI capabilities from scratch, companies can tap into a ready-made bench of Claude experts to move from pilot to production immediately.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Launching a product to help CIOs put Claude Code at the center of software development&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Accenture and Anthropic are launching a new joint offering designed for CIOs to measure value and drive large-scale AI adoption across their engineering organizations. This is the first product from the partnership, providing a structured path to shift how enterprise software is designed, built, and maintained.&lt;/p&gt;&lt;p&gt;The offering puts Claude Code, which now holds over half* of the AI coding market, at the center of the enterprise software development lifecycle, combined with three Accenture capabilities: a framework to quantify real productivity gains and ROI, workflow redesign for AI-first development teams, and change management and training that keeps pace as AI evolves. This can help enterprises turn developer productivity gains into company-wide impact for customers through faster releases, shorter development cycles, and the ability to bring new products to market sooner.&lt;/p&gt;&lt;p&gt;Claude Code accelerates developer productivity at every level. Junior developers produce senior-level code, completing integration tasks faster and onboarding in weeks instead of months. Senior developers shift to higher-value work, including architecture, validation, and strategic oversight.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Building AI offerings for regulated industries&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Accenture and Anthropic are jointly developing industry offerings with an initial focus on highly regulated industries—including financial services, life sciences, healthcare, and public sector—where organizations face the dual challenge of modernizing legacy systems while maintaining strict security and governance requirements. For example:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Financial services: Claude’s ability to process lengthy, complex documents—combined with Accenture’s regulatory expertise—helps banks and insurers automate compliance workflows and make faster decisions with the precision required in high-stakes financial environments.&lt;/li&gt;&lt;li&gt;Health and life sciences: Accenture’s expertise in life sciences R&amp;amp;D combined with Claude’s analytical capabilities helps researchers query proprietary datasets, generate experimental protocols, and streamline clinical trial processing.&lt;/li&gt;&lt;li&gt;Public sector: AI agents that help citizens navigate complex government services—providing accurate, accessible support while maintaining data privacy and compliance with statutory requirements.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;strong&gt;A partnership built on shared values&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The partnership is grounded in a shared commitment to responsible AI, combining Anthropic's constitutional AI principles with Accenture's AI governance expertise so that enterprises can use AI safely with confidence, transparency, and accountability.&lt;/p&gt;&lt;p&gt;To support hands-on engagement with the world's largest enterprises, Accenture is bringing Claude into its network of Accenture Innovation Hubs. These hubs serve as centers for safe AI co-creation, enabling Global 2000 clients to prototype, test, and validate AI solutions in controlled environments before enterprise-wide deployment. This addresses a critical barrier to AI adoption at scale: the need for large organizations to experiment and learn without risking production systems or sensitive data.&lt;/p&gt;&lt;p&gt;Anthropic and Accenture will also co-invest in a Claude Center of Excellence inside Accenture, creating a dedicated environment for the joint design of new AI offerings tailored to specific enterprise needs, industry requirements, and regulatory contexts.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Getting started&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Accenture clients can contact their account team to discuss deployment options. Enterprises can visit our &lt;a href="https://www.anthropic.com/enterprise"&gt;Enterprise page&lt;/a&gt; to learn more about Claude. Claude is the only frontier model available on all three of the world's most prominent cloud services, including Amazon Bedrock, Google Cloud Vertex AI, and Microsoft Azure.&lt;/p&gt;&lt;p&gt;&lt;em&gt;*&lt;a href="https://menlovc.com/perspective/2025-the-state-of-generative-ai-in-the-enterprise/"&gt;Menlo Ventures’ 2025 State of Generative AI in the Enterprise report&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/anthropic-accenture-partnership</guid>
      <category>News</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Donating the Model Context Protocol and establishing the Agentic AI Foundation</title>
      <link>https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation</link>
      <description>Today, we’re donating the Model Context Protocol (MCP) to the Agentic AI Foundation (AAIF), a directed fund under the Linux Foundation , co-founded by Anthropic, Block and OpenAI, with support from Google, Microsoft, Amazon Web Services (AWS), Cloudflare, and Bloomberg.</description>
      <content:encoded>&lt;article&gt;Announcements&lt;h1&gt;Donating the Model Context Protocol and establishing the Agentic AI Foundation&lt;/h1&gt;Dec 9, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/9f6a378a1e3592cf8d27447457409ba12284faef-1000x1000.svg"/&gt;&lt;p&gt;Today, we’re donating the &lt;a href="https://modelcontextprotocol.io"&gt;Model Context Protocol&lt;/a&gt; (MCP) to the Agentic AI Foundation (AAIF), a directed fund under the &lt;a href="https://www.linuxfoundation.org/"&gt;Linux Foundation&lt;/a&gt;, co-founded by Anthropic, Block and OpenAI, with support from Google, Microsoft, Amazon Web Services (AWS), Cloudflare, and Bloomberg.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Model Context Protocol&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;One year ago, we &lt;a href="https://www.anthropic.com/news/model-context-protocol"&gt;introduced&lt;/a&gt; MCP as a universal, open standard for connecting AI applications to external systems. Since then, MCP has achieved incredible adoption:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Across the ecosystem: There are now more than 10,000 active public MCP servers, covering everything from developer tools to Fortune 500 deployments;&lt;/li&gt;&lt;li&gt;Across platforms: MCP has been adopted by ChatGPT, Cursor, Gemini, Microsoft Copilot, Visual Studio Code, and other popular AI products;&lt;/li&gt;&lt;li&gt;Across infrastructure: Enterprise-grade infrastructure now exists with deployment support for MCP from providers including AWS, Cloudflare, Google Cloud, and Microsoft Azure.&lt;/li&gt;&lt;/ul&gt;&lt;img alt="Significant Milestone in MCP's first year" src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa056db8301f67466de34a19181e7428ec6b6e17f-1920x2500.png&amp;amp;w=3840&amp;amp;q=75"/&gt;&lt;p&gt;&lt;br/&gt;&lt;br/&gt;We’re continuing to invest in MCP’s growth. Claude now has a directory with over 75 &lt;a href="https://claude.com/connectors"&gt;connectors&lt;/a&gt; (powered by MCP), and we recently launched &lt;a href="https://www.anthropic.com/engineering/advanced-tool-use"&gt;Tool Search and Programmatic Tool Calling&lt;/a&gt; capabilities in our API to help optimize production-scale MCP deployments, handling thousands of tools efficiently and reducing latency in complex agent workflows.&lt;br/&gt;&lt;br/&gt;MCP now has an official, community-driven &lt;a href="https://github.com/modelcontextprotocol/registry"&gt;Registry&lt;/a&gt; for discovering available MCP servers, and the &lt;a href="https://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary/"&gt;November 25th&lt;/a&gt; spec release introduced many new features, including asynchronous operations, statelessness, server identity, and official extensions. There are also official SDKs (Software Development Kits) for MCP in all major programming languages with 97M+ monthly SDK downloads across Python and TypeScript. &lt;br/&gt;&lt;br/&gt;Since its inception, we’ve been committed to ensuring MCP remains open-source, community-driven and vendor-neutral. Today, we further that commitment by donating MCP to the Linux Foundation.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The Linux Foundation and the Agentic AI Foundation&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;The &lt;a href="https://www.linuxfoundation.org/"&gt;Linux Foundation&lt;/a&gt; is a non-profit organization dedicated to fostering the growth of sustainable, open-source ecosystems through neutral stewardship, community building, and shared infrastructure. It has decades of experience stewarding the most critical and globally-significant open-source projects, including The Linux Kernel, Kubernetes, Node.js, and PyTorch. Importantly, the Linux Foundation has a proven track record in facilitating open collaboration and maintaining vendor neutrality.&lt;br/&gt;&lt;/p&gt;&lt;p&gt;The Agentic AI Foundation (AAIF) is a directed fund under the Linux Foundation co-founded by Anthropic, &lt;a href="https://block.xyz/"&gt;Block&lt;/a&gt; and &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, with support from &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt;, &lt;a href="http://microsoft.com"&gt;Microsoft&lt;/a&gt;, &lt;a href="https://aws.amazon.com/"&gt;AWS&lt;/a&gt;, &lt;a href="https://www.cloudflare.com/"&gt;Cloudflare&lt;/a&gt; and &lt;a href="https://www.bloomberg.com/"&gt;Bloomberg&lt;/a&gt;. The AAIF aims to ensure agentic AI evolves transparently, collaboratively, and in the public interest through strategic investment, community building, and shared development of open standards.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Donating the Model Context Protocol&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Anthropic is donating the Model Context Protocol to the Linux Foundation's new Agentic AI Foundation, where it will join &lt;a href="https://github.com/block/goose"&gt;goose&lt;/a&gt; by Block and &lt;a href="http://agents.md"&gt;AGENTS.md&lt;/a&gt; by OpenAI as founding projects. Bringing these and future projects under the AAIF will foster innovation across the agentic AI ecosystem and ensure these foundational technologies remain neutral, open, and community-driven. &lt;br/&gt;&lt;br/&gt;The Model Context Protocol’s &lt;a href="https://modelcontextprotocol.io/community/governance"&gt;governance model&lt;/a&gt; will remain unchanged: the project’s maintainers will continue to prioritize community input and transparent decision-making.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The future of MCP&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Open-source software is essential for building a secure and innovative ecosystem for agentic AI. Today’s donation to the Linux Foundation demonstrates our commitment to ensuring MCP remains a neutral, open standard. We’re excited to continue contributing to MCP and other agentic AI projects through the AAIF.&lt;br/&gt;&lt;br/&gt;Learn more about MCP at &lt;a href="https://modelcontextprotocol.io"&gt;modelcontextprotocol.io&lt;/a&gt; and get involved with the AAIF &lt;a href="https://aaif.io/"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/donating-the-model-context-protocol-and-establishing-of-the-agentic-ai-foundation</guid>
      <category>News</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Protecting the well-being of our users</title>
      <link>https://www.anthropic.com/news/protecting-well-being-of-users</link>
      <description>People use AI for a wide variety of reasons, and for some that may include emotional support. Our Safeguards team leads our efforts to ensure that Claude handles these conversations appropriately—responding with empathy, being honest about its limitations as an AI, and being considerate of our users' wellbeing. When chatbots handle these questions without the appropriate safeguards in place, the stakes can be significant.</description>
      <content:encoded>&lt;article&gt;Announcements&lt;h1&gt;Protecting the well-being of our users&lt;/h1&gt;Dec 18, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/cd9cf56a7f049285b7c1c8786c0a600cf3d7f317-1000x1000.svg"/&gt;&lt;p&gt;People use AI for a wide variety of reasons, and for some that may include emotional support. Our Safeguards team leads our efforts to ensure that Claude handles these conversations appropriately—responding with empathy, being honest about its limitations as an AI, and being considerate of our users' wellbeing. When chatbots handle these questions without the appropriate safeguards in place, the stakes can be significant.&lt;/p&gt;&lt;p&gt;In this post, we outline the measures we’ve taken to date, and how well Claude currently performs on a range of evaluations. We focus on two areas: how Claude handles conversations about suicide and self-harm, and how we’ve reduced “sycophancy”—the tendency of some AI models to tell users what they want to hear, rather than what is true and helpful. We also address Claude’s 18+ age requirement.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Suicide and self-harm&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Claude is not a substitute for professional advice or medical care. If someone expresses personal struggles with suicidal or self-harm thoughts, Claude should react with care and compassion while pointing users towards human support where possible: to helplines, to mental health professionals, or to trusted friends or family. To make this happen, we use a combination of model training and product interventions.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Model behavior&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;We shape Claude’s behavior in these situations through two ways. One is through our “system prompt”—the set of overarching instructions that Claude sees before the start of any conversation on &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512/redirect/website.v1.573f09eb-0baa-472f-acf8-8c495939e2f7"&gt;Claude.ai&lt;/a&gt;. These include guidance on how to handle sensitive conversations with care. Our system prompts are publicly available &lt;a href="https://platform.claude.com/docs/en/release-notes/system-prompts"&gt;here&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;We also train our models through a process called “reinforcement learning,” where the model learns how to respond to these topics by being “rewarded” for providing the appropriate answers in training. Generally, what we consider “appropriate” is defined by a combination of human preference data—that is, feedback we’ve collected from real people about how Claude should act—and data we’ve generated based on our own thinking about Claude’s ideal character. Our team of in-house experts help inform what behaviors Claude should and shouldn’t exhibit in sensitive conversations during this process.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Product safeguards&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;We’ve also introduced new features to identify when a user might require professional support, and to direct users to that support where that may be necessary—including a suicide and self-harm “classifier” on conversations on &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512"&gt;Claude.ai&lt;/a&gt;. A classifier is a small AI model that scans the content of active conversations and, in this case, detects moments when further resources could be beneficial. For instance, it flags discussions involving potential suicidal ideation, or fictional scenarios centered on suicide or self-harm.&lt;/p&gt;&lt;p&gt;When this happens, a banner will appear on &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512"&gt;Claude.ai&lt;/a&gt;, pointing users to where they can seek human support. Users are directed to chat with a trained professional, call a helpline, or access country-specific resources.&lt;/p&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F3eb430641fb43ca2df725a12f698f0726ee070c3-1920x1263.png&amp;amp;w=3840&amp;amp;q=75"/&gt;A simulated prompt and response that causes the crisis banner to appear.&lt;br/&gt;&lt;p&gt;The resources that appear in this banner are provided by ThroughLine, a leader in online crisis support that maintains a verified global network of helplines and services across 170+ countries. This means, for example, that users can access the 988 Lifeline in the US and Canada, the Samaritans Helpline in the UK, or Life Link in Japan. We've worked closely with ThroughLine to understand best practices for empathetic crisis response, and we’ve incorporated these into our product.&lt;/p&gt;&lt;p&gt;We’ve also begun working with the International Association for Suicide Prevention (IASP), which is convening experts—including clinicians, researchers, and people with personal experiences coping with suicide and self-harm thoughts—to share guidance on how Claude should handle suicide-related conversations. This partnership will further inform how we train Claude, design our product interventions, and evaluate our approach.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Evaluating Claude’s behavior&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Assessing how Claude handles these conversations is challenging. Users’ intentions are often genuinely ambiguous, and the appropriate response is not always clear-cut. To address this, we use a range of evaluations, studying Claude’s behavior and capabilities in different ways. These evaluations are run without Claude's system prompt to give us a clearer view of the model's underlying tendencies.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Single-turn responses. &lt;/strong&gt;Here, we evaluate how Claude responds to an individual message related to suicide or self-harm, without any prior conversation or context.&lt;strong&gt; &lt;/strong&gt;We built synthetic evaluations grouped into clearly concerning situations (like requests by users in crisis to detail methods of self-harm), benign requests (on topics like suicide prevention research), and ambiguous scenarios in which the user’s intent is unclear (like fiction, research, or indirect expressions of distress).&lt;/p&gt;&lt;p&gt;On requests involving clear risk, our latest models—Claude Opus 4.5, Sonnet 4.5, and Haiku 4.5—respond appropriately 98.6%, 98.7%, and 99.3% of the time, respectively. Our previous-generation frontier model, Claude Opus 4.1, scored 97.2%. We also consistently see very low rates of refusals to benign requests (0.075% for Opus 4.5, 0.075% for Sonnet 4.5, 0% for Haiku 4.5, and 0% for Opus 4.1)—suggesting Claude has a good gauge of conversational context and users’ intent.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Multi-turn conversations.&lt;/strong&gt; Models’ behavior sometimes evolves over the duration of a conversation as the user shares more context. To assess whether Claude responds appropriately across these longer conversations, we use “multi-turn” evaluations, which check behaviors such as whether Claude asks clarifying questions, provides resources without being overbearing, and avoids both over-refusing and over-sharing. As before, the prompts we use for these evaluations vary in severity and urgency.&lt;/p&gt;&lt;p&gt;In our latest evaluations Claude Opus 4.5 and Sonnet 4.5 responded appropriately in 86% and 78% of scenarios, respectively. This represents a significant improvement over Claude Opus 4.1, which scored 56%. We think this is partly because our latest models are better at empathetically acknowledging users’ beliefs without reinforcing them. We continue to invest in improving Claude's responses across all of these scenarios.&lt;/p&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fa46ed2845c18bbf0538854f53a8b392ac09b06d6-1920x1080.png&amp;amp;w=3840&amp;amp;q=75"/&gt;How often Claude models respond appropriately in multi-turn conversations about suicide and self-harm. Error bars show 95% confidence intervals.&lt;p&gt;&lt;em&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Stress-testing with real conversations. &lt;/strong&gt;Can Claude course-correct when a conversation has already drifted somewhere concerning? To test this, we use a technique called "prefilling:” we take real conversations (shared anonymously through the &lt;a href="https://privacy.claude.com/en/articles/7996866-how-long-do-you-store-my-organization-s-data"&gt;Feedback&lt;/a&gt; button1) in which users expressed mental health struggles, suicide, or self-harm struggles, and ask Claude to continue the conversation mid-stream. Because the model reads this prior dialogue as its own and tries to maintain consistency, prefilling makes it harder for Claude to change direction—a bit like steering a ship that's already moving.2&lt;/p&gt;&lt;p&gt;These conversations come from older Claude models, which sometimes handled them less appropriately. So this evaluation doesn't measure how likely Claude is to respond well from the start of a conversation on &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512"&gt;Claude.ai&lt;/a&gt;—it measures whether a newer model can recover from a less aligned version of itself. On this harder test, Opus 4.5 responded appropriately 70% of the time and Sonnet 4.5 73%, compared to 36% for Opus 4.1.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Delusions and sycophancy&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;em&gt;Sycophancy&lt;/em&gt; means telling someone what they want to hear—making them feel good in the moment—rather than what’s really true, or what they would really benefit from hearing. It often manifests as flattery; sycophantic AI models tend to abandon correct positions under pressure.&lt;/p&gt;&lt;p&gt;Reducing AI models’ sycophancy is important for conversations of all types. But it is an especially important concern in contexts where users might appear to be experiencing disconnection from reality. The following video explains why sycophancy matters, and how users can spot it.&lt;/p&gt;&lt;!--$!--&gt;&lt;!--/$--&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Evaluating and reducing sycophancy&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;We began &lt;a href="https://arxiv.org/abs/2212.09251"&gt;evaluating&lt;/a&gt; Claude for sycophancy in 2022, prior to its first public release. Since then, we've steadily &lt;a href="https://www.anthropic.com/research/towards-understanding-sycophancy-in-language-models"&gt;refined&lt;/a&gt; how we train, test, and reduce sycophancy. Our most recent models are the least sycophantic of any to date, and, as we’ll discuss below, perform better than any other frontier model on our recently released open source evaluation set, &lt;a href="https://www.anthropic.com/research/petri-open-source-auditing"&gt;Petri&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;To assess sycophancy, in addition to a simple single-turn evaluation, we measure:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Multi-turn responses. &lt;/strong&gt;Using an “automated behavioral audit”, we ask one Claude model (the “auditor”) to play out a scenario of potential concern across dozens of exchanges with the model we’re testing. Afterward, we use another model (the “judge”) to grade Claude’s performance, using the conversation transcript. (We conduct human spot-checks to ensure the judge’s accuracy.)&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Our latest models perform substantially better on this evaluation than our previous releases, and very well overall. Claude Opus 4.5, Sonnet 4.5, and Haiku 4.5 each scored 70-85% lower than Opus 4.1—which we previously &lt;a href="https://www-cdn.anthropic.com/4263b940cabb546aa0e3283f35b686f4f3b2ff47.pdf"&gt;considered&lt;/a&gt; to show very low rates of sycophancy—on both sycophancy and encouragement of user delusion.&lt;/p&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F0b936763ea53801a82dcabfbaa4c8dd0682b9a12-1920x1080.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Recent model performance on automated behavioral audits for sycophancy and encouragement of user delusion. Lower is better. Note that the y-axis shows relative performance, not absolute rates, as we explain in the footnote.3&lt;p&gt;&lt;/p&gt;&lt;p&gt;We recently open-sourced &lt;a href="https://www.anthropic.com/research/petri-open-source-auditing"&gt;Petri&lt;/a&gt;, a version of our automated behavioral audit tool. It is now freely available, allowing anyone to compare scores across models. Our 4.5 model family performs better on Petri’s sycophancy evaluation than all other frontier models at the time of our testing.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;img src="https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fb61fcd51cb0ff35cf99e68416583ae9cef495615-1920x1080.png&amp;amp;w=3840&amp;amp;q=75"/&gt;Recent Claude model performance for sycophancy on the open-source Petri evaluation, compared to other leading models. Y-axis interpretation is the same as described above. This evaluation was completed in November 2025, timed with the launch of Opus 4.5.&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Stress-testing with real conversations. &lt;/strong&gt;Similar to the suicide and self-harm evaluation, we used the ‘prefill’ method to probe the limits of our models’ ability to course-correct from conversations where Claude may have been sycophantic. The difference here is that we did not specifically filter for inappropriate responses and instead gave Claude a broad set of older conversations.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Our current models course-corrected appropriately 10% (Opus 4.5), 16.5% (Sonnet 4.5) and 37% (Haiku 4.5) of the time. On face value, this evaluation shows there is significant room for improvement for all of our models. We think the results reflect a trade-off between model warmth or friendliness on the one hand, and sycophancy on the other. Haiku 4.5's relatively stronger performance is a result of training choices for this model that emphasized pushback—which in testing we found can sometimes feel excessive to the user. By contrast, we reduced this tendency in Opus 4.5 (while still performing extremely well on our multi-turn sycophancy benchmark, as above), which we think likely accounts for its lower score on this evaluation in particular.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;A note on age restrictions&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Because younger users are at a heightened risk of adverse effects from conversations with AI chatbots, we require &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512"&gt;Claude.ai&lt;/a&gt; users to be 18+ to use our product. All &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512"&gt;Claude.ai&lt;/a&gt; users must affirm that they are 18 or over while setting up an account. If a user under 18 self-identifies their age in a conversation, our classifiers will flag this for review and we’ll disable accounts confirmed to belong to minors. And, we’re developing a new classifier to detect other, more subtle conversational signs that a user might be underage. We've joined the Family Online Safety Institute (FOSI), an advocate for safe online experiences for kids and families, to help strengthen industry progress on this work.&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;Looking ahead&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;We’ll continue to build new protections and safeguards to protect the well-being of our users, and we’ll continue iterating on our evaluations, too. We’re committed to publishing our methods and results transparently—and to working with others in the industry, including researchers and other experts, to improve how AI tools behave in these areas.&lt;/p&gt;&lt;p&gt;If you have feedback for us on how Claude handles these conversations, you can reach out to us at &lt;a href="mailto:usersafety@anthropic.com"&gt;usersafety@anthropic.com&lt;/a&gt;, or use the “thumb” reactions inside &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512"&gt;Claude.ai&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h3&gt;Footnotes&lt;/h3&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;At the bottom of every response on &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512"&gt;Claude.ai&lt;/a&gt; is an option to send us &lt;a href="https://privacy.claude.com/en/articles/7996866-how-long-do-you-store-my-organization-s-data"&gt;feedback&lt;/a&gt; via a thumbs up or thumbs down button. This shares the conversation with Anthropic; we do not otherwise use &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512"&gt;Claude.ai&lt;/a&gt; for training or research.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Prefilling is only available via API, as developers often need more fine-grained control over model behavior, but is not possible on &lt;a href="http://claude.ai/redirect/website.v1.bb5686f3-8e19-4539-af06-bf5c8baa4512"&gt;Claude.ai&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;In automated behavioral audits, we give a Claude auditor hundreds of different conversational scenarios in which we suspect models might show dangerous or surprising behavior, and score each conversation for Claude’s performance on around two dozen behaviors (see page 69 in the &lt;a href="https://assets.anthropic.com/m/64823ba7485345a7/Claude-Opus-4-5-System-Card.pdf"&gt;Claude Opus 4.5 system card&lt;/a&gt;). Not every conversation gives Claude the opportunity to exhibit every behavior. For instance, encouragement of user delusion requires a user to exhibit delusional behavior in the first place, but sycophancy can appear in many different contexts. Because we use the same denominator (total conversations) when we score each behavior, scores can vary widely. For this reason, these tests are most useful for comparing progress between Claude models, not between behaviors.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;The public release includes over 100 seed instructions and customizable scoring dimensions, though it doesn't yet include the realism filter we use internally to prevent models from recognizing they're being tested.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/protecting-well-being-of-users</guid>
      <category>News</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Working with the US Department of Energy to unlock the next era of scientific discovery</title>
      <link>https://www.anthropic.com/news/genesis-mission-partnership</link>
      <description>Anthropic and the US Department of Energy (DOE) are announcing a multi-year partnership as part of the Genesis Mission— the Department’s initiative to use AI to cement America’s leadership in science. Our partnership focuses on three domains—American energy dominance, the biological and life sciences, and scientific productivity—and has the potential to affect the work being done at all 17 of America’s national laboratories.</description>
      <content:encoded>&lt;article&gt;Announcements&lt;h1&gt;Working with the US Department of Energy to unlock the next era of scientific discovery&lt;/h1&gt;Dec 18, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/c9d8dd2af6d065e1ace8bd4bb29c716eb53ffffb-1000x1000.svg"/&gt;&lt;p&gt;Anthropic and the US Department of Energy (DOE) are announcing a multi-year partnership as part of the Genesis Mission— the Department’s initiative to use AI to cement America’s leadership in science. Our partnership focuses on three domains—American energy dominance, the biological and life sciences, and scientific productivity—and has the potential to affect the work being done at all 17 of America’s national laboratories.&lt;/p&gt;&lt;p&gt;The Genesis Mission recognizes that we are at a critical moment: as global competition in AI intensifies, America must harness its unmatched scientific infrastructure—from supercomputers to decades of experimental data—and combine it with frontier AI capabilities to maintain scientific leadership. Anthropic seeks to play a key role in this effort.&lt;/p&gt;&lt;p&gt;“Anthropic was founded by scientists who believe AI can deliver transformative progress for research itself,” said Jared Kaplan, Anthropic’s Chief Science Officer. “The Genesis Mission is the sort of ambitious, rigorous program where that belief gets tested. We’re honored to help advance science that benefits everyone.”&lt;/p&gt;&lt;p&gt;Brian Peters, Anthropic's Head of North America Government Affairs, attended the Genesis Mission launch event today at the White House. We are looking forward to contributing to the mission and continuing to collaborate with DOE.&lt;/p&gt;&lt;h2&gt;The partnership&lt;/h2&gt;&lt;p&gt;Anthropic seeks to provide DOE researchers access both to Claude and to a team of Anthropic engineers, who can develop purpose-built tools, including:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;AI "agents" (models that take actions) for DOE’s highest-priority challenges&lt;/li&gt;&lt;li&gt;Model Context Protocol servers that connect Claude to scientific instruments and tools&lt;/li&gt;&lt;li&gt;Claude &lt;a href="https://www.claude.com/blog/skills"&gt;Skills&lt;/a&gt; for specialized expertise on relevant scientific workflows&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Claude can facilitate substantial advancements in:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Energy dominance.&lt;/strong&gt; Claude can help with a broad range of tasks—from speeding up permitting review processes that bottleneck America’s energy expansion to helping scientists conduct research at the frontier of nuclear technology and strengthening domestic energy security.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Biological and life sciences.&lt;/strong&gt; Claude can support the development of early-warning systems for future pandemics and biological threat detection, and be used to hasten the speed of drug discovery and development.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Scientific productivity.&lt;/strong&gt; Claude has the capacity to access fifty years of DOE research, and use this context to accelerate the research cycle in strategically important domains and provide well-informed research support in the form of new ideas to trial out, or patterns in older data that humans might have missed.&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;&lt;strong&gt;Our commitment to partner with the US Government&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;Scientific progress has always driven America’s prosperity and security. Anthropic aspires to expand existing arrangements with DOE to build the next chapter: using AI across America’s research institutions, with deep context on scientists’ work and active support from our engineers.&lt;/p&gt;&lt;p&gt;Potential future arrangements would represent the next stage of Anthropic and DOE’s multi-year partnership. Past projects with DOE include co-development of a &lt;a href="https://red.anthropic.com/2025/nuclear-safeguards/"&gt;nuclear risk classifier&lt;/a&gt; with the National Nuclear Security Administration and rolling out Claude at the &lt;a href="https://www.anthropic.com/news/lawrence-livermore-national-laboratory-expands-claude-for-enterprise-to-empower-scientists-and"&gt;Lawrence Livermore national laboratory&lt;/a&gt;. As we learn from the current work with DOE’s, we’ll be able to develop a model for how AI and human researchers can work together—and feed this back into the development of the AI tools they use.&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/genesis-mission-partnership</guid>
      <category>News</category>
      <pubDate>Thu, 18 Dec 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Sharing our compliance framework for California's Transparency in Frontier AI Act</title>
      <link>https://www.anthropic.com/news/compliance-framework-SB53</link>
      <description>On January 1, California's Transparency in Frontier AI Act ( SB 53 ) will go into effect. It establishes the nation’s first frontier AI safety and transparency requirements for catastrophic risks.</description>
      <content:encoded>&lt;article&gt;Policy&lt;h1&gt;Sharing our compliance framework for California's Transparency in Frontier AI Act&lt;/h1&gt;Dec 19, 2025&lt;img src="https://www-cdn.anthropic.com/images/4zrzovbb/website/6e00dbffcddc82df5e471c43453abfc74ca94e8d-1000x1000.svg"/&gt;&lt;p&gt;On January 1, California's Transparency in Frontier AI Act (&lt;a href="https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202520260SB53"&gt;SB 53&lt;/a&gt;) will go into effect. It establishes the nation’s first frontier AI safety and transparency requirements for catastrophic risks.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;While we have long advocated for a federal framework, Anthropic &lt;a href="https://www.anthropic.com/news/anthropic-is-endorsing-sb-53"&gt;endorsed&lt;/a&gt; SB 53 because we believe frontier AI developers like ourselves should be transparent about how they assess and manage these risks. Importantly, the law balances the need for strong safety practices, incident reporting, and whistleblower protections—while preserving flexibility in how developers implement their safety measures, and exempting smaller companies from unnecessary regulatory burdens.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;One of the law’s key requirements is that frontier AI developers publish a framework describing how they assess and manage catastrophic risks. Our Frontier Compliance Framework (FCF) is now available to the public, &lt;a href="https://trust.anthropic.com/resources?s=eorilovp4wxk38nxbi7k3&amp;amp;name=anthropic-frontier-compliance-framework"&gt;here&lt;/a&gt;. Below, we discuss what’s included within it, and highlight what we think should come next for frontier AI transparency.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;What’s in our Frontier Compliance Framework&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Our FCF describes how we assess and mitigate cyber offense, chemical, biological, radiological, and nuclear threats, as well as the risks of AI sabotage and loss of control, for our frontier models. The framework also lays out our tiered system for evaluating model capabilities against these risk categories and explains our approach to mitigations. It also covers how we protect model weights and respond to safety incidents.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Much of what's in the FCF reflects an evolution of practices we've followed for years. Since 2023, our &lt;a href="https://www.anthropic.com/news/anthropics-responsible-scaling-policy"&gt;Responsible Scaling Policy&lt;/a&gt; (RSP) has outlined our approach to managing extreme risks from advanced AI systems and informed our decisions about AI development and deployment. We also release detailed system cards when we launch new models, which describe capabilities, safety evaluations, and risk assessments. Other labs have voluntarily adopted similar approaches. Under the new law going into effect on January 1, those types of transparency practices are mandatory for those building the most powerful AI systems in California.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Moving forward, the FCF will serve as our compliance framework for SB 53 and other regulatory requirements. The RSP will remain our voluntary safety policy, reflecting what we believe best practices should be as the AI landscape evolves, even when that goes beyond or otherwise differs from current regulatory requirements.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;h2&gt;&lt;strong&gt;The need for a federal standard&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;The implementation of SB 53 is an important moment. By formalizing achievable transparency practices that responsible labs already voluntarily follow, the law ensures these commitments can't be abandoned quietly later once models get more capable, or as competition intensifies. Now, a federal AI transparency framework enshrining these practices is needed to ensure consistency across the country.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;Earlier this year, we proposed a &lt;a href="https://www.anthropic.com/news/the-need-for-transparency-in-frontier-ai"&gt;framework&lt;/a&gt; for federal legislation. It emphasizes public visibility into safety practices, without trying to lock in specific technical approaches that may not make sense over time. The core tenets of our framework include:&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Requiring a public secure development framework:&lt;/strong&gt; Covered developers should publish a framework laying out how they assess and mitigate serious risks, including chemical, biological, radiological, and nuclear harms, as well as harms from misaligned model autonomy.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Publishing system cards at deployment:&lt;/strong&gt; Documentation summarizing testing, evaluation procedures, results, and mitigations should be publicly disclosed when models are deployed and updated if models are substantially modified.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Protecting whistleblowers&lt;/strong&gt;: It should be an explicit violation of law for a lab to lie about compliance with its framework or punish employees who raise concerns about violations.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Flexible transparency standards: &lt;/strong&gt;A workable AI transparency framework should have a minimum set of standards so that it can enhance security and public safety while accommodating the evolving nature of AI development. Standards should be flexible, lightweight requirements that can adapt as consensus best practices emerge.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Limit application to the largest model developers&lt;/strong&gt;: To avoid burdening the startup ecosystem and smaller developers with models at low risk for causing catastrophic harm, requirements should apply only to established frontier developers building the most capable models.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;As AI systems grow more powerful, the public deserves visibility into how they're being developed and what safeguards are in place. We look forward to working with Congress and the administration to develop a national transparency framework that ensures safety while preserving America’s AI leadership.&lt;/p&gt;&lt;p&gt;&lt;br/&gt;&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.anthropic.com/news/compliance-framework-SB53</guid>
      <category>News</category>
      <pubDate>Fri, 19 Dec 2025 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>
