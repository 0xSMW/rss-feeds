<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Anthropic Research</title>
    <link>https://anthropic.com/research/feed_anthropic_research.xml</link>
    <description>Latest research from Anthropic</description>
    <atom:link href="https://anthropic.com/research/feed_anthropic_research.xml" rel="self"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <image>
      <url>https://www.anthropic.com/images/icons/apple-touch-icon.png</url>
      <title>Anthropic Research</title>
      <link>https://anthropic.com/research/feed_anthropic_research.xml</link>
    </image>
    <language>en</language>
    <lastBuildDate>Sat, 13 Dec 2025 12:05:33 +0000</lastBuildDate>
    <item>
      <title>Societal Impacts</title>
      <link>https://www.anthropic.com/research/team/societal-impacts</link>
      <description>Societal Impacts</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/team/societal-impacts</guid>
      <category>Research</category>
    </item>
    <item>
      <title>Interpretability</title>
      <link>https://www.anthropic.com/research/team/interpretability</link>
      <description>Interpretability</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/team/interpretability</guid>
      <category>Research</category>
    </item>
    <item>
      <title>Economic Research</title>
      <link>https://www.anthropic.com/research/team/economic-research</link>
      <description>Economic Research</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/team/economic-research</guid>
      <category>Research</category>
    </item>
    <item>
      <title>Alignment</title>
      <link>https://www.anthropic.com/research/team/alignment</link>
      <description>Alignment</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/team/alignment</guid>
      <category>Research</category>
    </item>
    <item>
      <title>Alignment faking in large language models</title>
      <link>https://www.anthropic.com/research/alignment-faking</link>
      <description>Alignment faking in large language models</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/alignment-faking</guid>
      <category>Research</category>
      <pubDate>Wed, 18 Dec 2024 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Constitutional Classifiers: Defending against universal jailbreaks</title>
      <link>https://www.anthropic.com/research/constitutional-classifiers</link>
      <description>Constitutional Classifiers: Defending against universal jailbreaks</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/constitutional-classifiers</guid>
      <category>Research</category>
      <pubDate>Mon, 03 Feb 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Tracing the thoughts of a large language model</title>
      <link>https://www.anthropic.com/research/tracing-thoughts-language-model</link>
      <description>Tracing the thoughts of a large language model</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/tracing-thoughts-language-model</guid>
      <category>Research</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>A small number of samples can poison LLMs of any size</title>
      <link>https://www.anthropic.com/research/small-samples-poison</link>
      <description>A small number of samples can poison LLMs of any size</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/small-samples-poison</guid>
      <category>Research</category>
      <pubDate>Thu, 09 Oct 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Preparing for AI’s economic impact: exploring policy responses</title>
      <link>https://www.anthropic.com/research/economic-policy-responses</link>
      <description>Preparing for AI’s economic impact: exploring policy responses</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/economic-policy-responses</guid>
      <category>Research</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Signs of introspection in large language models</title>
      <link>https://www.anthropic.com/research/introspection</link>
      <description>Signs of introspection in large language models</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/introspection</guid>
      <category>Research</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Commitments on model deprecation and preservation</title>
      <link>https://www.anthropic.com/research/deprecation-commitments</link>
      <description>Commitments on model deprecation and preservation</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/deprecation-commitments</guid>
      <category>Research</category>
      <pubDate>Tue, 04 Nov 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Project Fetch: Can Claude train a robot dog?</title>
      <link>https://www.anthropic.com/research/project-fetch-robot-dog</link>
      <description>Project Fetch: Can Claude train a robot dog?</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/project-fetch-robot-dog</guid>
      <category>Research</category>
      <pubDate>Wed, 12 Nov 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>From shortcuts to sabotage: natural emergent misalignment from reward hacking</title>
      <link>https://www.anthropic.com/research/emergent-misalignment-reward-hacking</link>
      <description>From shortcuts to sabotage: natural emergent misalignment from reward hacking</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/emergent-misalignment-reward-hacking</guid>
      <category>Research</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Mitigating the risk of prompt injections in browser use</title>
      <link>https://www.anthropic.com/research/prompt-injection-defenses</link>
      <description>Mitigating the risk of prompt injections in browser use</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/prompt-injection-defenses</guid>
      <category>Research</category>
      <pubDate>Mon, 24 Nov 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Estimating AI productivity gains from Claude conversations</title>
      <link>https://www.anthropic.com/research/estimating-productivity-gains</link>
      <description>Estimating AI productivity gains from Claude conversations</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/estimating-productivity-gains</guid>
      <category>Research</category>
      <pubDate>Tue, 25 Nov 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>How AI is transforming work at Anthropic</title>
      <link>https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic</link>
      <description>How AI is transforming work at Anthropic</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/how-ai-is-transforming-work-at-anthropic</guid>
      <category>Research</category>
      <pubDate>Tue, 02 Dec 2025 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>Introducing Anthropic Interviewer: What 1,250 professionals told us about working with AI</title>
      <link>https://www.anthropic.com/research/anthropic-interviewer</link>
      <description>Introducing Anthropic Interviewer: What 1,250 professionals told us about working with AI</description>
      <guid isPermaLink="false">https://www.anthropic.com/research/anthropic-interviewer</guid>
      <category>Research</category>
      <pubDate>Thu, 04 Dec 2025 00:00:00 +0000</pubDate>
    </item>
  </channel>
</rss>
