<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>Hacker News Full Content Feed</title>
    <link>https://news.ycombinator.com/</link>
    <description>Hacker News front-page links with full article content.</description>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <generator>python-feedgen</generator>
    <language>en</language>
    <lastBuildDate>Thu, 25 Dec 2025 00:12:21 +0000</lastBuildDate>
    <item>
      <title>Microsoft please get your tab to autocomplete shit together</title>
      <link>https://ivanca.github.io/programming/2025/11/26/microsoft-pls-get-your-tab-to-autocomplete-shit-together/</link>
      <description>November 26, 2025

	
	
		• Programming</description>
      <content:encoded>&lt;article class="content"&gt;
&lt;p&gt;
	November 26, 2025

	
	
		•
	

	
		
		&lt;a href="https://ivanca.github.io/category/programming/"&gt;Programming&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;What do you think is gonna happen after I press tab when looking at this screenshot?&lt;/p&gt;
&lt;p&gt;&lt;img alt="Before" src="https://ivanca.github.io/uploads/before_tab.png"/&gt;&lt;/p&gt;
&lt;p&gt;That’s right, its gonna do nothing and suggest something else that it wasn’t any of the 2 initial suggestions&lt;/p&gt;
&lt;p&gt;&lt;img alt="Before" src="https://ivanca.github.io/uploads/after_tab.png"/&gt;&lt;/p&gt;
&lt;p&gt;Whoever team or person is on charge of the behavior of vscode autocomplete behavior at Microsoft (or at least the C# Dev Kit plugin) please do your job and fix this, thank you.&lt;/p&gt;

&lt;h3&gt;Meet the author&lt;/h3&gt;



&lt;img alt="Staff photo for Ivan Castellanos" src="https://ivanca.github.io/images/yo.png"/&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ivan Castellanos&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;p&gt;Ivan was born at a very young age, this has made a lot of people very angry and is widely regarded as a bad move.&lt;/p&gt;
&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;!--
&lt;h3&gt;Keep reading&lt;/h3&gt;
&lt;ol class="post-links post-list"&gt;
	
		&lt;li class="post-summary"&gt;
	
		&lt;div class="post-summary-image" style="background-image: url('/images/ai-bypass.png')"&gt;
			
		&lt;/div&gt;
	

	&lt;div class="post-summary-content has-post-summary-image"&gt;
		&lt;h3 class="post-summary-title"&gt;&lt;a href="/programming/2025/11/26/bypass-ai-upscalint-restrictions/"&gt;How to Deal With AI Restrictions When Upscaling Images&lt;/a&gt;&lt;/h3&gt;
		&lt;p class="post-summary-details"&gt;
	November 26, 2025

	
	
		&amp;bull;
	

	
		
		&lt;a class="post-summary-category" href="/category/programming/"&gt;Programming&lt;/a&gt;
	
&lt;/p&gt;

		
		
		&lt;p class="post-summary-author"&gt;
			&lt;img src="/images/yo.png" alt="Photo of Ivan Castellanos" width="30" height="30"&gt; Ivan Castellanos
		&lt;/p&gt;
	&lt;/div&gt;

	&lt;p class="post-summary-excerpt"&gt;Modern AI tools—Google Gemini, ChatGPT, and many others—often apply strict content-safety filters when you try to upscale certain images. These systems sometimes misclassify completely harmless images, blocking them from being processed. Through experimentation, I’ve noticed that you can sometimes avoid these false positives by lightly obfuscating the image before sending it to an AI model. After the upscale, you simply reverse the transformation to recover the original look.

&lt;/p&gt;
&lt;/li&gt;

	
&lt;/ol&gt;
--&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://ivanca.github.io/programming/2025/11/26/microsoft-pls-get-your-tab-to-autocomplete-shit-together/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 23:33:15 +0000</pubDate>
    </item>
    <item>
      <title>Tell HN: Merry Christmas</title>
      <link>https://news.ycombinator.com/item?id=46380168</link>
      <description>Merry Christmas to everyone. I hope you get some rest and can spend time with people who are dear to you and get to focus on what's important rather than getting lost in stressing about everything having to be perfect. Also much love to everyone who cannot spend their Christmas with dear people. To make sure this post meets the relevancy criteria, here is a Wikipedia article about some Christmas (more precisely advent) tradition which I personally really like: https://en.wikipedia.org/wiki/Christmas_market</description>
      <content:encoded>&lt;body&gt;&lt;a href="https://news.ycombinator.com"&gt;&lt;img src="https://news.ycombinator.com/y18t.svg"/&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/news"&gt;Hacker News&lt;/a&gt;&lt;a href="https://news.ycombinator.com/newest"&gt;new&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/front"&gt;past&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/newcomments"&gt;comments&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/ask"&gt;ask&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/show"&gt;show&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/jobs"&gt;jobs&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/submit"&gt;submit&lt;/a&gt;&lt;a href="https://news.ycombinator.com/login?goto=item%3Fid%3D46380168"&gt;login&lt;/a&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380168&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/item?id=46380168"&gt;Tell HN: Merry Christmas&lt;/a&gt;195 points by &lt;a href="https://news.ycombinator.com/user?id=basilikum"&gt;basilikum&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380168"&gt;1 hour ago&lt;/a&gt;  | &lt;a href="https://news.ycombinator.com/hide?id=46380168&amp;amp;goto=item%3Fid%3D46380168"&gt;hide&lt;/a&gt; | &lt;a href="https://hn.algolia.com/?query=Tell%20HN%3A%20Merry%20Christmas&amp;amp;type=story&amp;amp;dateRange=all&amp;amp;sort=byDate&amp;amp;storyText=false&amp;amp;prefix&amp;amp;page=0"&gt;past&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/fave?id=46380168&amp;amp;auth=b67f8a519793354e9d148bee2ae431a050dfa143"&gt;favorite&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/item?id=46380168"&gt;60 comments&lt;/a&gt;Different cultures celebrate Christmas at different days and time zones are a thing. But it's Christmas here, so:&lt;p&gt;Merry Christmas to everyone. I hope you get some rest and can spend time with people who are dear to you and get to focus on what's important rather than getting lost in stressing about everything having to be perfect.&lt;p&gt;Also much love to everyone who cannot spend their Christmas with dear people.&lt;p&gt;To make sure this post meets the relevancy criteria, here is a Wikipedia article about some Christmas (more precisely advent) tradition which I personally really like: &lt;a href="https://en.wikipedia.org/wiki/Christmas_market"&gt;https://en.wikipedia.org/wiki/Christmas_market&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;br/&gt;
&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380660&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=Grosvenor"&gt;Grosvenor&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380660"&gt;13 minutes ago&lt;/a&gt;  | &lt;a href="#46380357"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;         *             ,
                      _/^\_
                     &amp;lt;     &amp;gt;
    *                 /.-.\         *
             *        `/&amp;amp;\`                   *
                     ,@.*;@,
                    /_o.I %_\    *
       *           (`'--:o(_@;
                  /`;--.,__ `')             *
                 ;@`o % O,*`'`&amp;amp;\
           *    (`'--)_@ ;o %'()\      *
                /`;--._`''--._O'@;
               /&amp;amp;*,()~o`;-.,_ `""`)
    *          /`,@ ;+&amp;amp; () o*`;-';\
              (`""--.,_0 +% @' &amp;amp;()\
              /-.,_    ``''--....-'`)  *
         *    /@%;o`:;'--,.__   __.'\
             ;*,&amp;amp;(); @ % &amp;amp;^;~`"`o;@();         *
             /(); o^~; &amp;amp; ().o@*&amp;amp;`;&amp;amp;%O\
       jgs   `"="==""==,,,.,="=="==="`
          __.----.(\-''#####---...___...-----._
        '`         \)_`"""""`
                .--' ')
              o(  )_-\
                `"""` `&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380660&amp;amp;goto=item%3Fid%3D46380168%2346380660"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380357&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=DetectDefect"&gt;DetectDefect&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380357"&gt;52 minutes ago&lt;/a&gt;  | &lt;a href="#46380660"&gt;prev&lt;/a&gt; | &lt;a href="#46380391"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Shall we showcase our trees?&lt;p&gt;&lt;pre&gt;&lt;code&gt;        *
        |
       /.\
      /o..\
      /..O\
     /.o..o\
     /...o.\
    /..O..o.\
    ^^^[_]^^^&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380357&amp;amp;goto=item%3Fid%3D46380168%2346380357"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380526&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=cluckindan"&gt;cluckindan&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380526"&gt;30 minutes ago&lt;/a&gt;  | &lt;a href="#46380357"&gt;parent&lt;/a&gt; | &lt;a href="#46380749"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;      o
     / \
    o   o
       / \
      o   o
         / \
        o   o
       /   / \
      o   o   o
         /   / \
        o   o   o
&lt;/code&gt;&lt;/pre&gt;
I knew I should have invested in that fancy self-balancing one, oh well.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380526&amp;amp;goto=item%3Fid%3D46380168%2346380526"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380671&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=basilikum"&gt;basilikum&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380671"&gt;12 minutes ago&lt;/a&gt;  | &lt;a href="#46380357"&gt;root&lt;/a&gt; | &lt;a href="#46380526"&gt;parent&lt;/a&gt; | &lt;a href="#46380749"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Ah, don't worry. If you just append to one side always and do an anti-balancing one, you get a string of lights.&lt;p&gt;&lt;pre&gt;&lt;code&gt;  o  
   \  
    o  
     \  
      o  
       \  
        o  
         \  
          o  
           \  
            o  
             \  
              o  
               \  
                o&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380671&amp;amp;goto=item%3Fid%3D46380168%2346380671"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380749&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=blazingbanana"&gt;blazingbanana&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380749"&gt;1 minute ago&lt;/a&gt;  | &lt;a href="#46380357"&gt;parent&lt;/a&gt; | &lt;a href="#46380526"&gt;prev&lt;/a&gt; | &lt;a href="#46380469"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;                                .-^-.
                               /_/_\_\
                              /_/_/_\_\
                             /_/_/_/_\_\
                            /_/_/_/_/_\_\
                           /_/_/_o_/_/_\_\
                          /_/_o_/_/_o_/_\_\
                         /_/_/_/_/_/_/_/_\_\
                        /_/_o_/_/_o_/_/_/_\_\
                       /_/_/_/_/_/_/_/_/_/_\_\
                      /_/_/_o_/_/_o_/_/_o_/_\_\
                     /_/_/_/_/_/_/_/_/_/_/_/_\_\
                    /_/_o_/_/_o_/_/_o_/_/_o_/_\_\
                   /_/_/_/_/_/_/_/_/_/_/_/_/_/_\_\
                 /_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_\_\
                /_/_o_/_/_o_/_/_o_/_/_o_/_/_o_/_/_\_\
              /_/_/_/Merry Christmas HackerNews__/_/\_\
             /_/_o_/_/_o_/_/_o_/_/_o_/_/_o_/_/_o_/_/_\_\
            /_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_/_\_\
                           |||||||||||||||
                           |||||||||||||||
                           |||||||||||||||
                           |||||||||||||||
                          _|||||||||||||||_&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380749&amp;amp;goto=item%3Fid%3D46380168%2346380749"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380469&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sallveburrpi"&gt;sallveburrpi&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380469"&gt;37 minutes ago&lt;/a&gt;  | &lt;a href="#46380357"&gt;parent&lt;/a&gt; | &lt;a href="#46380749"&gt;prev&lt;/a&gt; | &lt;a href="#46380391"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;           @
          ***
         *****
        *******
       *********
      ***********
     *************
    ***************
           |
           |
&lt;/code&gt;&lt;/pre&gt;
Best I can do ;/&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380469&amp;amp;goto=item%3Fid%3D46380168%2346380469"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380756&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=blazingbanana"&gt;blazingbanana&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380756"&gt;0 minutes ago&lt;/a&gt;  | &lt;a href="#46380357"&gt;root&lt;/a&gt; | &lt;a href="#46380469"&gt;parent&lt;/a&gt; | &lt;a href="#46380504"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
It's the thought that counts&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380756&amp;amp;goto=item%3Fid%3D46380168%2346380756"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380504&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=xandrius"&gt;xandrius&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380504"&gt;32 minutes ago&lt;/a&gt;  | &lt;a href="#46380357"&gt;root&lt;/a&gt; | &lt;a href="#46380469"&gt;parent&lt;/a&gt; | &lt;a href="#46380756"&gt;prev&lt;/a&gt; | &lt;a href="#46380391"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
¥&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380504&amp;amp;goto=item%3Fid%3D46380168%2346380504"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380391&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=tekacs"&gt;tekacs&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380391"&gt;46 minutes ago&lt;/a&gt;  | &lt;a href="#46380357"&gt;prev&lt;/a&gt; | &lt;a href="#46380657"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Fun seeing HN restart to switch to the Christmas theme, in three steps:&lt;p&gt;&lt;a href="https://share.cleanshot.com/vJZv6k03"&gt;https://share.cleanshot.com/vJZv6k03&lt;/a&gt; (restarting the server)&lt;p&gt;&lt;a href="https://share.cleanshot.com/qFyM347P"&gt;https://share.cleanshot.com/qFyM347P&lt;/a&gt; (online but temporarily readonly)&lt;p&gt;&lt;a href="https://share.cleanshot.com/kW8kY7mp"&gt;https://share.cleanshot.com/kW8kY7mp&lt;/a&gt; (back online!)&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380391&amp;amp;goto=item%3Fid%3D46380168%2346380391"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380665&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=dang"&gt;dang&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380665"&gt;13 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;parent&lt;/a&gt; | &lt;a href="#46380695"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
You must have grabbed that first one awfully quickly!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380665&amp;amp;goto=item%3Fid%3D46380168%2346380665"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380695&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=brcmthrowaway"&gt;brcmthrowaway&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380695"&gt;8 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;parent&lt;/a&gt; | &lt;a href="#46380665"&gt;prev&lt;/a&gt; | &lt;a href="#46380444"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
What container is this running in?&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380695&amp;amp;goto=item%3Fid%3D46380168%2346380695"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380444&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=jagged-chisel"&gt;jagged-chisel&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380444"&gt;40 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;parent&lt;/a&gt; | &lt;a href="#46380695"&gt;prev&lt;/a&gt; | &lt;a href="#46380657"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Restart?!&lt;p&gt;ouch&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380444&amp;amp;goto=item%3Fid%3D46380168%2346380444"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380748&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=kelnos"&gt;kelnos&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380748"&gt;2 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;root&lt;/a&gt; | &lt;a href="#46380444"&gt;parent&lt;/a&gt; | &lt;a href="#46380481"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I feel like this obsession with zero downtime has gotten a bit silly.  Sure, for some things it's damn near required (though I imagine that's fewer things than most people think), but it 100% does not matter even a little bit if HN is unavailable for 10 seconds or so.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380748&amp;amp;goto=item%3Fid%3D46380168%2346380748"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380481&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=basilikum"&gt;basilikum&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380481"&gt;36 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;root&lt;/a&gt; | &lt;a href="#46380444"&gt;parent&lt;/a&gt; | &lt;a href="#46380748"&gt;prev&lt;/a&gt; | &lt;a href="#46380662"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
HN is a pretty simple, efficient monolithic web application. Some updates might need a restart. It's OK for some web requests to fail during that time. HN isn't life critical with sixtuple nine uptime requirements.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380481&amp;amp;goto=item%3Fid%3D46380168%2346380481"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380759&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=uyzstvqs"&gt;uyzstvqs&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380759"&gt;0 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;root&lt;/a&gt; | &lt;a href="#46380481"&gt;parent&lt;/a&gt; | &lt;a href="#46380502"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
It could probably be done with a simple if statement, but I'm guessing that dang enjoys the tradition of doing it manually every year.&lt;p&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380502&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sallveburrpi"&gt;sallveburrpi&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380502"&gt;33 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;root&lt;/a&gt; | &lt;a href="#46380481"&gt;parent&lt;/a&gt; | &lt;a href="#46380759"&gt;prev&lt;/a&gt; | &lt;a href="#46380668"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Tbh like 99% of web apps aren’t critical - most of them are for buying something or providing infrastructure to make it easier to buy something anyway.
It’s fine if your online shop is down for a few minutes (of course the business won’t see it like that but it’s true)&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380502&amp;amp;goto=item%3Fid%3D46380168%2346380502"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380555&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=basilikum"&gt;basilikum&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380555"&gt;26 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;root&lt;/a&gt; | &lt;a href="#46380502"&gt;parent&lt;/a&gt; | &lt;a href="#46380668"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
A sales site being down might lose you a sale. But the simplicity might save you so muh more than that loses you. And often the complexion of high availability infrastructure results in more downtime than it prevents.&lt;p&gt;For stuff like HN, I like the peek behind the scenes it provides. It's all just software written by some humans and way too often people take themselves and their shitty software way too serious.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380555&amp;amp;goto=item%3Fid%3D46380168%2346380555"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380668&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=lomase"&gt;lomase&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380668"&gt;12 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;root&lt;/a&gt; | &lt;a href="#46380481"&gt;parent&lt;/a&gt; | &lt;a href="#46380502"&gt;prev&lt;/a&gt; | &lt;a href="#46380662"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Steam, +130 million users, biggest gamming store, multi billion dolar company, is offline every week for a few minutes.&lt;p&gt;99.999999 is so overated.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380668&amp;amp;goto=item%3Fid%3D46380168%2346380668"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380662&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=dang"&gt;dang&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380662"&gt;13 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;root&lt;/a&gt; | &lt;a href="#46380444"&gt;parent&lt;/a&gt; | &lt;a href="#46380481"&gt;prev&lt;/a&gt; | &lt;a href="#46380657"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I'd rather restart once (well, twice) a year than keep that code around in production all the time.&lt;p&gt;It only affects traffic for about 10 seconds.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380662&amp;amp;goto=item%3Fid%3D46380168%2346380662"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380657&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=jherdman"&gt;jherdman&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380657"&gt;13 minutes ago&lt;/a&gt;  | &lt;a href="#46380391"&gt;prev&lt;/a&gt; | &lt;a href="#46380495"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas, friends. And a special cheers to everyone that makes this community possible. It’s one of the last bastions of all that is good about this internet.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380657&amp;amp;goto=item%3Fid%3D46380168%2346380657"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380495&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=gavide"&gt;gavide&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380495"&gt;34 minutes ago&lt;/a&gt;  | &lt;a href="#46380657"&gt;prev&lt;/a&gt; | &lt;a href="#46380739"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠈⠀⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⢀⠀⠀⡰⡇⠁⠀⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠀⠀⠰⢾⠇⠨⡦⠀⠂⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⡀⠀⢈⣹⠜⠻⢾⠃⠀⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⠁⢠⣿⡵⠾⣻⣶⠿⠦⠀⠀⠀⠀⠀⠀ ⠀⠀⠀⠀⢀⠀⢀⣠⣮⣦⡶⠻⠛⢶⣄⡀⠁⠀⠀⠀⠀ ⠀⠀⠀⠀⠀⠀⢀⣽⠏⠁⣠⣂⣦⣈⣝⣦⣄⠀⠈⠁⠀ ⠀⠀⠀⠀⠁⣠⣾⣵⣾⣾⠟⡙⠟⠿⣍⡉⠀⠀⠆⠀⠀ ⠀⠰⠀⠀⠄⣠⣶⣾⣭⡶⠟⠻⣶⡰⣜⣳⣦⣄⠀⡀⠀ ⠀⠀⠀⢀⣠⣴⣿⣋⡴⣪⠎⣄⡙⠻⠿⣯⣉⠉⠀⠀⠀ ⠀⠂⠀⢀⣉⡭⢿⡛⣛⣵⠎⠀⠙⢾⣶⣦⣭⣷⣦⠐⠀ ⠀⠀⢈⣙⣿⡿⠿⠟⣋⢅⡄⡄⡐⣄⢤⣉⠷⢦⣄⣀⠠ ⠐⠾⠿⢽⣷⡶⠶⡿⣓⣭⣾⣿⢷⣬⣓⢿⠿⠿⣯⣉⣁ ⠀⠀⠀⠉⠉⠉⠛⠛⠉⢀⣿⢿⡀⠙⠋⠓⠿⠿⠏⠉⠉ ⠀⠀⠀⠀⠀⠀⠠⠤⠶⠾⢿⡯⠷⠶⠤⠄⠀⠀⠀⠀⠀&lt;p&gt;Merry Christmas, HN!&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380495&amp;amp;goto=item%3Fid%3D46380168%2346380495"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380690&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=brulard"&gt;brulard&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380690"&gt;9 minutes ago&lt;/a&gt;  | &lt;a href="#46380495"&gt;parent&lt;/a&gt; | &lt;a href="#46380739"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
not sure what i'm looking at here...&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380690&amp;amp;goto=item%3Fid%3D46380168%2346380690"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380739&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=shredprez"&gt;shredprez&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380739"&gt;3 minutes ago&lt;/a&gt;  | &lt;a href="#46380495"&gt;prev&lt;/a&gt; | &lt;a href="#46380462"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas, everyone! Continually grateful for this community: stumbling into it as a teenager changed my life and I never get tired of spinning out about new tech big and small with the folks here. Stay safe, everybody&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380739&amp;amp;goto=item%3Fid%3D46380168%2346380739"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380462&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=dzink"&gt;dzink&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380462"&gt;38 minutes ago&lt;/a&gt;  | &lt;a href="#46380739"&gt;prev&lt;/a&gt; | &lt;a href="#46380531"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
May everyone here discover more and better ways to spread the joy of giving and doing good.&lt;p&gt;&lt;pre&gt;&lt;code&gt;              *
             /_\
            / o \
           /  *  \
          / o   o \
         /  . * .  \
        / o  * *  o \
       /  . * o * .  \
      / o  * * * *  o \
     /  . * o * o * .  \
    / o  * * * * * *  o \
   /______________________\
            |||||| 
            |||||| 
            ||||||&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380462&amp;amp;goto=item%3Fid%3D46380168%2346380462"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380531&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=pdevr"&gt;pdevr&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380531"&gt;29 minutes ago&lt;/a&gt;  | &lt;a href="#46380462"&gt;prev&lt;/a&gt; | &lt;a href="#46380728"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas to everyone.&lt;p&gt;Being a non-Christian and it being Christmas time, I am sharing one verse from the New Testament that is, in my opinion, useful - or at the very least, insightful - to anyone, regardless of religion.&lt;p&gt;Luke 16:10: He who is faithful in a very little thing is faithful also in much; and he who is unrighteous in a very little thing is unrighteous also in much.&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380531&amp;amp;goto=item%3Fid%3D46380168%2346380531"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380728&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=ilaksh"&gt;ilaksh&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380728"&gt;4 minutes ago&lt;/a&gt;  | &lt;a href="#46380531"&gt;prev&lt;/a&gt; | &lt;a href="#46380689"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://codepen.io/LimeWub/full/yQWbNW"&gt;https://codepen.io/LimeWub/full/yQWbNW&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380728&amp;amp;goto=item%3Fid%3D46380168%2346380728"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380689&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=BewareTheYiga"&gt;BewareTheYiga&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380689"&gt;9 minutes ago&lt;/a&gt;  | &lt;a href="#46380728"&gt;prev&lt;/a&gt; | &lt;a href="#46380717"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;             *
            /*\
           /***\
          /*****\
         /*******\
        /*********\
       /***  *  ***\
      /*************\
     /***  *  *  ****\
    /*****************\
   /***  *  *  *  *****\
  /*********************\
 /********** *** ********\
            |||
            |||
            |||
&lt;/code&gt;&lt;/pre&gt;
Merry Christmas, HN&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380689&amp;amp;goto=item%3Fid%3D46380168%2346380689"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380717&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=coffeemug"&gt;coffeemug&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380717"&gt;5 minutes ago&lt;/a&gt;  | &lt;a href="#46380689"&gt;prev&lt;/a&gt; | &lt;a href="#46380712"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Hope everyone has a healthy, rewarding and prosperous year. Special thanks to @dang and team for keeping this community a great place everyone wants to come back to. I love coming back here every day.&lt;p&gt;Merry Christmas to all!&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380717&amp;amp;goto=item%3Fid%3D46380168%2346380717"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380712&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=shortcord"&gt;shortcord&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380712"&gt;6 minutes ago&lt;/a&gt;  | &lt;a href="#46380717"&gt;prev&lt;/a&gt; | &lt;a href="#46380659"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Luke 2:14&lt;p&gt;&lt;pre&gt;&lt;code&gt;    [14] “Glory to God in the highest,
        and on earth peace among those with whom he is pleased!”&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380712&amp;amp;goto=item%3Fid%3D46380168%2346380712"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380659&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=randycupertino"&gt;randycupertino&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380659"&gt;13 minutes ago&lt;/a&gt;  | &lt;a href="#46380712"&gt;prev&lt;/a&gt; | &lt;a href="#46380452"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Here's to a happy and healthy 2026!&lt;p&gt;Thanks HN for all the thoughtful comments and interesting articles.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380659&amp;amp;goto=item%3Fid%3D46380168%2346380659"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380452&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=robofanatic"&gt;robofanatic&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380452"&gt;39 minutes ago&lt;/a&gt;  | &lt;a href="#46380659"&gt;prev&lt;/a&gt; | &lt;a href="#46380596"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;          *
         /|\
        //|\\
       ///|\\\
      ////|\\\\    
          |&lt;/code&gt;&lt;/pre&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380452&amp;amp;goto=item%3Fid%3D46380168%2346380452"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380596&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=lschueller"&gt;lschueller&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380596"&gt;21 minutes ago&lt;/a&gt;  | &lt;a href="#46380452"&gt;prev&lt;/a&gt; | &lt;a href="#46380750"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas to the awesome hn community!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380596&amp;amp;goto=item%3Fid%3D46380168%2346380596"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380750&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=tamimio"&gt;tamimio&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380750"&gt;1 minute ago&lt;/a&gt;  | &lt;a href="#46380596"&gt;prev&lt;/a&gt; | &lt;a href="#46380598"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Technically it’s merry Yule and Saturnalia, christ has nothing to do with it.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380750&amp;amp;goto=item%3Fid%3D46380168%2346380750"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380598&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=merryxmas"&gt;merryxmas&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380598"&gt;21 minutes ago&lt;/a&gt;  | &lt;a href="#46380750"&gt;prev&lt;/a&gt; | &lt;a href="#46380487"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;p&gt;&lt;pre&gt;&lt;code&gt;             Ⓜerry    
                           
           ©hr®istmas ‼ ⁉

           ⭕
          ↙▫⬇↘
         ↙▫↙⬇↘↘
        ↙↙▫↙⬇↘▫↘↘
      ↙▫↙㊗↙⬇↘↘▫↘↘
      ↙↙↙▫↙↙⬇↘▫↘↘↘↘
          #⃣#⃣
          ◽◾◽
&lt;/code&gt;&lt;/pre&gt;
#⃣ #⃣ #⃣ ™ ℹ ↔ ↕ ↖ ↗ ↘ ↙ ↩ ↪ ⌚ ⌛       ▪ ▫ ▶
◀ ◻ ◼ ◽ ◾                    
♠ ♣ ♥ ♦ ♨                    ⤴
⤵ ⬅ ⬆ ⬇ ⬛ ⬜  ⭕ 〰 〽 ㊗ ㊙&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380598&amp;amp;goto=item%3Fid%3D46380168%2346380598"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380487&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=judah"&gt;judah&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380487"&gt;35 minutes ago&lt;/a&gt;  | &lt;a href="#46380598"&gt;prev&lt;/a&gt; | &lt;a href="#46380699"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas!&lt;p&gt;"An angel of the Lord appeared to them, and the glory of the Lord shone around them, and they were terrified. But the angel said to them, “Do not be afraid. I bring you good news that will cause great joy for all the people. Today in the town of David a Savior has been born to you; he is the Messiah, the Lord. This will be a sign to you: You will find a baby wrapped in cloths and lying in a manger.” Suddenly a great company of the heavenly host appeared with the angel, praising God and saying,&lt;p&gt;“Glory to God in the highest heaven, and on earth peace to those on whom his favor rests.”"&lt;p&gt;-Luke 2&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380487&amp;amp;goto=item%3Fid%3D46380168%2346380487"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380616&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sneak"&gt;sneak&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380616"&gt;18 minutes ago&lt;/a&gt;  | &lt;a href="#46380487"&gt;parent&lt;/a&gt; | &lt;a href="#46380699"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Thankfully, christmas is no longer a religious holiday.  Now we can all participate together.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380616&amp;amp;goto=item%3Fid%3D46380168%2346380616"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380699&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=givemeethekeys"&gt;givemeethekeys&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380699"&gt;7 minutes ago&lt;/a&gt;  | &lt;a href="#46380487"&gt;prev&lt;/a&gt; | &lt;a href="#46380484"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas, everyone!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380699&amp;amp;goto=item%3Fid%3D46380168%2346380699"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380484&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=defrost"&gt;defrost&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380484"&gt;36 minutes ago&lt;/a&gt;  | &lt;a href="#46380699"&gt;prev&lt;/a&gt; | &lt;a href="#46380716"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
and a healthy dose of Australian Christmas Stereotypes to all: &lt;a href="https://www.youtube.com/watch?v=amL8QRiDH2E"&gt;https://www.youtube.com/watch?v=amL8QRiDH2E&lt;/a&gt;&lt;p&gt;including not the original Rolf Harris version: &lt;a href="https://www.youtube.com/watch?v=CQVEZLcBfS8"&gt;https://www.youtube.com/watch?v=CQVEZLcBfS8&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380484&amp;amp;goto=item%3Fid%3D46380168%2346380484"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380716&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=arjonagelhout"&gt;arjonagelhout&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380716"&gt;6 minutes ago&lt;/a&gt;  | &lt;a href="#46380484"&gt;prev&lt;/a&gt; | &lt;a href="#46380577"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas!&lt;p&gt;Here’s a quad tree:&lt;p&gt;11&lt;p&gt;11&lt;p&gt;—&lt;p&gt;0110&lt;p&gt;0110&lt;p&gt;1111&lt;p&gt;0110&lt;p&gt;—&lt;p&gt;00000000&lt;p&gt;00011000&lt;p&gt;00011000&lt;p&gt;00111100&lt;p&gt;01111110&lt;p&gt;11111111&lt;p&gt;00011000&lt;p&gt;00011000&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380716&amp;amp;goto=item%3Fid%3D46380168%2346380716"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380577&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=tehlike"&gt;tehlike&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380577"&gt;24 minutes ago&lt;/a&gt;  | &lt;a href="#46380716"&gt;prev&lt;/a&gt; | &lt;a href="#46380441"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas! I hope everyone has wonderful time with family.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380577&amp;amp;goto=item%3Fid%3D46380168%2346380577"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380441&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=Wasserpuncher"&gt;Wasserpuncher&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380441"&gt;41 minutes ago&lt;/a&gt;  | &lt;a href="#46380577"&gt;prev&lt;/a&gt; | &lt;a href="#46380439"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380441&amp;amp;goto=item%3Fid%3D46380168%2346380441"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380439&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=nullable_bool"&gt;nullable_bool&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380439"&gt;41 minutes ago&lt;/a&gt;  | &lt;a href="#46380441"&gt;prev&lt;/a&gt; | &lt;a href="#46380493"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry x-mas.  We all deserve love and happiness.  Be kind to your neighboor.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380439&amp;amp;goto=item%3Fid%3D46380168%2346380439"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380493&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=xandrius"&gt;xandrius&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380493"&gt;34 minutes ago&lt;/a&gt;  | &lt;a href="#46380439"&gt;prev&lt;/a&gt; | &lt;a href="#46380631"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
"A Spaceman Came Travelling" - Chris de Burgh&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380493&amp;amp;goto=item%3Fid%3D46380168%2346380493"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380631&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=GreyZephyr"&gt;GreyZephyr&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380631"&gt;15 minutes ago&lt;/a&gt;  | &lt;a href="#46380493"&gt;prev&lt;/a&gt; | &lt;a href="#46380423"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380631&amp;amp;goto=item%3Fid%3D46380168%2346380631"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380423&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=koakuma-chan"&gt;koakuma-chan&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380423"&gt;42 minutes ago&lt;/a&gt;  | &lt;a href="#46380631"&gt;prev&lt;/a&gt; | &lt;a href="#46380535"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I got scared when I refreshed and HN turned red&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380423&amp;amp;goto=item%3Fid%3D46380168%2346380423"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380535&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=robertwt7"&gt;robertwt7&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380535"&gt;29 minutes ago&lt;/a&gt;  | &lt;a href="#46380423"&gt;prev&lt;/a&gt; | &lt;a href="#46380447"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas everyone!!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380535&amp;amp;goto=item%3Fid%3D46380168%2346380535"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380447&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=nervysnail"&gt;nervysnail&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380447"&gt;40 minutes ago&lt;/a&gt;  | &lt;a href="#46380535"&gt;prev&lt;/a&gt; | &lt;a href="#46380458"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I was surprised to see HN change colour.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380447&amp;amp;goto=item%3Fid%3D46380168%2346380447"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380458&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=stoneman24"&gt;stoneman24&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380458"&gt;38 minutes ago&lt;/a&gt;  | &lt;a href="#46380447"&gt;prev&lt;/a&gt; | &lt;a href="#46380580"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
A Merry Christmas to everyone !&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380458&amp;amp;goto=item%3Fid%3D46380168%2346380458"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380580&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=tuggi"&gt;tuggi&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380580"&gt;24 minutes ago&lt;/a&gt;  | &lt;a href="#46380458"&gt;prev&lt;/a&gt; | &lt;a href="#46380451"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Xmas HN!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380580&amp;amp;goto=item%3Fid%3D46380168%2346380580"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380451&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=drfuzzy89"&gt;drfuzzy89&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380451"&gt;39 minutes ago&lt;/a&gt;  | &lt;a href="#46380580"&gt;prev&lt;/a&gt; | &lt;a href="#46380453"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas, everyone!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380451&amp;amp;goto=item%3Fid%3D46380168%2346380451"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380453&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=spankibalt"&gt;spankibalt&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380453"&gt;39 minutes ago&lt;/a&gt;  | &lt;a href="#46380451"&gt;prev&lt;/a&gt; | &lt;a href="#46380592"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas, bambini.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380453&amp;amp;goto=item%3Fid%3D46380168%2346380453"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380592&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=bossyTeacher"&gt;bossyTeacher&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380592"&gt;22 minutes ago&lt;/a&gt;  | &lt;a href="#46380453"&gt;prev&lt;/a&gt; | &lt;a href="#46380552"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJtZXNzYWdlIjoiTWVycnkgQ2hyaXN0bWFzIiwidG8iOiJIYWNrZXIgTmV3cyJ9.Lg_fp5WWKGLpbxI_YbRY-CfQiXe-gLXzDFMiChkXzY0&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380592&amp;amp;goto=item%3Fid%3D46380168%2346380592"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380552&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=reactordev"&gt;reactordev&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380552"&gt;26 minutes ago&lt;/a&gt;  | &lt;a href="#46380592"&gt;prev&lt;/a&gt; | &lt;a href="#46380195"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
What a year!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380552&amp;amp;goto=item%3Fid%3D46380168%2346380552"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380195&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=agentifysh"&gt;agentifysh&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380195"&gt;1 hour ago&lt;/a&gt;  | &lt;a href="#46380552"&gt;prev&lt;/a&gt; | &lt;a href="#46380558"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas y'all
keep promptin'&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380195&amp;amp;goto=item%3Fid%3D46380168%2346380195"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380558&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=michaelsbradley"&gt;michaelsbradley&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380558"&gt;26 minutes ago&lt;/a&gt;  | &lt;a href="#46380195"&gt;prev&lt;/a&gt; | &lt;a href="#46380432"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas&lt;p&gt;Christus natus est&lt;p&gt;O Χριστός γεννιέται&lt;p&gt;Христос раждается&lt;p&gt;המשיח נולד&lt;p&gt;ابن الله يولد اليوم&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380558&amp;amp;goto=item%3Fid%3D46380168%2346380558"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380432&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=tory"&gt;tory&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380432"&gt;41 minutes ago&lt;/a&gt;  | &lt;a href="#46380558"&gt;prev&lt;/a&gt; | &lt;a href="#46380545"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas :)&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380432&amp;amp;goto=item%3Fid%3D46380168%2346380432"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380545&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=black_knight"&gt;black_knight&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380545"&gt;27 minutes ago&lt;/a&gt;  | &lt;a href="#46380432"&gt;prev&lt;/a&gt; | &lt;a href="#46380482"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Meri Yule!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380545&amp;amp;goto=item%3Fid%3D46380168%2346380545"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380482&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sallveburrpi"&gt;sallveburrpi&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380482"&gt;36 minutes ago&lt;/a&gt;  | &lt;a href="#46380545"&gt;prev&lt;/a&gt; | &lt;a href="#46380387"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Feliz natal&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380482&amp;amp;goto=item%3Fid%3D46380168%2346380482"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380387&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=aclark"&gt;aclark&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380387"&gt;46 minutes ago&lt;/a&gt;  | &lt;a href="#46380482"&gt;prev&lt;/a&gt; | &lt;a href="#46380364"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry XMAS!!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380387&amp;amp;goto=item%3Fid%3D46380168%2346380387"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46380364&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46380168"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=curtisblaine"&gt;curtisblaine&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46380364"&gt;51 minutes ago&lt;/a&gt;  | &lt;a href="#46380387"&gt;prev&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Merry Christmas!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46380364&amp;amp;goto=item%3Fid%3D46380168%2346380364"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;br/&gt;&lt;br/&gt;
&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;br/&gt;
&lt;a href="https://news.ycombinator.com/newsguidelines.html"&gt;Guidelines&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/newsfaq.html"&gt;FAQ&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/lists"&gt;Lists&lt;/a&gt; | &lt;a href="https://github.com/HackerNews/API"&gt;API&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/security.html"&gt;Security&lt;/a&gt; | &lt;a href="https://www.ycombinator.com/legal/"&gt;Legal&lt;/a&gt; | &lt;a href="https://www.ycombinator.com/apply/"&gt;Apply to YC&lt;/a&gt; | &lt;a href="mailto:hn@ycombinator.com"&gt;Contact&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;
&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://news.ycombinator.com/item?id=46380168</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 22:56:00 +0000</pubDate>
    </item>
    <item>
      <title>Phoenix: A modern X server written from scratch in Zig</title>
      <link>https://git.dec05eba.com/phoenix/about/</link>
      <description>Phoenix is a new X server, written from scratch in Zig (not a fork of Xorg server). This X server is designed to be a modern alternative to the Xorg server.</description>
      <content:encoded>&lt;div class="content"&gt;&lt;h1&gt;Phoenix&lt;/h1&gt;
&lt;p&gt;Phoenix is a new X server, written from scratch in Zig (not a fork of Xorg server). This X server is designed to be a modern alternative to the Xorg server.&lt;/p&gt;
&lt;h2&gt;Current state&lt;/h2&gt;
&lt;p&gt;Phoenix is not ready to be used yet. At the moment it can render simple applications that do GLX, EGL or Vulkan graphics (fully hardware accelerated) nested in an existing X server.
Running Phoenix nested will be the only supported mode until Phoenix has progressed more and can run real-world applications.&lt;/p&gt;
&lt;h2&gt;Goals&lt;/h2&gt;
&lt;h3&gt;Simplicity&lt;/h3&gt;
&lt;p&gt;Be a simpler X server than the Xorg server by only supporting a subset of the X11 protocol, the features that are needed by relatively modern applications (applications written in the last ~20 years).&lt;br/&gt;
Only relatively modern hardware (made in the last ~15 years) which support linux drm and mesa gbm will be supported, and no server driver interface like the Xorg server. Just like how Wayland compositors work.&lt;/p&gt;
&lt;h3&gt;Security&lt;/h3&gt;
&lt;p&gt;Be safer than the Xorg server by parsing protocol messages automatically. As it's written in Zig, it also automatically catches illegal behaviors (such as index out of array bounds) when building with the &lt;code&gt;ReleaseSafe&lt;/code&gt; option.&lt;/p&gt;
&lt;p&gt;Applications will be isolated from each other by default and can only interact with other applications either through a GUI prompt asking for permission,
such as with screen recorders, where it will only be allowed to record the window specified
or by explicitly giving the application permission before launched (such as a window manager or external compositor).
This will not break existing clients as clients wont receive errors when they try to access more than they need, they will instead receive dummy data.&lt;br/&gt;
Applications that rely on global hotkeys should work, as long as a modifier key is pressed (keys such as ctrl, shift, alt and super). If an application needs global hotkeys without pressing a modifier key
then it needs to be given permissions to do so (perhaps by adding a command to run a program with more X11 permissions).&lt;br/&gt;
There will be an option to disable this to make the X server behave like the Xorg server.&lt;/p&gt;
&lt;h3&gt;Improvements for modern technology&lt;/h3&gt;
&lt;p&gt;Support modern hardware better than the Xorg server, such as proper support for multiple monitors (different refresh rates, VRR - not a single framebuffer for the whole collection of displays) and technology like HDR.&lt;/p&gt;
&lt;h3&gt;Improved graphics handling&lt;/h3&gt;
&lt;p&gt;No tearing by default and a built-in compositor. The compositor will get disabled if the user runs an external compositor (client application), such as picom
or if the client runs a fullscreen application and disabled vsync in the application. The goal is to also have lower vsync/compositor latency than the Xorg server.&lt;/p&gt;
&lt;h3&gt;New standards&lt;/h3&gt;
&lt;p&gt;New standards will be developed and documented, such as per-monitor DPI as randr properties.
Applications can use this property to scale their content to the specified DPI for the monitor they are on.&lt;/p&gt;
&lt;h3&gt;Extending the X11 protocol&lt;/h3&gt;
&lt;p&gt;If there is a need for new features (such as HDR) then the X11 protocol will be extended.&lt;/p&gt;
&lt;h3&gt;Wayland compatibility&lt;/h3&gt;
&lt;p&gt;Some applications might only run on Wayland in the future. Such applications should be supported by either Phoenix supporting Wayland natively or by running
an external application that works as a bridge between Wayland and X11 (such as 12to11).&lt;/p&gt;
&lt;h3&gt;Nested display server&lt;/h3&gt;
&lt;p&gt;Being able to run Phoenix nested under X11 or Wayland with hardware acceleration.
This is not only useful for debugging Phoenix but also for developers who want to test their window manager or compositor without restarting the display server they are running.&lt;br/&gt;
Being able to run Phoenix under Wayland as an alternative Xwayland server would be a good option.&lt;/p&gt;
&lt;h2&gt;Non-goals&lt;/h2&gt;
&lt;h3&gt;Replacing the Xorg server&lt;/h3&gt;
&lt;p&gt;The Xorg server will always support more features of the X11 protocol and wider range of hardware (especially older ones).&lt;/p&gt;
&lt;h3&gt;Multiple &lt;em&gt;screens&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;Multiple displays (monitors) are going to be supported but not X11 screens.&lt;/p&gt;
&lt;h3&gt;Exclusive access&lt;/h3&gt;
&lt;p&gt;GrabServer has no effect in Phoenix.&lt;/p&gt;
&lt;h3&gt;Endian-swapped client/server&lt;/h3&gt;
&lt;p&gt;This can be reconsidered if there is a reason.&lt;/p&gt;
&lt;h3&gt;Indirect (remote) GLX.&lt;/h3&gt;
&lt;p&gt;This is very complex as there are a lot of functions that would need to be implemented. These days remote streaming options are more efficient. Alternatively a proxy for glx could be implemented that does remote rendering.&lt;/p&gt;
&lt;h2&gt;Differences between the X11 protocol and Phoenix&lt;/h2&gt;
&lt;h3&gt;Core protocol&lt;/h3&gt;
&lt;p&gt;Several parts of the X11 protocol (core) are mandatory to be implemented by an X server, such as font related operations. However these are not going to be implemented in Phoenix.&lt;/p&gt;
&lt;h3&gt;Strings&lt;/h3&gt;
&lt;p&gt;Strings are in ISO Latin-1 encoding in the X11 protocol unless specified otherwise, however in Phoenix all strings are UTF-8 unless the protocol states that it's not an ISO Latin-1 string.&lt;/p&gt;
&lt;h2&gt;Installing&lt;/h2&gt;
&lt;p&gt;Run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;zig build -Doptimize=ReleaseSafe
sudo zig build install -p /usr/local -Doptimize=ReleaseSafe
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Uninstalling&lt;/h2&gt;
&lt;p&gt;Zig does currently not support the uninstall command so you have to remove files manually:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo rm /usr/local/bin/phoenix
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Building (for development)&lt;/h2&gt;
&lt;p&gt;Run &lt;code&gt;zig build&lt;/code&gt;, which builds Phoenix in debug mode. The compiled binary will be available at &lt;code&gt;./zig-out/bin/phoenix&lt;/code&gt;. You can alternatively build and run with one command: &lt;code&gt;zig build run&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;Generate x11 protocol documentation&lt;/h3&gt;
&lt;p&gt;Run &lt;code&gt;zig build -Dgenerate-docs=true&lt;/code&gt;. This will generate &lt;code&gt;.txt&lt;/code&gt; files in &lt;code&gt;./zig-out/protocol/&lt;/code&gt;. This generates x11 protocol documentation in the style of the official protocol documentation. The documentation is automatically generated from the protocol struct code.
Note that the generated documentation feature is a work-in-progress.&lt;/p&gt;
&lt;h2&gt;Dependencies&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://ziglang.org/download/"&gt;Zig 0.14.1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;x11 (&lt;code&gt;xcb&lt;/code&gt;) - for nested mode under X11, when building Phoenix with &lt;code&gt;-Dbackends=x11&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;wayland (&lt;code&gt;wayland-client&lt;/code&gt;, &lt;code&gt;wayland-egl&lt;/code&gt;) - for nested mode under Wayland, when building Phoenix with &lt;code&gt;-Dbackends=wayland&lt;/code&gt; (not currently supported)&lt;/li&gt;
&lt;li&gt;drm (&lt;code&gt;libdrm&lt;/code&gt;, &lt;code&gt;gbm&lt;/code&gt;) - for running Phoenix as a standalone X11 server, when building Phoenix with &lt;code&gt;-Dbackends=drm&lt;/code&gt; (not currently supported)&lt;/li&gt;
&lt;li&gt;OpenGL (&lt;code&gt;libglvnd&lt;/code&gt; which provides both &lt;code&gt;gl&lt;/code&gt; and &lt;code&gt;egl&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://git.dec05eba.com/phoenix/about/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 22:43:53 +0000</pubDate>
    </item>
    <item>
      <title>I Left YouTube</title>
      <link>https://zhach.news/how-i-left-youtube/</link>
      <description>I remember sitting down in a meeting room hearing the results of my third try at promo cycle trying to get from an L4 to an L5. I helped launch/lead features on YouTube, I led teams, I designed and implemented systems that were still in use to that day by many people, people all across the org knew me and said I was indispensable to the company and were surprised that I wasn't already at an L5/6 level. The results of that meeting? The same from the previous promotion decisions; “it’s unfortunately a no. You don’t have enough impact.”</description>
      <content:encoded>&lt;article class="post single-post"&gt;


&lt;p&gt;I remember sitting down in a meeting room hearing the results of my third try at promo cycle trying to get from an L4 to an L5. I helped launch/lead features on YouTube, I led teams, I designed and implemented systems that were still in use to that day by many people, people all across the org knew me and said I was indispensable to the company and were surprised that I wasn't already at an L5/6 level. The results of that meeting? The same from the previous promotion decisions; “it’s unfortunately a no. You don’t have enough impact.”&lt;/p&gt;&lt;p&gt;That Tuesday afternoon realization kicked off a grueling, educational, and emotionally taxing journey: leaving a "dream job" to find out what I was actually worth in the open market.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;The Mathematics of Leveling&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;In the software engineering world, we exist on a ladder. We call this ”Leveling”.&lt;/p&gt;&lt;p&gt;For those outside the tech industry, imagine the military. You have Lieutenants, Captains, Majors, and Generals. In tech, these are usually denoted as L3 (Entry/Junior), L4 (Mid), L5 (Senior), and L6 (Staff). L1/2 are saved for contractors or interns. After these denominations, one usually switches to a director or someone on the Leadership team. Your level dictates your salary, your stock grants, and most importantly, the scope of problems you are allowed to solve.&lt;/p&gt;&lt;p&gt;I found myself in a situation common to many engineers at large organizations. I was operating at a “Senior” or “Staff" level (architecting systems and roadmaps rather than just writing the code and tracking bugs), but my official title and compensation were stuck at just above junior level.&lt;/p&gt;&lt;p&gt;I faced a choice: continue to do way more work to prove myself for the lottery that is the promo cycle or leave to find a company that would recognize my output immediately. I chose the latter. And I decided to attempt a "double level" jump during my interviews (L4 to L6). I didn't just want a lateral move; I wanted the title that matched the work I was already doing.&lt;/p&gt;&lt;img src="https://zhach.news/content/images/2025/11/dual-career-ladder-ic-vs-management.png"/&gt;&lt;a href="https://www.levels.fyi/blog/what-are-career-levels-ladders.html?from=2021_report&amp;amp;ref=zhach.news"&gt;levels.fyi&lt;/a&gt;&lt;h3&gt;&lt;strong&gt;The Double Life of the Employed Candidate&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Hunting for a job is a full-time occupation. Doing so while maintaining high performance at a demanding job like YouTube is a recipe for cognitive fracture.&lt;/p&gt;&lt;p&gt;The strain comes from context switching. From 9:00 AM to 5:00 PM, I had to care deeply about our quarterly goals and production stability. Then, from 6:00 PM to midnight, I had to care about inverting binary trees and system architecture design.&lt;/p&gt;&lt;p&gt;I recall taking "calls" in my car, taking vacation days to practice and do interviews, tethering my laptop to my phone's hotspot to solve coding challenges while squatting in a coffee shop down the street from the office. This duality is exhausting. It forces you to lie by omission to people you respect. You can't tell your team, "I can't take that ticket because I need to study dynamic programming." You just have to work faster.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Navigating the NDA Minefield&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;One of the most complex hurdles in this cycle was proving I was capable of that "double level" jump without breaking Non-Disclosure Agreements (NDAs).&lt;/p&gt;&lt;p&gt;When you work at a place like YouTube, the scale of the problems you solve is the primary selling point. However, the &lt;em&gt;specifics&lt;/em&gt; of how you solved them are often trade secrets.&lt;/p&gt;&lt;p&gt;Here is the strategy I developed: Abstract the mechanism, not the metric&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;I couldn't tell interviewers exactly how a specific proprietary algorithm worked. Instead, I focused on the agnostic engineering principles.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Don't say: "I tweaked the YouTube watch-time algorithm using X variable."&lt;/li&gt;&lt;li&gt;Do say: "I optimized a high-throughput distributed system to prioritize user retention metrics, reducing latency by 150ms through a custom caching layer."&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It shows you understand the &lt;em&gt;systems&lt;/em&gt; (which is transferable knowledge) rather than just the &lt;em&gt;product&lt;/em&gt; (which stays at the old company). If you are ever in this position, focus on the scale of the data and the architectural patterns you used (like Microservices or Event-Driven Architecture) rather than the feature itself. In the end, it also helped me connect with external technologies and lingo better!&lt;/p&gt;&lt;h3&gt;The Elephant in the Room...&lt;/h3&gt;&lt;p&gt;Most interviewers asked me the question that people assume is the hardest to answer... "&lt;em&gt;describe&lt;/em&gt; &lt;em&gt;why you are not already an L5/6"&lt;/em&gt;. And honestly, this was the easiest part. People understood the problems with promos at Google/YouTube, but also this situation. The problem of "doing more work and not getting compensated" is pretty well-known.&lt;/p&gt;&lt;p&gt;What was unique was how long it took me to decide to leave. And I had to highlight the incredibly talented team I worked with and the amazing managers that taught me so much. There is so much value in knowing and feeling that the people around you care about you and want to build amazing things with you. &lt;/p&gt;&lt;img alt="man using MacBook" src="https://images.unsplash.com/photo-1553877522-43269d4ea984?crop=entropy&amp;amp;cs=tinysrgb&amp;amp;fit=max&amp;amp;fm=jpg&amp;amp;ixid=M3wxMTc3M3wwfDF8c2VhcmNofDN8fGVtcGxveWVlfGVufDB8fHx8MTc2NDM3MTM4Nnww&amp;amp;ixlib=rb-4.1.0&amp;amp;q=80&amp;amp;w=2000"/&gt;Photo by &lt;a href="https://unsplash.com/@charlesdeluvio?ref=zhach.news"&gt;charlesdeluvio&lt;/a&gt; / &lt;a href="https://unsplash.com/?utm_source=ghost&amp;amp;utm_medium=referral&amp;amp;utm_campaign=api-credit"&gt;Unsplash&lt;/a&gt;&lt;h3&gt;&lt;strong&gt;The Thirteen-Interview Marathon&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;The most alarming trend I analyzed during this cycle is the inflation of the interview loop.&lt;/p&gt;&lt;p&gt;At one prominent tech company, I underwent &lt;strong&gt;13 separate interviews&lt;/strong&gt; for a single role. This included initial screens, coding rounds, system design rounds, behavioral checks, and meetings with cross-functional partners.&lt;/p&gt;&lt;p&gt;From a critical perspective, this signals organizational dysfunction. If a company requires 13 people to sign off on a hire, it suggests they operate on a consensus-based model that stifles autonomy. It implies a fear of making mistakes that outweighs the desire for talent.&lt;/p&gt;&lt;p&gt;When I analyze the data from my own process, the companies with 5 to 8 rounds had the clearest internal culture. They knew what they wanted. The company with 13 rounds was fishing for a reason to say "no” (which some ultimately told me).&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;The Final Conversation&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;We often hear that "people leave managers, not jobs." But sometimes, people leave jobs despite loving their managers.&lt;/p&gt;&lt;p&gt;My final conversation with my manager was heart-wrenching. I had prepared a script, anticipating a counter-offer or a guilt trip. Instead, I was met with soft and understanding empathy. &lt;/p&gt;&lt;p&gt;I explained that my growth curve had flattened. I wasn't leaving because the team failed me; I was leaving because I had outgrown the pot I was planted in. Staying would have required me to stagnate to fit the available space. I needed to leave to see what I was capable of. And he listened to every word.&lt;/p&gt;&lt;p&gt;I walked out of the meeting feeling incredibly bittersweet, with tears ready to fall. He knew my talent, he knew how hard I worked, and he still was incredibly supportive while I said I was leaving.&lt;/p&gt;&lt;p&gt;This is a hard lesson for both employees and leaders: &lt;strong&gt;Retention has a ceiling.&lt;/strong&gt; Sometimes, the best thing a manager can do for that high-performer is to wish them luck as they walk out the door. It wasn't his fault I wasn't promoted to the level I wanted—he was fighting the same bureaucratic machine I was.&lt;/p&gt;&lt;img src="https://zhach.news/content/images/2025/11/Gemini_Generated_Image_tzci7etzci7etzci.png"/&gt;Gemini made - “Telling my manager I’m quitting and both of us are upset about it"&lt;h3&gt;&lt;strong&gt;The Takeaway&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;Leaving a recognizable brand like Google/YouTube is frightening. You lose the immediate validation that comes with the name on your resume. But careers are long, and comfort is the enemy of progress.&lt;/p&gt;&lt;p&gt;If you feel like you are solving problems two levels above your pay grade, and the only reward you get is &lt;em&gt;more work&lt;/em&gt;, it is time to test the market. The interview fatigue is real, and the conversations are hard, but the clarity you gain on your own value is worth the struggle.&lt;/p&gt;&lt;p&gt;I’m curious about your experiences with career stagnation. &lt;strong&gt;Have you ever felt like you were "acting" at a higher level than your title? How did you handle the conversation with your leadership?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Please share your stories in the comments below.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;Links and Resources&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Software Engineering Levels:&lt;/strong&gt; &lt;a href="https://www.levels.fyi/?ref=zhach.news"&gt;levels.fyi&lt;/a&gt; (Excellent resource for comparing titles and compensation across big tech).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Github: &lt;/strong&gt;&lt;a href="https://github.com/artsy/README/blob/main/careers/ladder.md?ref=zhach.news"&gt;Career Ladder&lt;/a&gt; (detailed guide on how Github views levels; and I personally like their view)&lt;/li&gt;&lt;li&gt;&lt;strong&gt;System Design Interview Guide:&lt;/strong&gt; &lt;a href="https://github.com/donnemartin/system-design-primer?ref=zhach.news"&gt;System Design Primer on GitHub&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;strong&gt;Navigating NDAs:&lt;/strong&gt; &lt;a href="https://hbr.org/?ref=zhach.news"&gt;Harvard Business Review: Non-Disclosure Agreements&lt;/a&gt; &lt;/li&gt;&lt;/ul&gt;




&lt;img alt="Zhachory Volker" src="https://zhach.news/content/images/size/w150/2025/09/profile_half.png"/&gt;


&lt;h4&gt;&lt;a href="https://zhach.news/author/zhachory/"&gt;Zhachory Volker&lt;/a&gt;&lt;/h4&gt;

                    New York
                



&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://zhach.news/how-i-left-youtube/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 21:54:48 +0000</pubDate>
    </item>
    <item>
      <title>Nvidia buying AI chip startup Groq for about $20B in cash</title>
      <link>https://www.cnbc.com/2025/12/24/nvidia-buying-ai-chip-startup-groq-for-about-20-billion-biggest-deal.html</link>
      <description>Nvidia buying AI chip startup Groq for about $20 billion, biggest deal</description>
      <content:encoded>&lt;div class="nav-menu-mainLinks"&gt;&lt;a href="https://www.cnbc.com/markets/"&gt;Markets&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/pre-markets/"&gt;Pre-Markets&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/us-markets/"&gt;U.S. Markets&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/currencies/"&gt;Currencies&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/cryptocurrency/"&gt;Cryptocurrency&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/futures-and-commodities/"&gt;Futures &amp;amp; Commodities&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/bonds/"&gt;Bonds&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/funds-and-etfs/"&gt;Funds &amp;amp; ETFs&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="https://www.cnbc.com/business/"&gt;Business&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/economy/"&gt;Economy&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/finance/"&gt;Finance&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/health-and-science/"&gt;Health &amp;amp; Science&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/media/"&gt;Media&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/real-estate/"&gt;Real Estate&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/energy/"&gt;Energy&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/climate/"&gt;Climate&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/transportation/"&gt;Transportation&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/cnbc-investigations/"&gt;Investigations&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/industrials/"&gt;Industrials&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/retail/"&gt;Retail&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/wealth/"&gt;Wealth&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/sports/"&gt;Sports&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/life/"&gt;Life&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/small-business/"&gt;Small Business&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="https://www.cnbc.com/investing/"&gt;Investing&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/personal-finance/"&gt;Personal Finance&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/fintech/"&gt;Fintech&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/financial-advisors/"&gt;Financial Advisors&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/options-action/"&gt;Options Action&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/etf-street/"&gt;ETF Street&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://buffett.cnbc.com"&gt;Buffett Archive&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/earnings/"&gt;Earnings&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/trader-talk/"&gt;Trader Talk&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="https://www.cnbc.com/technology/"&gt;Tech&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/cybersecurity/"&gt;Cybersecurity&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/ai-artificial-intelligence/"&gt;AI&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/enterprise/"&gt;Enterprise&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/internet/"&gt;Internet&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/media/"&gt;Media&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/mobile/"&gt;Mobile&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/social-media/"&gt;Social Media&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/cnbc-disruptors/"&gt;CNBC Disruptor 50&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/tech-guide/"&gt;Tech Guide&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="https://www.cnbc.com/politics/"&gt;Politics&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/white-house/"&gt;White House&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/policy/"&gt;Policy&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/defense/"&gt;Defense&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/congress/"&gt;Congress&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/expanding-opportunity/"&gt;Expanding Opportunity&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="https://www.cnbc.com/tv/"&gt;Video&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/latest-video/"&gt;Latest Video&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/live-tv/full-episodes/"&gt;Full Episodes&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/live-tv/"&gt;Livestream&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/live-audio/"&gt;Live Audio&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/live-tv/schedule/"&gt;Live TV Schedule&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/podcast/"&gt;CNBC Podcasts&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/video-ceo-interviews/"&gt;CEO Interviews&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/documentaries/"&gt;CNBC Documentaries&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/digital-original/"&gt;Digital Originals&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="https://www.cnbc.com/watchlist/"&gt;Watchlist&lt;/a&gt;&lt;a href="https://www.cnbc.com/investingclub/subscribe?__source=investingclub|globalnav|join&amp;amp;tpcc=investingclub|globalnav|join"&gt;Investing Club&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/investingclub/charitable-trust/"&gt;Trust Portfolio&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/investingclub/analysis/"&gt;Analysis&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/investingclub/trade-alerts/"&gt;Trade Alerts&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/investingclub/video/"&gt;Meeting Videos&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/investingclub/homestretch/"&gt;Homestretch&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/investingclub/jim-cramer-columns/"&gt;Jim's Columns&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/investingclub/education/"&gt;Education&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/investingclub/subscribe?__source=investingclub|dropdownnav&amp;amp;tpcc=investingclub|dropdownnav"&gt;Subscribe&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img alt="Join IC" src="https://static-redesign.cnbcfm.com/dist/93743f20be95b721880f.svg"/&gt;&lt;a href="https://www.cnbc.com/application/pro?__source=pro|globalnav|join&amp;amp;tpcc=pro|globalnav|join"&gt;PRO&lt;/a&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/pro/news/"&gt;Pro News&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/josh-brown/"&gt;Josh Brown&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/mike-santoli-insight/"&gt;Mike Santoli&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/analyst-calls-of-the-day/"&gt;Calls of the Day&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/my-portfolio/"&gt;My Portfolio&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/live-tv/"&gt;Livestream&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/live-tv/full-episodes/"&gt;Full Episodes&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/pro-stock-screener/"&gt;Stock Screener&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/2023/05/11/market-strategist-survey-forecast.html"&gt;Market Forecast&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/pro/options-investing/"&gt;Options Investing&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/cnbc-pro-chart-investing/"&gt;Chart Investing&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.cnbc.com/application/pro/?__source=pro|dropdownnav&amp;amp;tpcc=pro|dropdownnav"&gt;Subscribe&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;img alt="Join Pro" src="https://static-redesign.cnbcfm.com/dist/69ae09b80acd376e9c97.svg"/&gt;&lt;a href="https://www.cnbc.com/live-tv/"&gt;Livestream&lt;/a&gt;Menu&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://www.cnbc.com/2025/12/24/nvidia-buying-ai-chip-startup-groq-for-about-20-billion-biggest-deal.html</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 21:02:15 +0000</pubDate>
    </item>
    <item>
      <title>Keystone (YC S25) is hiring engineer #1 to automate coding</title>
      <link>https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer</link>
      <description>Your team's on-call AI engineer</description>
      <content:encoded>&lt;body class="retro ycdc2 waas show_job"&gt;&lt;a&gt;&lt;img src="https://bookface-images.s3.amazonaws.com/small_logos/8c3915c83dfe6a246f33ae908d5156017a0cef3f.png"/&gt;&lt;/a&gt;&lt;h2&gt;&lt;a href="https://www.ycombinator.com/companies/keystone"&gt;Keystone&lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Your team's on-call AI engineer&lt;/p&gt;&lt;h1&gt;Founding Engineer&lt;/h1&gt;$150K - $300K•0.50% - 3.00%•San Francisco, CA, US&lt;strong&gt;Job type&lt;/strong&gt;Full-time&lt;strong&gt;Role&lt;/strong&gt;Engineering, Full stack&lt;strong&gt;Experience&lt;/strong&gt;1+ years&lt;strong&gt;Visa&lt;/strong&gt;US citizen/visa only&lt;strong&gt;Skills&lt;/strong&gt;Python, React, TypeScriptConnect directly with founders of the best YC-funded startups.&lt;a href="https://account.ycombinator.com/authenticate?continue=https%3A%2F%2Fwww.workatastartup.com%2Fapplication%3Fsignup_job_id%3D87772&amp;amp;defaults%5BsignUpActive%5D=true&amp;amp;defaults%5Bwaas_company%5D=30659"&gt;Apply to role ›&lt;/a&gt;&lt;img alt="Pablo Hansen" src="https://bookface-images.s3.us-west-2.amazonaws.com/avatars/2a9e6de3c5120ee7cf2787b9b0a6f9544f3006b8.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=ASIAQC4NIECANNCBF5KS%2F20251225%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20251225T001210Z&amp;amp;X-Amz-Expires=3600&amp;amp;X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGYaCXVzLXdlc3QtMiJHMEUCIAgj5leSSDtCWLwF%2BMHqCL3OpofdGFOmT98O7Q76RxydAiEAoU6yBVEN28b42PuaNcGNV%2BwMRVIwbbXiwAjnpv8Oa30q5QMILxAAGgwwMDYyMDE4MTEwNzIiDAZOgAHHf4jQE%2BdsTyrCAzdPauryz5xeRmalwmsXX9X6Ce0CsRgJlH6j9l%2BoE0a07JMeKEq9a2atc2ylHdCMXD54BbObneNXygmAQaXbPvK2ZIZ57X9YMh61vMMvNE7xK4C6z4pjpz1MO2%2BcNB%2F2lQ554xXXVxi8QxSkq%2BpUb5wrZthSgFATJi92TjaCo1jvtPXnp%2BnXX7e65fHHPcuSpwZ%2BmMwMKzKimrgJKwxRsFj4DemWYBsuGT5MW1WohHkDlZgfRllni1MaIxk4YFL7iE0X4BBOE05ikHRm4rvT2DMedyslXfuhByCtNoOluaGQNslLsJFgyrZZDmsmk8erGFkopHGEF3EdR5GPxjg%2BSQntF5A7qcyOT%2BsrLZUqglSDRZD%2FUa%2FOmqQY263CagWGW02Vycr7%2Fc%2BfXXLxSMPazwidrEZy45aPMDSw6l6u3s2ERf8uNhY109DxzXtTGkOb4nyVJyEurrsok01oLQtHqzNXUHTakHjWNSvF9VfnAcDDdv7ATe4u5c%2Fa2Qqinaz8bSaUzbDum%2BTwd1cIhFm4sOZLOGLre3XXTkxsRykEzvcd3hYt%2BT%2FvXLLUAcFdaVJEjVlo7wyUaxokUpaEl3sWwwe%2F5zDCuLHKBjqlAWyoJLTGsI9R80HTJnRXquDhPEfGph0ngzoD9%2B2Na1S5rxw1scBBA4kQ6JDX%2Fv3x7%2FfI0dk%2BuoVU7zWXgdUslYd6fMZK7L4uE%2FKaW4bH9J9gQUHius%2FuDYR31VSxbnxbTjnxP0O4AIe84zEqKKNKIrawVtyzy%2FxjvnnSMsek0Gx%2FLQBCjJnp%2Bjvn6zDB3zxQMUfEtTm3GcTByWCSIyrzN9vrk2pwtA%3D%3D&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=939832e7b9d759c158510674c6d23518c16d22286e19b74d9f75a57eac901a3a"/&gt;Pablo HansenFounder&lt;img alt="Pablo Hansen" src="https://bookface-images.s3.us-west-2.amazonaws.com/avatars/2a9e6de3c5120ee7cf2787b9b0a6f9544f3006b8.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=ASIAQC4NIECANNCBF5KS%2F20251225%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20251225T001210Z&amp;amp;X-Amz-Expires=3600&amp;amp;X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGYaCXVzLXdlc3QtMiJHMEUCIAgj5leSSDtCWLwF%2BMHqCL3OpofdGFOmT98O7Q76RxydAiEAoU6yBVEN28b42PuaNcGNV%2BwMRVIwbbXiwAjnpv8Oa30q5QMILxAAGgwwMDYyMDE4MTEwNzIiDAZOgAHHf4jQE%2BdsTyrCAzdPauryz5xeRmalwmsXX9X6Ce0CsRgJlH6j9l%2BoE0a07JMeKEq9a2atc2ylHdCMXD54BbObneNXygmAQaXbPvK2ZIZ57X9YMh61vMMvNE7xK4C6z4pjpz1MO2%2BcNB%2F2lQ554xXXVxi8QxSkq%2BpUb5wrZthSgFATJi92TjaCo1jvtPXnp%2BnXX7e65fHHPcuSpwZ%2BmMwMKzKimrgJKwxRsFj4DemWYBsuGT5MW1WohHkDlZgfRllni1MaIxk4YFL7iE0X4BBOE05ikHRm4rvT2DMedyslXfuhByCtNoOluaGQNslLsJFgyrZZDmsmk8erGFkopHGEF3EdR5GPxjg%2BSQntF5A7qcyOT%2BsrLZUqglSDRZD%2FUa%2FOmqQY263CagWGW02Vycr7%2Fc%2BfXXLxSMPazwidrEZy45aPMDSw6l6u3s2ERf8uNhY109DxzXtTGkOb4nyVJyEurrsok01oLQtHqzNXUHTakHjWNSvF9VfnAcDDdv7ATe4u5c%2Fa2Qqinaz8bSaUzbDum%2BTwd1cIhFm4sOZLOGLre3XXTkxsRykEzvcd3hYt%2BT%2FvXLLUAcFdaVJEjVlo7wyUaxokUpaEl3sWwwe%2F5zDCuLHKBjqlAWyoJLTGsI9R80HTJnRXquDhPEfGph0ngzoD9%2B2Na1S5rxw1scBBA4kQ6JDX%2Fv3x7%2FfI0dk%2BuoVU7zWXgdUslYd6fMZK7L4uE%2FKaW4bH9J9gQUHius%2FuDYR31VSxbnxbTjnxP0O4AIe84zEqKKNKIrawVtyzy%2FxjvnnSMsek0Gx%2FLQBCjJnp%2Bjvn6zDB3zxQMUfEtTm3GcTByWCSIyrzN9vrk2pwtA%3D%3D&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=939832e7b9d759c158510674c6d23518c16d22286e19b74d9f75a57eac901a3a"/&gt;Pablo HansenFounder&lt;h2&gt;About the role&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;About Keystone&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;We're building AI-native error monitoring that automatically investigates production issues and generates code fixes. Think Sentry, but built from the ground up for a world where AI can actually understand your codebase, trace through logs, and tell you exactly what broke and how to fix it.&lt;/p&gt;
&lt;p&gt;We're starting here and expanding until we're the default tool for building product, period. Our mission is to free engineers from the drudgery of digging through logs, setting up systems, and debugging- so they can focus on understanding users and designing great products.&lt;/p&gt;
&lt;p&gt;We're in-person in SoMa, San Francisco. We raised a $5.2M seed from True Ventures, Twenty Two Ventures, Pear VC, and Ritual Capital- plus the founders of YC, Dropbox, Supabase, Eight Sleep, Graphite, Resend, RocketMoney, and more. Early design partners include teams at Perplexity and Lovable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;About the Role&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;You'd be the first engineering hire, working directly with me (the founder) to build the core product. You'll have more ownership and influence over the product, culture, and technical direction than you'd get almost anywhere else.&lt;/p&gt;
&lt;p&gt;Example projects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;2-week sprint to build a new product vertical from scratch&lt;/li&gt;
&lt;li&gt;Design a new interface for engineering workflows that wasn't possible until a model advancement that came out yesterday&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;You might be a great fit if you:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Have shipped products end-to-end (frontend to infra) and obsess over the details&lt;/li&gt;
&lt;li&gt;Work fast and comfortably with ambiguity- we're figuring things out as we go&lt;/li&gt;
&lt;li&gt;Get excited about hard problems at the intersection of AI and developer tools&lt;/li&gt;
&lt;li&gt;Want to be genuinely early, not "early at a 50-person series B"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Stack:&lt;/strong&gt; TypeScript, React (Next.js), Python, Postgres, Redis, AWS&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Comp &amp;amp; benefits:&lt;/strong&gt; Top-of-market salary + significant equity, full health/dental/vision, all meals covered, equipment budget&lt;/p&gt;
&lt;h2&gt;About the interview&lt;/h2&gt;&lt;p&gt;If there appears to be a fit, we'll reach to schedule 2-3 short technicals. After, we'll schedule an onsite in our office, where you'll work on a small project, discuss ideas, and get a sense for our in-person culture.&lt;/p&gt;
&lt;h2&gt;About &lt;!-- --&gt;Keystone&lt;/h2&gt;&lt;a href="https://www.ycombinator.com/companies/keystone"&gt;&lt;img alt="Keystone" src="https://bookface-images.s3.us-west-2.amazonaws.com/logos/06e7837c1e5c8ce88da333ac2efcf401d8cbee53.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=ASIAQC4NIECANNCBF5KS%2F20251225%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20251225T001210Z&amp;amp;X-Amz-Expires=3600&amp;amp;X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGYaCXVzLXdlc3QtMiJHMEUCIAgj5leSSDtCWLwF%2BMHqCL3OpofdGFOmT98O7Q76RxydAiEAoU6yBVEN28b42PuaNcGNV%2BwMRVIwbbXiwAjnpv8Oa30q5QMILxAAGgwwMDYyMDE4MTEwNzIiDAZOgAHHf4jQE%2BdsTyrCAzdPauryz5xeRmalwmsXX9X6Ce0CsRgJlH6j9l%2BoE0a07JMeKEq9a2atc2ylHdCMXD54BbObneNXygmAQaXbPvK2ZIZ57X9YMh61vMMvNE7xK4C6z4pjpz1MO2%2BcNB%2F2lQ554xXXVxi8QxSkq%2BpUb5wrZthSgFATJi92TjaCo1jvtPXnp%2BnXX7e65fHHPcuSpwZ%2BmMwMKzKimrgJKwxRsFj4DemWYBsuGT5MW1WohHkDlZgfRllni1MaIxk4YFL7iE0X4BBOE05ikHRm4rvT2DMedyslXfuhByCtNoOluaGQNslLsJFgyrZZDmsmk8erGFkopHGEF3EdR5GPxjg%2BSQntF5A7qcyOT%2BsrLZUqglSDRZD%2FUa%2FOmqQY263CagWGW02Vycr7%2Fc%2BfXXLxSMPazwidrEZy45aPMDSw6l6u3s2ERf8uNhY109DxzXtTGkOb4nyVJyEurrsok01oLQtHqzNXUHTakHjWNSvF9VfnAcDDdv7ATe4u5c%2Fa2Qqinaz8bSaUzbDum%2BTwd1cIhFm4sOZLOGLre3XXTkxsRykEzvcd3hYt%2BT%2FvXLLUAcFdaVJEjVlo7wyUaxokUpaEl3sWwwe%2F5zDCuLHKBjqlAWyoJLTGsI9R80HTJnRXquDhPEfGph0ngzoD9%2B2Na1S5rxw1scBBA4kQ6JDX%2Fv3x7%2FfI0dk%2BuoVU7zWXgdUslYd6fMZK7L4uE%2FKaW4bH9J9gQUHius%2FuDYR31VSxbnxbTjnxP0O4AIe84zEqKKNKIrawVtyzy%2FxjvnnSMsek0Gx%2FLQBCjJnp%2Bjvn6zDB3zxQMUfEtTm3GcTByWCSIyrzN9vrk2pwtA%3D%3D&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=33e94cf8068bc9e5ea925a221525bda23bfd1680611da8428b2774cb06171069"/&gt;&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/keystone"&gt;Keystone&lt;/a&gt;Founded:2025Batch:S25Team Size:1Status:ActiveLocation:San Francisco&lt;a href="https://withkeystone.com"&gt;&lt;/a&gt;&lt;a href="https://www.linkedin.com/company/107275953"&gt; &lt;/a&gt;&lt;a href="https://x.com/withkeystone"&gt;&lt;img alt="X (Twitter) logo" src="https://www.ycombinator.com/images/social/x-logo.svg"/&gt;&lt;/a&gt;Founders&lt;img alt="Pablo Hansen" src="https://bookface-images.s3.us-west-2.amazonaws.com/avatars/2a9e6de3c5120ee7cf2787b9b0a6f9544f3006b8.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=ASIAQC4NIECANNCBF5KS%2F20251225%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20251225T001210Z&amp;amp;X-Amz-Expires=3600&amp;amp;X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGYaCXVzLXdlc3QtMiJHMEUCIAgj5leSSDtCWLwF%2BMHqCL3OpofdGFOmT98O7Q76RxydAiEAoU6yBVEN28b42PuaNcGNV%2BwMRVIwbbXiwAjnpv8Oa30q5QMILxAAGgwwMDYyMDE4MTEwNzIiDAZOgAHHf4jQE%2BdsTyrCAzdPauryz5xeRmalwmsXX9X6Ce0CsRgJlH6j9l%2BoE0a07JMeKEq9a2atc2ylHdCMXD54BbObneNXygmAQaXbPvK2ZIZ57X9YMh61vMMvNE7xK4C6z4pjpz1MO2%2BcNB%2F2lQ554xXXVxi8QxSkq%2BpUb5wrZthSgFATJi92TjaCo1jvtPXnp%2BnXX7e65fHHPcuSpwZ%2BmMwMKzKimrgJKwxRsFj4DemWYBsuGT5MW1WohHkDlZgfRllni1MaIxk4YFL7iE0X4BBOE05ikHRm4rvT2DMedyslXfuhByCtNoOluaGQNslLsJFgyrZZDmsmk8erGFkopHGEF3EdR5GPxjg%2BSQntF5A7qcyOT%2BsrLZUqglSDRZD%2FUa%2FOmqQY263CagWGW02Vycr7%2Fc%2BfXXLxSMPazwidrEZy45aPMDSw6l6u3s2ERf8uNhY109DxzXtTGkOb4nyVJyEurrsok01oLQtHqzNXUHTakHjWNSvF9VfnAcDDdv7ATe4u5c%2Fa2Qqinaz8bSaUzbDum%2BTwd1cIhFm4sOZLOGLre3XXTkxsRykEzvcd3hYt%2BT%2FvXLLUAcFdaVJEjVlo7wyUaxokUpaEl3sWwwe%2F5zDCuLHKBjqlAWyoJLTGsI9R80HTJnRXquDhPEfGph0ngzoD9%2B2Na1S5rxw1scBBA4kQ6JDX%2Fv3x7%2FfI0dk%2BuoVU7zWXgdUslYd6fMZK7L4uE%2FKaW4bH9J9gQUHius%2FuDYR31VSxbnxbTjnxP0O4AIe84zEqKKNKIrawVtyzy%2FxjvnnSMsek0Gx%2FLQBCjJnp%2Bjvn6zDB3zxQMUfEtTm3GcTByWCSIyrzN9vrk2pwtA%3D%3D&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=939832e7b9d759c158510674c6d23518c16d22286e19b74d9f75a57eac901a3a"/&gt;Pablo Hansen&lt;a href="https://x.com/thepablohansen"&gt;&lt;img alt="Twitter account" src="https://www.ycombinator.com/images/social/x-logo.svg"/&gt;&lt;/a&gt;&lt;a href="https://linkedin.com/in/pablo-hansen"&gt; &lt;/a&gt;Founder&lt;img alt="Pablo Hansen" src="https://bookface-images.s3.us-west-2.amazonaws.com/avatars/2a9e6de3c5120ee7cf2787b9b0a6f9544f3006b8.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Credential=ASIAQC4NIECANNCBF5KS%2F20251225%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20251225T001210Z&amp;amp;X-Amz-Expires=3600&amp;amp;X-Amz-Security-Token=IQoJb3JpZ2luX2VjEGYaCXVzLXdlc3QtMiJHMEUCIAgj5leSSDtCWLwF%2BMHqCL3OpofdGFOmT98O7Q76RxydAiEAoU6yBVEN28b42PuaNcGNV%2BwMRVIwbbXiwAjnpv8Oa30q5QMILxAAGgwwMDYyMDE4MTEwNzIiDAZOgAHHf4jQE%2BdsTyrCAzdPauryz5xeRmalwmsXX9X6Ce0CsRgJlH6j9l%2BoE0a07JMeKEq9a2atc2ylHdCMXD54BbObneNXygmAQaXbPvK2ZIZ57X9YMh61vMMvNE7xK4C6z4pjpz1MO2%2BcNB%2F2lQ554xXXVxi8QxSkq%2BpUb5wrZthSgFATJi92TjaCo1jvtPXnp%2BnXX7e65fHHPcuSpwZ%2BmMwMKzKimrgJKwxRsFj4DemWYBsuGT5MW1WohHkDlZgfRllni1MaIxk4YFL7iE0X4BBOE05ikHRm4rvT2DMedyslXfuhByCtNoOluaGQNslLsJFgyrZZDmsmk8erGFkopHGEF3EdR5GPxjg%2BSQntF5A7qcyOT%2BsrLZUqglSDRZD%2FUa%2FOmqQY263CagWGW02Vycr7%2Fc%2BfXXLxSMPazwidrEZy45aPMDSw6l6u3s2ERf8uNhY109DxzXtTGkOb4nyVJyEurrsok01oLQtHqzNXUHTakHjWNSvF9VfnAcDDdv7ATe4u5c%2Fa2Qqinaz8bSaUzbDum%2BTwd1cIhFm4sOZLOGLre3XXTkxsRykEzvcd3hYt%2BT%2FvXLLUAcFdaVJEjVlo7wyUaxokUpaEl3sWwwe%2F5zDCuLHKBjqlAWyoJLTGsI9R80HTJnRXquDhPEfGph0ngzoD9%2B2Na1S5rxw1scBBA4kQ6JDX%2Fv3x7%2FfI0dk%2BuoVU7zWXgdUslYd6fMZK7L4uE%2FKaW4bH9J9gQUHius%2FuDYR31VSxbnxbTjnxP0O4AIe84zEqKKNKIrawVtyzy%2FxjvnnSMsek0Gx%2FLQBCjJnp%2Bjvn6zDB3zxQMUfEtTm3GcTByWCSIyrzN9vrk2pwtA%3D%3D&amp;amp;X-Amz-SignedHeaders=host&amp;amp;X-Amz-Signature=939832e7b9d759c158510674c6d23518c16d22286e19b74d9f75a57eac901a3a"/&gt;Pablo Hansen&lt;a href="https://x.com/thepablohansen"&gt;&lt;img alt="Twitter account" src="https://www.ycombinator.com/images/social/x-logo.svg"/&gt;&lt;/a&gt;&lt;a href="https://linkedin.com/in/pablo-hansen"&gt; &lt;/a&gt;FounderSimilar Jobs&lt;img alt="Subsets" src="https://bookface-images.s3.amazonaws.com/small_logos/ef940e88fb60e59b177570256531952d8e4b1322.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/subsets"&gt;Subsets&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/subsets/jobs/dD7csOI-software-engineer-full-stack"&gt;Software Engineer (Full-stack)&lt;/a&gt;&lt;img alt="Embeddables" src="https://bookface-images.s3.amazonaws.com/small_logos/e2e7cc961daf91fd34139f65969fe6d1eb62c853.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/embeddables"&gt;Embeddables&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/embeddables/jobs/h19zkWg-senior-staff-engineer"&gt;Senior / Staff Engineer&lt;/a&gt;&lt;img alt="PearAI" src="https://bookface-images.s3.amazonaws.com/small_logos/dfc66990c87e4d8f300d62eedff5460f882406da.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/pearai"&gt;PearAI&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/pearai/jobs/FxLzw54-swe-marketing-internship-summer-2026"&gt;SWE / Marketing Internship (Summer 2026)&lt;/a&gt;&lt;img alt="Alinea" src="https://bookface-images.s3.amazonaws.com/small_logos/309f21a43676330a7d4946870c8eaef1865fe8b0.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/alinea"&gt;Alinea&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/alinea/jobs/2GVRUn2-full-stack-ios-software-engineer"&gt;Full Stack iOS Software Engineer&lt;/a&gt;&lt;img alt="Ergo" src="https://bookface-images.s3.amazonaws.com/small_logos/bd659fbea3fde9a2b42434fe03f0a75943f09e6a.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/ergo"&gt;Ergo&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/ergo/jobs/sjdRcRq-software-engineer-fullstack"&gt;Software Engineer - Fullstack&lt;/a&gt;&lt;img alt="Amplitude" src="https://bookface-images.s3.amazonaws.com/small_logos/fa98c8a53255b3fd2e9d4a65dbb47eec293729f1.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/amplitude"&gt;Amplitude&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/amplitude/jobs/vixZiNb-senior-ai-product-engineer"&gt;Senior AI Product Engineer &lt;/a&gt;&lt;img alt="Quickchat AI" src="https://bookface-images.s3.amazonaws.com/small_logos/cd166d2e1d19120e911f2639492f073fb0275541.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/quickchat-ai"&gt;Quickchat AI&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/quickchat-ai/jobs/w8NfYOL-software-engineer"&gt;Software Engineer&lt;/a&gt;&lt;img alt="Novoflow" src="https://bookface-images.s3.amazonaws.com/small_logos/5dc1e2e5cc8a224ba29a91be64f14ab1fbc9cde3.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/novoflow"&gt;Novoflow&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/novoflow/jobs/796IkzL-founding-software-engineer"&gt;Founding Software Engineer&lt;/a&gt;&lt;img alt="Sully.ai" src="https://bookface-images.s3.amazonaws.com/small_logos/9050d789232441d310c7b2bc53166a978e1f735d.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/sully-ai"&gt;Sully.ai&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/sully-ai/jobs/UD9lH5E-applied-research-engineer-contract-to-hire"&gt;Applied Research Engineer (Contract to Hire)&lt;/a&gt;&lt;img alt="Raindrop" src="https://bookface-images.s3.amazonaws.com/small_logos/53f3136371147d755b0a7f4891db765c11734499.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/raindrop"&gt;Raindrop&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/raindrop/jobs/a4Vqw1I-developer-experience-engineer"&gt;Developer Experience Engineer&lt;/a&gt;&lt;img alt="inBuild" src="https://bookface-images.s3.amazonaws.com/small_logos/565db1f58d2ff6409bb5c8eb3aefcdbc3f515329.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/inbuild"&gt;inBuild&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/inbuild/jobs/F5QTABH-founding-engineer"&gt;Founding Engineer&lt;/a&gt;&lt;img alt="CloudCruise" src="https://bookface-images.s3.amazonaws.com/small_logos/fcc29b79cc413f63314e6b00a79442a446cd544d.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/cloudcruise"&gt;CloudCruise&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/cloudcruise/jobs/coiFb4X-founding-engineer"&gt;Founding Engineer&lt;/a&gt;&lt;img alt="Apten" src="https://bookface-images.s3.amazonaws.com/small_logos/fba5782492516410e226be3162e29ac3095f17be.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/apten"&gt;Apten&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/apten/jobs/9vu8UGR-software-engineer-full-stack"&gt;Software Engineer (Full Stack)&lt;/a&gt;&lt;img alt="JustAI" src="https://bookface-images.s3.amazonaws.com/small_logos/166536f94d496e2b50084b3b8edf8b6d9e29040b.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/justai"&gt;JustAI&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/justai/jobs/lvEg20g-forward-deployed-gtm-engineer"&gt;Forward Deployed / GTM Engineer&lt;/a&gt;&lt;img alt="Quindar" src="https://bookface-images.s3.amazonaws.com/small_logos/8b1c3c4a91e008bf2dae946586ed7d25fa59ec49.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/quindar"&gt;Quindar&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/quindar/jobs/UtEwV2R-mission-integration-engineer"&gt;Mission Integration Engineer&lt;/a&gt;&lt;img alt="Tennr" src="https://bookface-images.s3.amazonaws.com/small_logos/9ce9a2d0eb717408f7a56ad8fd6c76940b02a6a9.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/tennr"&gt;Tennr&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/tennr/jobs/ZBmYR5m-ai-engineer"&gt;AI Engineer&lt;/a&gt;&lt;img alt="Lago" src="https://bookface-images.s3.amazonaws.com/small_logos/29939f1cfbd3fe315d3ded8f43c33775de6b9c89.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/lago"&gt;Lago&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/lago/jobs/jJPZUh5-support-engineer-l3"&gt;Support Engineer (L3)&lt;/a&gt;&lt;img alt="JustPaid" src="https://bookface-images.s3.amazonaws.com/small_logos/82ec739461b339d9ec575319f0ea12411f9e30bd.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/justpaid"&gt;JustPaid&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/justpaid/jobs/BTj82qc-full-stack-software-developer-engineer-hacker-hiring-in-silicon-valley"&gt;Full Stack Software Developer/Engineer/Hacker (Hiring in Silicon Valley)&lt;/a&gt;&lt;img alt="RentHop" src="https://bookface-images.s3.amazonaws.com/small_logos/1d46a914ebd920dcb8bc39852cc8704c1b4ef08f.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/renthop"&gt;RentHop&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/renthop/jobs/vgPHwmG-taipei-full-stack-php-developer"&gt;Taipei Full Stack PHP Developer&lt;/a&gt;&lt;img alt="Quill" src="https://bookface-images.s3.amazonaws.com/small_logos/cadeb9c28b524b34507f63691f600743f4fa5b6f.png"/&gt;&lt;a href="https://www.ycombinator.com/companies/quill"&gt;Quill&lt;/a&gt;&lt;a href="https://www.ycombinator.com/companies/quill/jobs/w0Z3xNm-software-engineer"&gt;Software Engineer&lt;/a&gt;&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://www.ycombinator.com/companies/keystone/jobs/J3t9XeM-founding-engineer</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 21:01:05 +0000</pubDate>
    </item>
    <item>
      <title>Spaced repetition for efficient learning (2019)</title>
      <link>https://gwern.net/spaced-repetition</link>
      <description>Haskell , nootropic , psychedelics , spaced repetition</description>
      <content:encoded>&lt;article&gt;



&lt;p&gt;&lt;a href="https://gwern.net/doc/cs/haskell/index"&gt;Haskell&lt;/a&gt;, &lt;a href="https://gwern.net/doc/nootropic/index"&gt;nootropic&lt;/a&gt;, &lt;a href="https://gwern.net/doc/psychedelic/index"&gt;psychedelics&lt;/a&gt;, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/index"&gt;spaced repetition&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Efficient memorization using the spacing effect: literature review of widespread applicability, tips on use &amp;amp; what it’s good for.&lt;/p&gt;

2009-03-11–10y2019-05-17
&lt;em&gt;finished&lt;/em&gt;
&lt;a href="https://gwern.net/about#confidence-tags"&gt;certainty&lt;/a&gt;: &lt;em&gt;highly likely&lt;/em&gt;
&lt;a href="https://gwern.net/about#importance-tags"&gt;importance&lt;/a&gt;: &lt;em&gt;9&lt;/em&gt;
&lt;a href="#backlinks"&gt;backlinks&lt;/a&gt;
&lt;a href="#similars"&gt;similar&lt;/a&gt;
&lt;a href="#link-bibliography"&gt;bibliography&lt;/a&gt;


&lt;ul&gt;
&lt;li&gt;&lt;a href="#spacing-effect"&gt;Spacing Effect&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#if-youre-so-good-why-arent-you-rich"&gt;If You’re so Good, Why Aren’t You Rich&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#literature-review"&gt;Literature Review&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#background-testing-works"&gt;Background: Testing Works!&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#subjects"&gt;Subjects&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#downsides"&gt;Downsides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#distributed"&gt;Distributed&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#generality-of-spacing-effect"&gt;Generality of Spacing Effect&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#review-summary"&gt;Review Summary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#using-it"&gt;Using It&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#how-much-to-add"&gt;How Much To Add&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#overload"&gt;Overload&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#what-to-add"&gt;What to Add&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#the-workload"&gt;The Workload&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#when-to-review"&gt;When to Review&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#prospects-extended-flashcards"&gt;Prospects: Extended Flashcards&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#popularity"&gt;Popularity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#where-was-i-going-with-this"&gt;Where Was I Going With This?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#see-also"&gt;See Also&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#external-links"&gt;External Links&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#flashcard-sources"&gt;Flashcard Sources&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt; 
&lt;blockquote&gt;
&lt;p&gt;Spaced repetition is a centuries-old psychological technique for efficient memorization &amp;amp; practice of skills where instead of attempting to memorize by ‘cramming’, memorization can be done far more efficiently by instead spacing out each review, with increasing durations as one learns the item, with the scheduling done by software. Because of the greater efficiency of its slow but steady approach, spaced repetition can scale to memorizing hundreds of thousands of items (while crammed items are almost immediately forgotten) and is especially useful for foreign languages &amp;amp; medical studies.&lt;/p&gt;
&lt;p&gt;I review what this technique is useful for, some of the large research literature on it and the testing effect (up to ~2013, primarily), the available software tools and use patterns, and miscellaneous ideas &amp;amp; observations on it.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;One of the most fruitful areas of computing is making up for human frailties. They do arithmetic perfectly because we can’t&lt;a href="#fn1"&gt;1&lt;/a&gt;. They remember terabytes because we’d forget. They make the best calendars, because they always check what there is to do today. Even if we do not remember exactly, merely remembering a reference can be just as good, like the point of reading a manual or textbook all the way through: it is not to remember everything that is in it for later but to later remember &lt;em&gt;that&lt;/em&gt; something is in it (and skimming them, you learn the right words to search for when you actually need to know more about a particular topic).&lt;/p&gt;
&lt;p&gt;We use any number of such &lt;a href="https://en.wikipedia.org/wiki/Neuroprosthetics"&gt;neuroprosthetics&lt;/a&gt;&lt;a href="#fn2"&gt;2&lt;/a&gt;, but there are always more to be discovered. They’re worth looking for because they are so valuable: a shovel is much more effective than your hand, but a &lt;a href="https://en.wikipedia.org/wiki/Power_shovel"&gt;power shovel&lt;/a&gt; is orders of magnitude better than both - even if it requires training and expertise to use.&lt;/p&gt;

&lt;h1&gt;&lt;a href="#spacing-effect"&gt;Spacing Effect&lt;/a&gt;&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;You can get a good deal from rehearsal,&lt;br/&gt;
If it just has the proper dispersal.&lt;br/&gt;
You would just be an ass,&lt;br/&gt;
To do it &lt;em&gt;en masse&lt;/em&gt;,&lt;br/&gt;
Your remembering would turn out much worsal.&lt;/p&gt;
&lt;p&gt;Ulrich Neisser&lt;a href="#fn3"&gt;3&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;My current favorite prosthesis is the class of software that exploits the &lt;a href="https://en.wikipedia.org/wiki/Spacing_effect"&gt;spacing effect&lt;/a&gt;, a centuries-old observation in cognitive psychology, to achieve results in studying or memorization much better than conventional student techniques; it is, alas, obscure&lt;a href="#fn4"&gt;4&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The spacing effect essentially says that if you have a question (“What is the fifth letter in this random sequence you learned?”), and you can only study it, say, 5 times, then your memory of the answer (‘e’) will be strongest if you spread your 5 tries out over a long period of time - days, weeks, and months. One of the worst things you can do is blow your 5 tries within a day or two. You can think of the ‘&lt;a href="https://en.wikipedia.org/wiki/Forgetting_curve"&gt;forgetting curve&lt;/a&gt;’ as being like a chart of a radioactive &lt;a href="https://en.wikipedia.org/wiki/Half-life"&gt;half-life&lt;/a&gt;: each review bumps your memory up in strength 50% of the chart, say, but review doesn’t do much in the early days because the memory simply hasn’t decayed much! (&lt;em&gt;Why&lt;/em&gt; does the spacing effect work, on a biological level? There are clear neurochemical differences between massed and spaced &lt;a href="https://onlinelibrary.wiley.com/doi/epdf/10.1155/2012/581291"&gt;in animal models&lt;/a&gt; with spacing (&amp;gt;1 hour) enhancing &lt;a href="https://en.wikipedia.org/wiki/Long-term_potentiation"&gt;long-term potentiation&lt;/a&gt; but not massed&lt;a href="#fn5"&gt;5&lt;/a&gt;, but the why and wherefore - that’s an open question; see the concept of &lt;a href="https://en.wikipedia.org/wiki/Engram_(neuropsychology)"&gt;memory traces&lt;/a&gt; or the &lt;a href="#when-to-review"&gt;sleep&lt;/a&gt; studies.) A graphical representation of the forgetting curve:&lt;/p&gt;

&lt;p&gt;&lt;img alt="Stahl et al 2010; CNS Spectrums" src="https://gwern.net/doc/psychology/spaced-repetition/forgetting-curve-stahl.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;Stahl et al 2010; &lt;em&gt;CNS Spectrums&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Even better, it’s known that &lt;a href="https://en.wikipedia.org/wiki/Testing_effect"&gt;active recall&lt;/a&gt; is a far superior method of learning than simply passively being exposed to information.&lt;a href="#fn6"&gt;6&lt;/a&gt; Spacing also scales to huge quantities of information; gambler/financier &lt;a href="https://en.wikipedia.org/wiki/Edward_O._Thorp"&gt;Edward O. Thorp&lt;/a&gt; harnessed “spaced learning” when he was a physics grad student “in order to be able to work longer and harder”&lt;a href="#fn7"&gt;7&lt;/a&gt;, and &lt;a href="https://en.wikipedia.org/wiki/Roger_Craig_(Jeopardy!_contestant)"&gt;Roger Craig&lt;/a&gt; set multiple records on the quiz show &lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Jeopardy!"&gt;Jeopardy!&lt;/a&gt;&lt;/em&gt; 2010–201114ya in part thanks to &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2011-qs-rogercraigwinsjeopardy.html#comment-3004"&gt;using Anki&lt;/a&gt; to memorize chunks of a collection of &lt;a href="https://www.j-archive.com/"&gt;&amp;gt;200,000&lt;/a&gt; past questions&lt;a href="#fn8"&gt;8&lt;/a&gt;; a later Jeopardy winner, Arthur Chu, also used spaced repetition&lt;a href="#fn9"&gt;9&lt;/a&gt;. Med school students (who have become a major demographic for SRS due to the extremely large amounts of factual material they are expected to memorize during medical school) usually have thousands of cards, especially if using pre-made decks (more feasible for medicine due to fairly standardized curriculums &amp;amp; general lack of time to make custom cards). Foreign-language learners can easily reach 10-30,000 cards; &lt;a href="https://gwern.net/doc/www/old.reddit.com/d5083ea03ae56bf188d1f64235439df68b6d05ca.html"&gt;one Anki user&lt;/a&gt; reports a deck of &amp;gt;765k &lt;a href="https://subs2srs.sourceforge.net/"&gt;automatically-generated&lt;/a&gt; cards filled with Japanese audio samples from many sources (“Youtube videos, video games, TV shows, etc”).&lt;/p&gt;
&lt;p&gt;A graphic might help; imagine here one can afford to review a given piece of information a few times (one is a busy person). By looking at the odds we can remember the item, we can see that cramming wins in the short term, but unexercised memories decay so fast that after not too long spacing is much superior:&lt;/p&gt;

&lt;p&gt;&lt;img alt="Wired (original, Wozniak?); massed vs spaced (alternative)" src="https://gwern.net/doc/psychology/spaced-repetition/forgetting-curve-wired-wozniak.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Wired&lt;/em&gt; (original, Wozniak?); massed vs spaced (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2013-memotrainerrr.png"&gt;alternative&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;It’s more dramatic if we look at a video visualizing decay of a corpus of memory with &lt;a href="https://www.youtube.com/watch?v=ai2K3qHpC7c#t=2m40s"&gt;random review vs most-recent review vs spaced review&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;&lt;a href="#if-youre-so-good-why-arent-you-rich"&gt;If You’re so Good, Why Aren’t You Rich&lt;/a&gt;&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Most people find the concept of programming obvious, but the doing impossible.&lt;a href="#fn10"&gt;10&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Of course, the latter strategy (cramming) is precisely what students do. They cram the night before the test, and a month later can’t remember anything. So why do people do it? (I’m not innocent myself.) Why is spaced repetition so dreadfully unpopular, even among the people who try it once?&lt;a href="#fn11"&gt;11&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img alt="Scumbag Brain meme: knows everything when cramming the night before the test / and forgets everything a month later" src="https://gwern.net/doc/psychology/spaced-repetition/2013-gwern-meme-scumbagbrain.png"/&gt;&lt;/p&gt;
&lt;p&gt;Scumbag Brain meme: knows everything when cramming the night before the test / and forgets everything a month later&lt;/p&gt;

&lt;p&gt;Because it does work. Sort of. Cramming is a trade-off: you trade a strong memory now for weak memory later. (Very weak&lt;a href="#fn12"&gt;12&lt;/a&gt;.) And tests are usually of all the new material, with occasional old questions, so this strategy pays off! That’s the damnable thing about it - its memory longevity &amp;amp; quality are, in sum, less than that of spaced repetition, but cramming delivers its goods &lt;em&gt;now&lt;/em&gt;&lt;a href="#fn13"&gt;13&lt;/a&gt;. So cramming is a rational, if short-sighted, response, and even SRS software recognize its utility &amp;amp; support it to some degree&lt;a href="#fn14"&gt;14&lt;/a&gt;. (But as one might expect, if the testing is continuous and incremental, then the learning tends to also be long-lived&lt;a href="#fn15"&gt;15&lt;/a&gt;; I do not know if this is because that kind of testing is a disguised accidental spaced repetition system, or the students/subjects simply studying/acting differently in response to small-stakes exams.) In addition to this short-term advantage, there’s &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2011-mccabe.pdf"&gt;an ignorance&lt;/a&gt; of the advantages of spacing and a subjective &lt;em&gt;illusion&lt;/em&gt; that the gains persist&lt;a href="#fn16"&gt;16&lt;/a&gt;&lt;a href="#fn17"&gt;17&lt;/a&gt; (cf. &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2012-son.pdf"&gt;Son &amp;amp; Simon2012&lt;/a&gt;&lt;a href="#fn18"&gt;18&lt;/a&gt;, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2014-mulligan.pdf"&gt;Mulligan &amp;amp; Peterson2014&lt;/a&gt;, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2013-bjork.pdf"&gt;Bjork et al 2013&lt;/a&gt;, &lt;a href="https://www.pnas.org/doi/10.1073/pnas.1821936116"&gt;Deslauriers et al 2019&lt;/a&gt;); from &lt;a href="https://gwern.net/doc/www/sites.williams.edu/08ce3bc11d6021b41f77b3fa150a94616702f1d6.pdf"&gt;Kornell2009’s&lt;/a&gt; study of GRE vocab (emphasis added):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Across experiments, &lt;em&gt;spacing&lt;/em&gt; was more effective than massing for 90% of the participants, yet after the first study session, 72% of the participants believed that &lt;em&gt;massing&lt;/em&gt; had been more effective than spacing….When they do consider spacing, they often exhibit the illusion that massed study is more effective than spaced study, even when the reverse is true (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1994-dunlosky.pdf"&gt;Dunlosky &amp;amp; Nelson, 1994&lt;/a&gt;; Kornell &amp;amp; Bjork, 200817yaa; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2001-simon.pdf"&gt;Simon &amp;amp; Bjork2001&lt;/a&gt;; &lt;a href="https://www.willatworklearning.com/2005/11/research_review.html"&gt;Zechmeister &amp;amp; Shaughnessy, 1980&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As one would expect if the testing and spacing effects are real things, students who naturally test themselves and study well in advance of exams tend to have higher GPAs.&lt;a href="#fn19"&gt;19&lt;/a&gt; If we interpret questions as tests, we are not surprised to see that 1-on-1 tutoring works &lt;a href="https://en.wikipedia.org/wiki/Bloom%27s_2_sigma_problem"&gt;dramatically better&lt;/a&gt; than regular teaching and that tutored students answer orders of magnitude more questions&lt;a href="#fn20"&gt;20&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This short-term perspective is not a good thing in the long term, of course. Knowledge builds on knowledge; one is not learning independent bits of trivia. &lt;a href="https://en.wikipedia.org/wiki/Richard_Hamming"&gt;Richard Hamming&lt;/a&gt; recalls in &lt;a href="https://gwern.net/doc/science/1986-hamming#conscientiousness"&gt;“You and Your Research”&lt;/a&gt; that “You observe that most great scientists have tremendous drive….Knowledge and productivity are like &lt;a href="https://en.wikipedia.org/wiki/Compound_interest"&gt;compound interest&lt;/a&gt;.”&lt;/p&gt;
&lt;p&gt;Knowledge needs to accumulate, and flashcards with spaced repetition can aid in just that accumulation, fostering steady review even as the number of cards and intellectual prerequisites mounts into the &lt;a href="#the-workload"&gt;thousands&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This long term focus may explain why explicit spaced repetition is an uncommon studying technique: the pay-off is distant &amp;amp; counterintuitive, the cost of self-control near &amp;amp; vivid. (See &lt;a href="https://en.wikipedia.org/wiki/Hyperbolic_discounting"&gt;hyperbolic discounting&lt;/a&gt;.) It doesn’t help that it’s pretty difficult to figure out &lt;em&gt;when&lt;/em&gt; one should review - the optimal point is when you’re just about to forget about it, but that’s the kicker: if you’re just about to forget about it, how are you supposed to remember to review it? You only remember to review what you remember, and what you already remember isn’t what you need to review!&lt;a href="#fn21"&gt;21&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The paradox is resolved by letting a computer handle all the calculations. We can thank &lt;a href="https://en.wikisource.org/wiki/Memory:_A_Contribution_to_Experimental_Psychology"&gt;Hermann Ebbinghaus&lt;/a&gt; for investigating in such tedious detail than we can, in fact, program a computer to calculate both the forgetting curve and optimal set of reviews&lt;a href="#fn22"&gt;22&lt;/a&gt;. This is the insight behind &lt;a href="https://en.wikipedia.org/wiki/Spaced_repetition"&gt;spaced repetition&lt;/a&gt; software: ask the same question over and over, but over increasing spans of time. You start with asking it once every few days, and soon the human remembers it reasonably well. Then you expand intervals out to weeks, then months, and then years. Once the memory is formed and dispatched to long-term memory, it needs but occasional exercise to remain hale and hearty&lt;a href="#fn23"&gt;23&lt;/a&gt; - I remember well the large dinosaurs made of cardboard for my 4th or 5th birthday, or the tunnel made out of boxes, even though I recollect them once or twice a year at most.&lt;/p&gt;


&lt;h2&gt;&lt;a href="#literature-review"&gt;Literature Review&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;But don’t take my word for it - &lt;em&gt;Nullius in verba&lt;/em&gt;! We can look at the science. Of course, if you do take my word for it, you probably just want to read about how to use it and all the nifty things you can do, so I suggest you &lt;a href="#using-it"&gt;skip all the way down&lt;/a&gt; to that section. Everyone else, we start at the beginning:&lt;/p&gt;

&lt;h3&gt;&lt;a href="#background-testing-works"&gt;Background: Testing Works!&lt;/a&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;“If you read a piece of text through twenty times, you will not learn it by heart so easily as if you read it ten times while attempting to recite from time to time and consulting the text when your memory fails.” –&lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Novum_Organum"&gt;The New Organon&lt;/a&gt;&lt;/em&gt;, &lt;a href="https://en.wikipedia.org/wiki/Francis_Bacon"&gt;Francis Bacon&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The &lt;a href="https://en.wikipedia.org/wiki/Testing_effect"&gt;testing effect&lt;/a&gt; is the established psychological observation that the mere act of testing someone’s memory will strengthen the memory (regardless of whether there is feedback). Since &lt;a href="https://en.wikipedia.org/wiki/Spaced_repetition"&gt;spaced repetition&lt;/a&gt; is just testing on particular days, we ought to establish that testing works better than regular review or study, and that it works outside of memorizing random dates in history. To cover a few papers:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Allen, G.A., Mahler, W.A., &amp;amp; Estes, W.K. (196956ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1969-allen.pdf"&gt;“Effects of recall tests on long-term retention of paired associates”&lt;/a&gt;. &lt;em&gt;Journal of Verbal Learning and Verbal Behavior&lt;/em&gt;, 8, 463-470&lt;/p&gt;
&lt;p&gt;1 test results in memories as strong a day later as studying 5 times; intervals improve retention compared to massed presentation.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Karpicke &amp;amp; Roediger (200322ya). &lt;a href="https://gwern.net/doc/www/www.wsu.edu/992e041a4a60ef70f816fadb6ac3ecc7409ba6c1.html"&gt;“The Critical Importance of Retrieval for Learning”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In learning Swahili vocabulary, students were given varying routines of testing or studying or testing and studying; this resulted in similar scores during the learning phase. Students were asked to predict what percentage they’d remember (average: 50% over all groups). One week later, the students who tested remembered ~80% of the vocabulary versus ~35% for non-testing students. Some students were tested or studied more than others; diminishing returns set in quickly once the memory had formed the first day. Students reported rarely testing themselves and not testing already learned items.&lt;/p&gt;
&lt;p&gt;Lesson: again, testing improves memory compared to studying. Also, no student knows this.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Roediger &amp;amp; Karpicke (200619yaa). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2006-roediger.pdf"&gt;“Test-Enhanced Learning: Taking Memory Tests Improves Long-Term Retention”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Students were tested (with no feedback) on reading comprehension of a passage over 5 minutes, 2 days, and 1 week. Studying beat testing over 5 minutes, but nowhere else; students believed studying superior to testing over all intervals. At 1 week, testing scores were ~60% versus ~40%.&lt;/p&gt;
&lt;p&gt;Lesson: testing improves memory compared to studying. Everyone (teachers &amp;amp; students) ‘knows’ the opposite.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Karpicke &amp;amp; Roediger (200619yaa). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2007-karpicke.pdf"&gt;“Expanding retrieval promotes short-term retention, but equal interval retrieval enhances long-term retention”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;General scientific prose comprehension; from Roediger &amp;amp; Karpicke2006b: “After 2 days, initial testing produced better retention than restudying (68% versus 54%), and an advantage of testing over restudying was also observed after 1 week (56% versus 42%).”&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Roediger &amp;amp; Karpicke (200619yab). &lt;a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.858.5753&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;“The Power of Testing Memory: Basic Research and Implications for Educational Practice”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Literature review; 7 studies before 194184ya demonstrating testing improves retention, and 6 afterwards. See also the reviews &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2006-thalheimer.pdf"&gt;“Spacing Learning Events Over Time: What the Research Says”&lt;/a&gt; &amp;amp; &lt;a href="https://laplab.ucsd.edu/articles/Carpenter_etal_EPR2012.pdf"&gt;“Using spacing to enhance diverse forms of learning: Review of recent research and implications for instruction”&lt;/a&gt;, Carpenter et al 2012.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Agarwal et al 2008, &lt;a href="https://pdfs.semanticscholar.org/7521/c9adbe66cb2e777f37b6b00e97f5f95633c2.pdf"&gt;“Examining the Testing Effect with Open- and Closed-Book Tests”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As with #2, the purer forms of testing (in this case, open-book versus closed-book testing) did better over the long run, and students were deluded about what worked best.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bangert-Drowns et al 1991. &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1991-bangertdrowns.pdf"&gt;“Effects of frequent classroom testing”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Meta-analysis of 35 studies (1929–60198936ya) varying tests during school semesters. 29 found benefits; 5 found negatives; 1 null result. Meta-study found large benefits to testing even once, then diminishing returns.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Cook2006, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2006-cook.pdf"&gt;“Impact of self-assessment questions and learning styles in Web-based learning: a randomized, controlled, crossover trial”&lt;/a&gt;; final scores were higher when the doctors (residents) learned with questions.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Johnson &amp;amp; Kiviniemi2009, &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2747780/"&gt;“The Effect of Online Chapter Quizzes on Exam Performance in an Undergraduate Social Psychology Course”&lt;/a&gt; (“This study examined the effectiveness of compulsory, mastery-based, weekly reading quizzes as a means of improving exam and course performance. Completion of reading quizzes was related to both better exam and course performance.”); see also &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2012-mcdaniel.pdf"&gt;McDaniel et al 2012&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Metsämuuronen2013, &lt;a href="https://www.ccsenet.org/journal/index.php/jedp/article/download/19582/15080"&gt;“Effect of Repeated Testing on the Development of Secondary Language Proficiency”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Meyer &amp;amp; Logan2013, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2013-meyer.pdf"&gt;“Taking the Testing Effect Beyond the College Freshman: Benefits for Lifelong Learning”&lt;/a&gt;; verifies testing effect in older adults has similar &lt;a href="https://en.wikipedia.org/wiki/Effect_size"&gt;effect size&lt;/a&gt; as younger&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Larsen &amp;amp; Butler2013, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2013-larsen.pdf"&gt;“Test-enhanced learning”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Yang et al 2021, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2021-yang.pdf"&gt;“Testing (Quizzing) Boosts Classroom Learning: A Systematic And Meta–Analytic Review”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;(One might be tempted to object that testing works for &lt;em&gt;some&lt;/em&gt; &lt;a href="https://en.wikipedia.org/wiki/Learning_styles"&gt;learning styles&lt;/a&gt;, perhaps verbal styles. This is an unsupported assertion inasmuch as the experimental literature on learning styles is poor and the existing evidence mixed that there are such things as learning styles.&lt;a href="#fn24"&gt;24&lt;/a&gt;)&lt;/p&gt;

&lt;h4&gt;&lt;a href="#subjects"&gt;Subjects&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;The above studies often used pairs of words or words themselves. How well does the testing effect generalize?&lt;/p&gt;
&lt;p&gt;Materials which benefited from testing:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;foreign vocabulary (eg. Karpicke &amp;amp; Roediger2003, &lt;a href="https://gwern.net/doc/www/home.cs.colorado.edu/9596a4aa6a1cfc50aadc329fe0acc4c30de8ee82.pdf"&gt;Cepeda et al 2009&lt;/a&gt;, Fritz et al 2007&lt;a href="#fn25"&gt;25&lt;/a&gt;, &lt;a href="https://gwern.net/doc/www/scholar.sun.ac.za/597ea379e3550e15a6355df58db5b19464dddd42.pdf"&gt;de la Rouviere2012&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Graduate_Record_Examinations"&gt;GRE&lt;/a&gt; materials (like vocab, &lt;a href="#kornell-2009"&gt;Kornell2009&lt;/a&gt;); prose passages on general scientific topics (Karpicke &amp;amp; Roediger, 200619yaa; Pashler et al, 200322ya)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;trivia (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1991-mcdaniel.pdf"&gt;McDaniel &amp;amp; Fisher1991&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;elementary &amp;amp; middle school lessons with subjects such as biographical material and science (&lt;a href="https://archive.org/details/recitationasafa00gategoog"&gt;Gates1917&lt;/a&gt;; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1939-spitzer.pdf"&gt;Spitzer1939&lt;/a&gt;&lt;a href="#fn26"&gt;26&lt;/a&gt; and Vlach &amp;amp; Sandhofer2012&lt;a href="#fn27"&gt;27&lt;/a&gt;, respectively)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Agarwal et al 2008: short-answer tests superior on textbook passages&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;history textbooks; retention better with initial short-answer test rather than multiple choice (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1982-nungester.pdf"&gt;Nungester &amp;amp; Duchastel1982&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1975-laporte.pdf"&gt;LaPorte &amp;amp; Voss1975&lt;/a&gt; also found better retention compared to multiple-choice or recognition problems&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1981-duchastel"&gt;Duchastel &amp;amp; Nungester, 1981&lt;/a&gt;: 6 months after testing, testing beat studying in retention of a history passage&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1981-duchastel.pdf"&gt;Duchastel1981&lt;/a&gt;: free recall decisively beat short-answer &amp;amp; multiple choice for reading comprehension of a history passage&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1989-glover.pdf"&gt;Glover1989&lt;/a&gt;: free recall self-test beat recognition or &lt;a href="https://en.wikipedia.org/wiki/Cloze_test"&gt;Cloze deletions&lt;/a&gt;; subject matter was the labels for parts of flowers&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2007-kang.pdf"&gt;Kang et al 2007&lt;/a&gt;: prose passages; initial short answer testing produced superior results 3 days later on both multiple choice and short answer tests&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2002-leeming.pdf"&gt;Leeming2002&lt;/a&gt;: tests in 2 psychology courses, introductory &amp;amp; memory/learning; “80% versus 74% for the introductory psychology course and 89% versus 80% for the learning and memory course”&lt;a href="#fn28"&gt;28&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This covers a pretty broad range of what one might call ‘declarative’ knowledge. Extending testing to other fields is more difficult and may reduce to ‘write many frequent analyses, not large ones’ or ‘do lots of small exercises’, whatever those might mean in those fields:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A third issue, which relates to the second, is whether our proposal of testing is really appropriate for courses with complex subject matters, such as the philosophy of Spinoza, Shakespeare’s comedies, or creative writing. Certainly, we agree that most forms of objective testing would be difficult in these sorts of courses, but we do believe the general philosophy of testing (broadly speaking) would hold-students should be continually engaged and challenged by the subject matter, and there should not be merely a midterm and final exam (even if they are essay exams). Students in a course on Spinoza might be assigned specific readings and thought-provoking essay questions to complete every week. This would be a transfer-appropriate form of weekly ‘testing’ (albeit with take-home exams). Continuous testing requires students to continuously engage themselves in a course; they cannot coast until near a midterm exam and a final exam and begin studying only then.&lt;a href="#fn29"&gt;29&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;


&lt;h4&gt;&lt;a href="#downsides"&gt;Downsides&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Testing does have some known flaws:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;interference in recall - ability to remember tested items drives out ability to remember similar untested items&lt;/p&gt;
&lt;p&gt;Most/all studies were in laboratory settings and found relatively small effects:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In sum, although various types of recall interference are quite real (and quite interesting) phenomena, we do not believe that they compromise the notion of test-enhanced learning. At worst, interference of this sort might dampen positive testing effects somewhat. However, the positive effects of testing are often so large that in most circumstances they will overwhelm the relatively modest interference effects.&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;multiple choice tests can accidentally lead to ‘negative suggestion effects’ where having previously seen a falsehood as an item on the test makes one more likely to believe it.&lt;/p&gt;
&lt;p&gt;This is mitigated or eliminated when there’s quick feedback about the right answer (see Butler &amp;amp; Roediger2008 &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2008-butler.pdf"&gt;“Feedback enhances the positive effects and reduces the negative effects of multiple-choice testing”&lt;/a&gt;). Solution: don’t use multiple choice; inferior in testing ability to free recall or short answers, anyway.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Neither problem seems major.&lt;/p&gt;



&lt;h3&gt;&lt;a href="#distributed"&gt;Distributed&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;A lot depends on &lt;em&gt;when&lt;/em&gt; you do all your testing. Above we saw some benefits to testing a lot the moment you learn something, but the same number of tests could be spread out over time, to give us the &lt;em&gt;spacing effect&lt;/em&gt; or &lt;em&gt;spaced repetition&lt;/em&gt;. There are hundreds of studies involving the spacing effect:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/uweb.cas.usf.edu/f1052ecdd92f0ecc3f57bdd890a4a6558483ec45.pdf"&gt;Cepeda et al 2006&lt;/a&gt; is a review of 184 articles with 317 experiments; other reviews include:&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ruch1928, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1928-ruch.pdf"&gt;“Factors influencing the relative economy of massed and distributed practice in learning”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Crowder1976, &lt;a href="https://www.amazon.com/Principles-Learning-Memory-Experimental-Psychology/dp/0898591155/"&gt;&lt;em&gt;Principles of learning and memory&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Dempster1989, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1989-dempster.pdf"&gt;“Spacing effects and their implications for theory and practice”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Delaney et al 2010, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2010-delaney.pdf"&gt;“Spacing and testing effects: A deeply critical, lengthy, and at times discursive review of the literature”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Donovan &amp;amp; Radosevich1999, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1999-donovan.pdf"&gt;“A meta-analytic review of the distribution of practice effect: Now you see it, now you don’t”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Greene1992, &lt;a href="https://www.amazon.com/Human-Memory-Paradigms-Robert-Greene/dp/080580997X/"&gt;&lt;em&gt;Human memory: Paradigms and paradoxes&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Janiszewski et al 2003, &lt;a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.200.8846&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;“A meta-analysis of the spacing effect in verbal learning: Implications for research on advertising repetition and consumer memory”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Pavlik &amp;amp; Anderson2003, &lt;a href="https://gwern.net/doc/www/act-r.psy.cmu.edu/f4b85d71f1bd93309c094119607097a071bb09e3.pdf"&gt;“An ACT-R model of the spacing effect”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Balota et al 2007, &lt;a href="https://gwern.net/doc/www/psychnet.wustl.edu/13ef191de62e05c797f57dea636fd88aceda45f7.pdf"&gt;“Is Expanded Retrieval Practice a Superior Form of Spaced Retrieval? A Critical Review of the Extant Literature”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Carpenter et al 2012, &lt;a href="https://gwern.net/doc/www/files.eric.ed.gov/d4c13c54c8c572edcddb399d9edd03d7b31c30c5.pdf"&gt;“Using Spacing to Enhance Diverse Forms of Learning: Review of Recent Research and Implications for Instruction”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Almost unanimously they find spacing out tests is superior to massed testing when the final test/measurement is conducted days or years later&lt;a href="#fn30"&gt;30&lt;/a&gt;, although the mechanism isn’t clear&lt;a href="#fn31"&gt;31&lt;/a&gt;. Besides all the previously mentioned studies, we can throw in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Peterson, L. R., Wampler, R., Kirkpatrick, M., &amp;amp; Saltzman, D. (196362ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1963-peterson.pdf"&gt;“Effect of spacing presentations on retention of a paired associate over short intervals”&lt;/a&gt;. &lt;em&gt;Journal of Experimental Psychology&lt;/em&gt;, 66(2), 206-209&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Glenberg, A. M. (197748ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1977-glenberg.pdf"&gt;“Influences of retrieval processes on the spacing effect in free recall”&lt;/a&gt;. &lt;em&gt;Journal of Experimental Psychology: Human Learning and Memory&lt;/em&gt;, 3(3), 282-294&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Balota et al 1989, &lt;a href="https://gwern.net/doc/www/psychnet.wustl.edu/ad28721c2c4227dff59f1061c900d6ee8b7096da.pdf"&gt;“Age-related differences in the impact of spacing, lag and retention interval”&lt;/a&gt;. &lt;em&gt;Psychology and Aging&lt;/em&gt;, 4, 3-9&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The research literature focuses &lt;em&gt;extensively&lt;/em&gt; on the question of &lt;em&gt;what kind&lt;/em&gt; of spacing is best and what this implies about memory: a spacing that has static fixed intervals or a spacing which expands? This is important for understanding memory and building models of it, and would be helpful for integrating spaced repetition into classrooms (for example, &lt;a href="https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2013.00589/full"&gt;Kelley &amp;amp; Whatson2013’s&lt;/a&gt; 10 minutes studying / 10 minutes break schedule, repeating the same material 3 times, designed to trigger LTM formation on that block of material?) But for practical purposes, this is uninteresting; to sum it up, there are many studies pointing each way, and whatever difference in efficiency exists, is minimal. Most existing software follows SuperMemo in using an expanding spacing algorithm, so it’s not worth worrying about; as Mnemosyne developer Peter Bienstman says, it’s not clear the more complex algorithms really help&lt;a href="#fn32"&gt;32&lt;/a&gt;, and the Anki developers &lt;a href="https://faqs.ankiweb.net/what-spaced-repetition-algorithm.html"&gt;were concerned about&lt;/a&gt; the complexity, difficulty of reimplementing SM’s proprietary algorithms, lack of substantial gains, &amp;amp; larger errors SM3+ risks attempting to be more optimal. So too here.&lt;/p&gt;
&lt;p&gt;For those interested, 3 of the studies that found fixed spacings better than expanding:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Carpenter, S. K., &amp;amp; DeLosh, E. L. (200520ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2005-carpenter.pdf"&gt;“Application of the testing and spacing effects to name learning”&lt;/a&gt;. &lt;em&gt;Applied Cognitive Psychology&lt;/em&gt;, 19, 619-636&lt;a href="#fn33"&gt;33&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Logan, J. M. (200421ya). &lt;em&gt;Spaced and expanded retrieval effects in younger and older adults&lt;/em&gt;. Unpublished doctoral dissertation, Washington University, St. Louis, MO&lt;/p&gt;
&lt;p&gt;This thesis is interesting inasmuch as Logan found that young adults did considerably worse with an expanding spacing after a day.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Karpicke &amp;amp; Roediger, 200619yaa&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The fixed vs expanding issue aside, a list of additional generic studies finding benefits to spaced vs massed:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Cepeda et al 2006 (large review used elsewhere in this page)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Karpicke &amp;amp; Roediger2006a&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rohrer &amp;amp; Taylor2006. &lt;a href="https://gwern.net/doc/www/uweb.cas.usf.edu/f3db157e6865f52ea1c6a9a798ef6ef3d90f20cc.pdf"&gt;“The effects of over-learning and distributed practice on the retention of mathematics knowledge”&lt;/a&gt;. &lt;em&gt;Applied Cognitive Psychology&lt;/em&gt;, 20: 1209–1224 (see also &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2007-rohrer.pdf"&gt;Rohrer &amp;amp; Taylor2007&lt;/a&gt;, &lt;a href="https://gwern.net/doc/www/escholarship.org/8b8cf9c5d31cdc8726cafc89299bf70e68abb45d.pdf"&gt;Rohrer et al 2005&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Seabrook et al 2005. &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2005-seabrook.pdf"&gt;“Distributed and Massed Practice: From Laboratory to Classroom”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Keppel, Geoffrey. &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1967-keppel.pdf"&gt;“A Reconsideration of the Extinction-Recovery Theory”&lt;/a&gt;. &lt;em&gt;Journal of Verbal Learning &amp;amp; Verbal Behavior&lt;/em&gt;. 6(4) 196758ya, 476-486&lt;/p&gt;
&lt;p&gt;A week later, the massed reviewers went from 5.9 correct → 2.1; the spaced reviewers went from 5.5 → 5.0. (Note the usual observation: massed was initially better, and later much worse, less than half as good.)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bloom &amp;amp; Schuell1981, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1981-bloom.pdf"&gt;“Effects of massed and distributed practice on the learning and retention of second-language vocabulary”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Four days after the 2 high school groups memorized 16 French words, the spaced group remembered 15 and the massed 11.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rea &amp;amp; Modigliani1985, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1985-rea.pdf"&gt;“The effect of expanded versus massed practice on the retention of multiplication facts and spelling lists”&lt;/a&gt;&lt;a href="#fn34"&gt;34&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A test immediately following the training showed superior performance for the distributed group (70% correct) compared to the massed group (53% correct). These results seem to show that the spacing effect applies to school-age children and to at least some types of materials that are typically taught in school.&lt;a href="#fn35"&gt;35&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Donovan &amp;amp; Radosevich1999, &lt;a href="#donovan-radosevich-1999"&gt;“A meta-analytic review of the distribution of practice effect: Now you see it, now you don’t”&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;According to Donovan &amp;amp; Radosevich’s meta-analysis of spacing studies, the &lt;a href="https://en.wikipedia.org/wiki/Effect_size"&gt;effect size&lt;/a&gt; for the spacing effect is &lt;a href="https://en.wikipedia.org/wiki/Effect_size#Cohen%27s_d"&gt;&lt;em&gt;d&lt;/em&gt;&lt;/a&gt; = 0.42. This means that the average person getting distributed training remembers better than about 67% of the people getting massed training. This effect size is nothing to sneeze at-in education research, effect sizes as low as &lt;em&gt;d&lt;/em&gt; = 0.25 are considered “practically significant”, while effect sizes above &lt;em&gt;d&lt;/em&gt; = 1 are rare.&lt;a href="#fn36"&gt;36&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;In one meta-analysis by Donovan &amp;amp; Radosevich1999, for instance, the size of the spacing effect declined sharply as conceptual difficulty of the task increased from low (eg. rotary pursuit) to average (eg. word list recall) to high (eg. puzzle). By this finding, the benefits of spaced practise may be muted for many mathematics tasks.&lt;a href="#fn37"&gt;37&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The Donovan meta-analysis notes that the effect size is smaller in studies with better methodology, but still important.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Bahrick, Harry P; Phelphs, Elizabeth. &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1987-bahrick.pdf"&gt;“Retention of Spanish vocabulary over 8 years”&lt;/a&gt;. &lt;em&gt;Journal of Experimental Psychology: Learning, Memory, &amp;amp; Cognition&lt;/em&gt;. Vol 13(2) April 198738ya, 344-349; the extremely long delay after the initial training period makes this particularly interesting:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Harry Bahrick and Elizabeth Phelps (198738ya) examined the retention of 50 Spanish vocabulary words after an eight-year delay. Subjects were divided into three groups. Each practiced for seven or eight sessions, separated by a few minutes, a day, or 30 days. In each session, subjects practiced until they could produce the list perfectly one time….Eight years later, people in the no-delay group could recall 6% of the words, people in the one-day delay group could remember 8%, and those in the 30-day group averaged 15%. Everyone also took a multiple choice test, and again, the spacing effect was observed. The no-delay group scored 71%, the one-day group scored 80%, and the 30-day group scored 83%.&lt;/p&gt;
&lt;p&gt;…Bahrick and his colleagues varied both the spacing of practice and the amount of practice. Practice sessions were spaced 14, 28, or 56 days apart, and totaled 13 or 26 sessions. They tested subjects’ memory one, two, three, and five years after training. Once again, it took a bit longer to reach the criterion within each session when practice sessions were spaced farther apart, but again, this small investment paid dividends years later. It didn’t matter whether testing occurred at one, two, three, or five years after practice-the 56-day group always remembered the most, the 28-day group was next, and the 14-day group remembered the least. Further, the effect was quite large. If words were practiced every 14 days, you needed twice as much practice to reach the same level of performance as when words were practiced every 56 days!&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Pashler et al 2003; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2003-pashler.pdf"&gt;“Is Temporal Spacing of Tests Helpful Even When It Inflates Error Rates?”&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Long intervals between tests necessarily means you will often err; errors were thought to intrinsically reduce learning. While the extra errors do damage accuracy in the short-run, the long intervals are powerful enough that they still win.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;works in ill subpopulations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;works on short-term review conducted with Alzheimer’s patients; spacing used on the scale of seconds and minutes, with modest success in teaching object locations or daily tasks to do&lt;a href="#fn38"&gt;38&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Camp, C. J. (198936ya). “Facilitation of new learning in Alzheimer’s disease”. In G. C. Gilmore, P. J. Whitehouse, &amp;amp; M. L. Wykle (Eds.), &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1989-gilmore-memoryaginganddementia.pdf"&gt;&lt;em&gt;Memory, aging, and dementia&lt;/em&gt;&lt;/a&gt; (pp. 212-225)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Camp, C. J., &amp;amp; McKitrick, L. A. (199233ya). “Memory interventions in Alzheimer’s-type dementia populations: Methodological and theoretical issues”. In R. L. West &amp;amp; J. D. Sinnott (Eds.), &lt;em&gt;Everyday memory and aging: Current research and methodology&lt;/em&gt; (pp. 152-172) -&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;works with traumatic brain injury; Goverover et al 2009, &lt;a href="https://pdfs.semanticscholar.org/0eb4/8078fdc906f368d22f324e0520e4ee4f9c08.pdf"&gt;“Application of the spacing effect to improve learning and memory for functional tasks in traumatic brain injury: a pilot study”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;and multiple sclerosis; Goverover et al 2009, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2009-goverover.pdf"&gt;“A functional application of the spacing effect to improve learning and memory in persons with multiple sclerosis”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;math&lt;a href="#fn39"&gt;39&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;multiplication (Ria &amp;amp; Modigliani1985)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Permutation"&gt;permuting&lt;/a&gt; a sequence (Rohrer &amp;amp; Taylor2006)on&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;calculating the volume of &lt;a href="https://en.wikipedia.org/wiki/Polyhedron"&gt;polyhedrons&lt;/a&gt; (Rohrer &amp;amp; Taylor2007)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;statistics (&lt;a href="https://gwern.net/doc/www/people.tamu.edu/152abdda0168e4cabcc6b63e2f013c612eaa7ced.pdf"&gt;Smith &amp;amp; Rothkopf1984&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;pre-calculus (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1997-revak.pdf"&gt;Revak1997&lt;/a&gt;&lt;a href="#fn40"&gt;40&lt;/a&gt; but there’s a related &lt;a href="https://digitalcommons.lib.uconn.edu/dissertations/AAI3464319/"&gt;null ‘calculus I’ result&lt;/a&gt; as well) and algebra (&lt;a href="https://gwern.net/doc/www/www.ncbi.nlm.nih.gov/2827e00cfdd92c27c95ed4fb50b81cd8748ee277.pdf"&gt;Mayfield &amp;amp; Chase2002&lt;/a&gt;, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2013-patac.pdf"&gt;Patac &amp;amp; Patac2013&lt;/a&gt;; possible null, &lt;a href="https://gwern.net/doc/www/getd.libs.uga.edu/c6e8cb41c66f055e0751c340cbe1ac720e48e50a.pdf"&gt;Sutherland2013&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;medicine (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2009-kerfoot-2.pdf"&gt;Kerfoot &amp;amp; Brotschi2009&lt;/a&gt;, &lt;a href="https://qualitysafety.bmj.com/content/21/10/819.abstract"&gt;Shaw et al 2012&lt;/a&gt;; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2009-kerfoot.pdf"&gt;Kerfoot2009&lt;/a&gt;, a 2 year followup to &lt;a href="https://pdfs.semanticscholar.org/f2b5/aed794e5d164065a184207f2663620b96ba3.pdf"&gt;Kerfoot et al 2007&lt;/a&gt; and Kerfoot has a number of &lt;a href="https://gwern.net/doc/www/app.qstream.com/837e7b34437ca4eb491a2445b8137251e129f6cf.html"&gt;other relevant studies&lt;/a&gt;; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2013-gyorki.pdf"&gt;Gyorki et al 2013&lt;/a&gt;) and surgery (Moulton et al 2006, &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1856544/"&gt;“Teaching Surgical Skills: What Kind of Practice Makes Perfect? A Randomized, Controlled Trial”&lt;/a&gt;, distributed practice of microvascular suturing; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2014-spruit.pdf"&gt;Spruit et al 2014&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;introductory psychology (Balch2006, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2006-balch.pdf"&gt;“Encouraging Distributed Study: A Classroom Experiment on the Spacing Effect”&lt;/a&gt;&lt;a href="#fn41"&gt;41&lt;/a&gt;. &lt;em&gt;Teaching of Psychology&lt;/em&gt;, 33, 249-252)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;8th-grade American history (&lt;a href="https://laplab.ucsd.edu/articles/CarpenterPashlerCepeda2009.pdf"&gt;Carpenter, Pashler, and Cepeda2009&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;learning to read with phonics (Seabrook et al 2005)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;music (&lt;a href="https://gwern.net/doc/www/works.bepress.com/6231da74f5201ec67ab2de100117f9b5096df6e7.pdf"&gt;Stambaugh2009&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;biology (middle school; &lt;a href="https://www.frontiersin.org/journals/human-neuroscience/articles/10.3389/fnhum.2013.00589/full"&gt;Kelly &amp;amp; Whatson2013&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;statistics (introductory; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2015-maas.pdf"&gt;Maas et al 2015&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;memorizing website passwords (&lt;a href="https://gwern.net/doc/www/www.usenix.org/312fca94dae955e6c5ef3b5a501f48abf3269cdc.pdf"&gt;Bonneau &amp;amp; Schechter2014&lt;/a&gt;, &lt;a href="https://gwern.net/doc/www/arxiv.org/0387b201b08a5bbade2de7b18b724df492fa0e38.pdf"&gt;Blocki et al 2014&lt;/a&gt;, &lt;a href="https://gwern.net/doc/www/arxiv.org/cf0a1dcb7600d6a0345889b03fb444717aec9052.pdf"&gt;Blum &amp;amp; Vempala2017&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;possibly not Australian constitutional law (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2015-colbran.pdf"&gt;Colbran et al 2015&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;&lt;a href="#generality-of-spacing-effect"&gt;Generality of Spacing Effect&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;We have already seen that spaced repetition is effective on a variety of academic fields and mediums. Beyond that, spacing effects can be found in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;various “domains (eg. learning perceptual motor tasks or learning lists of words)”&lt;a href="#fn42"&gt;42&lt;/a&gt; such as spatial&lt;a href="#fn43"&gt;43&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“across species (eg. &lt;a href="https://www.jneurosci.org/content/21/7/2404.long"&gt;rats&lt;/a&gt;, pigeons, and humans [or &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3044934/"&gt;flies&lt;/a&gt; or &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC311375/"&gt;bumblebees&lt;/a&gt;, and sea slugs, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1972-carew.pdf"&gt;Carew et al 1972&lt;/a&gt; &amp;amp; &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC155928/"&gt;Sutton et al 2002&lt;/a&gt;])”&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“across age groups [infancy&lt;a href="#fn44"&gt;44&lt;/a&gt;, childhood&lt;a href="#fn45"&gt;45&lt;/a&gt;, adulthood&lt;a href="#fn46"&gt;46&lt;/a&gt;, the elderly&lt;a href="#fn47"&gt;47&lt;/a&gt;] and individuals with different memory impairments”&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“and across retention intervals of seconds&lt;a href="#fn48"&gt;48&lt;/a&gt; [to days&lt;a href="#fn49"&gt;49&lt;/a&gt;] to months” (we have already seen studies using years)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The domains are limited, however. Cepeda et al 2006:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[&lt;a href="https://gwern.net/doc/www/digitalcommons.usu.edu/85d5379d46ea57192d26c167a91b4025573a1208.pdf"&gt;Moss1995&lt;/a&gt;, reviewing 120 articles] concluded that longer ISIs facilitate learning of verbal information (eg. spelling&lt;a href="#fn50"&gt;50&lt;/a&gt;) and motor skills (eg. mirror tracing); in each case, over 80% of studies showed a distributed practice benefit. In contrast, only one third of intellectual skill (eg. math computation) studies showed a benefit from distributed practice, and half showed no effect from distributed practice.&lt;/p&gt;
&lt;p&gt;…[Donovan &amp;amp; Radosevich1999] The largest effect sizes were seen in low rigor studies with low complexity tasks (eg. rotary pursuit, typing, and peg reversal), and retention interval failed to influence effect size. The only interaction Donovan and Radosevich examined was the interaction of ISI and task domain. It is important to note that task domain moderated the distributed practice effect; depending on task domain and lag, an increase in ISI either increased or decreased effect size. Overall, Donovan and Radosevich found that increasingly distributed practice resulted in larger effect sizes for verbal tasks like free recall, foreign language, and verbal discrimination, but these tasks also showed an inverse-U function, such that very long lags produced smaller effect sizes. In contrast, increased lags produced smaller effect sizes for skill tasks like typing, gymnastics, and music performance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Skills like gymnastics and music performance raise an important point about the testing effect and spaced repetition: they are for the maintenance of memories or skills, they do not increase it beyond what was already learned. If one is a gifted amateur when one starts reviewing, one remains a gifted amateur. Ericsson covers what is necessary to &lt;em&gt;improve&lt;/em&gt; and attain new expertise: &lt;a href="https://en.wikipedia.org/wiki/Practice_(learning_method)#Deliberate_practice"&gt;deliberate practice&lt;/a&gt;&lt;a href="#fn51"&gt;51&lt;/a&gt;. From &lt;a href="https://gwern.net/doc/psychology/writing/1993-ericsson.pdf"&gt;“The Role of Deliberate Practice”&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The view that merely engaging in a sufficient amount of practice—regardless of the structure of that practice—leads to maximal performance, has a long and contested history. In their classic studies of Morse Code operators, Bryan and Harter (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1897-bryan.pdf"&gt;1897&lt;/a&gt;, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1899-william.pdf"&gt;1899&lt;/a&gt;) identified plateaus in skill acquisition, when for long periods subjects seemed unable to attain further improvements. However, with extended efforts, subjects could restructure their skill to overcome plateaus…Even very experienced Morse Code operators could be encouraged to dramatically increase their performance through deliberate efforts when further improvements were required…More generally, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1921-thorndike-educationalpsychology-v2-thepsychologyoflearning.pdf#page=188"&gt;Thorndike (1921104ya)&lt;/a&gt; observed that adults perform at a level far from their maximal level even for tasks they frequently carry out. For instance, adults tend to write more slowly and illegibly than they are capable of doing…The most cited condition [for optimal learning and improvement of performance] concerns the subjects’ motivation to attend to the task and exert effort to improve their performance…The subjects should receive immediate informative feedback and knowledge of results of their performance…In the absence of adequate feedback, efficient learning is impossible and improvement only minimal even for highly motivated subjects. Hence mere repetition of an activity will not automatically lead to improvement in, especially, accuracy of performance…In contrast to play, deliberate practice is a highly structured activity, the explicit goal of which is to improve performance. Specific tasks are invented to overcome weaknesses, and performance is carefully monitored to provide cues for ways to improve it further. We claim that deliberate practice requires effort and is not inherently enjoyable.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h5&gt;&lt;a href="#motor-skills"&gt;Motor Skills&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;It should be noted that reviews conflict on how much spaced repetition applies to motor skills; Lee &amp;amp; Genovese1988 find benefits, while Adams1987 and earlier do not. The difference may be that simple motor tasks benefit from spacing as suggested by &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1979-shea.pdf"&gt;Shea &amp;amp; Morgan1979&lt;/a&gt; (benefits to a randomized/spaced schedule), while &lt;em&gt;complex&lt;/em&gt; ones where the subject is already operating at his limits do not benefit, suggested by &lt;a href="https://pdfs.semanticscholar.org/c747/336e77ce39f7f5cdbd937684a7f564e9e194.pdf"&gt;Wulf &amp;amp; Shea2002&lt;/a&gt;. Stambaugh2009 mentions some divergent studies:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The contextual interference hypothesis (Shea and Morgan1979, Battig1966 [“Facilitation and interference” in &lt;a href="https://archive.org/details/acquisitionofski00conf"&gt;&lt;em&gt;Acquisition of skill&lt;/em&gt;&lt;/a&gt;]) predicted the blocked condition would exhibit superior performance immediately following practice (acquisition) but the random condition would perform better at delayed retention testing. This hypothesis is generally consistent in laboratory motor learning studies (eg. &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1983-lee.pdf"&gt;Lee &amp;amp; Magill1983&lt;/a&gt;, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2004-brady.pdf"&gt;Brady2004&lt;/a&gt;), but less consistent in applied studies of sports skills (with a mix of positive &amp;amp; negative eg. &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1997-landin.pdf"&gt;Landin &amp;amp; Hebert1997&lt;/a&gt;, Hall et al 1994, &lt;a href="https://gwern.net/doc/www/digitalcommons.mtu.edu/e173a9a1a6a853fc34209edaf721cde0b52fb1a2.pdf"&gt;Regal2013&lt;/a&gt;) and fine-motor skills (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2005-ollis.pdf"&gt;Ollis et al 2005&lt;/a&gt;, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2004-stemarie.pdf"&gt;Ste-Marie et al 2004&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Some of the positive spaced repetition studies (from Son &amp;amp; Simon2012):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Perhaps even prior to the empirical work on cognitive learning and the spacing effect, the benefits of spaced study had been apparent in an array of motor learning tasks, including maze learning (Culler1912), typewriting (Pyle1915), archery (Lashley1915), and javelin throwing (Murphy1916; see Ruch1928, for a larger review of the motor learning tasks which reap benefits from spacing; see also Moss1996, for a more recent review of motor learning tasks). Thus, as in the cognitive literature, the study of practice distribution in the motor domain is long established (see reviews by Adams1987; Schmidt &amp;amp; Lee2005), and most interest has centered around the impact of varying the separation of learning trials of motor skills in learning and retention of practiced skills. Lee &amp;amp; Genovese1988 conducted a review and meta-analysis of studies on distribution of practice, and they concluded that massing of practice tends to depress both immediate performance and learning, where learning is evaluated at some removed time from the practice period. Their main finding was, as in the cognitive literature, that learning was relatively stronger after spaced than after massed practice (although see Ammons1988; Christina &amp;amp; Shea1988; Newell et al 1988 for criticisms of the review)…Probably the most widely cited example is Baddeley &amp;amp; Longman1978’s study concerning how optimally to teach postal workers to type. They had learners practice once a day or twice a day, and for session lengths of either 1 or 2 h at a time. The main findings were that learners took the fewest cumulative hours of practice to achieve a performance criterion in their typing when they were in the most distributed practice condition. This finding provides clear evidence for the benefits of spacing practice for enhancing learning. However, as has been pointed out (; Lee &amp;amp; Wishart2005), there is also trade-off to be considered in that the total elapsed time (number of days) between the beginning of practice and reaching criterion was substantially longer for the most spaced condition….The same basic results have been repeatedly demonstrated in the decades since (see reviews by Magill &amp;amp; Hall1990; Lee &amp;amp; Simon2004), and with a wide variety of motor tasks including different badminton serves (Goode &amp;amp; Magill1986), rifle shooting (Boyce &amp;amp; Del Rey1990), a pre-established skill, baseball batting (Hall et al 1994), learning different logic gate configurations (Carlson et al 1989; Carlson &amp;amp; Yaure1990), for new users of automated teller machines (Jamieson &amp;amp; Rogers2000), and for solving mathematical problems as might appear in a class homework (Rohrer &amp;amp; Taylor2007; Le Blanc &amp;amp; Simon2008; Taylor &amp;amp; Rohrer2010).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Culler, E. A. (1912113ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1912-culler.pdf"&gt;“The effect of distribution of practice upon learning”&lt;/a&gt;. &lt;em&gt;Journal of Philosophical Psychology&lt;/em&gt;, 9, 580-583&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Pyle, W. H. (1915110ya). &lt;a href="https://books.google.com/books?lr=&amp;amp;id=P8RMAAAAYAAJ&amp;amp;oi=fnd&amp;amp;pg=PA247&amp;amp;ots=ngbgLvHiqb&amp;amp;sig=Dyur1KbbI6Egs4z1lFqm6rYUIqw#v=onepage&amp;amp;q&amp;amp;f=false"&gt;“Concentrated versus distributed practice”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Lashley1915, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1915-lashley.pdf"&gt;“The acquisition of skill in archery”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Murphy, H. H. (1916109ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1916-murphy.pdf"&gt;“Distributions of practice periods in learning”&lt;/a&gt;. Journal of Educational Psychology, 7, 150-162&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Adams, J. A. (198738ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1987-adams.pdf"&gt;“Historical review and appraisal of research on the learning, retention, and transfer of human motor skills”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Schmidt, R. A., &amp;amp; Lee, T. D. (200520ya). &lt;a href="https://www.amazon.com/Motor-Control-Learning-Behavioral-Emphasis/dp/0880114843/"&gt;&lt;em&gt;Motor control and learning: A behavioral emphasis&lt;/em&gt;&lt;/a&gt; (4th ed.). Urbana-Champaign: Human Kinetics&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Lee, T. D., &amp;amp; Genovese, E. D. (198837ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1988-lee.pdf"&gt;“Distribution of practice in motor skill acquisition: Learning and performance effects reconsidered”&lt;/a&gt;. Research Quarterly for Exercise and Sport, 59, 277-287&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Ammons, R. B. (198837ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1988-ammons.pdf"&gt;“Distribution of practice in motor skill acquisition: A few questions and comments”&lt;/a&gt;. Research Quarterly for Exercise and Sport, 59, 288-290&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Christina, R. W., &amp;amp; Shea, J. B. (198837ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1988-christina.pdf"&gt;“The limitations of generalization based on restricted information”&lt;/a&gt;. Research Quarterly for Exercise and Sport, 59, 291-297&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Newell, K. M., Antoniou, A., &amp;amp; Carlton, L. G. (198837ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1988-newell.pdf"&gt;“Massed and distributed practice effects: Phenomena in search of a theory?”&lt;/a&gt; Research Quarterly for Exercise and Sport, 59, 308-313&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Lee, T. D., &amp;amp; Wishart, L. R. (200520ya). &lt;a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.574.5400&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;“Motor learning conundrums (and possible solutions)”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Lee, T. D., &amp;amp; Simon, D. A. (200421ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2004-lee.pdf"&gt;“Contextual interference”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Goode, S., &amp;amp; Magill, R. A. (198639ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1986-goode.pdf"&gt;“Contextual interference effects in learning three badminton serves”&lt;/a&gt;. Research Quarterly for Exercise and Sport, 57, 308-314&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Boyce,, &amp;amp; Del Rey, P. (199035ya). “Designing applied research in a naturalistic setting using a contextual interference paradigm”. Journal of Human Movement Studies, 18, 189-200&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hall et al 1994, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1994-hall.pdf"&gt;“Contextual interference effects with skilled baseball players”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Carlson, R. A., &amp;amp; Yaure, R. G. (199035ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1990-carlson.pdf"&gt;“Practice schedules and the use of component skills in problem solving”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Carlson, R. A., Sullivan, M. A., &amp;amp; Schneider, W. (198936ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1989-carlson.pdf"&gt;“Practice and working memory effects in building procedural skill”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Jamieson,, &amp;amp; Rogers, W. A. (200025ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2000-jamieson.pdf"&gt;“Age-related effects of blocked and random practice schedules on learning a new technology”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Le Blanc, K. &amp;amp; Simon, D. A. (200817ya). “Mixed practice enhances retention and JOL accuracy for mathematical skills”. Poster presented at the 200817ya annual meeting of the Psychonomic Society, Chicago, IL&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Wymbs et al 2016, &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4747782/"&gt;“Motor Skills Are Strengthened through Reconsolidation”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Dayan &amp;amp; Cohen2011, &lt;a href="https://www.sciencedirect.com/science/article/pii/S0896627311009184"&gt;“Neuroplasticity subserving motor skill learning”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Landin et al 1993, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1993-landin.pdf"&gt;“The Effects of Variable Practice on the Performance of a Basketball Skill”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this vein, it’s interesting to note that interleaving may be helpful for tasks with a mental component as well: &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2003-hatala.pdf"&gt;Hatala et al 2003&lt;/a&gt;, &lt;a href="https://pdfs.semanticscholar.org/7e0c/1bb80cbc332f07bda26a75a163a9cf76d591.pdf"&gt;Helsdingen et al 2011&lt;/a&gt;, and according to &lt;a href="https://gwern.net/doc/www/jeffhuang.com/028d7482243a869ea1ec2115b89a379df942bd73.pdf"&gt;Huang et al 2013&lt;/a&gt; the rates at which Xbox &lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Halo:_Reach"&gt;Halo: Reach&lt;/a&gt;&lt;/em&gt; video game players advance in skill matches nicely predictions from distribution: players who play 4–8 matches a week advance more in skill per match, than players who play more (distributed); but advance slower per week than players who play many more matches / massed. (See also &lt;a href="https://eprints.whiterose.ac.uk/97780/"&gt;Stafford &amp;amp; Haasnoot2016&lt;/a&gt;.)&lt;/p&gt;


&lt;h5&gt;&lt;a href="#abstraction"&gt;Abstraction&lt;/a&gt;&lt;/h5&gt;
&lt;p&gt;Another potential objection is to argue&lt;a href="#fn52"&gt;52&lt;/a&gt; that spaced repetition inherently hinders any kind of abstract learning and thought because related materials are not being shown together - allowing for comparison and inference - but days or months apart. Ernst A. Rothkopf: “Spacing is the friend of recall, but the enemy of induction” (Kornell &amp;amp; Bjork2008, p. 585). This is plausible based on some of the early studies&lt;a href="#fn53"&gt;53&lt;/a&gt; but the 4 recent studies I know of directly examining the issue both found spaced repetition helped abstraction as well as general recall:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Kornell &amp;amp; Bjork2008a, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2008-kornell.pdf"&gt;“Learning concepts and categories: Is spacing the ‘enemy of induction’?”&lt;/a&gt; &lt;em&gt;Psychological Science&lt;/em&gt;, 19, 585-592&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Vlach, H. A., Sandhofer, C. M., &amp;amp; Kornell, N. (200817ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2008-vlach.pdf"&gt;“The spacing effect in children’s memory and category induction”&lt;/a&gt;. &lt;em&gt;Cognition&lt;/em&gt;, 109, 163-167&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Kenney2009. &lt;a href="https://gwern.net/doc/www/akenney.fastmail.fm.user.fm/7477c653aabfbdfef0069db81c04f9ebabaf0b8f.pdf"&gt;“The Spacing Effect in Inductive Learning”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Kornell, N., Castel, A. D., Eich, T. S., &amp;amp; Bjork, R. A. (201015ya). &lt;a href="https://gwern.net/doc/www/pdfs.semanticscholar.org/e57d8040b8bafdca6c9d5c494a8158f773cfdc4b.pdf"&gt;“Spacing as the friend of both memory and induction in younger and older adults”&lt;/a&gt;. &lt;em&gt;Psychology and Aging&lt;/em&gt;, 25, 498-503&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2011-zulkiply.pdf"&gt;Zulkiply et al 2011&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Vlach &amp;amp; Sandhofer2012, &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3399982/"&gt;“Distributing Learning Over Time: The Spacing Effect in Children’s Acquisition and Generalization of Science Concepts”&lt;/a&gt;, &lt;em&gt;Child Development&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Zulkiply2012, &lt;a href="https://espace.library.uq.edu.au/view/UQ:281052"&gt;“The spacing effect in inductive learning”&lt;/a&gt;; includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;replication of Kornell &amp;amp; Bjork2008&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Zulkiply et al 2011&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Zulkiply &amp;amp; Burt2012, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2012-zulkiply.pdf"&gt;“The exemplar interleaving effect in inductive learning: Moderation by the difficulty of category discriminations”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;unknown paper currently in peer review&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;McDanie et al 2013, &lt;a href="https://laplab.ucsd.edu/articles/McDaniel.Fadler.Pashler2013.pdf"&gt;“Effects of Spaced versus Massed Training in Function Learning”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Verkoeijen &amp;amp; Bouwmeester2014, &lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3978334/"&gt;“Is spacing really the ‘friend of induction’?”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rohrer et al 2014: &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2014-rohrer.pdf"&gt;1&lt;/a&gt;, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2014-rohrer-2.pdf"&gt;2&lt;/a&gt;; Rorher et al 2019: &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2019-rohrer.pdf"&gt;“A randomized controlled trial of interleaved mathematics practice”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Vlach et al 2014, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2014-vlach.pdf"&gt;“Equal spacing and expanding schedules in children’s categorization and generalization”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Gluckman et al, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2014-gluckman.pdf"&gt;“Spacing Simultaneously Promotes Multiple Forms of Learning in Children’s Science Curriculum”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;




&lt;h3&gt;&lt;a href="#review-summary"&gt;Review Summary&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;To bring it all together with the gist:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;testing is effective and comes with minimal &lt;a href="#downsides"&gt;negative factors&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;expanding spacing is roughly as good as or better than (wide) fixed intervals, but expanding is more convenient and the default&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;testing (and hence spacing) is best on intellectual, highly factual, verbal domains, but may still work in many low-level domains&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the research favors questions which force the user to use their memory as much as possible; in descending order of preference:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;free recall&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;short answers&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;multiple-choice&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Cloze deletion&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;recognition&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the research literature is comprehensive and most questions have been answered - somewhere.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the most common mistakes with spaced repetition are&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;formulating poor questions and answers&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;assuming it will help you learn, as opposed to maintain and preserve what one already learned&lt;a href="#fn54"&gt;54&lt;/a&gt;. (It’s hard to learn &lt;em&gt;from&lt;/em&gt; cards, but if you have learned something, it’s much easier to then devise a set of flashcards that will test your weak points.)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;h2&gt;&lt;a href="#using-it"&gt;Using It&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;One doesn’t need to use SuperMemo, of course; there are plenty of free alternatives. I like &lt;a href="https://en.wikipedia.org/wiki/Mnemosyne_(software)"&gt;Mnemosyne&lt;/a&gt; (&lt;a href="https://mnemosyne-proj.org/"&gt;homepage&lt;/a&gt;) myself - &lt;a href="https://en.wikipedia.org/wiki/Free_software"&gt;Free&lt;/a&gt;, packaged for &lt;a href="https://en.wikipedia.org/wiki/Ubuntu"&gt;Ubuntu Linux&lt;/a&gt;, easy to use, free mobile client, long track record of development and reliability (I’ve used it since ~2008). But the SRS &lt;a href="https://en.wikipedia.org/wiki/Anki_(software)"&gt;Anki&lt;/a&gt; is also popular, and has advantages in being more feature-rich and a larger &amp;amp; more active community (and possibly better support for East Asian language material and a better but proprietary mobile client).&lt;/p&gt;
&lt;p&gt;OK, but what does one do with it? It’s a surprisingly difficult question, actually. It’s akin to “the tyranny of the blank page” (or blank wiki); now that I have all this power - a mechanical golem that will never forget and never let me forget whatever I chose to - what do I choose to remember?&lt;/p&gt;

&lt;h3&gt;&lt;a href="#how-much-to-add"&gt;How Much To Add&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;The most difficult task, beyond that of just persisting until the benefits become clear, is deciding what’s valuable enough to add in. In a 3 year period, one can expect to spend &lt;a href="https://super-memory.com/articles/programming.htm"&gt;“30–40 seconds”&lt;/a&gt; on any given item. The long run &lt;a href="https://super-memory.com/articles/theory.htm"&gt;theoretical predictions&lt;/a&gt; are a little hairier. Given a single item, the formula for daily time spent on it is Time = 1⁄500 × &lt;em&gt;n&lt;/em&gt;thYear−1.5 + 1⧸30,000. During our 20th year, we would spend &lt;em&gt;t&lt;/em&gt; = 1⁄500 × 20−1.5 + 1⧸3,000, or &lt;code&gt;3.557e-4&lt;/code&gt; minutes a day. This is the average daily time, so to recover the annual time spent, we simply multiply by 365. Suppose we were interested in how much time a flashcard would cost us over 20 years. The average daily time changes every year (the graph looks like an exponential decay, remember), so we have to run the formula for each year and sum them all; in Haskell:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sum $ map (\year -&amp;gt; ((1/500 * year ** (-(1.5))) + 1/30000) * 365.25) [1..20]
# 1.8291&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Which evaluates to 1.8 minutes. (This may seem too small, but one doesn’t spend much time in the first year and the time drops off quickly&lt;a href="#fn55"&gt;55&lt;/a&gt;.) &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2012-muflax-dreamingofaworldundone.html.maff"&gt;Anki user muflax’s&lt;/a&gt; statistics put his per-card time at 71s, for example. But maybe &lt;a href="https://en.wikipedia.org/wiki/Piotr_Wo%C5%BAniak_(researcher)"&gt;Piotr Woźniak&lt;/a&gt; was being optimistic or we’re bad at &lt;a href="https://www.supermemo.com/en/blog/twenty-rules-of-formulating-knowledge"&gt;writing flashcards&lt;/a&gt;, so we’ll double it to 5 minutes. That’s our key rule of thumb that lets us decide what to learn and what to forget: if, over your lifetime, you will spend more than 5 minutes looking something up or will lose more than 5 minutes as a result of not knowing something, then it’s worthwhile to memorize it with spaced repetition. 5 minutes is the line that divides trivia from useful data.&lt;a href="#fn56"&gt;56&lt;/a&gt; (There might seem to be thousands of flashcards that meet the 5 minute rule. That’s fine. Spaced repetition can accommodate dozens of thousands of cards. See the &lt;a href="#the-workload"&gt;next section&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;To a lesser extent, one might wonder when one is in a hurry, should one learn something with spaced repetition and with massed? How far away should the tests or deadlines be before abandoning spaced repetition? It’s hard to compare since one would need a specific regimens to compare for the crossover point, but for massed repetition, the average time after memorization at which one has a 50% chance of remembering the memorized item seems to be 3-5 days.&lt;a href="#fn57"&gt;57&lt;/a&gt; Since there would be 2 or 3 repetitions in that period, presumably one would do better than 50% in recalling an item. 5 minutes and 5 days seems like a memorable enough rule of thumb: ‘don’t use spaced repetition if you need it sooner than 5 days or it’s worth less than 5 minutes’.&lt;/p&gt;

&lt;h4&gt;&lt;a href="#overload"&gt;Overload&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Spaced repetition is not infinite. Wozniak estimates &lt;a href="https://supermemo.guru/wiki/How_much_knowledge_can_human_brain_hold"&gt;a maximum number of ~300,000 items&lt;/a&gt; can be learned.&lt;/p&gt;
&lt;p&gt;One common experience of new users to spaced repetition is to add too much stuff—trivialities and things they don’t really care about. But they soon learn the curse of &lt;a href="https://en.wikipedia.org/wiki/Jorge_Luis_Borges"&gt;Borges’s&lt;/a&gt; &lt;a href="https://en.wikipedia.org/wiki/Funes_the_Memorious"&gt;Funes the Memorious&lt;/a&gt;. If they don’t actually want to learn the material they put in, they will soon stop doing the daily reviews - which will cause reviews to pile up, which will be further discouraging, and so they stop. At least with physical fitness there isn’t a precisely dismaying number indicating how far behind you are! But if you have too little at the beginning, you’ll have few repetitions per day, and you’ll see little benefit from the technique itself - it looks like boring flash card review.&lt;/p&gt;



&lt;h3&gt;&lt;a href="#what-to-add"&gt;What to Add&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I find one of the best uses for Mnemosyne is, besides the classic use of memorizing academic material such as geography or the periodic table or foreign vocabulary or Bible/Koran verses or the avalanche of medical school facts, to add in words from &lt;a href="https://en.wikipedia.org/wiki/Anu_Garg"&gt;A Word A Day&lt;/a&gt;&lt;a href="#fn58"&gt;58&lt;/a&gt; and &lt;a href="https://en.wikipedia.org/wiki/Wiktionary"&gt;Wiktionary&lt;/a&gt;, memorable quotes I see&lt;a href="#fn59"&gt;59&lt;/a&gt;, personal information such as birthdays (or license plates, a problem for me before), and so on. Quotidian uses, but all valuable to me. With a diversity of flashcards, I find my daily review interesting. I get all sorts of questions - now I’m trying to see whether a Haskell fragment is syntactically correct, now I’m pronouncing Korean &lt;a href="https://en.wikipedia.org/wiki/Hangul"&gt;hangul&lt;/a&gt; and listening to the answer, now I’m trying to find the Ukraine on a map, now I’m enjoying some &lt;a href="https://en.wikipedia.org/wiki/A._E._Housman"&gt;A.E. Housman&lt;/a&gt; poetry, followed by a few quotes from &lt;a href="https://www.lesswrong.com/"&gt;LessWrong&lt;/a&gt; quote threads, and so on. Other people use it for many other things; one application that impresses me for its simple utility is &lt;a href="https://www.lesswrong.com/posts/YbCc3NRrr5avvWSHT/who-wants-to-start-an-important-startup?commentId=CyxaAxbokswt6ZyPh"&gt;memorizing names &amp;amp; faces&lt;/a&gt; &lt;a href="https://www.lesswrong.com/posts/YbCc3NRrr5avvWSHT/who-wants-to-start-an-important-startup?commentId=RC2TbuNbD9sXTiH9e"&gt;of&lt;/a&gt; &lt;a href="https://www.lesswrong.com/posts/YbCc3NRrr5avvWSHT/who-wants-to-start-an-important-startup?commentId=qPQGQd6E3hZ5DsLz4"&gt;students&lt;/a&gt; although &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2012-chessdata-perfectpitchspacedrepetition.webm"&gt;learning musical notes&lt;/a&gt; is also not bad.&lt;/p&gt;


&lt;h3&gt;&lt;a href="#the-workload"&gt;The Workload&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;On average, when I’m studying a new topic, I’ll add 3–20 questions a day. Combined with my particular memory, I usually review about 90 or 100 items a day (out of the total &amp;gt;18,300). This takes under 20 minutes, which is not too bad. (I expect the time is expanded a bit by the fact that early on, my formatting guidelines were still being developed, and I hadn’t the full panoply of categories I do now - so every so often I must stop and edit categories.)&lt;/p&gt;
&lt;p&gt;If I haven’t been studying something recently, the exponential decaying of reviews slowly drops the daily review. For example, in March 201114ya, I wasn’t studying many things, so for 2011-03-24–2011-03-2614ya, my scheduled daily reviews are 73, 83, and 74; after that, it will 201213ya, the daily reviews are in the 40s or sometimes 50s for similar reasons, but the gradual shrinkage will continue.&lt;/p&gt;
&lt;p&gt;We can see this vividly, and we can even see a sort of analogue of the original forgetting curve, if we ask Mnemosyne 2.0 to graph the number of cards to review per day for the next year up to February 201312ya (assuming no additions or missed reviews etc.):&lt;/p&gt;

&lt;p&gt;&lt;img alt="A wildly varying but clearly decreasing graph of predicted cards per day" src="https://gwern.net/doc/psychology/spaced-repetition/gwern-scheduled-cards.png"/&gt;&lt;/p&gt;
&lt;p&gt;A wildly varying but clearly decreasing graph of predicted cards per day&lt;/p&gt;

&lt;p&gt;If Mnemosyne weren’t using spaced repetition, it would be hard to keep up with 18,300+ flashcards. But because it is using spaced repetition, keeping up is easy.&lt;/p&gt;
&lt;p&gt;Nor is 18.3k extraordinary. Many users have decks in the 6–7k range, Mnemosyne developer &lt;a href="https://groups.google.com/g/mnemosyne-proj-users/c/QzhysVWtdFE"&gt;Peter Bienstman&lt;/a&gt; has &amp;gt;8.5k &amp;amp; Patrick Kenny &amp;gt;27k, &lt;a href="https://groups.google.com/g/mnemosyne-proj-users/c/7_RPX9sdc4s"&gt;Hugh Chen&lt;/a&gt; has a 73k+ deck, and in &lt;code&gt;irc://irc.libera.chat#anki&lt;/code&gt;, they tell me of one user who triggered bugs with his &amp;gt;200k deck. 200,000 may be a bit much, but for regular humans, some amount smaller seems possible—it’s interesting to compare SRS decks to the feat of &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2010-seamon.pdf"&gt;memorizing &lt;em&gt;Paradise Lost&lt;/em&gt;&lt;/a&gt; or to the Muslim title of &lt;a href="https://en.wikipedia.org/wiki/Hafiz_(Quran)"&gt;‘hafiz’&lt;/a&gt;, one who has memorized the ~80,000 words of the Koran, or the stricter ‘hafid’, one who had memorized the Koran &lt;em&gt;and&lt;/em&gt; 100,000 &lt;a href="https://en.wikipedia.org/wiki/Hadith"&gt;hadiths&lt;/a&gt; as well. Other forms of memory are still more powerful.&lt;a href="#fn60"&gt;60&lt;/a&gt; (I suspect that spaced repetition is involved in one of the few well-documented cases of “&lt;a href="https://en.wikipedia.org/wiki/Hyperthymesia"&gt;hyperthymesia&lt;/a&gt;”, &lt;a href="https://en.wikipedia.org/wiki/Jill_Price"&gt;Jill Price&lt;/a&gt;: reading &lt;a href="https://gwern.net/doc/www/web.archive.org/92844d9f67069e6ecf323637f66b468cf374695d.html"&gt;&lt;em&gt;Wired&lt;/em&gt;&lt;/a&gt;, she has ordinary fallible powers of memorization for surprise demands with no observed anatomical differences and is restricted to “her own personal history and certain categories like television and airplane crashes”; further, she is a packrat with obsessive-compulsive traits who keeps &amp;gt;50,000 pages of detailed diaries—perhaps due to a childhood trauma—associates daily events nigh-involuntarily with past events. Marcus says the other instances of hyperthymesia resemble Price.)&lt;/p&gt;


&lt;h3&gt;&lt;a href="#when-to-review"&gt;When to Review&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;When should one review? In the morning? In the evening? Any old time? The studies demonstrating the spacing effect do not control or vary the time of day, so in one sense, the answer is: it doesn’t matter - if it did matter, there would be considerable variance in how effective the effect is based on when a particular study had its subjects do their reviews.&lt;/p&gt;
&lt;p&gt;So one reviews at whatever time is convenient. Convenience makes one more likely to stick with it, and sticking with it overpowers any temporary improvement.&lt;/p&gt;
&lt;p&gt;If one is not satisfied with that answer, then on general considerations, one ought to review before bedtime &amp;amp; sleep. &lt;a href="https://en.wikipedia.org/wiki/Memory_consolidation#Spacing_effect"&gt;Memory consolidation&lt;/a&gt; seems to be related, and &lt;a href="https://en.wikipedia.org/wiki/Sleep_and_memory"&gt;sleep&lt;/a&gt; is known to powerfully influence what memories enter long-term memory, &lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0033079"&gt;strengthening memories&lt;/a&gt; of material learned close to bedtime and &lt;a href="https://www.pnas.org/doi/full/10.1073/pnas.0900271106"&gt;increasing creativity&lt;/a&gt;; interrupting sleep without affecting total sleep time or quality still &lt;a href="https://www.pnas.org/doi/10.1073/pnas.1015633108"&gt;damages memory formation in mice&lt;/a&gt;&lt;a href="#fn61"&gt;61&lt;/a&gt;. So reviewing before bedtime would be best. (Other mental exercises show improvement when trained before bedtime; for example, &lt;a href="https://gwern.net/dnb-faq#sleep"&gt;dual &lt;em&gt;n&lt;/em&gt;-back&lt;/a&gt;.) One possible mechanism is that it may be that the &lt;a href="https://www.jneurosci.org/content/31/5/1563.full"&gt;&lt;em&gt;expectancy&lt;/em&gt;&lt;/a&gt; of future reviews/tests is enough to encourage memory consolidation during sleep; so if one reviews and goes to bed, presumably the expectancy is stronger than if one reviewed at breakfast and had an eventful day and forgot entirely about the reviewed flashcards. (See also the correlation between time of studying &amp;amp; GPA in Hartwig &amp;amp; Dunlosky2012.) Neural growth may be related; from Stahl2010:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Recent advances in our understanding of the neurobiology underlying normal human memory formation have revealed that learning is not an event, but rather a process that unfolds over time.&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1876761/"&gt;16&lt;/a&gt;,&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3650827/"&gt;17&lt;/a&gt;,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2010-oneill.pdf"&gt;18&lt;/a&gt;,[Squire2003 &lt;em&gt;&lt;a href="https://www.amazon.com/Fundamental-Neuroscience-Second-Larry-Squire/dp/0126603030/"&gt;Fundamental Neuroscience&lt;/a&gt;&lt;/em&gt;],&lt;a href="https://gwern.net/doc/www/davidjf.free.fr/12f68acf6714e8d2200c12fddf7b1b1241fc1f82.pdf"&gt;20&lt;/a&gt; Thus, it is not surprising that learning strategies that repeat materials over time enhance their retention.20,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1980-glenberg.pdf"&gt;21&lt;/a&gt;,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1991-toppino.pdf"&gt;22&lt;/a&gt;,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1978-landauer.pdf"&gt;23&lt;/a&gt;,&lt;a href="https://gwern.net/doc/www/www.wsu.edu/992e041a4a60ef70f816fadb6ac3ecc7409ba6c1.html"&gt;24&lt;/a&gt;,&lt;a href="https://pdfs.semanticscholar.org/6698/bf91c9333faa0d333a800254b8063230d4f4.pdf"&gt;25&lt;/a&gt;,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2007-pashler.pdf"&gt;26&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;…Thousands of new cells are generated in this region every day, although many of these cells die within weeks of their creation.&lt;a href="https://pdfs.semanticscholar.org/45c2/7c08fbb43f8728e69a7447366d4a4f74e088.pdf"&gt;31&lt;/a&gt; The survival of dentate gyrus neurons has been shown to be enhanced in animals when they are placed into learning situations.16-20 Animals that learn well retain more dentate gyrus neurons than do animals that do not learn well. Furthermore, 2 weeks after testing, animals trained in discrete spaced intervals over a period of time, rather than in a single presentation or a ‘massed trial’ of the same information, remember better.16-20 The precise mechanism that links neuronal survival with learning has not yet been identified. One theory is that the hippocampal neurons that preferentially survive are the ones that are somehow activated during the learning process.16-20&lt;a href="#fn62"&gt;62&lt;/a&gt; The distribution of learning over a period of time may be more effective in encouraging neuronal survival by allowing more time for changes in gene expression and protein synthesis that extend the life of neurons that are engaged in the learning process.&lt;/p&gt;
&lt;p&gt;…Transferring memory from the encoding stage, which occurs during alert wakefulness, into consolidation must thus occur at a time when interference from ongoing new memory formation is reduced.17,18 One such time for this transfer is during sleep, especially during non-rapid eye movement sleep, when the hippocampus can communicate with other brain areas without interference from new experiences.&lt;a href="https://pdfs.semanticscholar.org/d0a7/f06ed267f3193daab1175a65abb7a067bef4.pdf"&gt;32&lt;/a&gt;,&lt;a href="https://pdfs.semanticscholar.org/77fd/0cf03de8a6c4f56c5decc7c47ebe69cf98c1.pdf"&gt;33&lt;/a&gt;,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2001-maquet.pdf"&gt;34&lt;/a&gt; Maybe that is why some decisions are better made after a good night’s rest and also why pulling an all-nighter, studying with sleep deprivation, may allow you to pass an exam an hour later but not remember the material a day later.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4&gt;&lt;a href="#prospects-extended-flashcards"&gt;Prospects: Extended Flashcards&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Let’s step back for a moment. What are all our flashcards, small and large, doing for us? Why do I have a pair of flashcards for the word ‘anent’ among many others? I can just look it up.&lt;/p&gt;
&lt;p&gt;But look ups take time compared to already knowing something. (Let’s ignore the previously discussed 5 minute rule.) If we think about this abstractly in a computer science context, we might recognize it as an old concept in algorithms &amp;amp; optimization discussions—the &lt;a href="https://en.wikipedia.org/wiki/Space%E2%80%93time_tradeoff"&gt;space-time tradeoff&lt;/a&gt;. We trade off lookup time against limited skull space.&lt;/p&gt;
&lt;p&gt;Consider the sort of factual data already given as examples - we might one day need to know the average annual rainfall in Honolulu or Austin, but it would require too much space to memorize such data for all capitals. There are millions of English words, but in practice any more than 100,000 is excessive. More surprising is a sort of procedural knowledge. An extreme form of space-time tradeoffs in computers is when a computation is replaced by pre-calculated constants. We could take a math &lt;a href="https://en.wikipedia.org/wiki/Function_(mathematics)"&gt;function&lt;/a&gt; and calculate its output for each possible input. Usually such a &lt;a href="https://en.wikipedia.org/wiki/Lookup_table"&gt;lookup table&lt;/a&gt; of input to output is really large. Think about how many entries would be in such a table for all possible integer multiplications between 1 and 1 billion. But sometimes the table is really small (like binary Boolean functions) or small (like trigonometric tables) or large but still useful (&lt;a href="https://en.wikipedia.org/wiki/Rainbow_table"&gt;rainbow tables&lt;/a&gt; usually start in the gigabytes and easily reach terabytes).&lt;/p&gt;
&lt;p&gt;Given an infinitely large lookup table, we could replace &lt;em&gt;completely&lt;/em&gt; the skill of, say, addition or multiplication by the lookup table. No computation. The space-time tradeoff taken to the extreme of the space side of the continuum. (We could go the other way and define multiplication or addition as the slow computation which doesn’t know any specifics like the &lt;a href="https://en.wikipedia.org/wiki/Multiplication_table"&gt;multiplication table&lt;/a&gt; - as if every time you wanted to add 2+2 you had to count on 4 fingers.)&lt;/p&gt;
&lt;p&gt;So suppose we were children who wanted to learn multiplication. SRS and Mnemosyne can’t help because multiplication is not a specific factoid? The space-time tradeoff shows us that we can de-proceduralize multiplication and turn it partly into factoids. It wouldn’t be hard for us to write a quick script or macro to generate, say, 500 random cards which ask us to multiply AB by XY, and import them to Mnemosyne.&lt;a href="#fn63"&gt;63&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;After all, which is your mind going to do - get good at multiplying 2 numbers (generate on-demand), or memorize 500 different multiplication problems (&lt;a href="https://en.wikipedia.org/wiki/Memoization"&gt;memoize&lt;/a&gt;)? From my experience with multiple subtle variants on a card, the mind gives up after just a few and falls back on a problem-solving approach - which is exactly what one wants to exercise, in this case. Congratulations; you have done the impossible.&lt;/p&gt;
&lt;p&gt;From a software engineering point of view, we might want to modify or improve the cards, and 500 snippets of text would be a tad hard to update. So coolest would be a ‘dynamic card’. Add a markup type like &lt;code&gt;&amp;lt;eval src="​"&amp;gt;&lt;/code&gt; , and then Mnemosyne feeds the &lt;code&gt;src&lt;/code&gt; argument straight into the Python interpreter, which returns a &lt;a href="https://en.wikipedia.org/wiki/Tuple"&gt;tuple&lt;/a&gt; of the question text and the answer text. The question text is displayed to the user as usual, the user thinks, requests the answer, and grades himself. In Anki, Javascript is supported directly by the application in HTML &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt; tags (currently &lt;a href="https://docs.ankiweb.net/templates/styling.html#javascript"&gt;inline only&lt;/a&gt; but Anki could presumably import libraries by default), for example for kinds of &lt;a href="https://www.ojisanseiuchi.com/2016/03/12/JavaScript-in-Anki-cards/"&gt;syntax highlighting&lt;/a&gt;, so any kind of dynamic card could be written that one wants.&lt;/p&gt;
&lt;p&gt;So for multiplication, the dynamic card would get 2 random integers, print a question like &lt;code&gt;x * y = ?&lt;/code&gt; and then print the result as the answer. Every so often you would get a new multiplication question, and as you get better at multiplication, you see it less often - exactly as you should. Still in a &lt;a href="https://www.reddit.com/r/math/comments/hvqzd/printable_math_flashcards_in_pdf_and_latex_source/c1yror5/"&gt;math vein&lt;/a&gt;, you could generate variants on formulas or programs where one version is the correct one and the others are subtly wrong; I do this by hand with my programming flashcards (especially if I make an error doing exercises, that signals a finer point to make several flashcards on), but it can be done automatically. &lt;a href="https://www.lesswrong.com/posts/3r4GETDPMf335HfpA/memory-spaced-repetition-and-life?commentId=Mpc8rgQC4THkh38SF"&gt;kpreid&lt;/a&gt; &lt;a href="https://www.lesswrong.com/posts/3r4GETDPMf335HfpA/memory-spaced-repetition-and-life?commentId=Mpc8rgQC4THkh38SF"&gt;describes&lt;/a&gt; one tool of his:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I have written &lt;a href="https://github.com/kpreid/mathquiz/"&gt;a program&lt;/a&gt; (in the form of &lt;a href="https://kpreid.github.io/mathquiz/mathquiz.html"&gt;a web page&lt;/a&gt;) which does a specialized form of this [generating ‘damaged formulas’]. It has a set of generators of formulas and damaged formulas, and presents you with a list containing several formulas of the same type (eg. ∫ 2x dx = x^2 + C) but with one damaged (eg. ∫ 2x dx = 2x^2 + C).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This approach generalizes to anything you can generate random problems of or have large databases of examples of. Khan Academy apparently does something like this in associating large numbers of (algorithmicly-generated?) problems with each of its little modules and tracking retention of the skill in order to decide when to do further review of that module. For example, maybe you are studying Go and are interested in learning &lt;a href="https://en.wikipedia.org/wiki/Life_and_death"&gt;life-and-death positions&lt;/a&gt;. Those are things that can be generated by computer Go programs, or fetched from places like &lt;a href="https://www.goproblems.com/"&gt;GoProblems.com&lt;/a&gt;. For even more examples, Go is rotationally invariant - the best move remains the same regardless of which way the board is oriented and since there is no canonical direction for the board (like in chess) a good player ought to be able to play the same no matter how the board looks - so each specific example can be mirrored in 3 other ways. Or one could test one’s ability to ‘read’ a board by writing a dynamic card which takes each example board/problem and adds some random pieces as long as some go-playing program like &lt;a href="https://en.wikipedia.org/wiki/GNU_Go"&gt;GNU Go&lt;/a&gt; says the best move hasn’t changed because of the added noise.&lt;/p&gt;
&lt;p&gt;One could learn an awful lot of things this way. Programming languages could be learned this way - someone learning &lt;a href="https://en.wikipedia.org/wiki/Haskell"&gt;Haskell&lt;/a&gt; could take all the functions listed in the Prelude or his Haskell textbook, and ask &lt;a href="https://en.wikipedia.org/wiki/QuickCheck"&gt;QuickCheck&lt;/a&gt; to generate random arguments for the functions and ask the &lt;a href="https://en.wikipedia.org/wiki/Glasgow_Haskell_Compiler"&gt;GHC&lt;/a&gt; interpreter &lt;code&gt;ghci&lt;/code&gt; what the function and its arguments evaluate to. Games other than go, like chess, may work (a live example being &lt;a href="https://gwern.net/doc/www/chesstempo.com/01756e1305cd97d8abb5e2a7380635f9ea40f4fd.html"&gt;Chess Tempo&lt;/a&gt; &amp;amp; &lt;a href="https://listudy.org/en"&gt;Listudy&lt;/a&gt;, and see the experience of &lt;a href="https://dfan.org/blog/2013/07/07/mnemosyne-part-3/"&gt;Dan Schmidt&lt;/a&gt;; or &lt;a href="https://gwern.net/doc/www/blog.waleedkhan.name/d8eecb29c6c0d89cf06b2d38744a24629c35681b.html"&gt;&lt;em&gt;Super Smash Brothers&lt;/em&gt;&lt;/a&gt;). A fair bit of mathematics. If the dynamic card has Internet access, it can pull down fresh questions from an &lt;a href="https://en.wikipedia.org/wiki/RSS"&gt;RSS feed&lt;/a&gt; or just a website; this functionality could be quite useful in a foreign language learning context with every day bringing a fresh sentence to translate or another exercise.&lt;/p&gt;
&lt;p&gt;With some NLP software, one could write dynamic flashcards which test all sorts of things: if one confuses verbs, the program could take a template like “$PRONOUN $VERB $PARTICLE $OBJECT % {right: caresse, wrong: caresses}” which yields flashcards like “Je caresses le chat” or “Tu caresse le chat” and one would have to decide whether it was the correct conjugation. (The dynamicism here would help prevent memorizing specific sentences rather than the underlying conjugation.) In full generality, this would probably be difficult, but simpler approaches like templates may work well enough. Jack Kinsella:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I wish there were dynamic SRS decks for language learning (or other disciplines). Such decks would count the number of times you have reviewed an instance of an underlying grammatical rule or an instance of a particular piece of vocabulary, for example its singular/plural/third person conjugation/dative form. These sophisticated decks would present users with fresh example sentences on every review, thereby preventing users from remembering specific answers and compelling them to learn the process of applying the grammatical rule afresh. Moreover, these decks would keep users entertained through novelty and would present users with tacit learning opportunities through rotating vocabulary used in non-essential parts of the example sentence. Such a system, with multiple-level review rotation, would not only prevent against overfit learning, but also increase the total amount of knowledge learned per minute, an efficiency I’d gladly invest in.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Even though these things seem like ‘skills’ and not ‘data’!&lt;/p&gt;





&lt;h1&gt;&lt;a href="#popularity"&gt;Popularity&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;As of 2011-05-02:&lt;/p&gt;




&lt;p&gt;Metric&lt;/p&gt;
&lt;p&gt;Mnemosyne&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.tbrk.org/software/mnemododo.html"&gt;Mnemododo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Anki_(software)"&gt;Anki&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;iSRS&lt;/p&gt;
&lt;p&gt;&lt;a href="https://anymemo.org/"&gt;AnyMemo&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;Homepage Alexa&lt;/p&gt;
&lt;p&gt;&lt;a href="https://web.archive.org/web/20140723063333/https://www.alexa.com/siteinfo/mnemosyne-proj.org"&gt;383k&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://web.archive.org/web/20140723063456/https://www.alexa.com/siteinfo/tbrk.org"&gt;27.5m&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://web.archive.org/web/20140723063317/https://www.alexa.com/siteinfo/ankisrs.net"&gt;112k&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://web.archive.org/web/20140723063242/https://www.alexa.com/siteinfo/anymemo.org"&gt;1,766k&lt;/a&gt;&lt;a href="#fn64"&gt;64&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;ML/forum members&lt;/p&gt;
&lt;p&gt;&lt;a href="https://groups.google.com/g/mnemosyne-proj-users"&gt;461&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://groups.google.com/group/ankisrs/"&gt;4129&lt;/a&gt;/&lt;a href="https://groups.google.com/group/ankisrs-users/about"&gt;215&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://groups.google.com/g/isrs-support"&gt;129&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;Ubuntu installs&lt;/p&gt;
&lt;p&gt;&lt;a href="https://popcon.ubuntu.com/universe/by_inst"&gt;7k&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://popcon.ubuntu.com/unknown/by_inst"&gt;9k&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;Debian installs&lt;/p&gt;
&lt;p&gt;&lt;a href="https://qa.debian.org/popcon.php?package=mnemosyne"&gt;164&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://qa.debian.org/popcon.php?package=anki"&gt;364&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;Arch votes&lt;/p&gt;
&lt;p&gt;&lt;a href="https://aur.archlinux.org/packages/mnemosyne"&gt;85&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://aur.archlinux.org/packages/anki20-bin"&gt;96&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;iPhone ratings&lt;/p&gt;
&lt;p&gt;Unreleased&lt;a href="#fn65"&gt;65&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://apps.apple.com/us/app/ankimobile-flashcards/id373493387"&gt;193&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://gwern.net/doc/www/web.archive.org/ef6287c515140ee884b528e55a3a30ac920ca510.html"&gt;69&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;Android ratings&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.tbrk.org/software/mnemododo.html"&gt;20&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://play.google.com/store/apps/details?id=com.ichi2.anki"&gt;703&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://play.google.com/store/apps/details?id=org.liberty.android.fantastischmemo"&gt;836&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;Android installs&lt;/p&gt;

&lt;p&gt;&lt;a href="https://www.tbrk.org/software/mnemododo.html"&gt;100-500&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://play.google.com/store/apps/details?id=com.ichi2.anki"&gt;10-50k&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://play.google.com/store/apps/details?id=org.liberty.android.fantastischmemo"&gt;50-100k&lt;/a&gt;&lt;/p&gt;




&lt;p&gt;SuperMemo doesn’t fall under the same ratings, but it has sold in the hundreds of thousands over its 2 decades:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Biedalak is CEO of SuperMemo World, which sells and licenses Wozniak’s invention. Today, SuperMemo World employs just 25 people. The venture capital never came through, and the company never moved to California. About 50,000 copies of SuperMemo were sold in 200619ya, most for less than $48.99$302006. Many more are thought to have been pirated.&lt;a href="#fn66"&gt;66&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It seems safe to estimate the combined market-share of Anki, Mnemosyne, iSRS and other SRS apps at somewhere under 50,000 users (making due allowance for users who install multiple times, those who install and abandon it, etc.). Relatively few users seem to have migrated from SuperMemo to those newer programs, so it seems fair to simply add that 50k to the other 50k and conclude that the worldwide population is somewhere around (but probably under) 100,000.&lt;/p&gt;


&lt;h1&gt;&lt;a href="#where-was-i-going-with-this"&gt;Where Was I Going With This?&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;Nowhere, really. Mnemosyne/SR software in general are just one of my favorite tools: it’s based on a famous effect&lt;a href="#fn67"&gt;67&lt;/a&gt; discovered by science, and it exploits it elegantly&lt;a href="#fn68"&gt;68&lt;/a&gt; and usefully. It’s a testament to the Enlightenment ideal of improving humanity through reason and overcoming our human flaws; the idea of SR is seductive in its mathematical rigor&lt;a href="#fn69"&gt;69&lt;/a&gt;. In this age where so often the ideal of ‘self-improvement’ and progress are decried, and gloom are espoused by even the common people, it’s really nice to just have a small example like this in one’s daily life, an example not yet so prosaic and boring as the lightbulb.&lt;/p&gt;


&lt;h1&gt;&lt;a href="#see-also"&gt;See Also&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;In the course of using Mnemosyne, I’ve written a number of scripts to generate repetitively varying cards.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/haskell/mnemo.hs"&gt;&lt;code&gt;mnemo.hs&lt;/code&gt;&lt;/a&gt; will take any newline-delimited chunk of text, like a poem, and generates every possible &lt;a href="https://en.wikipedia.org/wiki/Cloze_test"&gt;Cloze deletion&lt;/a&gt;; that is, an ABC poem will become 3 questions: _BC/ABC, A_C/ABC, AB_/ABC&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/haskell/mnemo2.hs"&gt;&lt;code&gt;mnemo2.hs&lt;/code&gt;&lt;/a&gt; works as above, but is more limited and is intended for long chunks of text where &lt;code&gt;mnemo.hs&lt;/code&gt; would cause a combinatorial explosion of generated questions; it generates a subset: for ABCD, one gets __CD/ABCD, A__D/ABCD, and AB__/ABCD (it removes 2 lines, and iterates through the list).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/haskell/mnemo3.hs"&gt;&lt;code&gt;mnemo3.hs&lt;/code&gt;&lt;/a&gt; is intended for date or name-based questions. It’ll take input like “Barack Obama is %47%.” and spit out some questions based on this: “Barack Obama is _7./47”, “Barack Obama is 4_./47” etc.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/haskell/mnemo4.hs"&gt;&lt;code&gt;mnemo4.hs&lt;/code&gt;&lt;/a&gt; is intended for long lists of items. If one wants to memorize the list of US Presidents, the natural questions for flashcards goes something like “Who was the 3rd president?/Thomas Jefferson”, “Thomas Jefferson was the _rd president./3”, “Who was president after John Adams?/Thomas Jefferson”, “Who was president before James Madison?/Thomas Jefferson”.&lt;/p&gt;
&lt;p&gt;You note there’s repetition if you do this for each president - one asks the ordinal position of the item both ways (item -&amp;gt; position, position -&amp;gt; item), what precedes it, and what succeeds it. &lt;code&gt;mnemo4.hs&lt;/code&gt; automates this, given a list. In order to be general, the wording is a bit odd, but it’s better than writing it all out by hand! (Example output is in the &lt;a href="https://en.wikipedia.org/wiki/Comment_(computer_programming)"&gt;comments&lt;/a&gt; to the source code).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The reader might well be curious by this point what &lt;em&gt;my&lt;/em&gt; Mnemosyne database looks like. I use Mnemosyne quite a bit, and as of 2020-02-02, I have 16,149 (active) cards in my deck. Said curious reader may find my cards &amp;amp; media at &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2019-02-03-gwern-mnemosyne-export.cards.xz"&gt;&lt;code&gt;gwern.cards&lt;/code&gt;&lt;/a&gt; (52M; Mnemosyne 2.x format).&lt;/p&gt;
&lt;p&gt;&lt;!-- the metadata:
Gwern’s flashcards (~2008–2019)
gwern
gwern@gwern.net
English, Japanese, Korean, Haskell, R, Python, statistics, China, quotes, philosophy (ancient &amp; modern), etc.
revision: 6 (increment each time)
--&gt;&lt;/p&gt;
&lt;p&gt;The Mnemosyne project has been collecting user-submitted spaced repetition statistical data for years. The full dataset as of 2014-01-27 &lt;a href="https://groups.google.com/g/mnemosyne-proj-users/c/tPHlkTFVX_4/m/oF61BF44iQkJ"&gt;is available for download&lt;/a&gt; by anyone who wishes to analyze it.&lt;/p&gt;


&lt;h1&gt;&lt;a href="#external-links"&gt;External Links&lt;/a&gt;&lt;/h1&gt;
&lt;p&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Michael Nielsen: &lt;a href="https://augmentingcognition.com/ltm.html"&gt;“Augmenting Long-term Memory”&lt;/a&gt;; &lt;a href="https://quantum.country/qcvc"&gt;“Quantum computing for the very curious”&lt;/a&gt;; &lt;a href="https://numinous.productions/ttft/"&gt;“How can we develop transformative tools for thought?”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.lesswrong.com/posts/Ww2dxwWpSfkQB4NZb/a-year-of-spaced-repetition-software-in-the-classroom"&gt;“A Year of Spaced Repetition Software in the Classroom”&lt;/a&gt;; &lt;a href="https://www.lesswrong.com/posts/dtCfxYubZgRnEkGpQ/a-second-year-of-spaced-repetition-software-in-the-classroom"&gt;two years&lt;/a&gt;; &lt;a href="https://www.lesswrong.com/posts/F6ZTtBXn2cFLmWPdM/seven-years-of-spaced-repetition-software-in-the-classroom-1"&gt;seven year followup&lt;/a&gt;; cf. &lt;a href="https://gwern.net/doc/www/theeffortfuleducator.com/8c140b5eb16266f2b73df63e135b954a8c92572c.html"&gt;“Easy Application of Spaced Practice in the Classroom”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.alljapaneseallthetime.com/blog/all-japanese-all-the-time-ajatt-how-to-learn-japanese-on-your-own-having-fun-and-to-fluency/"&gt;AJATT table of contents&lt;/a&gt; -(applying SRS to learning Japanese)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Math&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://cognitivemedium.com/srs-mathematics"&gt;“Using spaced repetition systems to see through a piece of mathematics”&lt;/a&gt;, Michael Nielsen&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://bentilly.blogspot.com/2009/09/teaching-linear-algebra.html"&gt;“Teaching linear algebra”&lt;/a&gt; (with spaced repetition), by Ben Tilly; &lt;a href="https://bentilly.blogspot.com/2012/10/my-sons-flashcard-routine.html"&gt;Manual flashcards for his 2nd grader&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://nautil.us/how-i-rewired-my-brain-to-become-fluent-in-math-rd-235086/"&gt;“How I Rewired My Brain to Become Fluent in Math”&lt;/a&gt; (&lt;a href="https://gwern.net/doc/www/news.ycombinator.com/563f84359fa93c5dd17d4d867136896fe6924540.html"&gt;HN&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.lesswrong.com/posts/8ZugMc4E5959Xh86i/how-i-use-anki-to-learn-mathematics"&gt;“How I use Anki to learn mathematics”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://cronokirby.com/posts/2021/02/spaced-repetition-for-mathematics/"&gt;“Spaced Repetition for Mathematics”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Programming&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://super-memory.com/articles/programming.htm"&gt;“SuperMemo as a new tool increasing the productivity of a programmer. A case study: programming in Object Windows”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.jackkinsella.ie/articles/janki-method"&gt;“Janki Method: Using spaced repetition systems to learn and retain technical knowledge”&lt;/a&gt; (&lt;a href="https://gwern.net/doc/www/old.reddit.com/c6bfacb045fd0f4ae4055c84864fc66cb06297b5.html"&gt;Reddit discussion&lt;/a&gt;); &lt;a href="https://www.jackkinsella.ie/articles/autodidactism"&gt;SRS problems &amp;amp; solutions&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://sive.rs/srs"&gt;“Memorizing a programming language using spaced repetition software”&lt;/a&gt; (Derek Sivers; &lt;a href="https://gwern.net/doc/www/news.ycombinator.com/a6f1f1922ad84624da2fc114f165674c018a4b0a.html"&gt;HN&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.shortcutfoo.com/blog/introducing-interval-training-for-shortcuts"&gt;learning text editor shortcuts&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://blog.developer.atlassian.com/golang-flashcards-and-spaced-repetition/"&gt;“Learning Go with flashcards and spaced repetition”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://web.archive.org/web/20200209152222/https://senrigan.io/blog/chasing-10x-leveraging-a-poor-memory-in-software-engineering/"&gt;“Chasing 10X: Leveraging A Poor Memory In Engineering”&lt;/a&gt;; &lt;a href="https://web.archive.org/web/20200209014707/https://senrigan.io/blog/everything-i-know-strategies-tips-and-tricks-for-spaced-repetition-anki/"&gt;“Everything I Know: Strategies, Tips, and Tricks for Anki”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/empiria.io/80ec18340a62bb4cb49295136f1b7fffba82f071.html"&gt;“Remembering R—Using Spaced Repetition to finally write code fluently”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.gresearch.com/news/anki-as-learning-superpower-computer-science-edition/"&gt;“Anki as Learning Superpower: Computer Science Edition”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://quantifiedself.com/blog/spaced-repetition-and-learning/"&gt;“QS Primer: Spaced Repetition and Learning”&lt;/a&gt; -(talks on applications of spaced repetition)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Value compared to curriculums:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Point: &lt;a href="https://www.scotthyoung.com/blog/2012/08/05/forgetting-is-good/"&gt;“Why Forgetting Can Be Good”&lt;/a&gt;, by Scott H. Young&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Counterpoint: &lt;a href="https://gwern.net/doc/www/web.archive.org/882fc234d501006a154bec31211cc2c739fb6d6c.html"&gt;“Spaced repetition in natural and artificial learning”&lt;/a&gt;, by Ryan Muller&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;My own observation is that an optimally constructed curriculum &lt;em&gt;could&lt;/em&gt; effectively implement spaced repetition, but even if it did (most don’t), unless it is computerized it will not adapt to the user.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.salon.com/2014/04/20/ditch_the_10000_hour_rule_why_malcolm_gladwells_famous_advice_falls_short/"&gt;“Ditch the 10,000 hour rule! Why Malcolm Gladwell’s famous advice falls short; Contrary to what the bestselling author would tell you, obsessive practice isn’t the key to success. Here’s why”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/web.archive.org/8c1b37f6de804fc06c7818c4cc4bfd01c3714f02.html"&gt;“How to Memorize the Quran and Never Forget it”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://groups.google.com/g/mnemosyne-proj-users/c/_RC55gH7DrY"&gt;Bash scripts&lt;/a&gt; for generating vocabulary flashcards (processing multiple online dictionaries, good for having multiple examples; images; and audio)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;vocabulary selection:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://jtauber.com/blog/2004/11/26/programmed_vocabulary_learning_as_a_travelling_salesman_problem/"&gt;“Programmed Vocabulary Learning as a Traveling Salesman Problem”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://jtauber.com/blog/2006/05/05/teaching_new_testament_greek/"&gt;“Teaching New Testament Greek”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/graded-reader.org/9d2ec59902c0f4a82a47b3463e56a0b444ddfe94.html"&gt;graded-reader&lt;/a&gt;: &lt;a href="https://jtauber.com/blog/2008/02/10/a_new_kind_of_graded_reader/"&gt;“A New Kind of Graded Reader”&lt;/a&gt; (video talk)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://groups.google.com/g/graded-reader"&gt;Mailing list&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://code.google.com/archive/p/graded-reader"&gt;Programs&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/web.archive.org/e15445137d043a752bd3caaa33b979a8f10961f1.html"&gt;“Diff revision: diff-based revision of text notes, using spaced repetition”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hacker News discussion: &lt;a href="https://gwern.net/doc/www/news.ycombinator.com/d97eb8622a236b16aab9fb4b580d7db1ec31f6b8.html"&gt;1&lt;/a&gt;, &lt;a href="https://gwern.net/doc/www/news.ycombinator.com/454e0aba0ac72dd11f2f9fb70d7522d1580438b0.html"&gt;2&lt;/a&gt;, &lt;a href="https://gwern.net/doc/www/news.ycombinator.com/837e30ad4c01147c6a091162a6e51bd1387ce459.html"&gt;3&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.lesswrong.com/posts/As9E3HfgED2zkTAfB/a-vote-against-spaced-repetition"&gt;“A vote against spaced repetition”&lt;/a&gt;; &lt;a href="https://yourawesomememory.com/how-flashcards-fail-confessions-of-a-tired-memory-guy/"&gt;“How Flashcards Fail: Confessions of a Tired Memory Guy”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://blog.beeminder.com/hieroglyphs/"&gt;“Learning Ancient Egyptian in an Hour Per Week with Beeminder”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/rs.io/90565242f056f7517ede5dbe0dfb5cedc0031b0a.html"&gt;“Anki, 10000 Cards Later: How my Anki usage has evolved”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“Using Anki with Babies / Toddlers”: &lt;a href="https://www.reddit.com/r/Anki/comments/5ixzzx/anki_for_babies/"&gt;1&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/Anki/comments/8iydl7/using_anki_with_babies_toddlers/"&gt;2&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/Anki/comments/a9wqau/using_anki_with_babies_toddlers_update/"&gt;2&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/Anki/comments/eit54e/starting_my_175_year_old_on_anki/"&gt;4&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/chrislakin.blog/26211d4302094f644646b87eae409137dd44343b.html"&gt;followup at age 5&lt;/a&gt; (cf. &lt;a href="https://gwern.net/doc/iq/2006-vandermaas.pdf"&gt;mutualism&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/supermemo.guru/171890c33599bc421e57465447bd6abd9b0f151a.html"&gt;“SuperMemo does not work for kids”&lt;/a&gt;, Piotr Wozniak&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.duolingo.com/"&gt;Duolingo&lt;/a&gt; &lt;a href="https://www.quora.com/Do-you-have-any-plans-for-optimizing-Duolingos-vocabulary-learning-using-spaced-repetition"&gt;uses spaced repetition&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.wired.com/2012/01/everything-about-learning/"&gt;“Everything You Thought You Knew About Learning Is Wrong”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.spacedrepetition.com/"&gt;SeRiouS&lt;/a&gt;: &lt;a href="https://gwern.net/doc/www/conference.cali.org/80607107d37b10042d9f10ddc2f5cd8be916d161.html"&gt;“Spaced Repetition Technology for Legal Education”&lt;/a&gt;, &lt;a href="https://sites.suffolk.edu/legaltech/2014/03/11/serious-an-lpti-supported-project-to-improve-students-learning-and-bar-performance/"&gt;“SeRiouS: an LPTI-supported Project to Improve Students’ Learning and Bar Performance”&lt;/a&gt;, Gabe Teninbaum (&lt;a href="https://www.youtube.com/watch?v=dtClgl07lg8"&gt;video presentation&lt;/a&gt;)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/www.ejlt.org/d49bf80aab1f75c60449212983bc7658772dfa5b.html"&gt;“The role of digital flashcards in legal education: theory and potential”&lt;/a&gt;, Colbran et al 2014&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.newyorker.com/books/page-turner/why-we-should-memorize"&gt;“Why We Should Memorize [Poetry]”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.nytimes.com/2014/11/23/sunday-review/studying-for-the-test-by-taking-it.html"&gt;“Studying for the Test by Taking It”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/www.rand.org/fb672d38af12c609801856651ba37d2a54d6d98b.pdf"&gt;“Making Summer Count: How Summer Programs Can Boost Children’s Learning”&lt;/a&gt;, McCombs et al 2011 (&lt;a href="https://en.wikipedia.org/wiki/RAND_Corporation"&gt;RAND&lt;/a&gt; MG1120)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.learningmedicinebook.com/"&gt;&lt;em&gt;Learning Medicine: An Evidence-Based Guide&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1998-arthur.pdf"&gt;“Factors that Influence Skill Decay And Retention: a Quantitative Review and Analysis”&lt;/a&gt;, Arthur et al 1998&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/cbmm.mit.edu/0d8ff7384824ed448c938118839eb62b8753b410.pdf"&gt;“On The Forgetting Of College Academics: At ‘Ebbinghaus speed’?”&lt;/a&gt;, Subirana et al 2017&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.theguardian.com/science/2017/feb/08/total-recall-the-people-who-never-forget"&gt;“Total recall: the people who never forget; An extremely rare condition may transform our understanding of memory”&lt;/a&gt; (obsessive recording &amp;amp; reviewing demonstrates you can recall much of your life if you live nothing worth recalling); &lt;a href="https://www.newyorker.com/books/page-turner/the-mystery-of-s-the-man-with-an-impossible-memory"&gt;“The Mystery of S., the Man with an Impossible Memory: The neuropsychologist Alexander Luria’s case study of Solomon Shereshevsky helped spark a myth about a man who could not forget. But the truth is more complicated”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/alexvermeer.com/00f6480a2a50bda6d5f34a85b5454c9f78bcee29.html"&gt;&lt;em&gt;Anki Essentials&lt;/em&gt;&lt;/a&gt;, Vermeer&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://genedan.com/no-126-four-years-of-spaced-repetition/"&gt;“No. 126: Four Years of Spaced Repetition”&lt;/a&gt; (Gene Dan, actuarial studies)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/deusexvita.medium.com/43d568f7c348c439cc6789a83b5e44c93ed116db.html"&gt;“One Year Anki Update”&lt;/a&gt; (biology grad school)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://ncase.me/remember/"&gt;“How To Remember Anything Forever-ish”: an interactive comic&lt;/a&gt; (Nicky Case)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/arxiv.org/327a12372aa4b772bbe3c7525800c4dd6d3b47ce.pdf"&gt;“The Overfitted Brain: Dreams evolved to assist generalization”&lt;/a&gt;, Hoel2020&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2016-mazza.pdf"&gt;“Relearn Faster and Retain Longer: Along With Practice, Sleep Makes Perfect”&lt;/a&gt;, Mazza et al 2016&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0120644"&gt;“Replication and Analysis of Ebbinghaus’ Forgetting Curve”&lt;/a&gt;, Murre &amp;amp; Dros2015&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.annualreviews.org/doi/10.1146/annurev-psych-010416-044022"&gt;“Learning from Errors”&lt;/a&gt;, Metcalfe2017&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://ai.glossika.com/"&gt;Glossika&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Discussion&lt;/strong&gt;: &lt;a href="https://gwern.net/doc/www/news.ycombinator.com/483ef8b6f992a89924da904c5f106f909152c39f.html"&gt;HN&lt;/a&gt;/&lt;a href="https://gwern.net/doc/www/news.ycombinator.com/4590ab1d23ffcb37e43ca762bf1b42fc44898278.html"&gt;2&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;&lt;a href="#flashcard-sources"&gt;Flashcard Sources&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;the &lt;a href="https://mnemosyne-proj.org/card-sets"&gt;Mnemosyne deck collection&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;the &lt;a href="https://ankiweb.net/shared/decks"&gt;Anki deck collection&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.cram.com/"&gt;FlashCardExchange.com&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.studystack.com/"&gt;StudyStack.com&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.cram.com/topics/popular"&gt;Flashcarddb&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;




&lt;ol&gt;
&lt;li&gt;&lt;p&gt;“One does not learn computing by using a hand calculator, but one can forget arithmetic.” —&lt;a href="#perlis-1982"&gt;Perlis1982&lt;/a&gt;&lt;a href="#fnref1"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Listing other neuroprosthetics is hard. It’s an interesting idea, but as proponents of &lt;a href="https://en.wikipedia.org/wiki/Externalism"&gt;externalism&lt;/a&gt; like &lt;a href="https://en.wikipedia.org/wiki/Andy_Clark"&gt;Andy Clark&lt;/a&gt; have found, it’s easier to feel that externalism is meaningful than to nail down a clear definition which separates a neuroprosthetic or part of one’s mind from a random tool you like or find useful. Consider whether a pencil and paper a neuroprosthetic: clearly it is not for a child learning to write, who must carefully compose the words in his mind and put them down one after another, but it is not so clear for an adult who has been writing all his life and can doodle or write down thoughts without thinking about them and may even be surprised at what they happened to write.&lt;/p&gt;
&lt;p&gt;I like this definition: “a neuroprosthetic is anything whose results you use without further thought”. So in the classic example, when Otto needs to go somewhere, he never thinks “I am an amnesiac who stores locations in my notepad, and I must look up the location” - he just looks up the location. A good heuristic would be anything whose destruction leaves one feeling lost, slow, stupid, or ignorant.&lt;/p&gt;
&lt;p&gt;By this standard, I can think of only a few tools I use without noticeable thought:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;keybindings such as window manager shortcuts, in particular shortcuts for Google searches; on occasion, &lt;a href="https://en.wikipedia.org/wiki/Xmonad"&gt;XMonad’s&lt;/a&gt; Prompt gets inscrutably wedged, locking it. When this happens, I &lt;em&gt;have&lt;/em&gt; to restart X because I Google everything and the keybinding is &lt;em&gt;so&lt;/em&gt; engrained that not using it is unbearable. It would be like trying to write with your weak hand.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Google_Calendar"&gt;Google Calendar&lt;/a&gt; and &lt;a href="https://gwern.net/prediction-market#predictionbook-nights"&gt;PredictionBook&lt;/a&gt;: it is incredible how many followups or reminders or regularly happening tasks I can put into Google Calendar or PB. I have outsourced many habits or thoughts to them, and I no longer think of it as anything special. If either were gone, I would feel frightened - what events were passing, what beliefs falsified, what opportunities opening up (or closing!) that I had suddenly become ignorant of?&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Evernote"&gt;Evernote&lt;/a&gt;, for a similar reason; many of my memories have ceased to be things like “octopuses see too fast to watch TV and so only HDTV or &lt;a href="https://en.wikipedia.org/wiki/Ultra-high-definition_television"&gt;UHDTV&lt;/a&gt; works for them; I read this in &lt;em&gt;Orion Magazine&lt;/em&gt;” and become things like “octopus TV Evernote”, and if I want to know what it was about octopuses &amp;amp; TV, well, I’ll have to look it up in Evernote. &lt;a href="https://en.wikipedia.org/wiki/Mnemosyne_%28software%29"&gt;Mnemosyne&lt;/a&gt; plays a similar role for me, but there the memories are much clearer on their own because of the spaced repetition.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;my website Gwern.net; I’ve had to say many times that I don’t know what I think about something, but whatever that is, it’s on my website. (A more extreme form of the Evernote/Mnemosyne neuroprosthetic.) A commenter once wrote that reading Gwern.net felt like he was crawling around in my head. He was more right than he realized.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;a href="#fnref2"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;as quoted in &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1988-bjork.pdf"&gt;“Retrieval practice and the maintenance of knowledge”&lt;/a&gt;, Bjork1988&lt;a href="#fnref3"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;From &lt;a href="https://gwern.net/doc/www/web.archive.org/f971550f32c8b567327415b91c75a7e317b40a16.html"&gt;“Close the Book. Recall. Write It Down: That old study method still works, researchers say. So why don’t professors preach it?”&lt;/a&gt;; &lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/The_Chronicle_of_Higher_Education"&gt;The Chronicle of Higher Education&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Two psychology journals have recently published papers showing that this strategy works, the latest findings from a decades-old body of research. When students study on their own, “active recall” - recitation, for instance, or flashcards and other self-quizzing - is the most effective way to inscribe something in long-term memory. Yet many college instructors are only dimly familiar with that research…&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;a href="https://andrewvs.blogs.com/usu/files/the_spacing_effect.pdf"&gt;“The Spacing Effect: A Case Study in the Failure to Apply the Results of Psychological Research”&lt;/a&gt; (Dempster1988), whose title alone summarizes the situation (see also Kelley2007, &lt;a href="https://www.amazon.com/Making-Minds-Whats-Education-Should/dp/0415414113/"&gt;&lt;em&gt;Making Minds: What’s Wrong with Education - and What Should We Do About It?&lt;/em&gt;&lt;/a&gt;):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Second, it [the spacing effect] is remarkably robust. In many cases, two spaced presentations are about twice as effective as two massed presentations (eg. Hintzman, 197451ya; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1970-melton.pdf"&gt;Melton, 1970&lt;/a&gt;), and the difference between them increases as the frequency of repetition increases (Underwood, 197055ya)…&lt;/p&gt;
&lt;p&gt;The spacing effect was known as early as 1885140ya when Ebbinghaus published the results of his seminal work on memory. With himself as the subject, Ebbinghaus found that for a single 12-syllable series, 68 immediately successive repetitions had the effect of making possible an errorless recital after seven additional repetitions on the following day. However, the same effect was achieved by only 38 distributed repetitions spread over 3 days. On the basis of this and other related findings, Ebbinghaus concluded that ‘with any considerable number of repetitions a suitable distribution of them over a space of time is decidedly more advantageous than the massing of them at a single time’ (Ebbinghaus, 1885140ya/1913112ya. p. 89)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Son &amp;amp; Simon2012:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Furthermore, even after acknowledging the benefits of spacing, changing teaching practices proved to be enormously difficult. Delaney et al 2010 wrote: “Anecdotally, high school teachers and college professors seem to teach in a linear fashion without repetition and give three or four noncumulative exams.” (p. 130). Focusing on the math domain, where one might expect a very easy-to-review-and-to-space strategy, Rohrer (200916ya) points out that mathematics textbooks usually present topics in a non-spaced, non-mixed fashion. Even much earlier, Vash (198936ya) had written: “Education policy setters know perfectly well that [spaced practice] works better [than massed practice]. They don’t care. It isn’t tidy. It doesn’t let teachers teach a unit and dust off their hands quickly with a nice sense of ‘Well, that’s done.’” (p. 1547478ya).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Rohrer, D. (200916ya). “The effects of spacing and mixing practice problems”. Journal for Research in Mathematics Education, 40, 4-17&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Vash, C. L. (198936ya). “The spacing effect: A case study in the failure to apply the results of psychological research”. American Psychologist, 44, 1547478ya (a comment on Dempster’s article?)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;a href="https://www.psywww.com/intropsych/ch06-memory/what-should-a-student-do.html#spacingeffect"&gt;&lt;em&gt;Psychology: An Introduction&lt;/em&gt;&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In one practical demonstration of the spacing effect, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1993-bahrick.pdf"&gt;Bahrick, Bahrick, Bahrick, &amp;amp; Bahrick (199332ya)&lt;/a&gt; showed that retention of foreign language vocabulary was greatly enhanced if practice sessions were spaced far apart. For example, “Thirteen retraining sessions spaced at 56 days yielded retention comparable to 26 sessions spaced at 14 days.” In other words, subjects could use &lt;em&gt;half as many study sessions&lt;/em&gt;, if the study sessions were spread over a time period &lt;em&gt;four times as long&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref4"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.pnas.org/doi/10.1073/pnas.1120700109"&gt;“Synaptic evidence for the efficacy of spaced learning”&lt;/a&gt;, Kramar et al 2012 (&lt;a href="https://medicalxpress.com/news/2012-03-neurobiology-superiority-spaced-massed.html"&gt;“Take your time: Neurobiology sheds light on the superiority of spaced versus massed learning”&lt;/a&gt;):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The superiority of spaced versus massed training is a fundamental feature of learning. Here, we describe unanticipated timing rules for the production of long-term potentiation (LTP) in adult rat hippocampal slices that can account for one temporal segment of the spaced trials phenomenon. Successive bouts of naturalistic theta burst stimulation of field CA1 afferents markedly enhanced previously saturated LTP if spaced apart by 1 h or longer, but were without effect when shorter intervals were used. Analyses of F-actin-enriched spines to identify potentiated synapses indicated that the added LTP obtained with delayed theta trains involved recruitment of synapses that were “missed” by the first stimulation bout. Single spine glutamate-uncaging experiments confirmed that less than half of the spines in adult hippocampus are primed to undergo plasticity under baseline conditions, suggesting that intrinsic variability among individual synapses imposes a repetitive presentation requirement for maximizing the percentage of potentiated connections. We propose that a combination of local diffusion from initially modified spines coupled with much later membrane insertion events dictate that the repetitions be widely spaced. Thus, the synaptic mechanisms described here provide a neurobiological explanation for one component of a poorly understood, ubiquitous aspect of learning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref5"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There are many studies to the effect that active recall is best. Here’s one recent study, &lt;a href="https://gwern.net/doc/www/ses.enseigne.ac-lyon.fr/1f1594dd08047a0de89277e5ffab3effda9b1115.pdf"&gt;“Retrieval Practice Produces More Learning than Elaborative Studying with Concept Mapping”&lt;/a&gt;, Karpicke2011 (covered in &lt;a href="https://www.sciencedaily.com/releases/2011/01/110121111216.htm"&gt;&lt;em&gt;Science Daily&lt;/em&gt;&lt;/a&gt; and the &lt;a href="https://www.nytimes.com/2011/01/21/science/21memory.html"&gt;&lt;em&gt;NYT&lt;/em&gt;&lt;/a&gt;):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Educators rely heavily on learning activities that encourage elaborative studying, while activities that require students to practice retrieving and reconstructing knowledge are used less frequently. Here, we show that practicing retrieval produces greater gains in meaningful learning than elaborative studying with concept mapping. The advantage of retrieval practice generalized across texts identical to those commonly found in science education. The advantage of retrieval practice was observed with test questions that assessed comprehension and required students to make inferences. The advantage of retrieval practice occurred even when the criterial test involved creating concept maps. Our findings support the theory that retrieval practice enhances learning by retrieval-specific mechanisms rather than by elaborative study processes. Retrieval practice is an effective tool to promote conceptual learning about science.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From &lt;a href="https://www.nytimes.com/2010/09/07/health/views/07mind.html"&gt;“Forget What You Know About Good Study Habits”&lt;/a&gt;. &lt;em&gt;New York Times&lt;/em&gt;;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Cognitive scientists do not deny that honest-to-goodness cramming can lead to a better grade on a given exam. But hurriedly jam-packing a brain is akin to speed-packing a cheap suitcase, as most students quickly learn - it holds its new load for a while, then most everything falls out….When the neural suitcase is packed carefully and gradually, it holds its contents for far, far longer. An hour of study tonight, an hour on the weekend, another session a week from now: such so-called spacing improves later recall, without requiring students to put in more overall study effort or pay more attention, dozens of studies have found.&lt;/p&gt;
&lt;p&gt;“The idea is that forgetting is the friend of learning”, said Dr. Kornell. “When you forget something, it allows you to relearn, and do so effectively, the next time you see it.”&lt;/p&gt;
&lt;p&gt;That’s one reason cognitive scientists see testing itself - or practice tests and quizzes - as a powerful tool of learning, rather than merely assessment. The process of retrieving an idea is not like pulling a book from a shelf; it seems to fundamentally alter the way the information is subsequently stored, making it far more accessible in the future.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2006-roediger.pdf"&gt;In one of his own experiments&lt;/a&gt;, Dr. Roediger and Jeffrey Karpicke, who is now at Purdue University, had college students study science passages from a reading comprehension test, in short study periods. When students studied the same material twice, in back-to-back sessions, they did very well on a test given immediately afterward, then began to forget the material. But if they studied the passage just once and did a practice test in the second session, they did very well on one test two days later, and another given a week later.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref6"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;The Mathematics of Gambling&lt;/em&gt;, Thorp1984, &lt;a href="https://gwern.net/doc/statistics/decision/1984-thorp-themathematicsofgambling-ch4.pdf"&gt;§2 “The Wheels”, Chapter 4&lt;/a&gt;, pg43–44:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It was the spring of 195570ya. I was finishing my second year of graduate physics at U.C.L.A…I changed my field of study from physics to mathematics…I attended classes and studied 50–60 hours a week, generally including Saturdays and Sundays. I had read about the psychology of learning in order to be able to work longer and harder. I found that “spaced learning” worked well: study for an hour, then take a break of at least ten minutes (shower, meal, tea, errands, etc.). One Sunday afternoon about 3 p.m., I came to the co-op dining room for a tea break…My head was bubbling with physics equations, and several of my good friends were sitting around chatting.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref7"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;From &lt;a href="https://www.amazon.com/Final-Jeopardy-Machine-Quest-Everything/dp/0547483163/"&gt;&lt;em&gt;Final Jeopardy: Man Versus Machine and the Quest to Know Everything&lt;/em&gt;&lt;/a&gt;, by Stephen Baker, pg214:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The program he put together tested him on categories, gauged his strengths (sciences, NFL football) and weaknesses (fashion, Broadway shows), and then directed him toward the preparation most likely to pay off in his own match. To patch these holes in his knowledge, Craig used a free online tool called &lt;a href="https://en.wikipedia.org/wiki/Anki_(software)"&gt;Anki&lt;/a&gt;, which provides electronic flash cards for hundreds of fields of study, from Japanese vocabulary to European monarchs. The program, in Craig’s words, is based on psychological research on ‘the forgetting curve’. It helps people find holes in their knowledge and determines how often they need those areas to be reviewed to keep them in mind. In going over world capitals, for example, the system learns quickly that a user like Craig knows London, Paris, and Rome, so it might spend more time reinforcing the capital of, say, Kazakhstan. (And what would be the Kazakh capital? ‘Astana’, Craig said in a flash. ‘It used to be Almaty, but they moved it.’)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref8"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.mentalfloss.com/article/54853/our-interview-jeopardy-champion-arthur-chu"&gt;“Our Interview With &lt;em&gt;Jeopardy!&lt;/em&gt; Champion Arthur Chu”&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[Chu:] …&lt;em&gt;Jeopardy!&lt;/em&gt; is aimed at the sort of average TV viewer, so they’re not going to ask things that are pointlessly obscure…So I used a program called Anki which uses a method called “spaced repetition.” It keeps track of where you’re doing well or poorly, and pushes you to study the flashcards you don’t know as well, until you develop an even knowledge base about a particular subject, and I just made flashcards for those specific things. I memorized all the world capitals, it wasn’t that hard once I had the flashcards and was using them every day. I memorized the US State Nicknames (they’re on Wikipedia), memorized the basic important facts about the 44 US Presidents. I really focused on those. But there’s a lot more stuff to know. I went on &lt;em&gt;Jeopardy!&lt;/em&gt; knowing that there was stuff I didn’t know. For instance, everyone laughs about sports - but I also knew that [sports clues] were the least likely to come up in Double Jeopardy and Final Jeopardy and be very important. So I decided I shouldn’t sweat it too much, I should just recognize that I didn’t know them and let that go, as long as I can get the high value clues. So that was how I prepared.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref9"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Alan J. Perlis, &lt;a href="https://gwern.net/doc/cs/algorithm/1982-perlis.pdf"&gt;“Epigrams in Programming”&lt;/a&gt; (198243ya)&lt;a href="#fnref10"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Web developer Persol &lt;a href="https://www.lesswrong.com/posts/YbCc3NRrr5avvWSHT/who-wants-to-start-an-important-startup?commentId=cmjjdPpksrjgynF8z"&gt;writes in August 2012&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I actually wrote a site that did this [spaced repetition] a few months ago. I had about 4000 users who had actually gone through a complete session…As guessed, the problem is that I couldn’t get people to start forming it as a habit. There is no immediate payback. Less than 20 people out of 4000 did more than one session…Additionally, there are at least 18 competitors. Here’s the list I &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2012-persol-srssitecomparison.pdf"&gt;made at the time&lt;/a&gt;. Very few seem to be successful. I shut the site down about a month ago. There are numerous free competitors which don’t have any great annoyances. I wouldn’t suggest starting another of these sites unless you figured out an effective way to “gamify” it.&lt;/p&gt;
&lt;p&gt;…~4000 people finished a session. Many more ‘tried’ than 4000…I just couldn’t determine which users were bots that registered randomly vs users that didn’t finish the first session.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Tried: lots (but unknown)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finished 1 session: ~4000&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Finished &amp;gt;1 session: ~20 [0.5%]&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref11"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/www.cnsspectrums.com/544f105c6bfdbaf38ae1b308373bf7644a15cef2.html"&gt;“Play it Again: The Master Psychopharmacology Program as an Example of Interval Learning in Bite-Sized Portions”&lt;/a&gt;, Stahl et al 2010:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Since Ebbinghaus’ time, a voluminous amount of research has confirmed this simple but important fact: the retention of new information degrades rapidly unless it is reviewed in some manner. A modern example of this loss of knowledge without repetition is a study of cardiopulmonary resuscitation (CPR) skills that demonstrated rapid decay in the year following training. By 3 years post-training only 2.4% were able to perform CPR successfully.&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1985-mckenna.pdf"&gt;6&lt;/a&gt; Another recent study of physicians taking a tutorial they rated as very good or excellent showed mean knowledge scores increasing from 50% before the tutorial to 76% immediately afterward.&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2517967/"&gt;7&lt;/a&gt; However, score gains were only half as great 3-8 days later and incredibly, there was no [statistically-]significant knowledge retention measurable at all at 55 days.7 Similar results have been reported by us in follow-up studies of knowledge retention from continuing medical education programs.1 [Stahl SM, Davis RL. &lt;a href="https://www.amazon.com/Practices-Medical-Educators-Stephen-Stahl/dp/1422500497/"&gt;&lt;em&gt;Best Practices for Medical Educators&lt;/em&gt;&lt;/a&gt;. Carlsbad, CA: NEI Press; 200916ya]&lt;/p&gt;
&lt;p&gt;…This may be due to the fact that lectures with assigned reading are the easiest for teachers. Also, medical learning is rarely measured immediately after a lecture or after reading new material for the first time and then measured again a few days or weeks later, so that the low retention rates of this approach may not be widely appreciated.1,&lt;a href="https://gwern.net/doc/www/pdfs.semanticscholar.org/191557c35430cc1408868f124af48e4a6c9f80fc.pdf"&gt;4&lt;/a&gt; No wonder formal medical education conferences without enabling or practice-reinforcing strategies appear to have relatively little impact on practice and healthcare outcomes.&lt;a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.556.6124&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;8&lt;/a&gt;,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1998-davis.pdf"&gt;9&lt;/a&gt;,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1995-davis.pdf"&gt;10&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref12"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;One study looking at cramming is the 199332ya “Cramming: A barrier to student success, a way to beat the system or an effective learning strategy?”, Vacha et al 1993, abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tested the hypothesis that cramming is an ineffective study strategy by examining the weekly study diaries of 166 undergraduates. All subjects also completed an end-of-semester questionnaire measuring study habits. subjects were classified in the following study patterns: ideal, confident, zealous, or crammer. Contrary to the hypothesis, results suggest that cramming is an effective approach, most widespread in courses using take-home essay examinations and major research papers. Crammers’ grades were as good as or better than those of subjects using other strategies; the longer subjects were in college, the more likely it was that they crammed. Crammers studied more hours than most students and were as interested in their courses as other students.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note that there is no measure of long-term retention, suggesting that people who only care about grades are rationally choosing to cram.&lt;a href="#fnref13"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Anki has its &lt;a href="https://docs.ankiweb.net/filtered-decks.html#filtered-decks--cramming"&gt;Cram Mode&lt;/a&gt; and Mnemosyne 2.0 has a cramming plugin. When a SRS doesn’t have explicit support, it’s always possible to ‘game’ the algorithm by setting one’s scores artificially low, so the SR algorithm thinks you are stupid and need to do a lot of repetitions.&lt;a href="#fnref14"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://journals.sagepub.com/doi/pdf/10.2304/plat.2002.2.2.70"&gt;“Examining the examiners: Why are we so bad at assessing students?”&lt;/a&gt;, Newstead2002:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.56.6901&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;Conway, Cohen &amp;amp; Stanhope1992&lt;/a&gt; looked at long term memory for the information presented on a psychology course. They found that some types of information, especially that relating to research methods, were remembered better than others. But in a follow up analysis, they found that the type of assessment used had an effect on memory. In essence, material assessed by continuous assessment was more likely to be remembered than information assessed by exams.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref15"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Stahl2010:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For example, simple restudying allows the learner to reexperience all of the material but actually produces poor long-term retention.&lt;a href="https://pdfs.semanticscholar.org/6698/bf91c9333faa0d333a800254b8063230d4f4.pdf"&gt;25&lt;/a&gt;,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2007-pashler.pdf"&gt;26&lt;/a&gt;,&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2006-roediger.pdf"&gt;35&lt;/a&gt; Why do students keep studying the original materials? Certainly if this is their only choice, then restudying is a necessary tactic. Another answer may be that repeated studying falsely inflates students’ confidence in their ability to remember in the future because they sense that they understand it now, and they and their instructors may be unaware of the many studies that show poor retention on delayed testing after this form of repetition.25,26,35&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref16"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;From Kornell et al 2010:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Contrary to the massing-aids-induction hypothesis, final test performance was consistently and considerably superior in the spaced condition. A large majority of participants, however, judged massing to be more effective than spacing, despite making the judgment &lt;em&gt;after&lt;/em&gt; taking the test.&lt;/p&gt;
&lt;p&gt;…Metacognitive judgments-that is, judgments about one’s own memory and cognition-are often based on feelings of fluency(eg. see &lt;a href="https://gwern.net/doc/psychology/cognitive-bias/illusion-of-depth/1998-benjamin.pdf"&gt;Benjamin, Bjork, &amp;amp; Schwartz, 1998&lt;/a&gt;; &lt;a href="https://gwern.net/doc/www/castel.bol.ucla.edu/853adb133392924818abd8bc050d526177227570.pdf"&gt;Rhodes &amp;amp; Castel, 2008&lt;/a&gt;). Because massing naturally leads to feelings of fluency and increases short-term task performance during learning, learners frequently rate spacing as less effective than massing, even when their performance shows the opposite pattern (Baddeley &amp;amp; Longman1978; Kornell &amp;amp; Bjork, 200817ya; Simon &amp;amp; Bjork, 200124ya; Zechmeister &amp;amp; Shaughnessy, 198045ya). Averaged across Kornell and Bjork’s (200817ya) experiments, for example, more than 80% of participants rated massing as equally or more effective than spacing, whereas only 15% of participants actually performed better in the massed condition than in the spaced condition.&lt;/p&gt;
&lt;p&gt;…Such an illusion was apparent in the induction condition. Contrary to previous research, however, participants gave higher ratings for spacing than massing during repetition learning (see, eg. Simon &amp;amp; Bjork, 200124ya; Zechmeister &amp;amp; Shaughnessy, 198045ya). This outcome may have occurred because of a process of a habituation: Six presentations and a total of 30 s spent studying a single painting may have come to seem inefficient and pointless. Thus, there appears to be a turning point in metacognitive ratings based on fluency: As fluency increases, metacognitive ratings increase up to a point, but as fluency continues to increase and encoding or retrieval becomes too easy, metacognitive ratings may begin to decrease.&lt;/p&gt;
&lt;p&gt;…In advance of their research, Kornell &amp;amp; Bjork2008 were convinced that such inductive learning would benefit from massing, yet their results showed the opposite. Undaunted, we remained convinced that spacing would be more beneficial for repetition learning than for inductive learning- especially for older adults, given their overall declines in episodic memory. The current results disconfirmed our expectations once again. If our intuitions are erroneous, despite our years spent proving and praising the spacing effect-including roughly 40 years’ worth contributed by Robert A. Bjork-those of the average student are surely mistaken as well (as the inaccuracy of the participants’ metacognitive ratings suggests). We have, perhaps, fallen victim to the illusion that making learning easy makes learning effective, rather than recognizing that spacing is a desirable difficulty (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1994-bjork.pdf"&gt;Bjork1994&lt;/a&gt;) that enhances inductive learning as well as repetition learning well into old age.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref17"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;From Son &amp;amp; Simon2012:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Thus, while spacing may boost learning, it may be thought to be relatively inefficient in terms of study time. As we discuss later, this feeling of inefficiency may be one of the reasons that spacing is not the more popular strategy. Interestingly, in that same study (Baddeley &amp;amp; Longman1978; and see also Pirolli &amp;amp; Anderson1985 and Woodworth &amp;amp; Schlosberg1954 [&lt;em&gt;Experimental Psychology&lt;/em&gt;]), there was evidence of such a thing as &lt;em&gt;laboring in vain&lt;/em&gt;. That is, exceeding a certain number of hours of practice a day (more than approximately 2h) led to no increases in learning, as might be expected. Related to the deficient-processing theory mentioned above, these results are crucial in understanding intuitively how the spacing effect works: We simply get burnt out. These data are also analogous to the cognitive literature on &lt;em&gt;overlearning&lt;/em&gt;, which shows that while continuous study over long periods of time might seem beneficial (and even feel good) in the short-term, the benefits disappear soon afterwards (Rohrer et al 2005; Rohrer &amp;amp; Taylor2006)…In the above-described Baddeley &amp;amp; Longman1978’s study, for example, after postal workers practiced typing in either massed or spaced study sessions, they had to indicate how satisfied they were with the training. Results showed that while spacing led to the best learning, it was the &lt;em&gt;least&lt;/em&gt; liked. Similarly, Simon &amp;amp; Bjork2001 found that people preferred the massing strategy on a motor learning task.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Baddeley, A. D., &amp;amp; Longman, D. J. A. (197847ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1978-baddeley.pdf"&gt;“The influence of length and frequency of training session on the rate of learning to type”&lt;/a&gt;. Ergonomics, 21, 627-635&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Pirolli, P., &amp;amp; Anderson, J. R. (198540ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1985-pirolli.pdf"&gt;“The role of practice in fact retrieval”&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref18"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2012-hartwig.pdf"&gt;“Study strategies of college students: Are self-testing and scheduling related to achievement?”&lt;/a&gt;, Hartwig &amp;amp; Dunlosky2012:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Previous studies, such as those by Kornell and Bjork (&lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, 14:219-224, 200718ya) and Karpicke, Butler, and Roediger (&lt;em&gt;Memory&lt;/em&gt;, 17:471-479, 200916ya), have surveyed college students’ use of various study strategies, including self-testing and rereading. These studies have documented that some students do use self-testing (but largely for monitoring memory) and rereading, but the researchers did not assess whether individual differences in strategy use were related to student achievement. Thus, we surveyed 324 undergraduates about their study habits as well as their college grade point average (GPA). Importantly, the survey included questions about self-testing, scheduling one’s study, and a checklist of strategies commonly used by students or recommended by cognitive research. Use of self-testing and rereading were both positively associated with GPA. Scheduling of study time was also an important factor: Low performers were more likely to engage in late-night studying than were high performers; massing (versus spacing) of study was associated with the use of fewer study strategies overall; and all students-but especially low performers-were driven by impending deadlines. Thus, self-testing, rereading, and scheduling of study play important roles in real-world student achievement.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;(See also &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2013-dunlosky.pdf"&gt;Dunlosky et al 2013&lt;/a&gt;.) Note the self-testing correlation excludes flashcards, a result that both the authors and me found surprising. The sleep connection is interesting, given the &lt;a href="#when-to-review"&gt;hypothesized link&lt;/a&gt; between stronger memory formation &amp;amp; studying before a good night’s sleep - you can hardly get a good night’s sleep if you are cramming late into the night (correlated with lower grades) but you can if you do so at a reasonable time in the evening (in time to get a solid night).&lt;/p&gt;
&lt;p&gt;See also &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2012-susser.pdf"&gt;Susser &amp;amp; McCabe2012&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Laboratory studies have demonstrated the long-term memory benefits of studying material in multiple distributed sessions as opposed to one massed session, given an identical amount of overall study time (ie. the &lt;em&gt;spacing effect&lt;/em&gt;). The current study goes beyond the laboratory to investigate whether undergraduates know about the advantage of spaced study, to what extent they use it in their own studying, and what factors might influence its utilization. Results from a web-based survey indicated that participants (&lt;em&gt;n&lt;/em&gt; = 285) were aware of the benefits of spaced study and would use a higher level of spacing under ideal compared to realistic circumstances. However, self-reported use of spacing was intermediate, similar to massing and several other study strategies, and ranked well below commonly used strategies such as rereading notes. Several factors were endorsed as important in the decision to distribute study time, including the perceived difficulty of an upcoming exam, the amount of material to learn, how heavily an exam is weighed in the course grade, and the value of the material. Further, level of metacognitive self-regulation and use of elaboration strategies were associated with higher rates of spaced study.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref19"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/apps.dtic.mil/33f3b18cb5baf70b282a705d680617a8d9dd040a.pdf"&gt;&lt;em&gt;Analytic Culture in the US Intelligence Community: An Ethnographic Study&lt;/em&gt;&lt;/a&gt;, Johnston2005, pg89:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To investigate the intensity of instructional interactions, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1994-graesser.pdf"&gt;Art Graesser and Natalie Person1994&lt;/a&gt; compared questioning and answering in classrooms with those in tutorial settings.5 They found that classroom groups of students ask about three questions an hour and that any single student in a classroom asks about 0.11 questions per hour. In contrast, they found that students in individual tutorial sessions asked 20-30 questions an hour and were required to answer 117-146 questions per hour. Reviews of the intensity of interaction that occurs in technology-based instruction have found even more active student response levels. [J. D. Fletcher, &lt;em&gt;Technology, the Columbus Effect, and the Third Revolution in Learning&lt;/em&gt;.]&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Although Graesser &amp;amp; Person1994 also found that sheer number of questions was not necessarily important, suggesting &lt;a href="https://en.wikipedia.org/wiki/Diminishing_returns"&gt;diminishing marginal returns&lt;/a&gt; or perhaps bad question asking.&lt;a href="#fnref20"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“SuperMemo is based on the insight that there is an ideal moment to practice what you’ve learned. Practice too soon and you waste your time. Practice too late and you’ve forgotten the material and have to relearn it. The right time to practice is just at the moment you’re about to forget. Unfortunately, this moment is different for every person and each bit of information. Imagine a pile of thousands of flash cards. Somewhere in this pile are the ones you should be practicing right now. Which are they?” Gary Wolf, &lt;a href="https://www.wired.com/2008/04/ff-wozniak/"&gt;“Want to Remember Everything You’ll Ever Learn? Surrender to This Algorithm”&lt;/a&gt;, &lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Wired_(magazine)"&gt;Wired Magazine&lt;/a&gt;&lt;/em&gt;&lt;a href="#fnref21"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;“Make no mistake about it: Computers process numbers - not symbols. We measure our understanding (and control) by the extent to which we can arithmetize an activity.” Perlis, &lt;em&gt;ibid.&lt;/em&gt;&lt;a href="#fnref22"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;this exponential expansion is how a SR program can handle continual input of cards: if cards were scheduled at fixed intervals, like every other day, review would soon become quite impossible - I have &amp;gt;18000 items in Mnemosyne, but I don’t have time to review 9000 questions a day!&lt;a href="#fnref23"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;See the 200817ya &lt;a href="https://en.wikipedia.org/wiki/Meta-analysis"&gt;meta-analysis&lt;/a&gt;, &lt;a href="https://gwern.net/doc/www/www.psychologicalscience.org/c4bd186ce8e3ad84128353c84b6ef82322316cef.pdf"&gt;“Learning Styles: Concepts and Evidence”&lt;/a&gt; (&lt;a href="https://www.psychologicalscience.org/news/releases/learning-styles-debunked-there-is-no-evidence-supporting-auditory-and-visual-learning-psychologists-say.html"&gt;APS press release&lt;/a&gt;); from the abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;…in order to demonstrate that optimal learning requires that students receive instruction tailored to their putative learning style, the experiment must reveal a specific type of interaction between learning style and instructional method: Students with one learning style achieve the best educational outcome when given an instructional method that differs from the instructional method producing the best outcome for students with a different learning style. In other words, the instructional method that proves most effective for students with one learning style is not the most effective method for students with a different learning style.&lt;/p&gt;
&lt;p&gt;Our review of the literature disclosed ample evidence that children and adults will, if asked, express preferences about how they prefer information to be presented to them. There is also plentiful evidence arguing that people differ in the degree to which they have some fairly specific aptitudes for different kinds of thinking and for processing different types of information. However, we found virtually no evidence for the interaction pattern mentioned above, which was judged to be a precondition for validating the educational applications of learning styles. Although the literature on learning styles is enormous, very few studies have even used an experimental methodology capable of testing the validity of learning styles applied to education. Moreover, of those that did use an appropriate method, several found results that flatly contradict the popular meshing hypothesis.&lt;/p&gt;
&lt;p&gt;We conclude therefore, that at present, there is no adequate evidence base to justify incorporating learning-styles assessments into general educational practice. Thus, limited education resources would better be devoted to adopting other educational practices that have a strong evidence base, of which there are an increasing number. However, given the lack of methodologically sound studies of learning styles, it would be an error to conclude that all possible versions of learning styles have been tested and found wanting; many have simply not been tested at all.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref24"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Fritz, C. O., Morris, P. E., Acton, M., Etkind, R., &amp;amp; Voelkel, A. R (200718ya). “Comparing and combining expanding retrieval practice and the keyword mnemonic for foreign vocabulary learning”. &lt;em&gt;Applied Cognitive Psychology&lt;/em&gt;, 21, 499-526.&lt;a href="#fnref25"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;From Balota et al 2007, describing &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1939-spitzer.pdf"&gt;Spitzer1939, “Studies in retention”&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Spitzer (193986ya) incorporated a form of expanded retrieval in a study designed to assess the ability of sixth graders to learn science facts. Impressively, Spitzer tested over 3600 students in Iowa-the entire sixth-grade population of 91 elementary schools at the time. The students read two articles, one on peanuts and the other on bamboo, and were given a 25-item multiple choice test to assess their knowledge (such as ‘To which family of plants does bamboo belong?’). Spitzer tested a total of nine groups, manipulating both the timing of the test (administered immediately or after various delays) and the number of identical tests students received (one to three). Spitzer did not incorporate massed or equal interval retrieval conditions, but he had at least two groups that were tested on an expanding schedule of retrieval, in which the intervals between tests were separated by the passage of time (in days) rather than by intervening to-be-learned information. For example, in one of the groups, the first test was given immediately, the second test was given seven days after the first test, and the third test was given 63 days after the second test. Thus, in essence, this group was tested on a 0-7-63 day expanding retrieval schedule. Spitzer compared performance of the expanded retrieval group to a group given a single test 63 days after reading the original article. On the first (immediate) test, the expanded retrieval group correctly answered 53% of the questions. After 63 days and two previous tests, their score was still an impressive 43%. The single test group correctly answered only 25% of the original items after 63 days, giving the expanded retrieval group an 18% retention advantage. This is quite impressive, given that this large benefit remained after a 63-day retention interval. Similar beneficial effects were found in a group tested on a 0-1-21 day expanded retrieval schedule compared to a group given a single test after 21 days. Of course, this study does not decouple the effects of testing from spacing or expansion, but the results do clearly indicate considerable learning and retention using the expanded repeated testing procedure. Spitzer concluded that ‘…examinations are learning devices and should not be considered only as tools for measuring achievement of pupils’ (p. 656, italics added)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref26"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3399982/"&gt;“Distributing Learning Over Time: The Spacing Effect in Children’s Acquisition and Generalization of Science Concepts”&lt;/a&gt;, Vlach &amp;amp; Sandhofer2012:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The spacing effect describes the robust finding that long-term learning is promoted when learning events are spaced out in time, rather than presented in immediate succession. Studies of the spacing effect have focused on memory processes rather than for other types of learning, such as the acquisition and generalization of new concepts. In this study, early elementary school children (5-7 year-olds; &lt;em&gt;N&lt;/em&gt; = 36) were presented with science lessons on one of three schedules: massed, clumped, and spaced. The results revealed that spacing lessons out in time resulted in higher generalization performance for both simple and complex concepts. Spaced learning schedules promote several types of learning, strengthening the implications of the spacing effect for educational practices and curriculum.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref27"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;See also Balch2006, who compared spacing &amp;amp; massed in an introductory psychology course as well.&lt;a href="#fnref28"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Roediger &amp;amp; Karpicke2006b again.&lt;a href="#fnref29"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Balota et al 2007 review:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;No feedback or correction was given to subjects if they made errors or omitted answers. &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1978-landauer.pdf"&gt;Landauer &amp;amp; Bjork1978&lt;/a&gt; found that the expanding-interval schedule produced better recall than equal-interval testing on a final test at the end of the session, and equal-interval testing, in turn, produced better recall than did initial massed testing. Thus, despite the fact that massed testing produced nearly errorless performance during the acquisition phase, the other two schedules produced better retention on the final test given at the end of the session. However, the difference favoring the expanding retrieval schedule over the equal-interval schedule was fairly small at around 10%. In research following up Landauer and Bjork’s (197847ya) original experiments, practically all studies have found that spaced schedules of retrieval (whether equal-interval or expanding schedules) produce better retention on a final test given later than do massed retrieval tests given immediately after presentation (eg. Cull, 200025ya; Cull, Shaughnessy, &amp;amp; Zechmeister, 199629ya), although exceptions do exist. For example, in Experiments 3 and 4 of Cull et al 1996, massed testing produced performance as good as equal-interval testing on a 5-5-5 schedule, but most other experiments have found that any spaced schedule of testing (either equal-interval or expanding) is better than a massed schedule for performance on a delayed test. However, whether expanding schedules are better than equal-interval schedules for long-term retention-the other part of Landauer and Bjork’s interesting findings-remains an open question. Balota, Duchek, and Logan (in press) have provided a thorough consideration of the relevant evidence and have shown that it is mixed at best, and that most researchers have found no difference between the two schedules of testing. That is, performance on a final test at the end of a session often shows no difference in performance between equal-interval and expanding retrieval schedules.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Cull, for those curious (Cull, W. L. (200025ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2000-cull.pdf"&gt;“Untangling the benefits of multiple study opportunities and repeated testing for cued recall”&lt;/a&gt;. &lt;em&gt;Applied Cognitive Psychology&lt;/em&gt;, 14, 215-235):&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Cull (200025ya) compared expanded retrieval to equal interval spaced retrieval in a series of four experiments designed to mimic typical teaching or study strategies encountered by students. He examined the role of testing versus simply restudying the material, feedback, and various retention intervals on final test performance. Paired associates (an uncommon word paired with a common word, such as bairn-print) were presented in a manner similar to the flashcard techniques students often use to learn vocabulary words. The intervals between retrieval attempts of to-be-learned information ranged from minutes in some experiments to days in others. Interestingly, across four experiments, Cull did not find any evidence of an advantage of an expanded condition over a uniform spaced condition (ie. no [substantial] expanded retrieval effect), although both conditions consistently produced large advantages over massed presentations. He concluded that distributed testing of any kind, expanded or equal interval, can be an effective learning aid for teachers to provide for their students.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref30"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The Balota et al 2007 review offers a synthesis of current theories on how massed and spaced differ, based on &lt;a href="https://en.wikipedia.org/wiki/Encoding_(memory)"&gt;memory encoding&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;According to encoding variability theory, performance on a memory test is dependent upon the overlap between the contextual information available at the time of test and the contextual information available during encoding. During massed study, there is relatively little time for contextual elements to fluctuate between presentations and so this condition produces the highest performance in an immediate memory test, when the test context strongly overlaps with the same contextual information encoded during both of the massed presentations. In contrast, when there is spacing between the items, there is time for fluctuation to take place between the presentations during study, and hence there is an increased likelihood of having multiple unique contexts encoded. Because a delayed test will also allow fluctuation of context, it is better to have multiple unique contexts encoded, as in the spaced presentation format, as opposed to a single encoded context, as in the massed presentation format.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Storm et al 2010 did 3 experiments on reading comprehension:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;On a test 1 week later, recall was enhanced by the expanding schedule, but only when the task between successive retrievals was highly interfering with memory for the passage. These results suggest that the extent to which learners benefit from expanding retrieval practice depends on the degree to which the to-be-learned information is vulnerable to forgetting.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref31"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;From Mnemosyne’s &lt;a href="https://mnemosyne-proj.org/principles.php"&gt;Principles&lt;/a&gt; page:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Mnemosyne algorithm is very similar to &lt;a href="https://www.supermemo.com/en/blog/application-of-a-computer-to-improve-the-results-obtained-in-working-with-the-supermemo-method"&gt;SM2&lt;/a&gt; used in one of the early versions of SuperMemo. There are some modifications that deal with early and late repetitions, and also to add a small, healthy dose of randomness to the intervals. Supermemo now uses SM11. However, we are a bit skeptical that the huge complexity of the newer SM algorithms provides for a statistically relevant benefit. But, that is one of the facts we hope to find out with our data collection. We will only make modifications to our algorithms based on common sense or if the data tells us that there is a statistically relevant reason to do so.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref32"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Balota et al 2007:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Carpenter and DeLosh (200520ya, Exp. 2) have recently investigated face-name learning under massed, expanded (1-3-5), and equal interval (3-3-3) conditions. This study also involved study and study and test procedures during the acquisition phase. Carpenter and DeLosh found a large effect of spacing, but no evidence of a benefit of expanded over equal interval practice. In fact, Carpenter and DeLosh reported a reliable benefit of the equal interval condition over the expanded retrieval condition.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref33"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Balota et al 2007 again:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Rea &amp;amp; Modigliani1985 tested the effectiveness of expanded retrieval in a third-grade classroom setting. In separate conditions, students were given new multiplication problems or spelling words to learn. The problem or word was presented audiovisually once and then tested on either a massed retrieval schedule of 0-0-0-0 or an expanding schedule of 0-1-2-4, in which the intervals involved being tested on old items or learning new items. After each test trial for a given item, the item was re-presented in its entirety so students received feedback on what they were learning. Performance during the learning phase was at 100% for both spelling words and multiplication facts. On an immediate final retention test, Rea and Modigliani found a performance advantage for all items-math and spelling- practiced on an expanding schedule compared to the massed retrieval schedule. They suggested, as have others, that spacing combined with the high success rate inherent in the expanded retrieval schedule produced better retention than massed retrieval practice. However, as in Spitzer’s study, Rea and Modigliani did not test an appropriate equal interval spacing condition. Hence, their finding that expanded retrieval is superior to massed retrieval in third graders could simply reflect the superiority of spaced versus massed rehearsal-in other words, the spacing effect.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref34"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://gwern.net/doc/www/psychnet.wustl.edu/13ef191de62e05c797f57dea636fd88aceda45f7.pdf"&gt;Balota et al 2007&lt;/a&gt;.&lt;a href="#fnref35"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Balota et al 2007; &amp;gt;1 is rare in psychology, see &lt;a href="https://gwern.net/doc/www/jenni.uchicago.edu/138a837f0971ccedf8731b20132fb4c46e0d81a1.pdf"&gt;“One Hundred Years of Social Psychology Quantitatively Described”&lt;/a&gt;, Bond et al 2003&lt;a href="#fnref36"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rohrer &amp;amp; Taylor2006&lt;a href="#fnref37"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Balota et al 2007:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;…long-term retention of information has been demonstrated over several days in some cases (eg. Camp et al, 199629ya). For example, in the latter study, Camp et al employed an expanding retrieval strategy to train 23 individuals with mild to moderate AD to refer to a daily calendar as a cue to remember to perform various personal activities (eg. take medication). Following a baseline phase to determine whether subjects would spontaneously use the calendar, spaced retrieval training was implemented by repeatedly asking the subject the question, ‘How are you going to remember what to do each day?’ at expanding time intervals. The results indicated that 20/23 subjects did learn the strategy (ie. to look at the calendar) and retained it over a 1-week period.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref38"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rohrer &amp;amp; Taylor2006 warns us, though, about many of the other math studies:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In one meta-analysis by Donovan &amp;amp; Radosevich1999, for instance, the size of the spacing effect declined sharply as conceptual difficulty of the task increased from low (eg. rotary pursuit) to average (eg. word list recall) to high (eg. puzzle). By this finding, the benefits of spaced practise may be muted for many mathematics tasks.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref39"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;What is especially nice about this study was that not only did it use high-quality (intelligent &amp;amp; motivated) college students (&lt;a href="https://en.wikipedia.org/wiki/United_States_Air_Force_Academy"&gt;United States Air Force Academy&lt;/a&gt;), the conditions were relatively controlled - both groups had the &lt;em&gt;same&lt;/em&gt; homework (so equal testing effect), but like Rohrer &amp;amp; Taylor2006/2007, the &lt;em&gt;distribution&lt;/em&gt; was what varied:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The course topics, textbook, handouts, reading assignments, and graded assignments (with the exception of quiz, homework, and participation points) were identical for the treatment and control groups. The listing of homework assignments in the syllabus differed between groups. The control group was assigned daily homework related to the topic(s) presented that day in class. Peterson (197154ya) calls this the vertical model for assigning mathematics homework. The treatment group was assigned homework in accordance with a distributed organizational pattern that combines practice on current topics and reinforcement of previously covered topics. Under the distributed model, approximately 40% of the problems on a given topic were assigned the day the topic was first introduced, with an additional 20% assigned on the next lesson and the remaining 40% of problems on the topic assigned on subsequent lessons (Hirsch et al, 198342ya). In Hirsch’s research and in this study, after the initial homework assignment, problem(s) representing a given topic resurfaced on the 2nd, 4th, 7th, 12th, and 21st lesson. Consequently, treatment group homework for lesson one consisted of only one topic; homework for lessons two and three consisted of two topics; and homework for lesson four through six consisted of three topics. This pattern continued as new topics were added and was applied to all non-exam, non-laboratory lessons. As shown by Tables 1 and 2, the same homework problems were assigned to both groups with only the pattern of assignment differing. Because of the nature of the distributed practice model, homework for the treatment group contained fewer problems (relative to the control group) early in the semester with the number of problems increasing as the semester progressed. Later in the semester, homework for the treatment group contained more problems (relative to the control group)….The USAFA routinely collects study time data. After each exam, a large sample of cadets (at least 60% of the course population) anonymously reported the amount of time (in minutes) spent studying for the exam. Time spent studying was approximately equal for both groups (see Table 5). Descriptive data revels that, for both the treatment and control group, study time for the third exam was at least 16% greater than study time for any other exam. Study time for the final exam was at least 68% greater than study time for any of the hourly exams (see Table 5)&lt;/p&gt;
&lt;p&gt;…The treatment produced an effect size (f 2) of 0.013 on the first exam, 0.029 on the second exam, 0.035 on the fourth exam, and 0.040 on the final course percentage grade. Although the effect sizes appear to be small, the treatment group outscored the control group in every case. A mean difference of 5.13 percentage points on the first, second, and fourth exam translates to an advantage of about a third of a letter grade for students in the treatment group. In addition, higher minimum scores earned by the treatment group may indicate that the distributed practice treatment served to eliminate the extremely low scores (refer to Table 3)….Oddly, the distributed practice treatment did not produce a [statistically-]significant effect on final exam scores. One possible cause for the disparity was the USAFA policy exempting the top performers from the final exam. Of the 16 exempted students, 11 were from the treatment group with only 5 from the control group.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref40"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Balch2006 abstract:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Two introductory psychology classes (&lt;em&gt;N&lt;/em&gt; = 145) participated in a counterbalanced classroom experiment that demonstrated the spacing effect and, by analogy, the benefits of distributed study. After hearing words presented twice in either a massed or distributed manner, participants recalled the words and scored their recall protocols, reliably remembering more distributed than massed words. Posttest scores on a multiple-choice quiz covering points illustrated by the experiment averaged about twice the comparable pretest scores, indicating the effectiveness of the exercise in conveying content. Students’ subjective ratings suggested that the experiment helped convince them of the benefits of distributed study.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref41"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;See &lt;a href="https://gwern.net/doc/www/uweb.cas.usf.edu/f1052ecdd92f0ecc3f57bdd890a4a6558483ec45.pdf"&gt;Cepeda et al 2006&lt;/a&gt;&lt;a href="#fnref42"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Commins, S., Cunningham, L., Harvey, D., and Walsh, D. (200322ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2003-commins.pdf"&gt;“Massed but not spaced training impairs spatial memory”&lt;/a&gt;. &lt;em&gt;Behavioural Brain Research&lt;/em&gt; 139, 215-223&lt;a href="#fnref43"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Galluccio &amp;amp; Rovee-Collier2006, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2006-galluccio.pdf"&gt;“Nonuniform effects of reinstatement within the time window”&lt;/a&gt;. &lt;em&gt;Learning and Motivation&lt;/em&gt;, 37, 1-17.&lt;a href="#fnref44"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;See the previous sections for many using children; one previously uncited is Toppino1993, &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1993-toppino.pdf"&gt;“The spacing effect in preschool children’s free recall of pictures and words”&lt;/a&gt;; but &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2009-toppino.pdf"&gt;Toppino et al 2009&lt;/a&gt; adds some interesting qualifiers to spaced repetition in the young:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Preschoolers, elementary school children, and college students exhibited a spacing effect in the free recall of pictures when learning was intentional. When learning was incidental and a shallow processing task requiring little semantic processing was used during list presentation, young adults still exhibited a spacing effect, but children consistently failed to do so. Children, however, did manifest a spacing effect in incidental learning when an elaborate semantic processing task was used.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref45"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Another previously uncited study: Glenberg, A. M. (197946ya), &lt;a href="https://gwern.net/doc/www/link.springer.com/d2cd5f87f53d5b4f7dab9651ff5511f91763340f.pdf"&gt;“Component-levels theory of the effects of spacing of repetitions on recall and recognition”&lt;/a&gt;. &lt;em&gt;Memory &amp;amp; Cognition&lt;/em&gt;, 7, 95-112.&lt;a href="#fnref46"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;See Kornell et al 2010; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2012-simone.pdf"&gt;Simone et al 2012&lt;/a&gt; shows the spacing benefits but reduced in magnitude in its 56-74 year old subjects, similar to &lt;a href="https://www.sciencedirect.com/science/article/abs/pii/S1552526012001318"&gt;Jackson et al 2012&lt;/a&gt; and &lt;a href="https://gwern.net/doc/www/openscholarship.wustl.edu/49731dc7f7ee896c744b4472bd39d025b0fa3b57.pdf"&gt;Maddox2013&lt;/a&gt;&lt;a href="#fnref47"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mammarella, N., Russo, R., &amp;amp; Avons, S. E. (200223ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2002-mammarella.pdf"&gt;”Spacing effects in cued-memory tasks for unfamiliar faces and nonwords”&lt;/a&gt;. &lt;em&gt;Memory &amp;amp; Cognition&lt;/em&gt;, 30, 1238–1251&lt;a href="#fnref48"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Childers, J. B., &amp;amp; Tomasello, M. (200223ya). &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2002-childers.pdf"&gt;”Two-year-olds learn novel nouns, verbs, and conventional actions from massed or distributed exposures”&lt;/a&gt;. &lt;em&gt;Developmental Psychology&lt;/em&gt;, 38, 967-978&lt;a href="#fnref49"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;eg. &lt;a href="https://gwern.net/doc/www/files.eric.ed.gov/5242589a8f7dea7c08962d0b22d15038a4736c73.pdf"&gt;Fishman et al 1968&lt;/a&gt;&lt;a href="#fnref50"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The famous ‘10,000 hours of practice’ figure may not be as true or important as Ericsson and publicizers like Malcolm Gladwell imply, given the high &lt;a href="https://en.wikipedia.org/wiki/Variance"&gt;variance&lt;/a&gt; of expertise against time, and results from sports showing &lt;a href="https://gwern.net/doc/www/web.archive.org/e4fb61640822bb1c8370bc5cd741122afba6927f.html"&gt;smaller&lt;/a&gt; time investments (see also &lt;a href="https://scholar.google.com/scholar?q=author%3AHambrick%20%22deliberate%20practice%22"&gt;Hambrick’s corpus&lt;/a&gt; cutting ‘deliberate practice’ down to size), and Ericsson absurdly deny the powerful role of genetics and the necessary condition of having talent but the insight of ‘deliberate practice’ helping talented people probably is real. One may be able to get away with 3,000 hours rather than 10,000, but one isn’t going to do that with mindless repetition or no repetitions.&lt;a href="#fnref51"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Gentner, D., Loewenstein, J., &amp;amp; Thompson, L. (200322ya). &lt;a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.58.2647&amp;amp;rep=rep1&amp;amp;type=pdf"&gt;“Learning and transfer: A general role for analogical encoding”&lt;/a&gt;. &lt;em&gt;Journal of Educational Psychology&lt;/em&gt;, 95, 393-40&lt;a href="#fnref52"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;From Kornell et al 2010:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The benefits of spacing seem to diminish or disappear when to-be-learned items are not repeated exactly (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2005-appletonknapp.pdf"&gt;Appleton-Knapp, Bjork, &amp;amp; Wickens, 2005&lt;/a&gt;)…a number of studies have shown that massing, rather than spacing, promotes inductive learning. These studies have generally employed relatively simple perceptual stimuli that facilitate experimental control (&lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1950-gagne.pdf"&gt;Gagné, 1950&lt;/a&gt;; &lt;a href="https://pcl.sitehost.iu.edu/rgoldsto/interrelated/interrelated.html"&gt;Goldstone, 1996&lt;/a&gt;; &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1956-kurtz.pdf"&gt;Kurtz &amp;amp; Hovland, 1956&lt;/a&gt;; [Whitman J. R., &amp;amp; Garner, W. R. (196362ya). “Concept learning as a function of the form of internal structure”. &lt;em&gt;Journal of Verbal Learning &amp;amp; Verbal Behavior&lt;/em&gt;, 2, 195-202]).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref53"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;High error rates - indicating one didn’t actually learn the card contents in the first place - seem to be connected to failures of the spacing effect; there’s &lt;a href="https://www.columbia.edu/cu/psychology/metcalfe/PDFs/Son2010.pdf"&gt;some evidence&lt;/a&gt; that people naturally choose to mass study when they don’t yet know the material.&lt;a href="#fnref54"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The 20 years look like this (note the &lt;a href="https://en.wikipedia.org/wiki/Scientific_notation"&gt;scientific notation&lt;/a&gt;): &lt;code&gt;[0.742675, 0.27044575182838654, 0.15275979054767388, 0.10348750000000001, 7.751290630254386e-2, 6.187922936397532e-2, 5.161829250474865e-2, 4.445884397854832e-2, 3.923055555555555e-2, 3.5275438307530015e-2, 3.219809429218694e-2, 2.9748098818459235e-2, 2.7759942051635768e-2, 2.6120309801216147e-2, 2.474928593068675e-2, 2.35890625e-2, 2.2596898475825956e-2, 2.1740583401051353e-2, 2.0995431241707652e-2, 2.0342238287817983e-2]&lt;/code&gt;&lt;a href="#fnref55"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;modulo things where knowing it is useful even if you don’t need it often - it can be a brick in a pyramid of knowledge; cf. &lt;a href="https://www.wired.com/2008/04/ff-wozniak/"&gt;page 3&lt;/a&gt; of Wolf:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The problem of forgetting might not torment us so much if we could only convince ourselves that remembering isn’t important. Perhaps the things we learn - words, dates, formulas, historical and biographical details - don’t really matter. Facts can be looked up. That’s what the Internet is for. When it comes to learning, what really matters is how things fit together. We master the stories, the schemas, the frameworks, the paradigms; we rehearse the lingo; we swim in the episteme.&lt;/p&gt;
&lt;p&gt;The disadvantage of this comforting notion is that it’s false. “The people who criticize memorization - how happy would they be to spell out every letter of every word they read?” asks Robert Bjork, chair of UCLA’s psychology department and one of the most eminent memory researchers. After all, Bjork notes, children learn to read whole words through intense practice, and every time we enter a new field we become children again. “You can’t escape memorization,” he says. “There is an initial process of learning the names of things. That’s a stage we all go through. It’s all the more important to go through it rapidly.” The human brain is a marvel of associative processing, but in order to make associations, data must be loaded into memory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref56"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;See Stephen R. Schmidt’s webpage &lt;a href="https://gwern.net/doc/www/frank.itlab.us/16aacaabe05dfc07c0e966b994d7dd0a727cd90e.html#II.%20Decay%20Theory"&gt;“Theories of Forgetting”&lt;/a&gt;, which cites ‘Woodworth &amp;amp; Schlosbeg (196164ya)’ when presenting a &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1961-woodworth-forgettingcurveovertimein5studies.jpg"&gt;log graph&lt;/a&gt; of various studies’ forgetting curves.&lt;a href="#fnref57"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;which neatly addresses the issue of such mailing lists being useless (‘who learns a word after just one exposure?’).&lt;a href="#fnref58"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Mnemosyne in this case constitutes both a way to learn the quotes so I can use them, and a &lt;a href="https://en.wikipedia.org/wiki/Notebook_(style)"&gt;waste book&lt;/a&gt;; just the other day I had 3 or 4 apposite quotes for an essay because I had entered them into Mnemosyne months or years ago.&lt;a href="#fnref59"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;It’s well known that any speaker of a language understands many more words than they will ever use or be able to explicitly generate, that their “reading vocabulary” exceeds their “writing vocabulary”; less well-known is that on many problems, one can guess at well above random rates even while feeling unsure &amp;amp; ignorant, necessitating psychologists to employ forced-choice paradigms to reveal such &lt;a href="https://gwern.net/doc/psychology/dark-knowledge/index"&gt;“dark knowledge”&lt;/a&gt;. Even less known is the capacity of &lt;a href="https://en.wikipedia.org/wiki/Recognition_memory"&gt;recognition memory&lt;/a&gt; or “implicit memory” (cf. &lt;a href="https://en.wikipedia.org/wiki/McCollough_effect"&gt;McCollough effect&lt;/a&gt;); this memory can apply to things like recognizing images or text or music, typing, puzzle solving, etc. Andrew Drucker, in &lt;a href="https://gwern.net/doc/www/people.csail.mit.edu/746c7e23b92eb7cad4983f7799c61c41d9c56347.pdf"&gt;“Multiplying 10-digit numbers using Flickr: The power of recognition memory”&lt;/a&gt;, employs visual memory to calculate 9,883,603,368 × 4,288,997,768 = 42,390,752,785,149,282,624; he cites as precedent &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/1973-standing.pdf"&gt;Standing1973&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In one of the most widely-cited studies on recognition memory, Standing showed participants an epic 10,000 photographs over the course of 5 days, with 5 seconds’ exposure per image. He then tested their familiarity, essentially as described above. The participants showed an 83% success rate, suggesting that they had become familiar with about 6,600 images during their ordeal. Other volunteers, trained on a smaller collection of 1,000 images selected for vividness, had a 94% success rate.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One sometimes sees people argue that something is insecure or unguessable or free from possible placebo effect because it involves too many objects to explicitly memorize, but as these examples make clear, recognition memory can happen quickly and store surprisingly large amounts of information. This could be used for authentication (see for example &lt;a href="https://www.usenix.org/conference/usenixsecurity12/technical-sessions/presentation/bojinov"&gt;Bojinov et al 2012&lt;/a&gt;; &lt;a href="https://gwern.net/doc/www/news.ycombinator.com/3d8fffccfa940fdf3b86e955e283728d22946e04.html"&gt;HN&lt;/a&gt; &lt;a href="https://gwern.net/doc/www/news.ycombinator.com/5760dc1681f758e3cf2471532a88cfd2ec415d45.html"&gt;discussion&lt;/a&gt;) or message since recognition memory could be exploited as a sort of secure communication system. Two parties can share a set of 20,000 photographs (10,000 pairs); to send a message, have a messenger spend 5 days on 10,000 picked ones; and then to receive it, ask him to recognize which photograph he saw in each of the 10,000 pairs. The subject not only does not know what the binary message is or what means, he can’t even produce it since he cannot remember the photographs!&lt;/p&gt;
&lt;p&gt;At an 80% accuracy rate, we can even calculate how many bits of information can be entrusted to the messenger using &lt;a href="https://en.wikipedia.org/wiki/Noisy-channel_coding_theorem"&gt;Shannon’s theorem&lt;/a&gt;; a calculation gives 5.8 kilobits as the upper limit: if &lt;em&gt;p&lt;/em&gt; = 0.2 (based on the 80% success rate), then 10000 / (1 − (&lt;em&gt;p&lt;/em&gt; × log2 &lt;em&gt;p&lt;/em&gt; + (1 − &lt;em&gt;p&lt;/em&gt;) × (log2 (1 − &lt;em&gt;p&lt;/em&gt;)))) = 5,807.44. (This message can, of course, be encrypted.)&lt;/p&gt;
&lt;p&gt;So we see that &lt;a href="https://en.wikipedia.org/wiki/Frank_Herbert"&gt;Frank Herbert&lt;/a&gt; was right after all: the securest way to send a message is through a &lt;a href="https://dune.fandom.com/wiki/Distrans"&gt;“distrans” messenger&lt;/a&gt;! (The downside is that the implicit recognition memory decays; see &lt;a href="https://gwern.net/doc/cs/algorithm/information/1986-landauer.pdf"&gt;Landauer1986&lt;/a&gt; for adjusted estimates.)&lt;/p&gt;
&lt;p&gt;This system is even more interesting because the learning happens unconsciously, without volition, so the subject does not need to cooperate nor even know about it (they could be exposed to key images without realizing it, such as through ‘advertising’). Further, recognition of an image also happens unconsciously, and can be observed by &lt;a href="https://gwern.net/doc/psychology/neuroscience/2007-rugg.pdf"&gt;EEG&lt;/a&gt; &lt;a href="https://en.wikipedia.org/wiki/Event-related_potential"&gt;ERPs&lt;/a&gt; &amp;amp; fMRI (and probably other &lt;a href="https://scholar.google.com/scholar?as_sdt=0%2C21&amp;amp;q=%22recognition+memory%22+neurological+correlate"&gt;neural correlates&lt;/a&gt; or modalities like &lt;a href="https://en.wikipedia.org/wiki/Eye_tracking"&gt;eyetracking&lt;/a&gt; or &lt;a href="https://en.wikipedia.org/wiki/Electrodermal_activity"&gt;skin galvanic response&lt;/a&gt;). Thus, messages can be stored &amp;amp; retrieved both &lt;em&gt;unconsciously &amp;amp; involuntarily&lt;/em&gt; in brains!&lt;a href="#fnref60"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In this vein, I am reminded of what a former &lt;a href="https://en.wikipedia.org/wiki/Polyphasic_sleep"&gt;polyphasic sleeper&lt;/a&gt; &lt;a href="https://www.lesswrong.com/posts/p7CrByygeAqomsJqy/optimizing-sleep?commentId=LsuDzoEcksvGMp9Tt"&gt;told&lt;/a&gt; &lt;a href="https://www.lesswrong.com/posts/p7CrByygeAqomsJqy/optimizing-sleep?commentId=6nmQ5W7XucdXTqwJL"&gt;me&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I’ve been polyphasic for about a year. (Not anymore; kills my memory.)…Anki reps, mostly. I found that I could do proper review sessions for about 2–3 days and would hit an impenetrable wall. I couldn’t learn a single new card and had total brain fog until I got 3 hours more sleep. That, however, would reset my adaptation. The whole effect is a bit less pronounced on Everyman, but not much. It is however easier to add sleep when you already have a core. I didn’t notice any other major mental impairment after the initial sleep deprivation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref61"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For a more recent review, see &lt;a href="https://gwern.net/doc/psychology/spaced-repetition/2013-philips.pdf"&gt;Philips et al 2013&lt;/a&gt;.&lt;a href="#fnref62"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Presumably one would immediately give them all some high grade like 5 to avoid suddenly having a daily load of 500 cards for a while.&lt;a href="#fnref63"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Smaller is better.&lt;a href="#fnref64"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://groups.google.com/g/mnemosyne-proj-users/c/W74Pzq712rU"&gt;“For Mnemosyne 2.x, Ullrich is working on an official Mnemosyne iPhone client which will have very easy syncing.”&lt;/a&gt;&lt;a href="#fnref65"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.wired.com/2008/04/ff-wozniak/"&gt;&lt;em&gt;Wired&lt;/em&gt;&lt;/a&gt;&lt;a href="#fnref66"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;See &lt;a href="https://www.wired.com/2008/04/ff-wozniak/"&gt;Page 4&lt;/a&gt;, Wolf2008:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The spacing effect was one of the proudest lab-derived discoveries, and it was interesting precisely because it was not obvious, even to professional teachers. The same year that Neisser revolted, Robert Bjork, working with Thomas Landauer of Bell Labs, published the results of two experiments involving nearly 700 undergraduate students. Landauer and Bjork were looking for the optimal moment to rehearse something so that it would later be remembered. Their results were impressive: The best time to study something is at the moment you are about to forget it. And yet - as Neisser might have predicted - that insight was useless in the real world.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref67"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;When I first read of SuperMemo, I had already taken a class in &lt;a href="https://en.wikipedia.org/wiki/Cognitive_psychology"&gt;cognitive psychology&lt;/a&gt; and was reasonably familiar with Ebbinghaus’s forgetting curve - so my reaction to its methodology was Huxley’s: “How extremely stupid not to have thought of that!”&lt;a href="#fnref68"&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;See &lt;a href="https://www.wired.com/2008/04/ff-wozniak/"&gt;page 7&lt;/a&gt;, Wolf2008&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;And yet now, as I grin broadly and wave to the gawkers, it occurs to me that the cold rationality of his approach may be only a surface feature and that, when linked to genuine rewards, even the chilliest of systems can have a certain visceral appeal. By projecting the achievement of extreme memory back along the forgetting curve, by provably linking the distant future - when we will know so much - to the few minutes we devote to studying today, Wozniak has found a way to condition his temperament along with his memory. He is making the future noticeable. He is trying not just to learn many things but to warm the process of learning itself with a draft of utopian ecstasy.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;a href="#fnref69"&gt;↩︎&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;



&lt;h1&gt;&lt;a href="#backlinks-section"&gt;Backlinks&lt;/a&gt;&lt;/h1&gt;
&lt;a href="https://gwern.net/metadata/annotation/backlink/%252Fspaced-repetition.html"&gt;[Backlinks (what links here)]&lt;/a&gt;


&lt;h1&gt;&lt;a href="#similars-section"&gt;Similar Links&lt;/a&gt;&lt;/h1&gt;
&lt;a href="https://gwern.net/metadata/annotation/similar/%252Fspaced-repetition.html"&gt;[Similar links by topic]&lt;/a&gt;


&lt;h1&gt;&lt;a href="#link-bibliography-section"&gt;Bibliography&lt;/a&gt;&lt;/h1&gt; &lt;!-- NOTE: In theory, '.collapse' on a '&lt;h1&gt;' is redundant with the '&lt;section&gt;'; but added to parallel Pandoc-generated headers which set all attributes/classes on both. --&gt;
&lt;a href="https://gwern.net/metadata/annotation/link-bibliography/%252Fspaced-repetition.html"&gt;[Bibliography of links/references used in page]&lt;/a&gt;

 &lt;!-- NOTE: unmatched, because it closes the opening div from the hakyll.hs $body$ Pandoc template --&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://gwern.net/spaced-repetition</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 20:48:53 +0000</pubDate>
    </item>
    <item>
      <title>Beijing is enforcing tough rules to ensure chatbots don’t misbehave</title>
      <link>https://www.wsj.com/tech/ai/china-is-worried-ai-threatens-party-ruleand-is-trying-to-tame-it-bfdcda2d</link>
      <description>wsj.com</description>
      <content:encoded>&lt;body style="margin:0"&gt;&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://www.wsj.com/tech/ai/china-is-worried-ai-threatens-party-ruleand-is-trying-to-tame-it-bfdcda2d</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 20:04:52 +0000</pubDate>
    </item>
    <item>
      <title>Show HN: Minimalist editor that lives in browser, stores everything in the URL</title>
      <link>https://github.com/antonmedv/textarea</link>
      <description>A minimalist text editor that lives entirely in your browser and stores everything in the URL hash.</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;h1&gt;&lt;a href="https://textarea.my"&gt;textarea.my&lt;/a&gt;&lt;/h1&gt;&lt;a href="#textareamy"&gt;&lt;/a&gt;
&lt;p&gt;A &lt;em&gt;minimalist&lt;/em&gt; text editor that lives entirely in your browser and stores everything in the URL hash.&lt;/p&gt;
&lt;h2&gt;Features&lt;/h2&gt;&lt;a href="#features"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;📝 &lt;strong&gt;It's a textarea!&lt;/strong&gt; Actually not.&lt;/li&gt;
&lt;li&gt;🗜️ &lt;strong&gt;Compression magic&lt;/strong&gt; - Your text gets compressed with deflate because we're fancy like that&lt;/li&gt;
&lt;li&gt;🔗 &lt;strong&gt;URL storage&lt;/strong&gt; - Share your notes by copying a 500-character URL. Your friends will love it!&lt;/li&gt;
&lt;li&gt;🌓 &lt;strong&gt;Dark mode&lt;/strong&gt; - Respects your poor eyes and your color scheme preference&lt;/li&gt;
&lt;li&gt;💾 &lt;strong&gt;Auto-save&lt;/strong&gt; - Debounced to 500ms because we're not savages&lt;/li&gt;
&lt;li&gt;📱 &lt;strong&gt;Mobile friendly&lt;/strong&gt; - Type your manifesto on the go&lt;/li&gt;
&lt;li&gt;🎯 &lt;strong&gt;No backend&lt;/strong&gt; - Zero servers were harmed in the making of this app&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;How to use&lt;/h2&gt;&lt;a href="#how-to-use"&gt;&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;Open &lt;a href="https://textarea.my"&gt;textarea.my&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Type stuff&lt;/li&gt;
&lt;li&gt;Marvel at the URL getting longer&lt;/li&gt;
&lt;li&gt;Try to share it&lt;/li&gt;
&lt;li&gt;...&lt;/li&gt;
&lt;li&gt;Profit&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Pro tips&lt;/h2&gt;&lt;a href="#pro-tips"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Start your document with &lt;code&gt;# Title&lt;/code&gt; to set a custom page title&lt;/li&gt;
&lt;li&gt;Your data lives in localStorage AND the URL. Double the fun!&lt;/li&gt;
&lt;li&gt;Feeling fancy? Add a &lt;code&gt;style&lt;/code&gt; attribute to the &lt;code&gt;&amp;lt;article&amp;gt;&lt;/code&gt; tag via DevTools. It'll be saved in the URL too!&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Examples&lt;/h2&gt;&lt;a href="#examples"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://medv.io/goto/crime-and-punishment-by-fyodor-dostoevsky.html"&gt;Crime and Punishment (by Fyodor Dostoevsky)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://textarea.my/#TVM9j9w2EE3NX_FwaRJAtwe4SHGu7g5I4MII4HNgpByRI4lZiqPMjFbeVPsj0hiI_9z-koCyDV9FznA-33v8EQ8VvyeGC55kzhHPVC2E73eQaj6xYcs-yeogO-Y6duEBo-aKXOHnRUalZcoRg-jchedJuFBkw1o9c-pghblVUSmFE9alC09KNuU6widGT_XvlR0ywFjzAKoJVXQ-hPAoWlFlf5xJ-8KYqBSDKApt6DXzYF14XB1JJBW2DrYwxwn92ve7TZioptuktFUshakLb7xF0dH2JSbGSXLk1qUZsZCZisxYxJz1Plwv_z0yjrmm7nr5jGbSkWFU-JvjVQMAgzIfrpfPIbyf-Ds8rAaLMgwdKP21mrc-WXFkrTukT2X1OOE3UpqlJpR8ZCxMWgzkSLTVQ_iT_QVV2OjU1lsr9WQTpy48Tcw6rKWcsanUsYP52veitZwh9RDa4ptmZ0Of1adEZ0TSZDvoRcxvk4wYypnVWr1V44TKmxV2bz5YHqvBaeGEqCJHTk1CSUTt0OonYds526ZsCysWZfM8ciNtkY31evl3Z6CJyroG3jsu9PGAD3y9fDoxjLliE7WvWL6VeGxSmnluBztrpbZlX2jmFH4VRdQ8syE7Kp9YQUUqI8o8Z_cGzhtHz6S2U7xxHqddVtM6U4WTOYcP2ScQbM6F4RM5ItXr5VPLBKfsnA4hPNQE81xKa7awWjb_KrNlOYNizImrd-GPGkVKY6gXn1jb7GtVHnJtA73jOdf07RtsoiV1TY8qa03ceqgc2brwvk3SEKVSWlwyVP4C-8akIHjmww8BAHqKx3GvcI9Vy093dzOn0yHLHZmx2505qR3GPPz8ek8YpPrtQHMu53vcvJDX2-eb7qXjpkNc1fKJXyRa_ofv8eqX5eMXZ5Qiet-od34d_gc="&gt;An Ode to Comic Sans (by ChatGPT)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Made with ❤️ and JavaScript&lt;/em&gt;&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/antonmedv/textarea</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 19:42:25 +0000</pubDate>
    </item>
    <item>
      <title>Fabrice Bellard: Biography (2009) [pdf]</title>
      <link>https://www.ipaidia.gr/wp-content/uploads/2020/12/117-2020-fabrice-bellard.pdf</link>
      <description>&lt;a href="https://news.ycombinator.com/item?id=46377862"&gt;Comments&lt;/a&gt;</description>
      <guid isPermaLink="false">https://www.ipaidia.gr/wp-content/uploads/2020/12/117-2020-fabrice-bellard.pdf</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 18:17:47 +0000</pubDate>
    </item>
    <item>
      <title>Show HN: Vibium – Browser automation for AI and humans, by Selenium's creator</title>
      <link>https://github.com/VibiumDev/vibium</link>
      <description>Browser automation without the drama.</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;h1&gt;Vibium&lt;/h1&gt;&lt;a href="#vibium"&gt;&lt;/a&gt;
&lt;p&gt;&lt;strong&gt;Browser automation without the drama.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Vibium is browser automation infrastructure built for AI agents. A single binary handles browser lifecycle, WebDriver BiDi protocol, and exposes an MCP server — so Claude Code (or any MCP client) can drive a browser with zero setup. Works great for AI agents, test automation, and anything else that needs a browser.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;New here?&lt;/strong&gt; &lt;a href="https://github.com/VibiumDev/vibium/blob/main/docs/tutorials/getting-started.md"&gt;Getting Started Tutorial&lt;/a&gt; — zero to hello world in 5 minutes.&lt;/p&gt;

&lt;h2&gt;Quick Reference&lt;/h2&gt;&lt;a href="#quick-reference"&gt;&lt;/a&gt;



Component
Purpose
Interface




&lt;strong&gt;Clicker&lt;/strong&gt;
Browser automation, BiDi proxy, MCP server
CLI / stdio / WebSocket :9515


&lt;strong&gt;JS Client&lt;/strong&gt;
Developer-facing API
npm package




&lt;h2&gt;Architecture&lt;/h2&gt;&lt;a href="#architecture"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;┌─────────────────────────────────────────────────────────────┐
│                         LLM / Agent                         │
│          (Claude Code, Codex, Gemini, Local Models)         │
└─────────────────────────────────────────────────────────────┘
                      ▲
                      │ MCP Protocol (stdio)
                      ▼
           ┌─────────────────────┐         
           │   Vibium Clicker    │
           │                     │
           │  ┌───────────────┐  │
           │  │  MCP Server   │  │
           │  └───────▲───────┘  │         ┌──────────────────┐
           │          │          │         │                  │
           │  ┌───────▼───────┐  │WebSocket│                  │
           │  │  BiDi Proxy   │  │◄───────►│  Chrome Browser  │
           │  └───────────────┘  │  BiDi   │                  │
           │                     │         │                  │
           └─────────────────────┘         └──────────────────┘
                      ▲
                      │ WebSocket BiDi :9515
                      ▼
┌─────────────────────────────────────────────────────────────┐
│                        JS/TS Client                         │
│                     npm install vibium                      │
│                                                             │
│    ┌─────────────────┐               ┌─────────────────┐    │
│    │ Async API       │               │    Sync API     │    │
│    │ await vibe.go() │               │    vibe.go()    │    │
│    │                 │               │                 │    │
│    └─────────────────┘               └─────────────────┘    │
└─────────────────────────────────────────────────────────────┘
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Components&lt;/h2&gt;&lt;a href="#components"&gt;&lt;/a&gt;
&lt;h3&gt;Clicker&lt;/h3&gt;&lt;a href="#clicker"&gt;&lt;/a&gt;
&lt;p&gt;A single Go binary (~10MB) that does everything:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Browser Management:&lt;/strong&gt; Detects/launches Chrome with BiDi enabled&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;BiDi Proxy:&lt;/strong&gt; WebSocket server that routes commands to browser&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MCP Server:&lt;/strong&gt; stdio interface for LLM agents&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Auto-Wait:&lt;/strong&gt; Polls for elements before interacting&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Screenshots:&lt;/strong&gt; Viewport capture as PNG&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Design goal:&lt;/strong&gt; The binary is invisible. JS developers just &lt;code&gt;npm install vibium&lt;/code&gt; and it works.&lt;/p&gt;
&lt;h3&gt;JS/TS Client&lt;/h3&gt;&lt;a href="#jsts-client"&gt;&lt;/a&gt;
&lt;pre&gt;// Option 1: require (REPL-friendly)
const { browserSync } = require('vibium')

// Option 2: dynamic import (REPL with --experimental-repl-await)
const { browser } = await import('vibium')

// Option 3: static import (in .mjs or .ts files)
import { browser, browserSync } from 'vibium'&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Sync API:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;const fs = require('fs')
const { browserSync } = require('vibium')

const vibe = browserSync.launch()
vibe.go('https://example.com')

const png = vibe.screenshot()
fs.writeFileSync('screenshot.png', png)

const link = vibe.find('a')
link.click()
vibe.quit()&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Async API:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;const fs = await import('fs/promises')
const { browser } = await import('vibium')

const vibe = await browser.launch()
await vibe.go('https://example.com')

const png = await vibe.screenshot()
await fs.writeFile('screenshot.png', png)

const link = await vibe.find('a')
await link.click()
await vibe.quit()&lt;/pre&gt;

&lt;h2&gt;For Agents&lt;/h2&gt;&lt;a href="#for-agents"&gt;&lt;/a&gt;
&lt;p&gt;One command to add browser control to Claude Code:&lt;/p&gt;
&lt;pre&gt;claude mcp add vibium -- npx -y vibium&lt;/pre&gt;
&lt;p&gt;That's it. No manual steps needed. Chrome downloads automatically during setup.&lt;/p&gt;



Tool
Description




&lt;code&gt;browser_launch&lt;/code&gt;
Start browser (visible by default)


&lt;code&gt;browser_navigate&lt;/code&gt;
Go to URL


&lt;code&gt;browser_find&lt;/code&gt;
Find element by CSS selector


&lt;code&gt;browser_click&lt;/code&gt;
Click an element


&lt;code&gt;browser_type&lt;/code&gt;
Type text into an element


&lt;code&gt;browser_screenshot&lt;/code&gt;
Capture viewport (base64 or save to file with &lt;code&gt;--screenshot-dir&lt;/code&gt;)


&lt;code&gt;browser_quit&lt;/code&gt;
Close browser




&lt;h2&gt;For Humans&lt;/h2&gt;&lt;a href="#for-humans"&gt;&lt;/a&gt;
&lt;pre&gt;npm install vibium&lt;/pre&gt;
&lt;p&gt;This automatically:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Installs the Clicker binary for your platform&lt;/li&gt;
&lt;li&gt;Downloads Chrome for Testing + chromedriver to platform cache:
&lt;ul&gt;
&lt;li&gt;Linux: &lt;code&gt;~/.cache/vibium/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;macOS: &lt;code&gt;~/Library/Caches/vibium/&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Windows: &lt;code&gt;%LOCALAPPDATA%\vibium\&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;No manual browser setup required.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Skip browser download&lt;/strong&gt; (if you manage browsers separately):&lt;/p&gt;
&lt;pre&gt;VIBIUM_SKIP_BROWSER_DOWNLOAD=1 npm install vibium&lt;/pre&gt;

&lt;h2&gt;Platform Support&lt;/h2&gt;&lt;a href="#platform-support"&gt;&lt;/a&gt;



Platform
Architecture
Status




Linux
x64
✅ Supported


macOS
x64 (Intel)
✅ Supported


macOS
arm64 (Apple Silicon)
✅ Supported


Windows
x64
✅ Supported




&lt;h2&gt;Quick Start&lt;/h2&gt;&lt;a href="#quick-start"&gt;&lt;/a&gt;
&lt;p&gt;&lt;strong&gt;As a library:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;import { browser } from "vibium";

const vibe = await browser.launch();
await vibe.go("https://example.com");
const el = await vibe.find("a");
await el.click();
await vibe.quit();&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;With Claude Code:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Once installed via &lt;code&gt;claude mcp add&lt;/code&gt;, just ask Claude to browse:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;"Go to example.com and click the first link"&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;Contributing&lt;/h2&gt;&lt;a href="#contributing"&gt;&lt;/a&gt;
&lt;p&gt;See &lt;a href="https://github.com/VibiumDev/vibium/blob/main/CONTRIBUTING.md"&gt;CONTRIBUTING.md&lt;/a&gt; for development setup and guidelines.&lt;/p&gt;

&lt;h2&gt;Roadmap&lt;/h2&gt;&lt;a href="#roadmap"&gt;&lt;/a&gt;
&lt;p&gt;V1 focuses on the core loop: browser control via MCP and JS client.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://github.com/VibiumDev/vibium/blob/main/V2-ROADMAP.md"&gt;V2-ROADMAP.md&lt;/a&gt; for planned features:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Python and Java clients&lt;/li&gt;
&lt;li&gt;Cortex (memory/navigation layer)&lt;/li&gt;
&lt;li&gt;Retina (recording extension)&lt;/li&gt;
&lt;li&gt;Video recording&lt;/li&gt;
&lt;li&gt;AI-powered locators&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Updates&lt;/h2&gt;&lt;a href="#updates"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/VibiumDev/vibium/blob/main/docs/updates/2025-12-22-day12-npm-publish.md"&gt;2025-12-22: Day 12 - Published to npm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/VibiumDev/vibium/blob/main/docs/updates/2025-12-21-day11-polish.md"&gt;2025-12-21: Day 11 - Polish &amp;amp; Error Handling&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/VibiumDev/vibium/blob/main/docs/updates/2025-12-20-day10-mcp.md"&gt;2025-12-20: Day 10 - MCP Server&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/VibiumDev/vibium/blob/main/docs/updates/2025-12-19-day9-actionability.md"&gt;2025-12-19: Day 9 - Actionability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/VibiumDev/vibium/blob/main/docs/updates/2025-12-19-day8-elements-sync.md"&gt;2025-12-19: Day 8 - Elements &amp;amp; Sync API&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/VibiumDev/vibium/blob/main/docs/updates/2025-12-17-halfway-there.md"&gt;2025-12-17: Halfway There&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/VibiumDev/vibium/blob/main/docs/updates/2025-12-16-week1-progress.md"&gt;2025-12-16: Week 1 Progress&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/VibiumDev/vibium/blob/main/docs/updates/2025-12-11-v1-announcement.md"&gt;2025-12-11: V1 Announcement&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;License&lt;/h2&gt;&lt;a href="#license"&gt;&lt;/a&gt;
&lt;p&gt;Apache 2.0&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/VibiumDev/vibium</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 17:49:02 +0000</pubDate>
    </item>
    <item>
      <title>Show HN: A local-first, reversible PII scrubber for AI workflows</title>
      <link>https://medium.com/@tj.ruesch/a-local-first-reversible-pii-scrubber-for-ai-workflows-using-onnx-and-regex-e9850a7531fc</link>
      <description>Listen</description>
      <content:encoded>&lt;article&gt;Press enter or click to view image in full size&lt;img src="https://miro.medium.com/v2/resize:fit:700/0*nUWn_DASgqq7MBkx"/&gt;Photo by &lt;a href="https://unsplash.com/@egorkomarov?utm_source=medium&amp;amp;utm_medium=referral"&gt;Egor Komarov&lt;/a&gt; on &lt;a href="https://unsplash.com/?utm_source=medium&amp;amp;utm_medium=referral"&gt;Unsplash&lt;/a&gt;&lt;h1&gt;A local-first, reversible PII scrubber for AI workflows using ONNX and Regex&lt;/h1&gt;&lt;a href="https://medium.com/@tj.ruesch?source=post_page---byline--e9850a7531fc---------------------------------------"&gt;&lt;img alt="Tom Jordi Ruesch" src="https://miro.medium.com/v2/resize:fill:32:32/0*dk3Wq-tVqNejqKAl.jpg"/&gt;&lt;/a&gt;&lt;a href="https://medium.com/@tj.ruesch?source=post_page---byline--e9850a7531fc---------------------------------------"&gt;Tom Jordi Ruesch&lt;/a&gt;Follow4 min read·7 hours ago&lt;a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Fp%2Fe9850a7531fc&amp;amp;operation=register&amp;amp;redirect=https%3A%2F%2Fmedium.com%2F%40tj.ruesch%2Fa-local-first-reversible-pii-scrubber-for-ai-workflows-using-onnx-and-regex-e9850a7531fc&amp;amp;user=Tom+Jordi+Ruesch&amp;amp;userId=fa0c0531a3ac&amp;amp;source=---header_actions--e9850a7531fc---------------------clap_footer------------------"&gt;&lt;/a&gt;&lt;a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2Fe9850a7531fc&amp;amp;operation=register&amp;amp;redirect=https%3A%2F%2Fmedium.com%2F%40tj.ruesch%2Fa-local-first-reversible-pii-scrubber-for-ai-workflows-using-onnx-and-regex-e9850a7531fc&amp;amp;source=---header_actions--e9850a7531fc---------------------bookmark_footer------------------"&gt;&lt;/a&gt;&lt;a href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2Fplans%3Fdimension%3Dpost_audio_button%26postId%3De9850a7531fc&amp;amp;operation=register&amp;amp;redirect=https%3A%2F%2Fmedium.com%2F%40tj.ruesch%2Fa-local-first-reversible-pii-scrubber-for-ai-workflows-using-onnx-and-regex-e9850a7531fc&amp;amp;source=---header_actions--e9850a7531fc---------------------post_audio_button------------------"&gt;&lt;p&gt;Listen&lt;/p&gt;&lt;/a&gt;&lt;p&gt;Share&lt;/p&gt;&lt;h2&gt;The Privacy-Translation Paradox&lt;/h2&gt;&lt;p&gt;Every engineering team eventually faces the same dilemma: You need to translate user content (support tickets, documents, chat logs) using high-quality engines like DeepL or LLMs like GPT-4, but you strictly cannot send Personally Identifiable Information (PII) to third-party APIs (yes, I’m European).&lt;/p&gt;&lt;p&gt;The solution is seemingly simple: &lt;strong&gt;Redact the data.&lt;/strong&gt; The problem? &lt;strong&gt;Redaction destroys translation quality.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;If you scrub “John bought a generic gift for Mary” into “PERSON bought a generic gift for PERSON,” the translation engine loses the context needed for grammatical gender agreement, case endings, and prepositions in target languages like French or German. Furthermore, most open-source PII scrubbers are “one-way” — they clean data for analytics, not for a round-trip translation workflow.&lt;/p&gt;&lt;p&gt;At ELAN Languages, I built a solution for this. Today, we are open-sourcing &lt;strong&gt;Bridge Anonymization&lt;/strong&gt;: a TypeScript library for reversible, context-aware PII masking designed specifically for translation pipelines.&lt;/p&gt;&lt;h2&gt;How &lt;code&gt;bridge-anonymization &lt;/code&gt;Works&lt;/h2&gt;&lt;p&gt;Unlike general-purpose scrubbers, Bridge is designed around a lifecycle:&lt;/p&gt;&lt;pre&gt;Detect -&amp;gt; Mask -&amp;gt; Translate -&amp;gt; Rehydrate&lt;/pre&gt;&lt;p&gt;It (Mask &amp;amp; Rehydrate, not Translate) runs entirely on-device (Node.js or Bun) using a hybrid engine of RegEx and quantized ONNX models.&lt;/p&gt;&lt;h3&gt;1. Hybrid Detection Strategy&lt;/h3&gt;&lt;p&gt;A single detection method isn’t enough. Regex is fast but limited; NER (Named Entity Recognition) is smart but heavy. &lt;code&gt;bridge-anonymization&lt;/code&gt; uses both:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Structured PII (Regex):&lt;/strong&gt; We use strict patterns for things that follow rules — IBANs (with Mod-97 checksum validation), Credit Cards (Luhn algorithm), and Emails.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Soft PII (NER):&lt;/strong&gt; For Names, Organizations, and Locations, we wrap a powerful NER model via ONNX Runtime.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This allows developers to choose their trade-off. You can run &lt;code&gt;anonymizeRegexOnly()&lt;/code&gt; for sub-millisecond performance on streams, or the full &lt;code&gt;anonymize()&lt;/code&gt; pipeline for high-precision document scrubbing.&lt;/p&gt;&lt;pre&gt;import { createAnonymizer } from '@elanlanguages/bridge-anonymization';&lt;br/&gt;&lt;br/&gt;// Auto-downloads the ~280MB quantized model on first run&lt;br/&gt;const anonymizer = createAnonymizer({&lt;br/&gt;  ner: { mode: 'quantized' }&lt;br/&gt;});&lt;br/&gt;&lt;br/&gt;await anonymizer.initialize();&lt;/pre&gt;&lt;h3&gt;2. The Semantic Masking Challenge&lt;/h3&gt;&lt;p&gt;While preventing leaks is solved, preserving &lt;em&gt;context&lt;/em&gt; remains the frontier.&lt;/p&gt;&lt;p&gt;In our current roadmap, we are tackling &lt;strong&gt;Semantic Masking&lt;/strong&gt;. The goal is to enrich our PII tags with metadata (Gender, Location Scope) so the machine translation engine can generate grammatically correct output.&lt;/p&gt;&lt;h3&gt;&lt;strong&gt;The Problem&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Gender Agreement:&lt;/strong&gt; Replacing “Mary” with generic XML leads to “Il a vu &lt;code&gt;&amp;lt;PII type=”PERSON” /&amp;gt;&lt;/code&gt;” (masculine default) instead of “Elle a vu…” (feminine).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Prepositions:&lt;/strong&gt; Replacing “Berlin” vs. “Germany” with generic &lt;code&gt;&amp;lt;PII type="LOCATION"/&amp;gt;&lt;/code&gt; confuses engines that need to know if the location is a city, country, landmark or other place.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;strong&gt;Our V1 Approach: Lookup Tables&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;For our first iteration, we are implementing a ‘lightweight’ &lt;strong&gt;semantic enricher&lt;/strong&gt; that runs post-NER detection.&lt;/p&gt;&lt;pre&gt;// Before&lt;br/&gt;&amp;lt;PII type="PERSON" id="1"/&amp;gt;&lt;br/&gt;&lt;br/&gt;// After (Enriched)&lt;br/&gt;&amp;lt;PII type="PERSON" gender="female" id="1"/&amp;gt;&lt;/pre&gt;&lt;h3&gt;&lt;strong&gt;The Implementation:&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Data Sources:&lt;/strong&gt; We aggregate open data from &lt;code&gt;gender-guesser&lt;/code&gt; (approx. 40k Western names) and &lt;code&gt;GeoNames&lt;/code&gt; (cities &amp;gt;15k population).&lt;/p&gt;&lt;h2&gt;Get Tom Jordi Ruesch’s stories in your inbox&lt;/h2&gt;&lt;p&gt;Join Medium for free to get updates from this writer.&lt;/p&gt;SubscribeSubscribe&lt;p&gt;&lt;strong&gt;Persons:&lt;/strong&gt; We check the first name against our database. If ambiguous (e.g., “Andrea” is male in Italian but female in German), we can use the &lt;code&gt;locale&lt;/code&gt; hint provided to the anonymizer to disambiguate.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Locations:&lt;/strong&gt; We classify entities into &lt;code&gt;city&lt;/code&gt;, &lt;code&gt;country&lt;/code&gt;, or &lt;code&gt;region&lt;/code&gt; based on the GeoNames export.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;But there is a trade-off:&lt;/strong&gt; We explicitly chose lookup tables over ML for Version 1 to keep the library as &lt;strong&gt;lightweight &lt;/strong&gt;as possible. While a model would handle edge cases better, carrying a static JSON/TXT files is significantly cheaper than loading another 100MB ONNX model just for gender inference. This covers ~90% of common Western names and major cities with near-zero runtime overhead.&lt;/p&gt;&lt;p&gt;In the future, we’ll put additional research into custom ML solutions to cover a broader (and context-aware) enrichment strategies.&lt;/p&gt;&lt;h3&gt;3. Fuzzy Rehydration&lt;/h3&gt;&lt;p&gt;When you send a string like &lt;code&gt;Hello &amp;lt;PII id="1"/&amp;gt;&lt;/code&gt; to a generic LLM or MT engine, the output often comes back "mangled." The engine might change the quotes to smart quotes, add spaces inside the tags, or reorder attributes.&lt;/p&gt;&lt;p&gt;If your library relies on strict string replacement, your pipeline breaks.&lt;/p&gt;&lt;p&gt;We implemented a &lt;strong&gt;Fuzzy Tag Matcher&lt;/strong&gt; that is resilient to these hallucinations. It detects variations in spacing, quoting, and attribute order to ensure we can always map the token back to the original value.&lt;/p&gt;&lt;pre&gt;// The mapping table is encrypted using AES-256-GCM&lt;br/&gt;const { anonymizedText, piiMap } = await anonymizer.anonymize("Call John at +49...");&lt;br/&gt;&lt;br/&gt;// Translate via any external API...&lt;br/&gt;const translated = await externalTranslate(anonymizedText);&lt;br/&gt;// Even if the API returns: "Rufen Sie &amp;lt; PII id = «1» type='PERSON' &amp;gt; an..."&lt;br/&gt;&lt;br/&gt;// Rehydrate seamlessly&lt;br/&gt;const final = rehydrate(translated, piiMap); &lt;br/&gt;// Result: "Rufen Sie John an..."&lt;/pre&gt;&lt;h3&gt;4. Security First&lt;/h3&gt;&lt;p&gt;Because the “PII Map” (the link between &lt;code&gt;ID:1&lt;/code&gt; and &lt;code&gt;John Smith&lt;/code&gt;) effectively &lt;em&gt;is&lt;/em&gt; the PII, we treat it as sensitive material.&lt;/p&gt;&lt;p&gt;The library includes a crypto module that forces AES-256-GCM encryption for the mapping table. The raw PII never leaves the local memory space, and the state object that persists between the masking and rehydration steps is encrypted at rest.&lt;/p&gt;&lt;h2&gt;Performance &amp;amp; Architecture&lt;/h2&gt;&lt;p&gt;We built this for Node.js environments for easy use in web-based applications (electron, tauri) and where Python isn’t always an option.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;Runtime:&lt;/strong&gt; We abstract the ONNX runtime to support both &lt;code&gt;onnxruntime-node&lt;/code&gt; and &lt;code&gt;onnxruntime-web&lt;/code&gt; (for Bun/Edge support).&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Quantization:&lt;/strong&gt; By default, we pull a quantized (INT8) version of the XLM-RoBERTa model (~280MB) which provides 95%+ of the accuracy of the full model at 1/4 the size (custom models are supported, too).&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Try it out&lt;/h2&gt;&lt;p&gt;The project is MIT licensed and available on npm.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;GitHub:&lt;/strong&gt; &lt;a href="https://github.com/elanlanguages/bridge-anonymization"&gt;github.com/elanlanguages/bridge-anonymization&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;NPM:&lt;/strong&gt; &lt;code&gt;npm install @elanlanguages/bridge-anonymization&lt;/code&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We’d love feedback on the NER implementation and edge cases in the rehydration logic!&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://medium.com/@tj.ruesch/a-local-first-reversible-pii-scrubber-for-ai-workflows-using-onnx-and-regex-e9850a7531fc</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 16:44:17 +0000</pubDate>
    </item>
    <item>
      <title>My 2026 Open Social Web Predictions</title>
      <link>https://www.timothychambers.net/2025/12/23/my-open-social-web-predictions.html</link>
      <description>Social Media</description>
      <content:encoded>&lt;article class="post h-entry"&gt;



&lt;a href="https://www.timothychambers.net/2025/12/23/my-open-social-web-predictions.html"&gt;
December 23, 2025 9:50am
&lt;/a&gt;


Reading Time: 7 minutes


&lt;img alt="Tim Chambers" src="https://cdn.micro.blog/tchambers/avatar.jpg"/&gt;
&lt;a href="https://www.timothychambers.net/"&gt;Tim Chambers&lt;/a&gt;



&lt;p&gt;&lt;a href="https://www.timothychambers.net/categories/social-media/"&gt;Social Media&lt;/a&gt;&lt;/p&gt;


&lt;p&gt;I just finished reviewing my 2025 predictions (how do you think I did grading myself?)
&lt;a href="https://www.timothychambers.net/2024/12/24/predictions-for-the-open-social.html"&gt;www.timothychambers.net/2024/12/2…&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Now it’s time to make some bets for 2026. I do this not to prove how great my prognostication muscles are, but to shine a spotlight on trends I think are vital, spur discussions, and give some attention to projects that have earned it. As always, I try to make these as quantifiable, verifiable and crisp as I can. Here goes:&lt;/p&gt;
&lt;p&gt;🌱 MILD&lt;/p&gt;
&lt;p&gt;Safe bets — would be surprising if these DON’T happen.&lt;/p&gt;
&lt;p&gt;▶️ Bluesky will cross 60 million registered users in 2026. Growth will slow from 2024’s explosive pace but remain steady, driven by continued X dissatisfaction and improved features.&lt;/p&gt;
&lt;p&gt;▶️ The ActivityPub Fediverse (excluding Threads) will cross 15 million registered users, monthly active users (excluding will plateau around 2-3 million.  Another good year in terms of stable base, but no big waves of new users. Both Bluesky and Fediverse growth won’t come from big waves of migration this year.&lt;/p&gt;
&lt;p&gt;▶️ Any smaller waves from X/Twitter or from a newly bought TikTok will benefit Meta (Threads/IG), BlueSky, and Fediverse in that order. I see nothing that would change that prediction that was true last year, too.&lt;/p&gt;
&lt;p&gt;▶️ Threads will pass 500 million monthly active users and remain the largest ActivityPub-adjacent platform by a wide margin. But see the next prediction:&lt;/p&gt;
&lt;p&gt;▶️ Threads federation will remain partial, and opt-in through all of 2026. Full two-way federation will NOT ship in 2026 but may move from about 90 percent there, to 95 percent done, inching forward but not finalized and prioritized as a feature.  As Manton wrote, that’s better than fully closed, and better than them stripping it out. (which they might do but I’m predicting not)  My bet:  the status quo continues. &lt;a href="https://www.manton.org/2025/12/19/laurens-hof-at-connected-places.html"&gt;www.manton.org/2025/12/1…&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;▶️ Ghost’s ActivityPub integration will bring 75,000+ new federated accounts to the Fediverse and Ghost will finish 2026 in the top 10 Fediverse server software by MAU.&lt;/p&gt;
&lt;p&gt;▶️ WordPress-based federated accounts will cross 50,000 as measured by FediDB. Currently at approximately 26,000 accounts across 12,700 servers, the WordPress-to-Fediverse pipeline becomes a meaningful growth contributor.&lt;/p&gt;
&lt;p&gt;🔥 MEDIUM-SPICEY
Plausible bets — could go either way, but evidence points toward yes.&lt;/p&gt;
&lt;p&gt;▶️ BridgyFed will shift to “opt-out” for Bluesky users bridging to ActivityPub — and the discourse will be far less contentious than the 2024 debates predicted. Cross-protocol interoperability quietly normalizes.&lt;/p&gt;
&lt;p&gt;▶️ At least one fully independent ATProto stack — PDS, Relay, and AppView operating without dependency on Bluesky PBC infrastructure — will achieve viability in 2026, meaning it has paying customers or sustainable funding. This will be the year ATProto proves (or fails to prove) it can exist beyond Bluesky-the-company.&lt;/p&gt;
&lt;p&gt;▶️ Mastodon gGmbH will hit key sustainability milestones in 2026. Their hosting revenue model will exceed internal targets, the new organizational structure will unlock additional grant funding (beyond NGI/NLnet), and the pace of Mastodon development will noticeably accelerate — shipping more significant features in 2026 than in the previous two years combined.&lt;/p&gt;
&lt;p&gt;▶️ Bluesky PBC will raise another round of funding in 2026 and announce more details on a proposed business model. Following their $15M Series A (October 2024), the company will close a larger round to extend runway. The announced business model will NOT be advertising-based. I’d expect subscriptions, marketplace fees, or enterprise services.&lt;/p&gt;
&lt;p&gt;▶️ The first “ATProto-native” social app that is NOT microblogging will cross 100,000 users. Whether it’s Frontpage (link aggregation), Leaflet (long-form), Smoke Signal, or something new — the ATmosphere diversifies beyond Bluesky-the-app.&lt;/p&gt;
&lt;p&gt;▶️ Flipboard’s Surf app will launch its 1.0 version in 2026 and cross 1 million downloads across iOS and Android by year end, with 100,000+ monthly active users. It will become the most-downloaded dedicated Open Social Web client, surpassing Mastodon’s official app and Graysky.&lt;/p&gt;
&lt;p&gt;▶️ Fedify will power the federation layer for at least one mid-sized social platform (500K+ users) that adds ActivityPub support in 2026. The “build vs. buy” calculation for federation shifts decisively toward “just use Fedify.”&lt;/p&gt;
&lt;p&gt;▶️ Fediscovery will ship in a stable Mastodon release in 2026, moving from behind feature flags to production-ready. The specifications for pluggable discovery providers — covering account search, follow recommendations, and trends — will reach 1.0 status, and at least one public Fediscovery-compatible provider will launch for general use. Small instance operators will finally have a real option to improve discovery without running their own infrastructure.&lt;/p&gt;
&lt;p&gt;▶️ The new “ActivityRank” algorithm in Loops will prove that ethical recommendations and decentralization can coexist. Dan Supernault’s approach — where each instance trains its own algorithm while surfacing content across the ActivityPub network — will be recognized as a breakthrough in solving the fediverse’s discoverability problem. By the end of 2026, the pattern will be studied or adopted by at least two other ActivityPub platforms.&lt;/p&gt;
&lt;p&gt;▶️ ATProto will advance from Internet Drafts to an official IETF Working Group in 2026. Following the September 2025 submission of initial specifications, Bluesky will secure enough support and independent implementers to form a dedicated Working Group — moving from “proposal being discussed” to “standard being formally developed.”&lt;/p&gt;
&lt;p&gt;🌶️ SPICY
Hot takes - a bit more risky - but I’m calling my shot.&lt;/p&gt;
&lt;p&gt;▶️ A well-known digital-native media publication (10M+ monthly visitors) will federate via ActivityPub in 2026 and publicly share positive results. Whether through Ghost, WordPress, or custom implementation, this outlet will report that federated followers drove meaningful engagement — making the business case for federation legible to other publishers for the first time. By year end, at least two additional publications will announce federation plans, citing this pioneer as proof of concept.&lt;/p&gt;
&lt;p&gt;▶️ At least one major news organization (top 50 US by traffic) will announce it is leaving X/Twitter entirely and making Bluesky or the Fediverse its primary social distribution channel. The “institutional exodus” begins.&lt;/p&gt;
&lt;p&gt;▶️ At least one major national government or major city will launch an official presence on BOTH Bluesky AND the ActivityPub Fediverse in 2026 — and it will be a European government. Expect surprising additional early adopters after this from Latin America, Asia-Pacific, or Africa to follow that lead and make moves that year to do the same. This is the year the move to “digital sovereignty" from US tech will benefit the open social web. Eurosky will inch along with some promise.&lt;/p&gt;
&lt;p&gt;▶️ Nostr ↔ ATProto ↔ ActivityPub three-way bridging becomes functional via BridgyFed or another service by end of 2026. The “protocol wars” narrative collapses into “just pick your client.”&lt;/p&gt;
&lt;p&gt;▶️ AltStore will be live with Federation features in at least 5 countries by end of 2026 (currently EU + Japan, with Brazil, Australia, UK announced). AltStore is an independent iOS app marketplace created by Riley Testut and Shane Gill — the first major alternative to Apple’s App Store, made possible by the EU’s Digital Markets Act. The federated app marketplace model will prove viable outside Europe, challenging Apple’s App Store dominance in multiple regulatory regimes simultaneously. Their ActivityPub integration — where app updates flow to Mastodon, Threads, and Bluesky — will become the most compelling non-social-media use case for decentrlized social features, proving definitively that such protocols extends beyond microblogging.&lt;/p&gt;
&lt;p&gt;▶️ Loops will become the third most-used Fediverse software by MAU by end of 2026, trailing only Mastodon and Pixelfed. The short-form video platform will cross 100,000 monthly active users, with Loops-originated content generating significant federated engagement from non-Loops clients — proving that ActivityPub can power video-centric social experiences.&lt;/p&gt;
&lt;p&gt;▶️ PieFed will emerge as the most feature-rich Threadiverse platform by end of 2026, surpassing Lemmy and Mbin in moderation tools, user experience, and federation capabilities. The platform will cross 10,000 monthly active users and its rapid development pace — shipping major features weekly — will make it the default recommendation for anyone starting a new Reddit-style community in the fediverse.&lt;/p&gt;
&lt;p&gt;▶️ More laws akin to Utah’s Digital Choice Act will pass or advance - sparking first steps towards interoperability to mainstream US discourse. The Utah law takes effect July 1, 2026, and several other states will pass similar ones, requiring social media platforms to enable data portability and interoperability. At least one major platform will announce ActivityPub or AT Protocol support to comply. The “Digital Choice” framing will prove more politically viable than “antitrust” for breaking Big Tech’s lock-in.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What did I miss? What did I get wrong? Let me know — and I’ll see you in December 2026 to grade these.&lt;/strong&gt;&lt;/p&gt;

&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.timothychambers.net/2025/12/23/my-open-social-web-predictions.html</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 15:59:23 +0000</pubDate>
    </item>
    <item>
      <title>When Compilers Surprise You</title>
      <link>https://xania.org/202512/24-cunning-clang</link>
      <description>Written by me, proof-read by an LLM. Details at end.</description>
      <content:encoded>&lt;div class="small-12 columns article"&gt;
&lt;h2&gt;When compilers surprise you&lt;/h2&gt;
&lt;p&gt;Written by me, proof-read by an LLM.
&lt;br/&gt;Details at end.&lt;/p&gt;
&lt;p&gt;Every now and then a compiler will surprise me with a really smart trick. When I first saw this optimisation I could hardly believe it. I was looking at loop optimisation, and wrote something like this simple function that sums all the numbers up to a given value:&lt;/p&gt;

&lt;p&gt;So far so decent: GCC has done some preliminary checks, then fallen into a loop that efficiently sums numbers using &lt;code&gt;lea&lt;/code&gt; (we’ve &lt;a href="https://xania.org/202512/02-adding-integers"&gt;seen this before&lt;/a&gt;). But taking a closer look at the loop we see something unusual:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.L3:
  lea edx, [rdx+1+rax*2]        ; result = result + 1 + x*2
  add eax, 2                    ; x += 2
  cmp edi, eax                  ; x != value
  jne .L3                       ; keep looping
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The compiler has cleverly realised it can do two numbers&lt;a href="#fn:check"&gt;1&lt;/a&gt; at a time using the fact it can see we’re going to add &lt;code&gt;x&lt;/code&gt; &lt;em&gt;and&lt;/em&gt; &lt;code&gt;x + 1&lt;/code&gt;, which is the same as adding &lt;code&gt;x*2 + 1&lt;/code&gt;. Very cunning, I think you’ll agree!&lt;/p&gt;
&lt;p&gt;If you turn the optimiser up to &lt;code&gt;-O3&lt;/code&gt; you’ll see the compiler works even harder to vectorise the loop using parallel adds. All very clever.&lt;/p&gt;
&lt;p&gt;This is all for GCC. Let’s see what clang does with our code:&lt;/p&gt;

&lt;p&gt;This is where I nearly fell off my chair: &lt;strong&gt;there is no loop&lt;/strong&gt;! Clang checks for positive &lt;code&gt;value&lt;/code&gt;, and if so it does:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  lea eax, [rdi - 1]        ; eax = value - 1
  lea ecx, [rdi - 2]        ; ecx = value - 2
  imul rcx, rax             ; rcx = (value - 1) * (value - 2)
  shr rcx                   ; rcx &amp;gt;&amp;gt;= 1
  lea eax, [rdi + rcx]      ; eax = value + rcx
  dec eax                   ; --eax
  ret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It was not at all obvious to me what on earth was going on here. By backing out the maths a little, this is equivalent to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;v + ((v - 1)(v - 2) / 2) - 1;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Expanding the parentheses:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;v + (vÂ² - 2v - v + 2) / 2 - 1
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Rearranging a bit:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(vÂ² - 3v + 2) / 2 + (v - 1)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Multiplying the &lt;code&gt;(v - 1)&lt;/code&gt; by 2 / 2:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(vÂ² - 3v + 2) / 2 + (2v - 2)/2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Combining those and cancelling:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(vÂ² - v) / 2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simplifying and factoring gives us &lt;code&gt;v(v - 1) / 2&lt;/code&gt; which is the closed-form solution to the “sum of integers”! Truly amazing&lt;a href="#fn:why"&gt;2&lt;/a&gt; - we’ve gone from an O(n) algorithm as written, to an O(1) one!&lt;/p&gt;
&lt;p&gt;I love that despite working with compilers for more than twenty years, they can still surprise and delight me. The years of experience and work that have been poured into making compilers great is truly humbling, and inspiring.&lt;/p&gt;
&lt;p&gt;We’re nearly at the end of this series - there’s so much more to say but that will have to wait for another time. Tomorrow will be a little different: see you then!&lt;/p&gt;
&lt;p&gt;&lt;em&gt;See &lt;a href="https://youtu.be/V9dy34slaxA"&gt;the video&lt;/a&gt; that accompanies this post.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This post is day 24 of &lt;a href="https://xania.org/AoCO2025"&gt;Advent of Compiler Optimisations 2025&lt;/a&gt;,
a 25-day series exploring how compilers transform our code.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post was written by a human (&lt;a href="https://xania.org/MattGodbolt"&gt;Matt Godbolt&lt;/a&gt;) and reviewed and proof-read by LLMs and humans.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Support Compiler Explorer on &lt;a href="https://patreon.com/c/mattgodbolt"&gt;Patreon&lt;/a&gt;
or &lt;a href="https://github.com/sponsors/compiler-explorer"&gt;GitHub&lt;/a&gt;,
or by buying CE products in the &lt;a href="https://shop.compiler-explorer.com"&gt;Compiler Explorer Shop&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Some of the initial code checks for odd/even and accounts accordingly. &lt;a href="#fnref:check"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Why does the compiler emit this exact sequence and not a slightly more straightforward sequence? I think it’s partly avoiding overflow in cases where it might otherwise overflow &lt;em&gt;and&lt;/em&gt; just a side effect of the way clang tracks and infers &lt;a href="https://xania.org/202512/09-induction-variables"&gt;induction variables&lt;/a&gt;. I really don’t know for sure, though. &lt;a href="#fnref:why"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://xania.org/202512/24-cunning-clang</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 13:27:50 +0000</pubDate>
    </item>
    <item>
      <title>I'm returning my Framework 16</title>
      <link>https://yorickpeterse.com/articles/im-returning-my-framework-16/</link>
      <description>My current laptop is an aging X1 Carbon generation 7, purchased some time in mid
2019. A few months ago a few keys of the keyboard stopped working, specifically
the 5, 6, - , = and Delete keys. Sometimes I can get it working again by
mashing one of them for a while, but it's not consistent. Given my past
experiences with X1 Carbon laptops breaking outside of warranty and the
frustration that comes with replacing their components, I decided it was time to
look for a replacement.</description>
      <content:encoded>&lt;div class="row content"&gt;&lt;p&gt;
My current laptop is an aging X1 Carbon generation 7, purchased some time in mid
2019. A few months ago a few keys of the keyboard stopped working, specifically
the 5, 6, &lt;code&gt;-&lt;/code&gt;, &lt;code&gt;=&lt;/code&gt; and Delete keys. Sometimes I can get it working again by
mashing one of them for a while, but it's not consistent. Given my past
experiences with X1 Carbon laptops breaking outside of warranty and the
frustration that comes with replacing their components, I decided it was time to
look for a replacement.&lt;/p&gt;&lt;p&gt;Unfortunately, buying a new X1 Carbon wasn't going to be an option: when it
comes to displays you now basically have two choices: a subpar not-quite-2K IPS
display, or a 2.5K (ish) OLED display. Since I use my laptop for programming
and often use it in low light conditions such as a living room with dimmed
lights in the evening, OLED just doesn't make sense. Knowing my luck I'd also
run into OLED burn-in the moment the warranty expires. There are also some
other issues with the X1 line in general, such as poor CPU cooling and the
absolute nightmare that is opening them up to replace parts or clean them
properly.&lt;/p&gt;&lt;p&gt;I looked at some other brands but it appears that in 2025 there's just aren't
many good options for Linux users. I narrowed it down to two options:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Buy a refurbished M1 or M2 Macbook and run &lt;a href="https://asahilinux.org/"&gt;Asahi Linux&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Buy a &lt;a href="https://frame.work/nl/en"&gt;Framework&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;I eliminated the use of Asahi Linux because of the following reasons:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;The battery life doesn't appear to be all that better than conventional
laptops when running Linux. This isn't entirely surprising because of a lot
of the battery improvements on macOS are the result of the software and
hardware integration, not &lt;em&gt;just&lt;/em&gt; the hardware&lt;/li&gt;&lt;li&gt;There seem to be issues with suspend not working as well (at least based on
various comments I came across), and hardware support in general is a bit
dodgy&lt;/li&gt;&lt;li&gt;If something needs replacing I basically have an expensive paperweight,
because everything is soldered together, assuming you could even find spare
parts in the first place&lt;/li&gt;&lt;li&gt;I'm not sure Asahi as a project will still be around in 5 years, but my
laptop will be&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;In contrast, Framework laptops has many supposed benefits: they're upgradable,
repairable, actively work on Linux and even FreeBSD support (or at least sponsor
developers working on this), allow you to customize the keyboard using
&lt;a href="https://qmk.fm/"&gt;QMK&lt;/a&gt;/&lt;a href="https://get.vial.today/"&gt;VIAL&lt;/a&gt;. In fact, on paper it
sounds like the perfect developer laptop. In reality, I'm not so sure.&lt;/p&gt;&lt;h2&gt;Table of contents&lt;/h2&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="#configuration"&gt;Configuration&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#building-the-laptop"&gt;Building the laptop&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#operating-system"&gt;Operating system&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#weight"&gt;Weight&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#design"&gt;Design&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#display"&gt;Display&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#power-led"&gt;Power LED&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#gpu"&gt;GPU&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#cpu"&gt;CPU&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#battery"&gt;Battery&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#wifi-and-bluetooth"&gt;WiFi and Bluetooth&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#keyboard"&gt;Keyboard&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#trackpad"&gt;Trackpad&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#speakers"&gt;Speakers&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#modular-ports"&gt;Modular ports&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Configuration&lt;/h2&gt;&lt;p&gt;Framework has three models of laptops: a 12 inch, 13.5 inch and 16 inch laptop.
My X1 Carbon is a 14 inch laptop but I've always felt like I wanted something
just &lt;em&gt;slightly&lt;/em&gt; larger. I ended up buying the Framework 16 for two reason:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;I read various reports of the Framework 13 having issues with poor battery
life, fan noise, heating, etc&lt;/li&gt;&lt;li&gt;While 16 inch is a fair bit larger than 14 inch, I was hoping it would be
manageable size wise&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The base configuration is as follows:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Framework 16 DIY edition&lt;/li&gt;&lt;li&gt;CPU: Ryzen AI 7 350&lt;/li&gt;&lt;li&gt;RAM: 2x8 GiB DDR5-5600&lt;/li&gt;&lt;li&gt;SSD: WD Black SN7100, 500 GiB&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I also bought an additional Intel AX210 WiFi card in case the default Mediatek
card would cause any trouble, as I don't trust brands other than Intel when it
comes to WiFi.&lt;/p&gt;&lt;p&gt;Shipping took about a week or so, with the laptop making quite the journey from
Taiwan to the Philippines to China, then to Japan and then back to China, then
to Istanbul, then to France and at last to The Netherlands. I'm not sure what
happened here, maybe the pilot got drunk or perhaps Fedex' tracking is just
broken.&lt;/p&gt;&lt;h2&gt;Building the laptop&lt;/h2&gt;&lt;p&gt;I bought the DIY edition which requires some manual assembly, though not nearly
as much as I feared. All I had to do was install the SSD, RAM, and the keyboard
spacers. The spacers, touchpad and keyboard use magnetic connectors so
installing and removing them is trivial. To access the SSD and RAM slots you
need to unscrew a plate that sits between these slots and the keyboard, but this
only takes a few minutes using the provided screwdriver.&lt;/p&gt;&lt;p&gt;I didn't measure how long it took me to install it the first time, but opening
it up and putting it back together a second time only took perhaps 5-10 minutes
at most. For comparison, to replace most parts of the X1 Carbon you essentially
have to take the whole thing apart and unscrew countless screws many of which
are hard to find. Unsurprisingly, I've lost some of these screws over the years
and dreaded opening it up the few times I had to.&lt;/p&gt;&lt;p&gt;This is an area where Framework excels compared to all other brands: it's just
&lt;em&gt;so&lt;/em&gt; easy to swap the parts out that it puts other brands to shame when it comes
to hardware maintainability.&lt;/p&gt;&lt;h2&gt;Operating system&lt;/h2&gt;&lt;p&gt;For the operating system I initially gave FreeBSD 15 a quick try. I knew it
wasn't going to be the final OS due to it still having issues with the Framework
hardware (e.g. suspend doesn't work properly), but I figured it was worth a try
just to see what would happen. The installation went fine and WiFi worked fine,
though that was because I swapped the Mediatek card with the Intel AX210 as the
Mediatek card doesn't work at all on FreeBSD. Upon loading the AMD drivers I
encountered a kernel crash, likely due to the same issue as discussed in &lt;a href="https://github.com/freebsd/drm-kmod/issues/391"&gt;this
drm-kmod issue&lt;/a&gt;. A laptop
without working GPU drivers isn't going to work, so at this point I decided to
give up on FreeBSD (&lt;a href="https://yorickpeterse.com/articles/installing-freebsd-15-on-my-desktop/"&gt;again&lt;/a&gt;) and
install Fedora 43 instead.&lt;/p&gt;&lt;p&gt;Fedora 43 worked just fine as expected, and everything worked, so let's take a
look at the hardware.&lt;/p&gt;&lt;h2&gt;Weight&lt;/h2&gt;&lt;p&gt;The Framework 16 weights about 2.2 kg according to my kitchen scale. For
comparison, my X1 Carbon weights 1.3 kg. That may not seem like a big
difference, but the extra kilogram makes carrying around the Framework 16 more
difficult. In particular, I don't feel comfortable carrying it with just one
hand while this isn't a problem with the X1.&lt;/p&gt;&lt;p&gt;The Framework is best described as a bit of a chonker and I certainly don't see
myself carrying it around a lot. This also gives it a bit of an identity crisis:
laptops should be portable, otherwise why not just get a desktop. And yet the
Framework 16 is neither portable nor remotely as powerful as a desktop, so who
exactly is the target audience?&lt;/p&gt;&lt;h2&gt;Design&lt;/h2&gt;&lt;p&gt;The design of the laptop is a bit polarizing. I like the combination of black
and silver, but I &lt;em&gt;hate&lt;/em&gt; how janky it all looks and feels due to the removable
spacers. Note the lines separating the touchpad from the spacers on the left and
right of it:&lt;/p&gt;&lt;p&gt;&lt;img alt="The Framework 16's touchpad and spacers" src="https://yorickpeterse.com/images/framework16/touchpad.jpg?hash=a100501d4c5f037b6e6717d81ff25c29d32fcbadb0c949f61f550a11efe8c06c"/&gt;&lt;/p&gt;&lt;p&gt;Not only does it look weird, you can also feel the gap and edges when resting
your palm on them. The silver spacers and touchpad are also raised slightly
relative to the black keyboard area, and the edges are quite sharp. If you have
arm hairs you may consider shaving them off or risk getting them stuck. I also
suspect gunk will build up in these edges over time.&lt;/p&gt;&lt;p&gt;The spacers aren't held solid in place either, meaning you can move them around
and they have a bit of flex to them:&lt;/p&gt;&lt;p&gt;You may need to turn up your volume to hear the noise the spacers make. Also,
apologies for the vertical video!&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;There's also a practical problem: due to the flex of the spacers if you try to
hold the laptop on its sides it will actually "wobble" a bit. Combined with the
weight I suspect that unless you hold on to this laptop for dear life, you
&lt;em&gt;will&lt;/em&gt; at some point drop it.&lt;/p&gt;&lt;p&gt;These issues could be considered a minor issue in isolation but remember, this
model costs &lt;strong&gt;&lt;em&gt;two thousand Euros&lt;/em&gt;&lt;/strong&gt; (I'll bring this up a few more times). For
a premium price I expect a premium design and build quality, and this isn't it.&lt;/p&gt;&lt;h2&gt;Display&lt;/h2&gt;&lt;p&gt;The display isn't terrible, but it's not great either. Like most laptop displays
that aren't Macbooks there's a bit of flex to the display, though this shouldn't
be much of an issue. The colors of the display are overly saturated, with reds
in particular looking more intense than they should. Here's a silly example of
what a particular shade of red looks like on my X1 Carbon:&lt;/p&gt;&lt;p&gt;&lt;img alt="A shade of red on the X1 Carbon" src="https://yorickpeterse.com/images/framework16/carbon_red.jpg?hash=a40faebdc93ea6347917272e614f846b35de4e510267be054210ce183984aad1"/&gt;&lt;/p&gt;&lt;p&gt;And here's the same color on the Framework 16:&lt;/p&gt;&lt;p&gt;&lt;img alt="A shade of red on the Framework 16" src="https://yorickpeterse.com/images/framework16/framework_red.jpg?hash=d4da87c847078b37dfd5b2de5133ddf9cb952f0c59a10dc4e77430b81aaa0052"/&gt;&lt;/p&gt;&lt;p&gt;Note that both displays were using the same brightness and the same color
temperature/night light setting. For comparison, here's what those colors should
look like when using a properly calibrated (at the hardware level at least) Eizo
CS2740 that I use for my desktop:&lt;/p&gt;&lt;p&gt;&lt;img alt="A shade of red on the Eizo CS2740" src="https://yorickpeterse.com/images/framework16/eizo_red.jpg?hash=93af55b0270fcba91c55bc0250edd818be95fd8680b6cf77d6e7ba69c0028f38"/&gt;&lt;/p&gt;&lt;p&gt;I'm aware the quality of the photos isn't great, but if you compare the
Framework version to the others you'll notice the colors are more saturated
compared to what they should look like.&lt;/p&gt;&lt;p&gt;The white/grey uniformity also leaves a lot to be desired, though this is true
for all modern IPS displays that aren't manufactured by Eizo:&lt;/p&gt;&lt;p&gt;&lt;img alt="The white uniformity of the Framework" src="https://yorickpeterse.com/images/framework16/gradient.jpg?hash=d502870a3e0bbbe1e0303abaf96adcbd1703e989d7fc2a464f778318a363a380"/&gt;&lt;/p&gt;&lt;p&gt;I find non-uniform displays distracting as it can create a sort of tunnel vision
effect/feeling. While the X1 Carbon also suffers from this problem, it feels
less pronounced than in case of the Framework. Of course the Eizo display
doesn't suffer from this problem at all (hence I bought it), but then it again
it costs a ridiculous €1700.&lt;/p&gt;&lt;p&gt;Which brings us to the brightness. This display is bright, even at the lowest
setting. I found various forum posts that mention the Framework 13 suffers from
a similar issue but that you can at least now lower the brightness further on
recent versions of Linux, but this isn't supported for the Framework 16. Here's
what that looks like in practice:&lt;/p&gt;&lt;p&gt;&lt;img alt="The brightness of the Framework 16 part 1" src="https://yorickpeterse.com/images/framework16/brightness1.jpg?hash=4b1fb9f5c698625f4f2a7f8078d0cbc4a28016214d87d6f9c9d8a263c20d0e6d"/&gt;
&lt;img alt="The brightness of the Framework 16 part 2" src="https://yorickpeterse.com/images/framework16/brightness2.jpg?hash=1c7812a9ff0dc3589cbc88db9d0c7091bf409ba7c1a37766c5eeceaa1b62db2f"/&gt;&lt;/p&gt;&lt;p&gt;The Framework 16 is on the left and the X1 Carbon on the right, both set to the
lowest brightness setting that is still usable.&lt;/p&gt;&lt;p&gt;The Framework 16 being so much brighter means that using it in a darker room
(e.g. a living room at night with the lights dimmed) makes you feel like a deer
looking into the headlights of a car that's about to run you over. In other
words, not fun.&lt;/p&gt;&lt;h2&gt;Power LED&lt;/h2&gt;&lt;p&gt;On the topic of brightness, the power button in the top right corner of the
keyboard has an LED that can't be turned off in the BIOS. Instead, you can set
it to a few different settings including "Ultra low", but it doesn't make much
of a difference as even at the lowest setting it's still too bright. This
wouldn't be so bad if it wasn't sitting in the bottom right corner of your eye
when you look at the display.&lt;/p&gt;&lt;p&gt;I ended up using &lt;a href="https://community.frame.work/t/disable-led-indicators-via-systemd/77995"&gt;this systemd
service&lt;/a&gt;
to turn the LED off upon booting, but something as simple as this should just be
a BIOS option. Not being able to turn the LED off is &lt;a href="https://github.com/FrameworkComputer/EmbeddedController/issues/11#issuecomment-2757847513"&gt;apparently a
feature&lt;/a&gt;.&lt;/p&gt;&lt;h2&gt;GPU&lt;/h2&gt;&lt;p&gt;I didn't do any GPU intensive testing such as video decoding. One
annoying issue is that the display has a tendency to flicker. On top of that,
there's a "nice" feature where the GPU reduces the display brightness based on
the contents on the screen to conserve battery. The problem is that it
takes a good two seconds or so to adjust, making it obvious and jarring to look
at. It's especially noticeable when switching to the workspace overview in Gnome
and back, due to a large section of this overview being a dark color.&lt;/p&gt;&lt;p&gt;This feature is disabled by adding &lt;code&gt;amdgpu.abmlevel=0&lt;/code&gt; to &lt;code&gt;GRUB_CMDLINE_LINUX&lt;/code&gt;
in &lt;code&gt;/etc/default/grubg&lt;/code&gt;, followed by running &lt;code&gt;sudo grub2-mkconfig -o
/boot/grub2/grub.cfg&lt;/code&gt; and a reboot. This also seems to reduce the amount of
flickering, though it still happened a few times after applying this setting.&lt;/p&gt;&lt;p&gt;Some additional details on the ambient dimming anti-feature are in &lt;a href="https://community.frame.work/t/screen-dimming-and-brightening-based-on-screen-contents/74013"&gt;this
forum post&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;I can see the value of this feature but only if the GPU waits longer before
adjusting the brightness and increases the transition time so it's less obvious.
In it's current form it's just a nuisance.&lt;/p&gt;&lt;h2&gt;CPU&lt;/h2&gt;&lt;p&gt;The CPU is fine, though I didn't extensively test its performance. It's
certainly better than the mediocre Intel CPU of my X1 Carbon. One thing I
noticed is that the CPU makes a sort of coil whine/crackling BZZZZZZ noise when
under load. This isn't unique to Framework (e.g. my X1 also does this), the more
open design (e.g. there's a big fan grill/mesh at the top of the keyboard) makes
this more noticeable.&lt;/p&gt;&lt;p&gt;I can't speak about the fan noise because I never heard them. This could either
mean they are quiet enough or that I didn't stress the CPU enough.&lt;/p&gt;&lt;h2&gt;Battery&lt;/h2&gt;&lt;p&gt;I didn't do any proper testing of battery usage, but it seems to be on par with
other Linux capable laptops based on my usage thus far. This means you'll likely
be looking at 6-8 hours of battery per charge for average programming usage. It
seems this is the case for basically any reasonable Linux-capable laptop these
days, unfortunately.&lt;/p&gt;&lt;p&gt;I did notice that it drains quite a bit when suspended: when I put it to sleep
the first night the battery was at 47%. When I opened the laptop again some 8
hours later the battery was at 42%. This means you're looking at about 5% of
battery per average night, which isn't great. Hibernate could be an alternative
but support for it on Fedora is a bit dodgy and requires some manual work I'm
not interested in, so I didn't test this.&lt;/p&gt;&lt;h2&gt;WiFi and Bluetooth&lt;/h2&gt;&lt;p&gt;Both the Intel and Mediatek cards work without issue. Both achieve the same
speeds on my 1 Gbps connection over a 5Ghz network (with a channel width of
80mhz): about 800-900 Mbps for uploads and somewhere between 600 and 700 Mbps
for downloads. While not being able to achieve the full 1 Gbps speed over WiFi
is expected, I was a bit surprised to see that uploads are in fact faster than
downloads.&lt;/p&gt;&lt;p&gt;I tested various other devices with similar WiFi hardware and they all upload
and download at about the same speeds, and all operate at slightly lower speeds
(500-600 Mbps, depending on your luck).&lt;/p&gt;&lt;p&gt;I don't think it's the network itself either: the access points are TP-Link
EAP660 HDs that can handle speeds well beyond 1 Gbps. As far as I know the
configuration is also sound (including the use of specific channels to reduce
interference to a minimum).&lt;/p&gt;&lt;p&gt;Still, 600-700 Mbps over WiFi is more than I'll probably ever need so I didn't
dive into this further.&lt;/p&gt;&lt;p&gt;I didn't specifically test Bluetooth but it did detect a few devices, so I'll
assume this will work just fine.&lt;/p&gt;&lt;h2&gt;Keyboard&lt;/h2&gt;&lt;p&gt;Some reviews I read mentioned that the keyboard has a bit of flex to it, but I
didn't notice this. The keycaps are a little mushy, which isn't too bad but not
great either. The difference in key size and spacing compared to the X1 did mean
I pressed the wrong key at times, but I suspect this is just a matter of
adjusting.&lt;/p&gt;&lt;p&gt;The keyboard runs QMK, albeit a rather outdated version of QMK released in 2022.
I experimented with porting the code to a newer version so I could take
advantage of some features that I use in my split keyboard, but couldn't get it
to work. The official way to configure the keyboard is by using &lt;a href="https://keyboard.frame.work/"&gt;this VIAL web
application&lt;/a&gt;. This application requires WebHID
support which isn't implemented by Firefox, requiring me to install and use
Chromium just to configure the keyboard. This isn't enough though, as on Linux
you'll need to install some additional udev rules to get things working. The
official rules provided by QMK didn't work, instead I used the rules from &lt;a href="https://community.frame.work/t/responded-help-configuring-fw16-keyboard-with-via/47176/5"&gt;this
forum reply&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Once set up I was able to configure the keyboard such as by changing the layout
from QWERTY to Colemak-DH. VIAL is pretty basic though and the interface is
rather clunky, so I'm not a fan of this approach. I hope that at some point
Framework will upstream their keyboard logic into the official QMK repository to
make this process easier.&lt;/p&gt;&lt;h2&gt;Trackpad&lt;/h2&gt;&lt;p&gt;The trackpad is decent, though I noticed it's overly sensitive when it comes to
scrolling. For example, on various occasions I lifted my fingers off the
trackpad without any swiping motion and somehow still managed to trigger a
scrolling motion. The trackpad of the X1 Carbon doesn't have this problem and
subsequently is easier and more pleasant to use.&lt;/p&gt;&lt;h2&gt;Speakers&lt;/h2&gt;&lt;p&gt;They're terribly. Or more precisely, they're terrible when the volume is less
than 50% or so. What appears to be happening is that adjusting the volume below
50% doesn't result in it being louder but instead changes how it sounds (for a
lack of a better description). At lower volumes it sounds like sound playing
over a phone in speaker mode, with a sort of tin can/metallic sound to it. Once
you hit 50% or so it starts to sound more like an OK set of speakers but it also
becomes noticeable louder. There's a setting in the BIOS that you can set to
"Linux" mode to supposedly improve the quality but it was already set to this
value.&lt;/p&gt;&lt;p&gt;While most laptop speakers aren't great (even the Dolby Atmos speakers of the X1
Carbon are mediocre), for a laptop that costs &lt;strong&gt;&lt;em&gt;two thousand Euros&lt;/em&gt;&lt;/strong&gt; the sound
is disappointing.&lt;/p&gt;&lt;h2&gt;Modular ports&lt;/h2&gt;&lt;p&gt;An interesting feature of the Framework is that you can swap out the various
ports. You want 6 USB-C ports? You can do that! What about 3 headphone jacks?
Also possible! Replacing them is quite easy, though for some reason my headphone
jack adapter required some additional force to be removed.&lt;/p&gt;&lt;p&gt;Like the keyboard area the design is a bit janky though, with visible
lines/space between the adapters and the case, though this at least is something
you won't notice unless you're explicitly looking for it.&lt;/p&gt;&lt;h2&gt;Conclusion&lt;/h2&gt;&lt;p&gt;Which brings me to the conclusion: is it worth buying this laptop, considering
most configurations will cost you around &lt;strong&gt;&lt;em&gt;two thousand Euros&lt;/em&gt;&lt;/strong&gt;? To be honest,
no, not at all. For a premium price I expect a premium laptop, but the Framework
16 feels more like a €1200-€1500 laptop &lt;em&gt;at best&lt;/em&gt; and certainly doesn't deliver
a premium experience. I understand Framework is a young company still trying to
figure out a lot of things, but &lt;strong&gt;&lt;em&gt;two thousand Euros&lt;/em&gt;&lt;/strong&gt; for this kind of laptop
is just absurd.&lt;/p&gt;&lt;p&gt;For this reason I've submitted a request to return the laptop. What I'll be
replacing my X1 Carbon with instead I'm not entirely sure of. One option is the
Framework 13 given that it solves at least some issues I have with the Framework
16 (e.g. it's bulkiness and inability to lower the brightness further), but it
also seems to share many of the other issues such as poor speaker quality and
(at least from hat I could find) worse heat regulation, and a (possibly) worse
battery.&lt;/p&gt;&lt;p&gt;I've looked at various other brands such as System76 and the many other Clevo
resellers, but they all seem to suffer similar issues such as poor battery life,
poor performance, difficult to maintain hardware wise, or some combination
thereof.&lt;/p&gt;&lt;p&gt;I guess for now the X1 Carbon will have to hold out a little longer, provided I
don't throw it out of the window the next time I can't get the various dodgy
keyboard keys to work.&lt;/p&gt;&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://yorickpeterse.com/articles/im-returning-my-framework-16/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 12:55:19 +0000</pubDate>
    </item>
    <item>
      <title>Avoid Mini-Frameworks</title>
      <link>https://laike9m.com/blog/avoid-mini-frameworks,171/</link>
      <description>I work in Google Ads infrastructure in the past four years. Over time, I've seen one pattern came along again and again, causing endless pain for developers, that is, creating mini-frameworks.</description>
      <content:encoded>&lt;article&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="#what-is-mini-framework"&gt;What is mini-framework?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#my-story"&gt;My Story&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#why-mini-frameworks-are-bad"&gt;Why mini-frameworks are bad?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#so-what-should-you-do-instead"&gt;So, What Should You Do Instead?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I work in Google Ads infrastructure in the past four years. Over time, I've seen one pattern came along again and again, causing endless pain for developers, that is, creating mini-frameworks.&lt;/p&gt;
&lt;h2&gt;What is mini-framework?&lt;/h2&gt;
&lt;p&gt;First, I'd like to give readers a sense of what I mean by "mini-frameworks". Imagine a company that has 1000 engineers, and they share the same tech stack. Over time, a team finds the shared tech stack unsatisfactory, either because they have to write boilerplate code over and over, or the performance is not good enough, or whatever. So they decided to create their own framework on top of the shared stack. You know it's a framework and not just a library, when you hear engineers present the work using concepts they invented, as a way to actualize their mental model. Framework like this is what I called "mini-framework", with some common characteristics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Created by a small number of team(s) to solve their pain points&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Wraps around the company/org-shared tech stack or framework&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Introduce new concepts that doesn't exist in the original stack&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Creators claim that the framework "magically" solves many problems, and push more people to use it&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you work for a big company, most likely you've seen or even done this. But why is it bad? Being a victim myself, I can share my story.&lt;/p&gt;
&lt;h2&gt;My Story&lt;/h2&gt;
&lt;p&gt;Over the years, my team has been using a Google-internal framework to write distributed programs, and are gradually migrating our org's codebase onto it. This framework is well-designed and maintained by a dedicated team. We're generally happy with it, though it has some itchy points (not pain points). Being a strong and ambitious engineer, my manager proposed that we add an abstraction layer on top of it, with the aim to lower the barrier for org adoption, and solve those itchy points on the way. I was skeptical and tried convincing my manager not to do it, but failed. Eventually, several engineers spent quarters to add this abstraction layer, and now the fun begins.&lt;/p&gt;
&lt;p&gt;First, one author tried to adopt it in our existing codebase. People thought it would be easy, but it took like a year. Why? Because during the migration, they found that the abstraction cannot handle certain use cases, so they have to spend time patching it to make it work. In the meantime, other people like me were writing new code using the original framework, this again added new requirements and workload for migration. Eventually, after spending way more time than initially planned, the migration completed, and my manager decided that newly-written code should use our own framework.&lt;/p&gt;
&lt;p&gt;You think this is the end? Of course not!&lt;/p&gt;
&lt;p&gt;Since I started writing code with the new framework, there wasn't a single time that I didn't want to curse and quit the job. The framework is so hard to use, it introduced so many concepts with the intent to hide complexity, but ended up bringing more. Since I'm not the person who writes it, I'm not familiar with all tricks and hacks. As a result, what used to cost me a day to finish can now take two weeks, plus I have to constantly ask the author how to do certain things, and even booked pair-programming sessions. As I heard, other team members were having the same complaints. As for the original goal of driving adoption, ofc it didn't help (if not slower). What's funny is that, this layer is supposed to make people outside of our team write code more easily, but now even our own team are suffering from it. &lt;/p&gt;
&lt;p&gt;Looking back, part of the problem was caused by bad design and implementation, but the fundamental problem lies in creating the mini-framework in the first place. I've observed other mini-frameworks, they all sort of have the same problem, just some worse than the others. So I've come up with a few thoughts to explain why mini-frameworks are bad.&lt;/p&gt;
&lt;h2&gt;Why mini-frameworks are bad?&lt;/h2&gt;
&lt;p&gt;First, &lt;strong&gt;mini-frameworks lacks feature completeness and compatibility&lt;/strong&gt;. People often think that they can magically "hide the unnecessary complexity", but in reality they can't. Even if the mini-framework can deal with 80% use cases well, they often lack the flexibility and features from the original framework to satisfy the rest 20%. DSL (Domain Specific Language) shares the same problem, and that's why people &lt;a href="https://news.ycombinator.com/item?id=37381409"&gt;hate it so much&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Second, &lt;strong&gt;mini-frameworks violates the ETC (Easier To Change) principle&lt;/strong&gt;. I first learned the concept from the legendary book &lt;em&gt;&lt;a href="https://pragprog.com/titles/tpp20/the-pragmatic-programmer-20th-anniversary-edition/"&gt;The Pragmatic Programmer&lt;/a&gt;&lt;/em&gt;, and it still astonishes me that many programmers (even experienced ones) are not aware of it. Put simply, it suggests to write code in a way that allows future modifications be made easily. Creating mini-frameworks violates this principle in two ways:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The mini-framework only models the current use cases to solve certain problems. When requirements change in the future, it often cannot keep up with it.&lt;/li&gt;
&lt;li&gt;Creating mini-framework often requires poking into the implementation details of the original framework, and those details were abstracted away for good reason: they can change at any time. The more implementation details that are relied upon, the harder for the maintaining team to evolve the original framework. &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Third, &lt;strong&gt;mini-frameworks is a realization of the creator's mental model, but it's not everyone's mental model&lt;/strong&gt;. People who tend to create mini-framework are often more opinionated, which is a good thing by itself. But when you create things for others to use, too opinionated can be a bad thing. I would even say that sometimes (not always), creating a mini framework directly reflects the author's ego, and they chose a framework because a tiny library don't recognize the "significance of the work".&lt;/p&gt;
&lt;p&gt;Fourth, &lt;strong&gt;mini-frameworks tend to cause tech stack fragmentation&lt;/strong&gt;. I generated an image to show what I mean: part of the system is migrated, others are not. As new layers kept being added, over time it gets worse. Not sure if other companies are like this, but at Google, I've never actually seen a code migration fully complete, which is kinda hilarious.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://s2.loli.net/2025/12/24/FvjuGLVUtkNB18i.jpg"/&gt;&lt;/p&gt;
&lt;p&gt;Last but also the most concerning: &lt;strong&gt;lack of maintenance&lt;/strong&gt;. Unlike shared infrastructure owned by dedicated teams, mini-frameworks were often owned by those 1 or 2 people who created it. Once they left the team or company, it becomes really hard to find successors — sure other team members may know roughly how things work, but certainly not as deep as the authors. Also, people lack the motivation to maintain existing stuff, because you don't get paid more or promoted doing this. Therefore, mini frameworks often die with the departure of the original authors, unless it has gained major adoption before that, which happens less likely than not.&lt;/p&gt;
&lt;h2&gt;So, What Should You Do Instead?&lt;/h2&gt;
&lt;p&gt;At this point, it's important to clarify what I'm against and what I'm not. I'm certainly not against adding abstractions——because abstractions are essentially, the program itself, we can't live without it. &lt;strong&gt;I'm against adding abstractions in a wrong way, and in the form that's not needed&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Let me bring this up once again since it's really important:
&lt;strong&gt;The real and only difference between a library and a framework, is whether it introduces new concepts&lt;/strong&gt;. The line can be blurry sometimes, but more often you can tell easily. For example, a library can include a set of subclasses or utility functions around the original framework, as they don't introduce new concepts. But if you see a README that starts with a "Glossary" section, you know it's 99.99% chance a framework (people may still refer to them as "libraries", but you get the idea).&lt;/p&gt;
&lt;p&gt;My point is, &lt;strong&gt;we should be really really careful introducing new concepts. If you can, avoid it&lt;/strong&gt;. The cognitive load brought by a bunch of buzz words is heavier than people realized, and especially, what the  framework author can realize. Words are the mirror of someone's thought, same with code. The authors create concepts because it is how they model the problem inside their brain, it is how they think. That's why they claim the concepts are "natural and straightforward", while others are struggling to understand.&lt;/p&gt;
&lt;p&gt;So rule No.1, &lt;strong&gt;avoid creating mini-frameworks, create libraries instead&lt;/strong&gt;. But in the cases where you do find it necessary to create a framework, my suggestions are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Link concepts to concrete business requirements, not something in your head&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Start fresh&lt;/strong&gt;. Don't build a wrapper around the existing framework, build your own from scratch. Yes this would make it a major decision that requires more discussions and resources, but it avoids many of the aforementioned issues. After all, you have good business justification to do this, right.. Right? &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Take it seriously&lt;/strong&gt;. Having seen many disasters caused by mini-frameworks, I can't help thinking if it's because people didn't take it seriously enough. My feeling is that, since people don't really understand the distinction between a library and a framework, both the initiator and reviewers of the decision tend to underthink it: "Oh it's just another abstraction, we do that all the time". As my story shows, it's really not. Creating and adopting a framework, whether mini or not, is always a serious decision, thus should be treated that way. By realizing the seriousness of this matter, I hope we can avoid making rashy decisions to create mini-frameworks that should not exist in the first place.&lt;/li&gt;
&lt;/ul&gt;



&lt;a href="http://disqus.com"&gt;comments powered by Disqus&lt;/a&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://laike9m.com/blog/avoid-mini-frameworks,171/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 12:04:02 +0000</pubDate>
    </item>
    <item>
      <title>The Windows Utility</title>
      <link>https://christitus.com/windows-tool/</link>
      <description>&lt;a href="https://news.ycombinator.com/item?id=46374413"&gt;Comments&lt;/a&gt;</description>
      <guid isPermaLink="false">https://christitus.com/windows-tool/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 10:48:24 +0000</pubDate>
    </item>
    <item>
      <title>Permission Systems for Enterprise That Scale</title>
      <link>https://eliocapella.com/blog/permission-systems-for-enterprise/</link>
      <description>December 12, 2025</description>
      <content:encoded>&lt;div class="blog-content"&gt;


&lt;a href="https://eliocapella.com/"&gt;
&lt;img alt="Go to home page" src="https://eliocapella.com/selfie.jpg"/&gt;
&lt;/a&gt;
&lt;h1&gt;Permission Systems for Enterprise that Scale&lt;/h1&gt;
&lt;p&gt;December 12, 2025&lt;/p&gt;

&lt;p&gt;
            Many startups eventually gravitate towards enterprise customers for
            bigger tickets and long-term contracts. As enterprise customers
            start using your product, they soon demand advanced permission
            systems to manage their different user roles and access levels. A
            naive implementation of permission checks works perfectly fine at
            first, but as they use your platform more and more, the amount of
            data, users, and relationships will put that implementation to the
            test. Soon your biggest paying customer will be threatening to churn
            because your app is just &lt;em&gt;too slow&lt;/em&gt;.
          &lt;/p&gt;
&lt;p&gt;
            To illustrate this problem, I've set up a simple example. Imagine an
            app with folders and files where an admin can see all folders and
            files, but standard users can only see files and folders they've
            created or that have been shared with them.
          &lt;/p&gt;
&lt;h2&gt;The Naive Approach (read-time permission queries)&lt;/h2&gt;
&lt;p&gt;
            Your first intuition will be to query the database on every request
            to calculate the permissions and the data that the user can access.
            First, you check the role of the user: is the user an admin or a
            standard user? If the user is not an admin, then query for all the
            resources the user has created or that have been shared with them.
          &lt;/p&gt;
&lt;p&gt;
            The first part is straightforward: if you are an admin, return all
            resources.
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const user = await sqlQueryOne(`SELECT * FROM users WHERE id = ?`, [
  userId,
]);

// Admin: Fetch all resources
if (user.type === "admin") {
  return await sqlQuery(`SELECT * FROM resources`);
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            For standard users, you need to query for resources created by them.
            If the resource is a folder, you will have access to all of its
            descendants.
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const accessibleResources = [];

const ownedResources = await sqlQuery(
  `SELECT * FROM resources WHERE owner_id = ?`,
  [userId],
);

// For each owned resource, fetch descendants recursively
for (const resource of ownedResources) {
  accessibleResources.push(resource);

  const descendants = await sqlQuery(
    `
    WITH RECURSIVE tree AS (
      SELECT id FROM resources WHERE parent_id = ?
      UNION ALL
      SELECT r.id FROM resources r JOIN tree t ON r.parent_id = t.id
    )
    SELECT r.* FROM resources r JOIN tree t ON r.id = t.id
  `,
    [resource.id],
  );
  accessibleResources.push(...descendants);
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            We can already see recursive queries appearing. As we own more
            resources with deeper nesting, the queries will get slower.
          &lt;/p&gt;
&lt;p&gt;
            Finally, we include all shared resources, their descendants if a
            folder was shared, plus their ancestors to show the full path.
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const sharedResources = await sqlQuery(
  `
  SELECT r.*
  FROM shares s
  JOIN resources r ON s.resource_id = r.id
  WHERE s.user_id = ?
`,
  [userId],
);

// For each shared resource, fetch ancestors and descendants
for (const resource of sharedResources) {
  accessibleResources.push(resource);

  // Query ancestors to show full path
  const ancestors = await sqlQuery(
    `
    WITH RECURSIVE ancestors AS (
      SELECT parent_id FROM resources WHERE id = ?
      UNION ALL
      SELECT r.parent_id FROM resources r JOIN ancestors a ON r.id = a.parent_id
      WHERE r.parent_id IS NOT NULL
    )
    SELECT r.* FROM resources r JOIN ancestors a ON r.id = a.parent_id
  `,
    [resource.id],
  );
  accessibleResources.push(...ancestors);

  // Another query for descendants of each shared resource
  const descendants = await sqlQuery(
    `
    WITH RECURSIVE tree AS (
      SELECT id FROM resources WHERE parent_id = ?
      UNION ALL
      SELECT r.id FROM resources r JOIN tree t ON r.parent_id = t.id
    )
    SELECT r.* FROM resources r JOIN tree t ON r.id = t.id
  `,
    [resource.id],
  );
  accessibleResources.push(...descendants);
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            The code is easy to follow, but the number of queries—especially
            recursive ones with nested folder structures—will quickly become a
            &lt;strong&gt;bottleneck&lt;/strong&gt; as you scale.
          &lt;/p&gt;
&lt;h2&gt;RBAC (write-time permission queries)&lt;/h2&gt;
&lt;p&gt;
            Because we normally develop apps that
            &lt;strong&gt;read more than they write&lt;/strong&gt;, it makes sense to
            optimize for reads. What does this look like? With
            &lt;a href="https://en.wikipedia.org/wiki/Role-based_access_control"&gt;Role Based Access Control&lt;/a&gt;
            we store the pre-computed permissions in the database, linking users
            with resources:
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- RBAC: Pre-computed permissions
-- access_type: 'owner' (full control), 'shared' (read only), 'path_only' (visible but no access)
CREATE TABLE permissions (
  user_id INTEGER NOT NULL,
  resource_id INTEGER NOT NULL,
  access_type TEXT NOT NULL,
  PRIMARY KEY (user_id, resource_id),
  FOREIGN KEY (user_id) REFERENCES users(id),
  FOREIGN KEY (resource_id) REFERENCES resources(id)
);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, when querying for resources, we can simply do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const resources = await sqlQuery(
  `SELECT r.* FROM resources r
   JOIN permissions p ON r.id = p.resource_id
   WHERE p.user_id = ?`,
  [userId],
);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            That's it! No recursive queries, no multiple queries, just a simple
            join. It's as fast as it gets, and easy to index too.
          &lt;/p&gt;
&lt;p&gt;
            Let's see how to maintain the permissions table. On every new
            resource, we need to grant the owner full access:
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;await sqlRun(
  `INSERT OR IGNORE INTO permissions (user_id, resource_id, access_type) VALUES (?, ?, 'owner')`,
  [ownerId, resourceId],
);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            That was easy, but some more complex logic is needed when sharing
            resources:
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Add the shared resource itself with 'shared' access
await sqlRun(
  `INSERT OR IGNORE INTO permissions (user_id, resource_id, access_type) VALUES (?, ?, 'shared')`,
  [userId, resourceId],
);

// Add ancestors for path visibility (path_only - no actual access)
const ancestorIds = await getAncestorIds(resourceId);
for (const ancestorId of ancestorIds) {
  await sqlRun(
    `INSERT OR IGNORE INTO permissions (user_id, resource_id, access_type) VALUES (?, ?, 'path_only')`,
    [userId, ancestorId],
  );
}

// Add all descendants with 'shared' access
const descendantIds = await getDescendantIds(resourceId);
for (const descId of descendantIds) {
  await sqlRun(
    `INSERT OR IGNORE INTO permissions (user_id, resource_id, access_type) VALUES (?, ?, 'shared')`,
    [userId, descId],
  );
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            You can clearly see the trade-off here: we moved the complexity from
            &lt;strong&gt;read-time&lt;/strong&gt; to &lt;strong&gt;write-time&lt;/strong&gt;. Every
            time a resource is created or shared, we need to update the
            permissions table accordingly. We added a point of failure, as the
            permissions table can get out of sync with the actual data.
          &lt;/p&gt;
&lt;h2&gt;Real-world example: PostHog&lt;/h2&gt;
&lt;p&gt;
            Although this is a simple example, while browsing the
            &lt;a href="https://posthog.com/"&gt;PostHog&lt;/a&gt; source
            code I found the exact same approach. They have an
            &lt;a href="https://github.com/PostHog/posthog/blob/master/ee/models/rbac/access_control.py"&gt;&lt;code&gt;AccessControl&lt;/code&gt;&lt;/a&gt;
            model that stores pre-computed permissions:
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# PostHog: ee/models/rbac/access_control.py
class AccessControl(models.Model):
    team = models.ForeignKey("posthog.Team", on_delete=models.CASCADE)
    access_level = models.CharField(max_length=32)  # 'none', 'viewer', 'editor'
    resource = models.CharField(max_length=32)      # 'dashboard', 'feature_flag', etc.
    resource_id = models.CharField(null=True)       # null = all, UUID = specific object

    # Can be scoped to a user or a role
    organization_member = models.ForeignKey(..., null=True)
    role = models.ForeignKey("Role", null=True)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            When listing resources, they simply
            &lt;a href="https://github.com/PostHog/posthog/blob/master/posthog/rbac/user_access_control.py#L700"&gt;filter the queryset&lt;/a&gt;
            based on these pre-computed permissions:
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# PostHog: posthog/rbac/user_access_control.py
def filter_queryset_by_access_level(self, queryset, ...):
    # Get pre-computed access controls from cache
    access_controls = self._get_access_controls(filters)

    # Build sets of allowed/blocked resource IDs
    for access_control in access_controls:
        if access_control.access_level != NO_ACCESS_LEVEL:
            allowed_resource_ids.add(access_control.resource_id)
        else:
            blocked_resource_ids.add(access_control.resource_id)

    # Filter queryset - no recursive queries needed!
    return queryset.filter(id__in=allowed_resource_ids)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            They also cache the access controls during a request to avoid
            repeated database lookups:
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# PostHog: posthog/rbac/user_access_control.py
def _get_access_controls(self, filters):
    key = json.dumps(filters, sort_keys=True)
    if key not in self._cache:
        self._cache[key] = list(AccessControl.objects.filter(...))
    return self._cache[key]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            The pattern is clear: &lt;strong&gt;pre-compute&lt;/strong&gt; permissions at
            write-time, &lt;strong&gt;store&lt;/strong&gt; them in a dedicated table, and
            &lt;strong&gt;filter&lt;/strong&gt; with simple lookups at read-time.
          &lt;/p&gt;
&lt;h2&gt;What about ABAC?&lt;/h2&gt;
&lt;p&gt;
            If you research ways to implement permission systems, you will often
            find
            &lt;a href="https://en.wikipedia.org/wiki/Attribute-based_access_control"&gt;Attribute-Based Access Control&lt;/a&gt;
            as a recommended approach. ABAC is great when you need to make
            complex decisions on whether a user can access a specific resource
            or not. Figma showed how they handle permissions, and this is an
            example of
            &lt;a href="https://www.figma.com/blog/how-we-rolled-out-our-own-permissions-dsl-at-figma/"&gt;ABAC in action.&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
            The main difference from our naive approach is that ABAC offers a
            declarative way of defining the rules and policies behind the
            permission checks. The engine will convert those policies into
            queries and code to execute them at read-time. Here is an example of
            how those rules could look for our example:
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Rule 1: Admins can access everything
allow if {
    input.user.type == "admin"
}

# Rule 2: Owners can access their resources
allow if {
    input.resource.owner_id == input.user.id
}

# Rule 3: Users can access resources shared with them
allow if {
    some share in data.shares
    share.resource_id == input.resource.id
    share.user_id == input.user.id
}

# ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            This approach is very clear and composable. It works great for
            single-resource access checks:
            &lt;em&gt;"can user X access resource Y?"&lt;/em&gt; It struggles when listing
            resources, as we would need to execute the policies for each
            resource and can't directly query the resources table with simple
            filters.
          &lt;/p&gt;
&lt;h2&gt;Optimizing for hierarchical data&lt;/h2&gt;
&lt;p&gt;
            Both approaches still rely on recursive queries to traverse the
            folder hierarchy. In SaaS applications with deeply nested
            structures, these recursive queries can also become a bottleneck.
            There are two common patterns to eliminate them.
          &lt;/p&gt;
&lt;h3&gt;Materialized paths&lt;/h3&gt;
&lt;p&gt;
            A simple alternative is storing the full path as a string column on
            each resource.
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ALTER TABLE resources ADD COLUMN path TEXT;

-- Example paths:
-- /1/           (root folder, id=1)
-- /1/5/         (child of root, id=5)
-- /1/5/12/      (grandchild, id=12)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finding descendants becomes a prefix search.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// All descendants of resource with path '/1/5/'
const descendants = await sqlQuery(
  `SELECT * FROM resources WHERE path LIKE ?`,
  [resource.path + "%"],
);

// All ancestors by parsing the path
const ancestorIds = resource.path.split("/").filter(Boolean);
const ancestors = await sqlQuery(
  `SELECT * FROM resources WHERE id IN (${ancestorIds.join(",")})`,
);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            Materialized paths are easier to implement but can be tricky when
            moving resources between folders, as you need to update the path of
            all descendants. Closure tables handle moves more gracefully.
          &lt;/p&gt;
&lt;h3&gt;Closure tables&lt;/h3&gt;
&lt;p&gt;
            A closure table pre-computes all ancestor-descendant relationships.
            Instead of traversing the tree at query time, you store every
            possible path—another trade-off between read and write times.
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE TABLE resource_closure (
  ancestor_id INTEGER NOT NULL,
  descendant_id INTEGER NOT NULL,
  depth INTEGER NOT NULL,
  PRIMARY KEY (ancestor_id, descendant_id),
  FOREIGN KEY (ancestor_id) REFERENCES resources(id),
  FOREIGN KEY (descendant_id) REFERENCES resources(id)
);

-- /1/           (root folder, id=1)
INSERT INTO resource_closure VALUES (1, 1, 0);

-- /1/5/         (child of root, id=5)
INSERT INTO resource_closure VALUES (5, 5, 0);
INSERT INTO resource_closure VALUES (1, 5, 1);

-- /1/5/12/      (grandchild, id=12)
INSERT INTO resource_closure VALUES (12, 12, 0);
INSERT INTO resource_closure VALUES (5, 12, 1);
INSERT INTO resource_closure VALUES (1, 12, 2);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            With this table, finding all descendants becomes a simple join with
            no recursion.
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// All descendants of a resource (instant lookup)
const descendants = await sqlQuery(
  `SELECT r.* FROM resources r
   JOIN resource_closure c ON r.id = c.descendant_id
   WHERE c.ancestor_id = ? AND c.depth &amp;gt; 0`,
  [resourceId],
);

// All ancestors of a resource (for showing the path)
const ancestors = await sqlQuery(
  `SELECT r.* FROM resources r
   JOIN resource_closure c ON r.id = c.ancestor_id
   WHERE c.descendant_id = ? AND c.depth &amp;gt; 0
   ORDER BY c.depth DESC`,
  [resourceId],
);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;
            The trade-off is write complexity. When creating a resource, you
            must insert closure entries for all ancestors.
          &lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// When creating a new resource under parentId
await sqlRun(
  `INSERT INTO resource_closure (ancestor_id, descendant_id, depth)
   SELECT ancestor_id, ?, depth + 1
   FROM resource_closure
   WHERE descendant_id = ?
   UNION ALL
   SELECT ?, ?, 0`,
  [newResourceId, parentId, newResourceId, newResourceId],
);&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;
            The core trade-off is clear: you can pay the cost at read-time with
            recursive queries, or at write-time by maintaining a permissions
            index. Starting with the naive approach makes sense it's simpler to
            implement and debug.
          &lt;/p&gt;
&lt;p&gt;
            But when your enterprise customers start experiencing slow load
            times, the RBAC approach becomes worth the added complexity. The
            performance difference is significant enough that it can eliminate
            the need for other workarounds like aggressive caching or complex
            pagination.
          &lt;/p&gt;
&lt;p&gt;
            The main risk with pre-computed permissions is data getting
            &lt;strong&gt;out of sync&lt;/strong&gt;. Plan for this by building a rebuild
            script from day one that can recompute all permissions from the
            source of truth. When bugs happen, and they will, you'll be glad you
            have it.
          &lt;/p&gt;

&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://eliocapella.com/blog/permission-systems-for-enterprise/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 09:50:52 +0000</pubDate>
    </item>
    <item>
      <title>US sanctions EU government officials behind the DSA</title>
      <link>https://mastodon.social/@fj/115773761468906515</link>
      <description>Frédéric Jacobs: "The US is sanctioning Thierry Breton and Trusted …" - Mastodon</description>
      <content:encoded>&lt;body class="app-body"&gt;







&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://mastodon.social/@fj/115773761468906515</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 09:43:34 +0000</pubDate>
    </item>
    <item>
      <title>Google 2025 recap: Research breakthroughs of the year</title>
      <link>https://blog.google/technology/ai/2025-research-breakthroughs/</link>
      <description>Dec 23, 2025</description>
      <content:encoded>&lt;article class="uni-article-wrapper"&gt;















&lt;h1&gt;Google's year in review: 8 areas with research breakthroughs in 2025&lt;/h1&gt;








&lt;p&gt;Dec 23, 2025&lt;/p&gt;
·



&lt;a&gt;

Share
&lt;/a&gt;

&lt;a href="https://twitter.com/intent/tweet?text=Google%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025%20%40google&amp;amp;url=https://blog.google/technology/ai/2025-research-breakthroughs/"&gt;

x.com
&lt;/a&gt;
&lt;a href="https://www.facebook.com/sharer/sharer.php?caption=Google%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025&amp;amp;u=https://blog.google/technology/ai/2025-research-breakthroughs/"&gt;

Facebook
&lt;/a&gt;
&lt;a href="https://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https://blog.google/technology/ai/2025-research-breakthroughs/&amp;amp;title=Google%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025"&gt;

LinkedIn
&lt;/a&gt;
&lt;a href="mailto:?subject=Google%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025&amp;amp;body=Check out this article on the Keyword:%0A%0AGoogle%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025%0A%0AThis year saw new AI models, transformative products and new breakthroughs in science and robotics.%0A%0Ahttps://blog.google/technology/ai/2025-research-breakthroughs/"&gt;

Mail
&lt;/a&gt;



Copy link









&lt;p&gt;
          This was a year of AI agents, reasoning and scientific discovery.
        &lt;/p&gt;




&lt;a href="https://blog.google/authors/jeff-dean/"&gt;




&lt;img alt="Jeff Dean" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Jeff_Dean_Photo_1.max-244x184.format-webp.webp"/&gt;



Jeff Dean

      Chief Scientist
    

&lt;/a&gt;
&lt;a href="https://blog.google/authors/demis-hassabis/"&gt;




&lt;img alt="Demis_headshot" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Demis_headshot.max-244x184.format-webp.webp"/&gt;



Demis Hassabis

      CEO, Google DeepMind
    

&lt;/a&gt;
&lt;a href="https://blog.google/authors/james-manyika/"&gt;




&lt;img alt="2024 Headshot for James Manyika" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/2024_Headshot_for_James_Manyika.max-244x184.format-webp.webp"/&gt;



James Manyika

      SVP, Research, Labs, Technology &amp;amp; Society
    

&lt;/a&gt;






      Read AI-generated summary
      



&lt;h2&gt;General summary&lt;/h2&gt;
&lt;p&gt;
&lt;p&gt;In 2025, Google made significant AI research breakthroughs with models like Gemini 3 and Gemma 3. These advancements improved AI's reasoning, multimodality, and efficiency, leading to new products and features across Google's portfolio. Expect more AI-driven innovations in science, computing, and tools for global challenges as Google prioritizes responsible AI development and collaboration.&lt;/p&gt;
&lt;/p&gt;

            Summaries were generated by Google AI. Generative AI is experimental.
          


&lt;h2&gt;Bullet points&lt;/h2&gt;
&lt;p&gt;
&lt;ul&gt;
&lt;li&gt;"Google's year in review: 8 areas with research breakthroughs in 2025" highlights AI advancements and more.&lt;/li&gt;
&lt;li&gt;Gemini 3 models showed big leaps in reasoning, multimodality, efficiency, and creative abilities.&lt;/li&gt;
&lt;li&gt;AI is transforming Google's products, from Pixel 10 to Search, with agentic capabilities.&lt;/li&gt;
&lt;li&gt;AI is boosting science, from genomics and healthcare to math, coding, and quantum computing.&lt;/li&gt;
&lt;li&gt;Google is prioritizing AI safety, collaboration, and addressing global challenges like climate change.&lt;/li&gt;
&lt;/ul&gt;
&lt;/p&gt;

            Summaries were generated by Google AI. Generative AI is experimental.
          


&lt;h2&gt;Basic explainer&lt;/h2&gt;
&lt;p&gt;
&lt;p&gt;Google had a super productive year with AI research. They made their AI models way better at thinking and understanding things. Google also made AI more useful in everyday products and helped people be more creative. Plus, they used AI to make big steps in science and to tackle global problems.&lt;/p&gt;
&lt;/p&gt;

            Summaries were generated by Google AI. Generative AI is experimental.
          


&lt;h4&gt;
          Explore other styles:
        &lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;


                  General summary
                

&lt;/li&gt;
&lt;li&gt;


                  Bullet points
                

&lt;/li&gt;
&lt;li&gt;


                  Basic explainer
                

&lt;/li&gt;
&lt;/ul&gt;










&lt;a&gt;

Share
&lt;/a&gt;

&lt;a href="https://twitter.com/intent/tweet?text=Google%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025%20%40google&amp;amp;url=https://blog.google/technology/ai/2025-research-breakthroughs/"&gt;

x.com
&lt;/a&gt;
&lt;a href="https://www.facebook.com/sharer/sharer.php?caption=Google%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025&amp;amp;u=https://blog.google/technology/ai/2025-research-breakthroughs/"&gt;

Facebook
&lt;/a&gt;
&lt;a href="https://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https://blog.google/technology/ai/2025-research-breakthroughs/&amp;amp;title=Google%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025"&gt;

LinkedIn
&lt;/a&gt;
&lt;a href="mailto:?subject=Google%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025&amp;amp;body=Check out this article on the Keyword:%0A%0AGoogle%27s%20year%20in%20review%3A%208%20areas%20with%20research%20breakthroughs%20in%202025%0A%0AThis year saw new AI models, transformative products and new breakthroughs in science and robotics.%0A%0Ahttps://blog.google/technology/ai/2025-research-breakthroughs/"&gt;

Mail
&lt;/a&gt;



Copy link
















&lt;img alt='The image depicts a visual collage or mosaic of multiple different images, with one image in the center that is black and displays the text "Gemini 3".' src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/end-of-year-blog_header_light_209.width-200.format-webp.webp"/&gt;

















&lt;p&gt;Your browser does not support the audio element.&lt;/p&gt;








          Listen to article
          
This content is generated by Google AI. Generative AI is experimental



[[duration]] minutes





















Voice









Speed









Voice



Speed
0.75X
1X
1.5X
2X






&lt;!--article text--&gt;


&lt;p&gt;2025 has been a year of extraordinary progress in research. With artificial intelligence, we can see its trajectory shifting from a tool to a utility: from something people use to something they can put to work. If 2024 was about laying the multimodal foundations for this era, 2025 was the year AI began to really think, act and explore the world alongside us. With quantum computing, we made progress towards real-world applications. And across the board, we helped turn research into reality, with more capable and useful products and tools making a positive impact on people's lives today.&lt;/p&gt;&lt;p&gt;Here’s a look back at some of the breakthroughs, products and scientific milestones that defined the work of Google, Google DeepMind and Google Research in a year of relentless progress.&lt;/p&gt;





&lt;h2&gt;Delivering breakthroughs on world-class models&lt;/h2&gt;&lt;p&gt;This year, we significantly advanced our model capabilities with breakthroughs on reasoning, multimodal understanding, model efficiency, and generative capabilities, beginning with the release of Gemini 2.5 in March and culminating in the November launch of Gemini 3 and the December launch of Gemini 3 Flash.&lt;/p&gt;&lt;p&gt;Built on a foundation of state-of-the-art reasoning, Gemini 3 Pro is our most powerful model to date, designed to help you bring any idea to life. It topped the LMArena Leaderboard and redefined multimodal reasoning with breakthrough scores on benchmarks like Humanity’s Last Exam — a fiendishly hard test for AI models to see if AI can truly think and reason like humans — and GPQA Diamond. It also set a new standard for frontier models in mathematics, achieving a new state-of-the-art of 23.4% on MathArena Apex. We followed shortly with Gemini 3 Flash, which combines Gemini 3's Pro-grade reasoning with Flash-level latency, efficiency and cost, making it the most performant model for its size. Gemini 3 Flash's quality surpasses our previous Gemini 2.5 Pro-scale model's capabilities at a fraction of the price and substantially better latency, continuing our Gemini-era trend of 'the next generation's Flash model is better than the previous generation's Pro model'.&lt;/p&gt;&lt;p&gt;Learn more about our progress on our world-class AI models this year:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/products/gemini/gemini-3-flash/"&gt;Gemini 3 Flash: frontier intelligence built for speed&lt;/a&gt; (Dec 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;A new era of intelligence with Gemini 3&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/nano-banana-pro/"&gt;Introducing Nano Banana Pro&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://developers.googleblog.com/introducing-veo-3-1-and-new-creative-capabilities-in-the-gemini-api/"&gt;Introducing Veo 3.1 and new creative capabilities in the Gemini API&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/"&gt;Gemini 2.5: Our most intelligent AI model&lt;/a&gt; (March 2025)&lt;/li&gt;&lt;/ul&gt;





&lt;p&gt;Gemini 3 Flash price &amp;amp; benchmark table. &lt;/p&gt;


&lt;img alt="Gemini benchmarks table" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/gemini-3-flash_final_benchmark-table_light_25-12-17_final.gif"/&gt;




&lt;p&gt;We’re committed to making useful AI technology accessible, with state-of-the-art open models. We built our Gemma family of models to be lightweight and open for public use; this year we were able to introduce multimodal capabilities, significantly increase the context window, expand multilingual capabilities, and improve efficiency and performance.&lt;/p&gt;&lt;p&gt;Learn more about this year’s advances in Gemma models:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/developers/gemma-3/"&gt;Introducing Gemma 3: The most capable model you can run on a single GPU or TPU&lt;/a&gt; (March 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://developers.googleblog.com/en/introducing-gemma-3-270m/"&gt;Introducing Gemma 3 270M: The compact model for hyper-efficient AI&lt;/a&gt; (Aug 2025)&lt;/li&gt;&lt;/ul&gt;





&lt;h2&gt;Innovating and transforming our products with AI&lt;/h2&gt;&lt;p&gt;Throughout 2025, we continued to advance the trajectory of AI from tool to utility, transforming our portfolio of products with new, powerful agentic capabilities. We reimagined software development by moving beyond tools that assist coding to introducing powerful, agentic systems that collaborate with developers. Key advances, such as the impressive coding capabilities in Gemini 3 and the launch of &lt;a href="https://antigravity.google/"&gt;Google Antigravity&lt;/a&gt;, mark a new era in AI-assisted software development.&lt;/p&gt;&lt;p&gt;Learn more about this year’s advances building developer tools:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/developers/gemini-3-developers/"&gt;Start building with Gemini 3&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://antigravity.google/blog/introducing-google-antigravity"&gt;Introducing Google Antigravity, a New Era in AI-Assisted Software Development&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;/ul&gt;







&lt;p&gt;This evolution was also clear across our core products, from AI-enabled features on the Pixel 10 and updates to AI Mode in Search, to AI-first innovations like the Gemini app and NotebookLM, which gained advanced features like Deep Research.&lt;/p&gt;&lt;p&gt;Learn more about how we’ve transformed our products with AI:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/products/pixel/google-pixel-10-ai-features-updates/"&gt;9 ways AI makes Pixel 10 our most helpful phone yet&lt;/a&gt; (Aug 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/products/search/ai-mode-search/"&gt;Expanding AI Overviews and introducing AI Mode&lt;/a&gt; (March 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/products/gemini/gemini-3-gemini-app/"&gt;Gemini 3 brings upgraded smarts and new capabilities to the Gemini app&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/google-labs/notebooklm-deep-research-file-types/"&gt;NotebookLM adds Deep Research and support for more source types&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;/ul&gt;





&lt;h2&gt;Empowering creativity and co-creating with AI&lt;/h2&gt;&lt;p&gt;2025 was a transformative year for generative media, giving people new and unprecedented capabilities to realize their creative ambitions. Generative media models and tools for video, images, audio and worlds became more effective and broadly used, with breakouts Nano Banana and Nano Banana Pro offering unprecedented capabilities for native image generation and editing. We worked with people in creative industries to develop tools like Flow and Music AI Sandbox, making them more helpful for creative workflows, and we expanded creative possibilities for people with new, AI-powered experiences in the Google Arts &amp;amp; Culture lab, major upgrades to image editing within the Gemini app, and the introduction of powerful new generative media models like Veo 3.1, Imagen 4 and Flow.&lt;/p&gt;&lt;p&gt;Learn more about how we’re building AI to enhance creativity:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/outreach-initiatives/arts-culture/ai-cultural-learning/"&gt;Art, science, travel: 3 new AI-powered experiences this holiday season&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/veo-updates-flow/"&gt;Introducing Veo 3.1 and advanced capabilities in Flow&lt;/a&gt; (Oct 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/products/gemini/updated-image-editing-model/"&gt;Nano Banana: Image editing in Gemini just got a major upgrade&lt;/a&gt; (Aug 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/generative-media-models-io-2025/"&gt;Veo 3, Imagen 4, and Flow: Fuel your creativity with new generative media models and tools&lt;/a&gt; (May 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/music-ai-sandbox-now-with-new-features-and-broader-access/"&gt;Music AI Sandbox, now with new features and broader access&lt;/a&gt; (April 2025)&lt;/li&gt;&lt;/ul&gt;







&lt;p&gt;As research breakthroughs continue to expand AI’s capabilities, Google Labs is where we share AI experiments as we develop them – hearing from users and evolving as we learn. Some of this year’s most engaging experiments from Labs: Pomelli, an AI experiment for on-brand marketing content; Stitch, which introduced a way to turn prompt and image inputs into complex UI designs and frontend code in minutes; Jules, an asynchronous coding agent that acts as a collaborative partner for developers; and Google Beam, a 3D video communications platform that used AI to advance the possibilities of remote presence.&lt;/p&gt;&lt;p&gt;Learn more about how we’re experimenting in Labs:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/google-labs/pomelli/"&gt;Create on-brand marketing content for your business with Pomelli&lt;/a&gt; (Oct 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/research/project-starline-google-beam-update/"&gt;Google Beam: Our AI-first 3D video communication platform&lt;/a&gt; (May 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://developers.googleblog.com/stitch-a-new-way-to-design-uis/"&gt;From idea to app: Introducing Stitch, a new way to design UIs&lt;/a&gt; (May 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/google-labs/jules/"&gt;Build with Jules, your asynchronous coding agent&lt;/a&gt; (May 2025)&lt;/li&gt;&lt;/ul&gt;





&lt;h2&gt;Advancing science and mathematics&lt;/h2&gt;&lt;p&gt;2025 was also a banner year for scientific advances with AI, marked by breakthroughs in life sciences, health, natural sciences, and mathematics.&lt;/p&gt;&lt;p&gt;In the space of a year, we made progress in building AI resources and tools that empower researchers and help them understand, identify, and develop treatments in healthcare. In genomics, where we’ve been applying advanced technology to research for 10 years, we moved beyond sequencing, using AI to interpret the most complex data. We also marked the 5-year anniversary of AlphaFold, the Nobel-winning AI system that solved the 50-year-old protein folding problem. AlphaFold has been used by over 3 million researchers in more than 190 countries, including over 1 million users in low- and middle-income countries.&lt;/p&gt;&lt;p&gt;Learn more about how we’re using AI to advance life sciences and health:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/alphafold-five-years-of-impact/"&gt;AlphaFold: Five years of impact&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://research.google/blog/using-ai-to-identify-genetic-variants-in-tumors-with-deepsomatic/"&gt;Using AI to identify genetic variants in tumors with DeepSomatic&lt;/a&gt; (Oct 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://research.google/blog/ai-as-a-research-partner-advancing-theoretical-computer-science-with-alphaevolve/"&gt;AI as a research partner: Advancing theoretical computer science with AlphaEvolve&lt;/a&gt; (Sept 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/alphagenome-ai-for-better-understanding-the-genome/"&gt;AlphaGenome: AI for better understanding the genome&lt;/a&gt; (June 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://research.google/blog/accelerating-scientific-breakthroughs-with-an-ai-co-scientist/"&gt;Accelerating scientific breakthroughs with an AI co-scientist&lt;/a&gt; (Feb 2025)&lt;/li&gt;&lt;/ul&gt;







&lt;p&gt;Gemini’s advanced thinking capabilities, including Deep Think, also enabled historic progress in mathematics and coding. Deep Think was able to solve problems that require deep abstract reasoning – achieving gold medal-standard in two international contests.&lt;/p&gt;&lt;p&gt;Learn more about how we’re advancing natural sciences and mathematics:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/gemini-achieves-gold-medal-level-at-the-international-collegiate-programming-contest-world-finals/"&gt;Gemini achieves gold-medal level at the International Collegiate Programming Contest World Finals&lt;/a&gt; (Sept 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/"&gt;Advanced version of Gemini with Deep Think officially achieves gold-medal standard at the International Mathematical Olympiad&lt;/a&gt; (July 2025)&lt;/li&gt;&lt;/ul&gt;





&lt;h2&gt;Shaping innovations in computing and the physical world&lt;/h2&gt;&lt;p&gt;We’re also leading major discoveries and shaping the future of science in areas like quantum computing, energy and moonshots. Research in this area drew new levels of public attention, with progress towards real-world applications of quantum computing as demonstrated by Quantum Echoes and, notably, Googler Michel Devoret becoming a 2025 Physics Nobel Laureate along with former Googler John Martinis and UC Berkeley’s John Clarke, for their foundational 1980s quantum research.&lt;/p&gt;&lt;p&gt;Learn more about our work on space infrastructure and quantum computing:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://research.google/blog/exploring-a-space-based-scalable-ai-infrastructure-system-design/"&gt;Project Suncatcher: Exploring a space-based, scalable AI infrastructure system design&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/inside-google/company-announcements/googler-michel-devoret-awarded-the-nobel-prize-in-physics/"&gt;Googler Michel Devoret awarded the Nobel Prize in Physics&lt;/a&gt; (Oct 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/research/quantum-echoes-willow-verifiable-quantum-advantage/"&gt;Our Quantum Echoes algorithm is a big step toward real-world applications for quantum computing&lt;/a&gt; (Oct 2025)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;In 2025, we continued to advance the core infrastructure that powers our AI, focusing on breakthroughs in hardware design and improving energy efficiency. This included the introduction of Ironwood, a new TPU built for the age of inference, which was designed using a method called &lt;a href="https://deepmind.google/blog/how-alphachip-transformed-computer-chip-design/"&gt;AlphaChip&lt;/a&gt;, alongside a commitment to measuring the environmental impact of our technology.&lt;/p&gt;&lt;p&gt;Learn more about how we’re using AI to develop chips, infrastructure and improve energy efficiency:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/products/google-cloud/ironwood-google-tpu-things-to-know/"&gt;3 things to know about Ironwood, our latest TPU&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://cloud.google.com/blog/products/infrastructure/measuring-the-environmental-impact-of-ai-inference"&gt;How much energy does Google’s AI use? We did the math&lt;/a&gt; (Aug 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/products/google-cloud/ironwood-tpu-age-of-inference/"&gt;Ironwood: The first Google TPU for the age of inference&lt;/a&gt; (April 2025)&lt;/li&gt;&lt;/ul&gt;





&lt;img alt="Ironwood Superpod" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Ironwood_superpod.width-100.format-webp.webp"/&gt;




&lt;p&gt;Our work in robotics and visual understanding brought AI agents into both the physical and virtual worlds, with advancements like the foundational Gemini Robotics models, the more sophisticated Gemini Robotics 1.5, and the introduction of Genie 3 as a new frontier for general-purpose world models.&lt;/p&gt;&lt;p&gt;Learn more about our work with world models and robotics:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/gemini-robotics-15-brings-ai-agents-into-the-physical-world/"&gt;Gemini Robotics 1.5 brings AI agents into the physical world&lt;/a&gt; (Sept 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/"&gt;Genie 3: A new frontier for world models&lt;/a&gt; (Aug 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/"&gt;Gemini Robotics brings AI into the physical world&lt;/a&gt; (March 2025)&lt;/li&gt;&lt;/ul&gt;








&lt;h2&gt;Tackling global challenges and opportunities at scale&lt;/h2&gt;&lt;p&gt;Our work throughout 2025 demonstrates how AI-enabled scientific progress is being directly applied to address the world's most critical and pervasive challenges. By leveraging state-of-the-art foundational models and agentic reasoning, we are significantly increasing our understanding of the planet and its systems, while also delivering impactful solutions in areas vital to human flourishing, including climate resilience, public health and education.&lt;/p&gt;&lt;p&gt;For example, we are using state-of-the-art foundational models and agentic reasoning to help increase our understanding of the planet, helping enable work that is making a difference in people’s lives now from weather predictions to urban planning to public health. For example, our flood forecasting information now covers more than two billion people in 150 countries for severe riverine floods. And our most advanced and efficient forecasting model, &lt;a href="https://blog.google/technology/google-deepmind/weathernext-2/"&gt;WeatherNext 2&lt;/a&gt; can generate forecasts 8x faster and with resolution up to 1-hour. Using this technology, we’ve supported weather agencies in making decisions based on a range of scenarios through our experimental cyclone predictions.&lt;/p&gt;&lt;p&gt;Learn more about our work in weather, mapping and wildfires:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/google-deepmind/weathernext-2/"&gt;WeatherNext 2: Our most advanced weather forecasting model&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/research/new-updates-and-more-access-to-google-earth-ai/"&gt;New updates and more access to Google Earth AI&lt;/a&gt; (Oct 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/google-earth-ai/"&gt;Google Earth AI: Our state-of-the-art geospatial AI models&lt;/a&gt; (July 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/alphaearth-foundations-helps-map-our-planet-in-unprecedented-detail/"&gt;AlphaEarth Foundations helps map our planet in unprecedented detail&lt;/a&gt; (July 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/how-were-supporting-better-tropical-cyclone-prediction-with-ai/"&gt;How we're supporting better tropical cyclone prediction with AI&lt;/a&gt; (June 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/inside-firesat-launch-muon-space/"&gt;Inside the launch of FireSat, a system to find wildfires earlier&lt;/a&gt; (March 2025)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We are working with partners to apply AI-enabled scientific progress closer to patients, opening up new avenues for disease management and therapeutic discovery.&lt;/p&gt;&lt;p&gt;Learn more about our health-related work:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/google-gemma-ai-cancer-therapy-discovery/"&gt;Cell2Sentence-Scale 27B:&lt;/a&gt; &lt;a href="https://blog.google/technology/ai/google-gemma-ai-cancer-therapy-discovery/"&gt;How a Gemma model helped discover a new potential cancer therapy pathway&lt;/a&gt; (Oct 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://research.google/blog/from-diagnosis-to-treatment-advancing-amie-for-longitudinal-disease-management/"&gt;From diagnosis to treatment: Advancing AMIE for longitudinal disease management&lt;/a&gt; (March 2025)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;AI is proving to be a powerful tool in education, enabling new forms of understanding and expanding curiosity through initiatives like LearnLM and Guided Learning in Gemini. We brought Gemini’s most powerful translation capabilities to Google Translate, enabling much smarter, more natural and accurate translations and piloting new speech to speech translation capabilities.&lt;/p&gt;&lt;p&gt;Learn more about how we’re using AI to enable learning:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/products/search/gemini-capabilities-translation-upgrades/"&gt;Bringing state-of-the-art Gemini translation capabilities to Google Translate&lt;/a&gt; (Dec 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/outreach-initiatives/education/guided-learning/"&gt;Guided Learning in Gemini: From answers to understanding&lt;/a&gt; (Aug 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/outreach-initiatives/education/google-learnlm-gemini-generative-ai/"&gt;How generative AI expands curiosity and understanding with LearnLM&lt;/a&gt; (May 2025)&lt;/li&gt;&lt;/ul&gt;








&lt;h2&gt;Prioritizing responsibility and safety&lt;/h2&gt;&lt;p&gt;We couple our research breakthroughs with rigorous and forward-looking work on responsibility and safety. As our models grow more capable, we’re continuing to advance and evolve our tools, resources and safety frameworks to anticipate and mitigate risk. Gemini 3 demonstrated this approach in action: it's our most secure model yet, and has undergone the most comprehensive set of safety evaluations of any Google AI model to date. And we’re looking further ahead, exploring a responsible path to AGI, prioritizing readiness, proactive risk assessment, and collaboration with the wider AI community.&lt;/p&gt;&lt;p&gt;Learn more about our responsibility and safety work:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/verify-google-ai-videos-gemini-app/"&gt;You can now verify Google AI-generated videos in the Gemini app&lt;/a&gt; (Dec 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/ai-image-verification-gemini-app/"&gt;How we’re bringing AI image verification to the Gemini app&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/strengthening-our-frontier-safety-framework/"&gt;Strengthening our Frontier Safety Framework&lt;/a&gt; (September 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/taking-a-responsible-path-to-agi/"&gt;Taking a responsible path to AGI&lt;/a&gt; (April 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/"&gt;Evaluating potential cybersecurity threats of advanced AI&lt;/a&gt; (April 2025)&lt;/li&gt;&lt;/ul&gt;





&lt;h2&gt;Leading frontier collaborations with industry, academia and civil society&lt;/h2&gt;&lt;p&gt;Advancing the frontier of AI responsibly demands collaboration across all parts of society. In 2025, we worked with leading AI labs to help to form the Agentic AI Foundation and support open standards to ensure a responsible and interoperable future for agentic AI. In education, we’ve partnered with school districts like Miami Dade County and education groups like Raspberry Pi to equip students with AI skills. Our research partnerships with universities like UC Berkeley, Yale, the University of Chicago and many more have been instrumental to some of this year’s most exciting frontier research, and we’re working with the US Department of Energy’s 17 national laboratories to transform how scientific research is conducted. And we’re working with filmmakers and other creative visionaries to put the best AI tools in their hands and explore storytelling in the age of AI.&lt;/p&gt;&lt;p&gt;Learn more about our work on frontier collaboration:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://deepmind.google/blog/google-deepmind-supports-us-department-of-energy-on-genesis/"&gt;Google DeepMind supports U.S. Department of Energy on Genesis: a national mission to accelerate innovation and scientific discovery&lt;/a&gt; (Dec 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.linuxfoundation.org/press/linux-foundation-announces-the-formation-of-the-agentic-ai-foundation"&gt;Formation of the Agentic AI Foundation (AAIF), Anchored by New Project Contributions Including Model Context Protocol (MCP), goose and AGENTS.md&lt;/a&gt; (Dec 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://cloud.google.com/blog/products/ai-machine-learning/announcing-official-mcp-support-for-google-services"&gt;Announcing Model Context Protocol (MCP) support for Google services&lt;/a&gt; (Dec 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/outreach-initiatives/education/ai-learning-commitments/"&gt;Our latest commitments in AI and learning&lt;/a&gt; (Nov 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/outreach-initiatives/education/google-ai-education-workforce-skills/"&gt;Partnering to power Miami’s AI-ready future&lt;/a&gt; (Oct 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/sweetwater-film/"&gt;AI on Screen premiere: “Sweetwater” short film explores new AI narratives&lt;/a&gt; (Sept 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/google-deepmind/ancestra-behind-the-scenes/"&gt;Behind “ANCESTRA”: combining Veo with live-action filmmaking&lt;/a&gt; (Jun 2025)&lt;/li&gt;&lt;li&gt;&lt;a href="https://blog.google/technology/ai/lab-session-shankar-mahadevan/"&gt;How Indian music legend Shankar Mahadevan experiments with Music AI Sandbox&lt;/a&gt; (April 2025)&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Looking ahead&lt;/h2&gt;&lt;p&gt;As we look towards 2026, we’re looking forward to continuing to advance the frontier, safely and responsibly, for the benefit of humanity.&lt;/p&gt;









&lt;img alt="EOY Collection_ss" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/EOY_Collection_ss.width-600.format-webp.webp"/&gt;






POSTED IN:






&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://blog.google/technology/ai/2025-research-breakthroughs/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 09:30:58 +0000</pubDate>
    </item>
    <item>
      <title>The e-scooter isn't new – London was zooming around on Autopeds a century ago</title>
      <link>https://www.ianvisits.co.uk/articles/the-e-scooter-isnt-new-london-was-zooming-around-on-autopeds-a-century-ago-86263/</link>
      <description>Published on 24th December 2025 by Ian Mansfield in History</description>
      <content:encoded>&lt;article class="post-86263 post type-post status-publish format-standard has-post-thumbnail hentry category-history tag-cycle-hire" id="post-86263" itemscope="" itemtype="https://schema.org/CreativeWork"&gt;

&lt;h1&gt;The e-scooter isn’t new – London was zooming around on Autopeds a century ago&lt;/h1&gt;

&lt;p&gt;Published on 24th December 2025 by &lt;a href="https://www.ianvisits.co.uk/articles/about-ian-mansfield/"&gt;Ian Mansfield&lt;/a&gt; in &lt;a href="https://www.ianvisits.co.uk/articles/category/history/"&gt;History&lt;/a&gt;&lt;/p&gt;
&lt;!-- end of .post-meta --&gt;

&lt;p&gt;The e-scooters that clutter up pavements may seem like a new thing, but a hundred years ago, there were already people zooming around London on powered scooters.&lt;/p&gt;
&lt;a href="https://8400e186.delivery.rocketcdn.me/articles/wp-content/uploads/sites/2/2025/12/Lady-Florence-Norman-autoped-backgroundexpandedusingai-01.jpg"&gt;&lt;img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20605%20370'%3E%3C/svg%3E"/&gt;&lt;/a&gt;Lady Florence Norman 1916 (street background expanded)
&lt;p&gt;These were the Autoped, an American import that was once popular enough to regularly appear in the newspapers before vanishing seemingly without a trace.&lt;/p&gt;
&lt;p&gt;Invented in the USA in 1915, they first appeared in London in &lt;a href="https://assets.newatlas.com/dims4/default/974930c/2147483647/strip/true/crop/1496x1080+0+0/resize/1330x960!/quality/90/?url=http%3A%2F%2Fnewatlas-brightspot.s3.amazonaws.com%2Farchive%2Fautoped-1916-motor-scooter-10.jpg"&gt;1917&lt;/a&gt;, despite a ban on imports during WWI, and really took off when the import ban was lifted in 1919.&lt;/p&gt;
&lt;p&gt;By today’s standards, they look like a bargain, selling for just £36, although that’s actually about £1,600 in today’s money, so they were really aimed at the wealthy buyers.&lt;/p&gt;
&lt;a href="https://8400e186.delivery.rocketcdn.me/articles/wp-content/uploads/sites/2/2025/12/autoped-01.jpg"&gt;&lt;img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABAAAAAI5AQAAAAAXw3VxAAAAAnRSTlMAAHaTzTgAAABeSURBVHja7cExAQAAAMKg9U9tDB+gAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADOBh7IAAEKt2IDAAAAAElFTkSuQmCC"/&gt;&lt;/a&gt;Clarion: Friday 28 November 1919 / Source: British Newspaper Archive
&lt;p&gt;Gamage’s, the people’s emporium, described them as being made for everybody who feels the necessity of making the most of time, of conserving health and energy, and keeping travelling expenses down to the minimum.&lt;/p&gt;
&lt;p&gt;It was &lt;a href="https://www-britishnewspaperarchive-co-uk.lonlib.idm.oclc.org/viewer/bl/0005980/19170203/537/0037"&gt;said&lt;/a&gt; to be able to reach speeds of 10mph, and unlike modern versions, the Autoped was powered by petrol.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(There was apparently an electric version by Eveready, but it might have been only in the USA)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For comfort over rough roads, they were fitted with 15-inch-diameter pneumatic tyres. The Lady magazine &lt;a href="https://www-britishnewspaperarchive-co-uk.lonlib.idm.oclc.org/viewer/bl/0005980/19161111/431/0042"&gt;suggested&lt;/a&gt; the Autoped would make for a more suitable alternative to the motorbike.&lt;/p&gt;
&lt;p&gt;They even played a key role in a silent movie, &lt;a href="https://www.imdb.com/title/tt0335914/"&gt;At Sword’s Point&lt;/a&gt;, about an annoying man who refuses to say no when rebuffed by a lady and, when trying to escape the relatives, steals an Autoped but collides with his pursuer, also on an Autoped. An “explosion followed, and they both disappeared”.&lt;/p&gt;
&lt;p&gt;Wait, what?&lt;/p&gt;
&lt;p&gt;His Majesty’s government wasn’t going to be left behind either, and there was a &lt;a href="https://www-britishnewspaperarchive-co-uk.lonlib.idm.oclc.org/viewer/bl/0000098/19170928/029/0003"&gt;report&lt;/a&gt; in the Pall Mall Gazette of a “distinguished looking autopedist, gracefully erect” sweeping down Whitehall delivering parcels to 10 Downing Street.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;American Miss Shirley Kellogg brings new motor scooter invention to England. &lt;/p&gt;
&lt;p&gt;However, by 1922, the adverts aren’t by Gammages, but by owners selling them off cheaply in the classified ads. Several noted that the owners were switching to a car instead.&lt;/p&gt;
&lt;p&gt;It seems that the British weather might have killed off the Autoped.&lt;/p&gt;
&lt;p&gt;But finally, to that famous image of a lady on an Autoped – it’s of Lady Florence Priscilla Norman, a noted suffragist and was given the Autoped by her husband, the Liberal MP, Henry Norman.&lt;/p&gt;
&lt;a href="https://8400e186.delivery.rocketcdn.me/articles/wp-content/uploads/sites/2/2025/12/Lady-Florence-Norman-autoped-backgroundexpandedusingai-01.jpg"&gt;&lt;img src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20605%20370'%3E%3C/svg%3E"/&gt;&lt;/a&gt;Lady Florence Norman 1916 (street background expanded)
&lt;p&gt;Just think, had the Autoped lingered on for a few more years and become more affordable as manufacturing increased, how different the streets of our cities could have been.&lt;/p&gt;
&lt;!-- .entry-content --&gt;
&lt;!-- end of .post-entry --&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.ianvisits.co.uk/articles/the-e-scooter-isnt-new-london-was-zooming-around-on-autopeds-a-century-ago-86263/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 08:32:27 +0000</pubDate>
    </item>
    <item>
      <title>Custom Cross Compiler with Nix</title>
      <link>https://www.hobson.space/posts/nixcross/</link>
      <description>This post is about trying to do something seemingly simple. You have an unusual
system that you want to write code for. You even have a cross compiler! But
how can you get this working with nix? Although the answer turned out to be
simple, the journey to getting there was super long and undocumented. I hope
this post saves you a lot of time!</description>
      <content:encoded>&lt;article&gt;


&lt;p&gt;This post is about trying to do something seemingly simple. You have an unusual
system that you want to write code for. You even have a cross compiler! But
how can you get this working with nix? Although the answer turned out to be
simple, the journey to getting there was super long and undocumented. I hope
this post saves you a lot of time!&lt;/p&gt;
&lt;h2&gt;
  My Motivations
  &lt;a href="#my-motivations"&gt;

Link to heading
&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;I have a deep love for an operating system called &lt;a href="https://www.riscosopen.org/content/"&gt;Risc Os&lt;/a&gt;. It is a really old operating system made by Acorn Computers Ltd. for their Archimedes range of computers
and you can still run it on Raspberry Pi! I love it for a few reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It’s so simple&lt;/li&gt;
&lt;li&gt;It was one of the first things I nerded out over after seeing at the
national computing museum in Bletchley Park&lt;/li&gt;
&lt;li&gt;Programming it in C helped is where pretty much all of my C knowledge comes from&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;But programming it is not easy. It predates every programming convention we have. There are no good text editors on it, and compiling is a pain!&lt;/p&gt;
&lt;p&gt;But there is a cross compiler! The only issue is that when you try to build it, it becomes obvious that you need a seriously old version of ubuntu on X86_64 linux (it’s a patched GCC 4.7.4) and these days, I sport an Arm Mac which won’t even build a compiler that old!&lt;/p&gt;
&lt;h3&gt;
  Can we nix it?
  &lt;a href="#can-we-nix-it"&gt;

Link to heading
&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;Well of course we can. I cannot think of a better use of a flake! And then we can use something like the &lt;a href="https://github.com/cpick/nix-rosetta-builder"&gt;rosetta builder&lt;/a&gt; from Mac OS to cross build software! I thought that would be easy, but my god it was not! Nix was a dream, but building old versions of GCC is a task I would not wish upon my worst enemies! But it is at this point we fast forward because this is the point I assume you are reading this. You have a cross toolchain built in nix (maybe because you have followed a great tutorial like &lt;a href="https://twosixtech.com/blog/repeatable-cross-gcc-toolchain-builds-with-nix/"&gt;this one&lt;/a&gt;). And that’s
all well and good…. but it’s a bit annoying.&lt;/p&gt;
&lt;p&gt;Every time you want to build something, you have to manually invoke the correct compiler (e.g. &lt;code&gt;arm-unknown-riscos-gcc&lt;/code&gt;), or you have to manually pass the correct &lt;code&gt;--target&lt;/code&gt; to &lt;code&gt;./configure&lt;/code&gt; or whatever. What you want is something more like a &lt;code&gt;pkgsCross."your platform".callPackage ...&lt;/code&gt; that does all of that for you! You want a custom cross-stdenv!&lt;/p&gt;
&lt;h3&gt;
  How C compilers work in Nix
  &lt;a href="#how-c-compilers-work-in-nix"&gt;

Link to heading
&lt;/a&gt;
&lt;/h3&gt;
&lt;p&gt;So if you follow &lt;a href="https://twosixtech.com/blog/repeatable-cross-gcc-toolchain-builds-with-nix/"&gt;the tutorial I linked&lt;/a&gt;, you will have noticed that the entire compiler, and tools, was built in one package. Why? The reason is that if you do as I did instead, and build binutils and GCC separately, when you finally try to invoke your cross GCC, it will weirdly try to use &lt;code&gt;ar&lt;/code&gt; and &lt;code&gt;as&lt;/code&gt; instead of &lt;code&gt;arm-unkonwn...-ar&lt;/code&gt; and &lt;code&gt;arm-unknown...-as&lt;/code&gt;. My initial solution was to build a wrapper for GCC (Nix has some nice tools for this) that passed the &lt;code&gt;-B&lt;/code&gt; argument and told GCC where the correct Binutils was, but this was when doubt started to grown in my mind. It felt a bit hack-y!&lt;/p&gt;
&lt;p&gt;What you are meant to do is wrap a C compiler with &lt;code&gt;pkgs.wrapCCWith&lt;/code&gt;. The documentation of which seems to not have been written! Fair enough! Let me give you a snippet from my flake:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wrappedGcc = pkgs.wrapCCWith {
  cc = riscosTools.rogcc;
  bintools = wrappedBintools;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;You will also want wrappedBintools:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wrappedBintools = pkgs.wrapBintoolsWith {
  bintools = riscosTools.robinutils;
  libc = null;
  coreutils = pkgs.coreutils;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now the magic begins! If you stick that in a shell and run &lt;code&gt;nix develop&lt;/code&gt; you will get your cross toolchain and it will all be working together… or will it?&lt;/p&gt;
&lt;p&gt;The answer is no. No it won’t. That would be too easy. If you look through the code in &lt;a href="https://github.com/NixOS/nixpkgs/tree/master/pkgs/build-support/cc-wrapper"&gt;&lt;code&gt;nixpkgs:/pkgs/build-support/cc-wrapper&lt;/code&gt;&lt;/a&gt;, you might see why. Of course, if we want to cross compile with nix, we have to tell nix that we are cross compiling!&lt;/p&gt;
&lt;h2&gt;
  Telling Nix we want to cross compile
  &lt;a href="#telling-nix-we-want-to-cross-compile"&gt;

Link to heading
&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;The reason nix failed to wrap our compiler is because pkgs is defined with three really important variables:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;buildPlatform – The platform we are building on&lt;/li&gt;
&lt;li&gt;targetPlatform – The platform we are building for&lt;/li&gt;
&lt;li&gt;hostPlatform – The platform which can run the stuff we are building&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So, if you are anything like me, you will have followed right up until 3. The concept of a host platform is really strange but it will make sense once I tell you this. The host platform is only important when we are building compilers (which we are).&lt;/p&gt;
&lt;p&gt;For example! I might want to use linux to build GCC that runs on mac but outputs code for Z80 CPUs. In which case:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;build = linux&lt;/li&gt;
&lt;li&gt;target = Z80&lt;/li&gt;
&lt;li&gt;host = darwin&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When you aren’t cross-building then this is simple, all three are your system. If you load nixpkgs into nix repl, then you can take a look at &lt;code&gt;pkgs.stdenv.[host,target,build]Platform&lt;/code&gt; and confirm that they are all the same.&lt;/p&gt;
&lt;p&gt;But what about when cross compiling? I shall specify, I do not mean building a cross compiler, I mean using a cross compiler to build a package. Well then &lt;code&gt;host = target != build&lt;/code&gt;. And this also makes sense!
If we build a normal package, say &lt;code&gt;pkgs.pkgsCross.mingwW64.hello&lt;/code&gt;, then our buildPlatform is our system’s platform (linux or darwin), we are targeting windows. What about the host platform? Well for the hello package, it makes no sense to ask given that it isn’t a compiler. If we build &lt;code&gt;pkgs.pkgsCross.mingwW64.gcc&lt;/code&gt;, then host = target. Because we would build a GCC that can run on windows. It is not the compiler we are using to build this package set!&lt;/p&gt;
&lt;h2&gt;
  The hidden package set
  &lt;a href="#the-hidden-package-set"&gt;

Link to heading
&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;So at this point, you may have realised something a bit strange, given that the various host, target and build platforms are defined for each package set in nix, where do the cross compilers live? They can’t live in the normal &lt;code&gt;pkgs&lt;/code&gt; for your system because the cross compiler’s targret differs from the package set’s target. But they can’t live in &lt;code&gt;pkgsCross&lt;/code&gt; because the compiler’s host (your system) differs from the package set’s. Sadly it matters! The reason being because for &lt;code&gt;wrapCC&lt;/code&gt; to correctly find your compiler and binutils, it needs to work out the compiler prefix (&lt;code&gt;arm-unknown-riscos-&lt;/code&gt; in my case) which it will only do if &lt;code&gt;host != build&lt;/code&gt;. The answer is a strange one and can be found in &lt;a href="https://github.com/NixOS/nixpkgs/blob/master/pkgs/stdenv/cross/default.nix"&gt;&lt;code&gt;nixpkgs:pkgs/stdenv/cross/default.nix&lt;/code&gt;&lt;/a&gt;. If you read this file closely, it starts with your normal &lt;code&gt;stdenv&lt;/code&gt;, then it sets &lt;code&gt;targetPlatform = crossSystem&lt;/code&gt; (so finally &lt;code&gt;host != build&lt;/code&gt;), then builds the cross stdenv where it uses the compiler from the previous stage!&lt;/p&gt;
&lt;p&gt;So how can we modify or extend this package set? I have no idea! It seems completely inaccessible! But we can always try to mimic the same trick!&lt;/p&gt;
&lt;h2&gt;
  The final solution
  &lt;a href="#the-final-solution"&gt;

Link to heading
&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;I shall now walk you through the solution I came up with. You can find the whole flake &lt;a href="https://github.com/yobson/riscos-nix/blob/main/flake.nix"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We start by importing &lt;code&gt;pkgs&lt;/code&gt; and defining our cross system:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pkgs = import nixpkgs {
  system = "x86_64-linux";
};

crossSystem = {
  config = "arm-unknown-none-elf";
  targetPrefix = "arm-unknown-riscos-";
  isCross = true;
  isStatic = true;
};

riscosPkgs = import nixpkgs {
  system = "x86_64-linux";
  inherit crossSystem;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;So far, pretty normal for cross compiling. I then have a section where I build the cross toolchain, I’ll leave it out, but the important things I define are &lt;code&gt;riscosTools.rogcc&lt;/code&gt; (my cross GCC), and &lt;code&gt;riscosTools.robinutils&lt;/code&gt;, my cross binutils. We move onto the &lt;em&gt;trick&lt;/em&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;buildSystem = import nixpkgs {
  system = "x86_64-linux";
  config.replaceStdenv = { pkgs }: pkgs.stdenv.override { 
	targetPlatform = riscosPkgs.stdenv.targetPlatform // { config = "arm-unknown-riscos" ;};
  };
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Here I define a new package set! I set the target platform with my target platform and then override config. Why? &lt;code&gt;arm-unknown-riscos&lt;/code&gt; is not a valid nix platform and so it will complain. I have to use &lt;code&gt;arm-unknown-none-elf&lt;/code&gt;. But annoyingly, &lt;code&gt;wrapCCWith&lt;/code&gt; uses &lt;code&gt;config&lt;/code&gt; to get the prefix for the compiler. I do a cheeky override here purely so it picks up the correct compiler.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wrappedBintools = buildSystem.wrapBintoolsWith {
  bintools = riscosTools.robinutils;
  libc = null;
  coreutils = buildSystem.coreutils;
};

wrappedGcc = buildSystem.wrapCCWith {
  cc = riscosTools.rogcc;
  bintools = wrappedBintools;
};
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I now use the &lt;code&gt;buildSystem&lt;/code&gt; to call &lt;code&gt;wrapBintoolsWith&lt;/code&gt; and &lt;code&gt;wrapCCWith&lt;/code&gt;. Finally! It will pick up the correct prefix.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;riscosPkgs = import nixpkgs {
  system = "x86_64-linux";
  inherit crossSystem;
  config.replaceCrossStdenv = {buildPackages, baseStdenv }:
    (buildPackages.overrideCC baseStdenv wrappedGcc).override {
      extraNativeBuildInputs = [riscosTools.elf2aif];
    };
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I can now define the package set!&lt;/p&gt;
&lt;p&gt;So does this work? Amazingly it does! I defined the following flake:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{
  description = "A new application for RISC OS";

  inputs = {
    utils.url = "github:numtide/flake-utils";

    # Point to your toolchain flake. This can be a local path or a git URL.
    riscos-nix.url = "path:../.";
  };

  outputs = { self, utils, riscos-nix }:
    utils.lib.eachDefaultSystem (system:
      let
        pkgs = riscos-nix.riscosPkgs;
      in
      {
        packages.default = pkgs.callPackage ./default.nix {};
      });
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;And &lt;code&gt;default.nix&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;{pkgs, lib}:

pkgs.stdenv.mkDerivation {
  pname = "hello-riscos";
  version = "1.0";

  src = ./.;
  hardeningDisable = [ "all" ];

  buildPhase = ''
    echo CC=$CC
    $CC hello.c -o hello
    elf2aif hello
  '';

  # The phase to install the executable into the Nix store
  installPhase = ''
    mkdir -p $out/bin
    cp hello $out/bin
  '';
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;and look what happened:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;james&amp;gt; file result/bin/hello
result/bin/hello: RISC OS AIF executable
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Who knew &lt;code&gt;file&lt;/code&gt; knows about Risc OS!&lt;/p&gt;
&lt;p&gt;That concludes things! I hope this saves you a lot of time!&lt;/p&gt;


&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.hobson.space/posts/nixcross/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 05:31:45 +0000</pubDate>
    </item>
    <item>
      <title>Don't Become the Machine</title>
      <link>https://armeet.bearblog.dev/becoming-the-machine/</link>
      <description>24 Dec, 2025</description>
      <content:encoded>&lt;main&gt;
&lt;h1&gt;Don't Become the Machine&lt;/h1&gt;
&lt;p&gt;


    24 Dec, 2025


&lt;/p&gt;
&lt;p&gt;I was recently recommended a YouTube video with the following title:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Only a slave quantifies its existence through productivity&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre&gt;'''''',,,,,,,,,,,'''''.''''''...........................................................................   .........................................  ...                                                                                                
'''''',,,,,,,,,,'''''''''''''''...........................................................................  .............................................                                                                                                             
''''',;;,,,,,,'''''''''''''''''...................................................................................................................   ......                                                                                                                         
''',,,;;,,,,,,,''''''''''''''...............................................................................................................................                                                                                                                                 
''',,,,,,,,,,,,,'''''''''''....................................................................................................................................  .                                                                                                       
'''''',,,,,,,,,,,,''''''''...................................................................................................................................................                                                                                        
''''''',,,,,,;;,,,'''''''............................................................................................................''.,:cclcllllllooooodxddxxxxkkxdddddddolcc:;,                                                                                        
'''''',,,,,,,,,,,''''''''...................................................................................................'',:::cloooxOXNNXXXKKK0000OOO0K00OOOkOOkkkOOOOOOOO000OOkxdollccc:,                                                                                     
'''',,,',,,,,,,,,''''''''''...................................................................................,:cooolodolllodoolloxkk0KXXXKK00kkkxxdddddxO000OxxxxxxdddxxkkO000KKKKKKKKKKKXXK0Oxoc:                                                                                         
''',,,,'',,,,,,,,,,,''''''...............................................................................,:ldkKXNNX0xoolccccllodk0KKKK0OkOkkxxxdoollccclodoolllllllllcllooddxxkOOO0KKXXXXXXXXXKK000Okxo:;;::,......                                                                                         
'',''''''',,,,,',,,'''''''...........................................................................,cox0XNWWWWWNNNXK0OOkkOO0KXKK0Okxollc::;;;,''..........................'',,,;:codxk0KKKKK00000OOOkxlclkklcllol'.                                                                                       
''',,,,'',,,,,,'',''''''''.......................................................................';lkKXXXXXNWNNNNNNNXNNXXKKK0Oxdol:;'.......'''''......''''.'',:ccc:,'''.''.............',,:ldxO00Okkkkkocldl,;;cxkl,...                                                                                    
''',,,,''',,,,,,,,'''''''''..................................................................':lx0XNNXK0KXXXNNNNNXXNXKKOxdo:;,.......''''''''',,,.......',,'''',;,'''''',;,.''..'..''..........':dkkkxkOocll;,:c::ll;;:;;,..                                                                                
''''',,,'',,,,,'''....'''................................................................';lx0XNXKOdoc;,cOXXNNXXKKKKOoc,.....................'...,'..,;,..'.....,::,,c:,:c;..,''cl,;l;.;c;........:dxxxdc;:;,cxOOkxl,';oxkdl:,..                                                                            
''',,,,''',,,,,''''....'''............................................................,coxOKK0kxxl,....;o0NNX00000Od;....''..............,;'';:;,';:,,;cc,,c;.,:;;cc;,c:';:,.';.,c,';:,':c,'::'';..lxxxl;,,;:lodxOKK0xlclokOOkxo:'....   .                                                                  
,,,,,,,',,,,,,'''''''''''''.......................................................,;:codkOOxol::;'..':d0X0xo:;:xOOx,..':cc,...'..,::'';;,,:c:;:lc;';c;,,::,;:,,;;',c:',,.';;..;'.,,.';;..;,.,;'',,:ooddoooddlloxko:o0NN0xollxOKK0kdc;'..  ..                                                                
,''''''''',,,''''''''''''''.....................................................,lxkOkdddolcc;'..',cxOOdc;,,'.;dO0k:..,;,,;'',;cc:;;;;,;:;,:l:,:c;.':;,'':;'';,''..,;'....''..'..''',;;;:cllloodkOKXXXXNNKkxdxxkKKl'lOkkKX0xolxO0XXXKkdc,....   ..                                                          
'''''''''',,,,'''''''''''.....................................................'lk0KOdooolooddolc:coxo:;;,'...'lkO00x;',,,,;cc;,,:lc'';;',:,.,;'.,,..,;;'.',..'.....',,',,,;,:lloddkOOOO0KKKKXX00KXNWWWWMWxlOOOOlxNx.,d:.;oOXXOxox0XXXXNXKOd:'.....                                                          
,,''''',,,,,,,,,'''''''''...................................................':xKNKd::clodxkkkxddddddoclc,....:xkkkkOxc:::c:,,;c;.,c:'.'......''.....',,'.',;;::cloddddddxxxOKKXXXNNNNWNNNNNNNX000XWMWWWWWKdollookk;.lkc',',:d0XKOxk00OOOO0KK0xl;'...                                                        
'''''',,,,,,,,,'''''''''''.................................................,lxOXNKkooooodxxxkkOkdollolloollc;coodxkxkkdc;,;,..,;,';cccclooollllloodxkkkkOOkkkkO0OOOOkxddxOKXXNWNWWWWMMWWWWWNX0OO00KXXXXK0Oxl:;;:;',lOOc,::;;;:cxKXKko:,',;:lk0KKOdc'..             .                                        
''''',,,,,'',,,'''''''''''...............................................,lolccc:cllllccloodxxxdlcclooooodxkkdlc:lc:lddddooddxO0K0OO0000KKKKKXXXNNWWWNNNNX0OkkkOOkkkOOkOKXNWWWWWWWWWWWWNNXK0OOxdoolc::::'.''....,cxOKk:,;cllllc::lkXXOl,.....,:lxOK0kl;..  ...  ...                                         
''',,,,,,,''',,''''''''..............................................'',:odool;'.''....'',,:cloxxxddooloxxdllol:;coxOKNXXXKOkdddolc:::cccc:cclllodxkO0XNNXK00KKKK00KKKXXNNNWWNNXK0Okkdoll:;,,''''....,l:..,::...';lkKKkolcloloooolccd0XKxc'......,:okKKOd:'...  ....                                        
'',,,,,,,,,,,,,''''''..............................................';;codxxo:'.,::,..,;:::,.....',:clodddodo;;clkK0xdolc:;;,,;:clldddkkOOkkkkxxdoc:,,lkKNKKXXNNNNXKKK00Oxxddoc::;,,''...',;;;;:;,'..,do'.';:;,,.....:dOKKOdoodoldOK0xook0KOo,.......,:okKKOo;.......                                        
',,,,,,,,,,,,'''''.'..............................................';coxO0Oo;.';:;',:llloo;'',''''.....,codol,:dkKKo;;;;;,;:ccdO00OkkkOOOOkxxdddxkOOO0KNNXXK0Okddol:;;,'',......',;,'.';:::::;,,'....cl,.';:;;l;........:xKNKOxoodkKNNXKOxdx00d;.......';ldk00ko:'.. .                                       
,,,,,,,,,,,,'''''..''.............................................,lxOXXk:''';:::lxkkkkxo:'''..''.''',,'',cocckKKOdoollc::ccclooododdxxkkkOOOOOOOkxdlcc::;,'......'...','....';:,'..':loll;.........'....,,'lo........  .,lkKXKkxdx0XNWWWKkodkOd,.......,;:cdOK0kl;.... ..                                  
,,,,,,,,,,''''''...''............................................;ld0XX0o;,;:cokOkkkkxkkdoo:::::;:olclc:;'.,ccd0kl;;:;;oxxxdxkkkkkkxdoollc:;,,'..................,c:;::;'..coodollclx00Oxxx:':,;oddxxc.....,:............  .,lkXNKkxxOKXXNNKo;o0Oc''......',;;cdOK0xl,......                                
,,,,,,,,,''''''''..............................................,lo::ONX0Okxxkxxkxxxkkdokkxxkxxkkkkkkxlc:.....'cko;;;,'.;dkxdolcc;,'......    ...............';clloodOxollc;dOdoldkxkO0Oxdodc;::k0dddkKd'.:l,.........','.......,lkKX0kxxOKXKkc,cO0xc,........',;cdOXKOo;.....                               
',,,,,,,'''''''''.............................................,oddccONNXXKOkkxxdlc::;,'',,;:::clodxkxl,.......':c:cc,...'.............'',,,.....;,.,:ccldc',loddxkxxOkdoo;.';::::;;:codol:,..''d0kxxkKKklloolool:.. ..'',;,'......,lOXX0xdxkOxc'cOX0d;;,.......':llokXX0d:...                               
,,,,,,,,'''''''''..'.........................................;oxxl:dKNNX0Okdl:;,'.........'.......',,.......;:,,ck0k:......,;,.......,:ccc:'...';:okolooO0c':ol:,,;clllc;'',;;coodkOOkkxdxkkdlloxxlc::cloxxdoddOOc... .',,,''','.....,lk0Kkddxdl;;dKX0xc;::......';::lOXKOd;..                              
'',,,,,''''''''''..'.''''...................................;dOOo:oKNKOkdc:,......'cdo;..;ll:..............:oc:odk0d,.,,'',;;lo:..','';cc:;::clddd0Kkocodc...,:clxO000Okddolloddooodooooodxxk0KXXKOxdoooc:loodkOd::l:'..''':lc,';ll:'...'ck00kddol:cxXX0Oxc,;:......,;:o0XKkl,.                             
'',,,,,'',,,,''''''''''''..................................:dOKx:oKWXkdl,'..'cc'..;lxOxollooc:::lc'........,;;oOOOd:'.,cc:;:::dkc'..,;::,;oodooO0dlc:;;;;;coxkOOOkxollc::;;;;;,,,,'',;;::::c::clooxOO0KKKOdoolc;'':c;;;;:;..l0koccloxoc,...;lxOOxdl:;ck0XXKOdc'.......,ccxKXKkc..                           
',,,,''''''',,,,'''''''...................................:xOKOldKNXOl;'....;ldddxkkxxdllloodxOKKOd:'.''....,oOKKk;....'lxocloooo:'.',;;,:xdlodxo;';lddk000kxlc:,;;;clllllooooodoodoooooooddooodxxdolldk0XNXKOl,''..':clcol'.,;:ldoc:codc,....;oxOkdl,,cxKXNNKxc;......':clkXX0o,..                         
''''''''''',,,''''.......................................:k0KOodKN0x:'...cl;:oddlc::ldddxxkxxxxxddkOxl::,..;dO00k:.......:xd::lc:;'...,:c:clccc;';ok00OOxl:,,;clodxxO0OkkOOkxkkxxdddxxkkkkOOOkkO00000Okdddxk0NNKOdl;,:look0xl:;;''lkkdcccll;....',cdkko:;dKXNNN0xl;''.  .;:cxO00x;.                         
''''''''''''''''''......................................,dOKkclKNOo,.....;oxdl:;;:ldOkl;;;lkKKK0xocclol:'.:xO00Oc..''.....'ll;,,,;;;;,'':;'...';lkOkoc;,,;coxxkkO00000KKKK000ko:,,;:lloxk0KKXXXXXXXXXXK0Okxoodk0XNNKOdoollxklclxo..:k0KOxlclc'.',...,lkOO0K0KXNNNXOdc'.  .,:cdkO0k:..                       
''''''',''''''''........................................ck0OccON0o,...,,;oxl;:oddxxkOd;....lKXK0xool:;:;,ckOOO0o...,;cc::;..,;',ll:lcll'....':dkOxc,,:cldkO0000000K00KXXXXXXOl'.';;;;:clccd0XNNNWWWWWNNXK0000Odoox0000000kl::lcc;;,.':lx00kdll;.......';ok0KKKXNNWWNKxc'. .';oddkOk:..                      
'''''''''.'''''........................................;x00o:kNKd,...';lxdllx0K0OkkxkOd:,':kXNNKOdoll,.,lO0OkOd'...'cxOkdl;.':,;dxooodc..';lxkko:,;lxOOO000000000KKKXXXXNNX0c..........''.;kXNNWWWWMMMWWWWNNXK0OkdoodkOO0KOl;'..,;cl:;,,ckXXOdc,.  ..';,..;oOK00XNNNWNKko:'..,loodxxc..                     
'''''''''''''.........................................'oO0k:dXNO:.....:xo:dKXXXNXK0OO00OO0XWWNXKOxool,'lO00xdo,.....:OOxoc,..',cxdc:;,';lxOOxc:coxO00000000KKKKKKKXXXXXNNNXOl'.............oKXNWMMMMMMMMWWWWWWNNX0kolodxxk00x:...ckxodx:'lx0X0o,.....,c;....'cokOKXNNNK0K0ko;.':cccllc,.                    
'''''''''''...........................................cxkklc0WKl.....;xd;o0KKXNNNNNXK0000000KKK0kdxo;,oOK0OOx:.......dOdc,',,:ooc'.';cdO00xl;:lxOO000000K0KXNNNXXXXXXXXNNNNk,..............cOXNWMMMMMMMMMWWWWWNNXK0kxdooddk00Oxl:cdkxdx:.,ldO0Od:,......   .',';cdkO0KKKKKK0Oxl;,;;:::c:..                  
,,,,,'''''...........................................;dxkxlxNWk,..':cxOccO00KXNNNNNNKdodxxxdooxkxdo:,o0XK0OOl........;do;.:lccldc.;odO00kl:cokkkkxxddoodkOKXNWWWWNXXXXNNWWNO;.';ccllool:,.;kXNWWMMMMMMMMMWNX0OxxxxkOOOkdlokOOO00Od:,;;,;:'.':lxOOxo:,....  ..,'..';lxk000KKKKXXOdc;;'',ldc'..               
,,,,'''''''.........................................'lddkdxXNKo'.',:lOx:okxxk0XNNWWXOdkKXXKkc,,coo:,oKXXK0Oo'....... .cl,.cxolloc'ck0KOl;:oxkOko:,;;,...';cd0NWWWWWNNNNNNNNXOc':oxkkkkkxdokKNWWMMMMMMMMWXkl,',:ccccldOOkkdox0OxO0Ol. .;cloo:,,cdkkkOxdllc;,,,,,,,....;okO0KKXXXXK0kdc:clcldc..              
,'''''''''..........................................;doool0NOkl'''..cKkcoo;,,;dKNNNKkO0kdoclol,,oc;dKXXXKOo,........ .:,..,llc:,.;xKKx;,cxkkOd;.'',,..'.....:kNWWWWWWNNNNNNNNXkolooddoox0KXNNWWMMMMMMMWOc'...';okkxo:ck00Odox00kk00l'.'coxkxo,':loxkkxxxxxddooddo'. ...':dOKKKK0xldk0Ol'.';ol'..            
,''''''''...........................................lkdolOWXkd:.....:KO:c;....;ONNWKdooclxkxdc';c:dKXXKKOd;..'''.... ....',,...'lkK0l,:dxkOOd;.......''...',,c0WWWWMWWNNNNXXNNNXK0kxkO0KKXNNWWMMMMMMMW0;....'..,:dO0OolOKOxddkO00KXKkc;dxldxk:..,',;;;::codl:;;;,',:cl:...,cdOKx;,lodK0c,::lkd,.            
,''','''...........................................,xxldKNNXkd:...,coOOcll,'';dKNNWWOc:d00kl;,:::dKXXXKOx:..''......':lxxl,....:OKk:,:dkkkOxc'......'...':okdckNWWWWMMWNNNNNWNNNXXXXXXXXXNNWWWMMMMMMMWd',c:'..''.,oOKOld00xdxdox0NX0kxllodkKO:............,;ccooooool:,... ..,clc:clkN0:.':d0k:.            
,,''''''...........................................:kkkKK0kOOkd,..'cld0xlkOkk0KXXNWNX0xddoolclc:dKXXXK0xl'.','.....;ooddkOc..'lOKk:,cxddkkxdl,,''''''',;lxkOdlkNWWMMMMMWWNNNNNNNNNXNNNNWWWWWWWWMMMMMWNx';ddo;'.....:xxlkX0OkkxoodOXKkxxdl:l0Kxo;.........;clc:;,....',;;::,.....';cdxd;...;k0ko,.           
'''''''...........................................'l0KK0oc;lOOxc.....'o0ooKXKK00KXXXK00OkOOxoccxKXXXK0ko,..;;,;....;ccoloo;.'lOKx:;ldddxxddxko;'';:;,:cloxkxdxKNWWMMMMMMWWNNNXKK00OO0KKXNWWWWWMMMMMMMWKl;lxkko,.....';dXNX00OxddllkXK00XXkcx0xddl;. ............,cdkOOkxdol'.;:,;;''......'::;:;.           
''''''............................................:kKXk:;,.'o00x;....':xOodK0OO0KKK0OOxoccol:lOXNXXK0kd:..''..'....:loxl;'.'lO0o,,cdxkOkxxxkkxl;,;:cclooddddxKNNWWWWWWWNX0kxxxxxxxkkxxxkOO0KNWWMMMMWWMWXkloxOKx,....;xKNNNXK0OkOxllkNNNNWXxlxdoxko.  . ........:x000Okkkddo:,;cllclc...',.....;:.           
'''''............................................;xKXx,.,,',:xKOd;...;dookkxkOOOOO0OOx:....,lOXNNXK0kdc..'........;xkdc'.',lOKx,'codkOkxk0OO0OOOxdxkddddxkOKXNWWNNNX0OkxxkO0KXNNNWWWWWNNXK0OOO0XWWWMMMWWNKOOkkxl:coOXNWNNWWX000OOxddkNWNNN0c,;cc;..  .......';:dO0OOkdooc:,,;:clllo:...;c;..',lx:...        
''''............................................,dKXk;....',,oK0xo:...''.,dOkxdxxxxdol;...'o0KXNNXKOxl...',......:oO0k;.,:cxXO;.;ldkOOkk0000KKKKKKXX0KXXXNNXXNWNNXOdxk0KNNXXNNNNWWWWWWWWWWWWNKkxkXWMMMMWWNNWWNXXNNWWWWWNNNNNK00OkxxdoOXNNNO;. ..';..  ..:llxkkxdlc;,'......'ccloloo'...;lc'.,;o0O:..        
'''............................................'oKNKc....''..:OXkooc'....'lxkOkxxoc:::;',lOKKXXNXKK0x,....'.  .'c:cooxc.'coO0l';loxOOk00000KKKKXXXXXXXXXXXXXXNNXOdx0NNNNNNK0Okxxxkkk0KKXNWWWWWWN0k0NMMWWWWWWMWWWWWWWWWWWWNNWNXXKOkxxxxKNNNKo...;cl;'.  .;:;;,'..........'..:lclood:..';cll;.';lOXk;.        
''............................................'lKNNk;...,,...;kNKkxxd:'...;:',lk0Oxl;;lkKXKOkkOO00Ok:.......  .,dl:;;c,.,lkKx,;ldkO0O0KK00KKKKKKKXXXXXKXXXXXXX0xd0NNNNNXOxdddkOOO0OxxxxxkKNWWWWWWXOOXMWWWWMMMMMWWMMMWWWMMWWWWWNXXK00OdkXWNX0c'coodxk:. ....... .',,'..';,.'loodldd,..;ccll,..,;lkKk,.       
''............................................:OXN0l'..,;'...:OXKOkkxxoc,......lxdxxcoKNKxlccclcoxxc'...........;ol;,...:dKKc;lxkKKKKKKKKKKXKKKKXXXKKKKKXXXXX0dxXWWNXKkddk0XNWWWWX000O00Okk0XNWWWWN0OXWWWWMMMMMMMMMMMWWMMWWWMMWNNXKKKxd0NXK0oc0OoxO0o........ .;lc..'od:..:dxxdoxo...;loodc...';lxKd.       
''...........................................;kNNXk;.',;,,'':xK0klcooooolc,....;;..,dXN0o:lddxxllxl'.....',:;...,,;,...:d0Xk;,ok0KKXK000OO000KXXXXKKKXXXXXXXKxkNMWWXkodk0XWWWWWWWNXKKKKXKK0xox0XNX0K0OXMMMMMMMMMMMMMMMMMMMMMMMWNNXXXXOokNXK0xcx00O0x,........'cl:..:dd;..,dkOkxkk:...,ldxkd,....:lx0l.      
............................................cOXWNNXOxdddxxkOKXKkolc:ccclccc:;......dNNkllk00Okocdd'.';;ccllol'..,,:;...:xKKo':xO0000ko:,,;;;:dOKKXKXXXXXXXNXkxXWWWXkld0KKXNWWWWWNXKKKXXX00KKk:;:ldkkOkkNMMMMMMMMMMMMMWWMMMMMMWWWWNXXXKddKX000xlok0k;,oc.....','..,cc,....ck000OOo,''.,oxO0x:....':lOO;.     
.........................................;coONNNXXXKKXXXXXKKKKOo;,.....'',::;;'...dNNx:lOKXKkoldd;.,dkdll:;,'...,;;,...;xXKc,lxO0Oxc'........,cdOKKXXXXXXNN0k0NWMW0llkO000KKXNNNNXKKKKXK00K00xclc::cdOx0WMMMMMMMMMWWN0kkkOOKXNWWWNNNNXkoOX0KKKx:lOKd,'. .......'','.....:k0KKK0kl','.'lk0KOl'..  .cxKd.     
........................................:xKXNWNXOxlccccllollodoc'...','.....',,.'xNXo;oOKXX0dloxc.'oxdl:'.....:ooodo,..:kXOccdxkOx:',:,......cddxO0KXXNXNNXkOXNWMW0ookkOOkO0KKKOkkkkKNNNNXKO0KxxOkdc;::dXWMMMMMMWNOdc,.....';lkXNNNNNXOdOXKKKKo;dxdkd'. ...','...',;'...o0KXNX0d,.....cOXNKx;... .,o00:.    
.......................................'o0NNXKOxo:,:xkkxdoc:::,.....''........';OWKl;lOXXX0xlldo,'lkd;.......,xdll:c:..l0Nkllodkxc':dd:.....'lddllk0KKKKXXKxONNWWW0ox0000KKKXXxok00xxKNXNXXK0KkdO0OOkl:;cd0NWMMWXd,';:'.....,::o0XNXXKOdONXKXXdcOkooOd.  .''. ..cdc..'':kXNNNXkc......c0NNN0l'.. .'lOXd..   
.......................................,dKNKKOxol;;kNNX0OOOkOOkdoc;,'.........;ON0:;oOXXKKxccol:;oOd'........,oddool'.;xKXOccdxxd,.cdo:.....'cll::x0KKKKXXKxONWNNN0oxKKKXXXXXKddKKOdckNNNNNNXXkoOK00KKx:::,:oOXWk,'ldl'.....:o:;o0NXXKkdONNNWXl'l0Oxx:. .......cxo'.;c:oKNNNNKd;',,;..;ONNNNk;... .;dX0;.   
.......................................,o0XKK0ko:.,kNWXkdoxxdolc::cllc:::;;,.;ONO:,lOXX00kccod:;d0x,....''....,:oxd'.;ok0Xk;:xxkx:.;ll;.....':cccd0KKXXXXNKxkXNXNNKolOKXXXXXXX0xolloxKWWWWNNNKocOKK0KXdlKXOo:,;lc,cxkl.....'oko:l0XKXXOx0WWWWk'..,;,.   ..   .,dd,.',':kXNWWN0l;;:;'..;ONNNN0l.....'oKXo.   
.......................................,lkKXXKk:...c0WNKkxd;..',,.....';:cc;:ON0:,oOKX0kd::od:.c00o,........'c;,cl;.'cdOKXx;:xkkkd;,:c:'.....,:lkKXXXXXXNNXkd0XXNNX0od0KKK0KKKKK000NWWWWWNNXKd;oKXKXN0cxWMMWX0xc,,cxk:.....:00klo0NXX0kdKWMMWd..';;;'        .,l:....'d0NNWWXx;....  .;ONNNNNd'.....c0WO'   
........................................:okXNXk,...,dXNNKkc...:do;'.......'ckNO:'lkkOOxo:;ldc.,kKko,.. .....';,:dxl'.:oxOKk;:xkkkkxo:;;'.....,lOKNNNNNNWWWNXkd0XKXNX0kkOOOkOOO00KXWWWWWWNNN0l;lKNXNWXolKWWMMWWWNx'..'','...xNXkcdKXNX0dxXMWWWO;':cod:.      ...,,.  .c0NWWWWO;..  ....,xXNNWNx'.....cOWK;   
.........................................;d0XX0l...,;dXWNKd'..coc;,'......'dXXl':docccc::coo'.oX0do;....... ..'ldool;,ldkOx:;dkxkOOOOxolclodxOXNWWWNNWWWWWWWXxoOKXXNXK0kkkkkkkkkOKXNNNNNXOo;:dKWWWWXd:xNWWWWWWWWN0l,..',,,lKXkodKXKKK0xkWWNXX0c;dOkkxc.    .'..',.  'xXWWWWNd'.',,;,..'dKNNNXd,.  .'l0WXc.  
..........................................,lOKX0o,.'.'dXNX0d,.','',''',,..;xX0l;;cdxdk0KOdl'.'xKOdl:. ....'...;occocc;:lxOxc;odddkOOOOOO0XNNNNNNNNNNNNNNNWWWMXdoOKXNNNNX0xdddxxxk0KXKOkdl;:d0NWWWN0l;oKNNNNNWWWWNWN0dc,..';cldk0XXKKOxd0WWNXK0lckkodko.  ..... ... .c0NWWWW0:..';;;'..'dKXXX0o;. ..,oKXKc.  
............................................;okKKx:''',oKNNX0Okkkdlccllc''lx0K0kkOdccdxxOk;..'cxkl:c' .'''....,oolcc;'';dxdo::lldxkkkOOO0KKKKK00KKKK00KKXXNWWNKdlx0XNNNNNXKkolc;,;cc:,;:cx0XNNNNKd;ckNWNXXNNNNWWNNXXNXKOko;''cld00OOxldXWWWXKX0clOK0d,..        ...;OXNNWWXd'..';;'.. .o0XXX0xc. ..'lxOOc...
..............................................;lodoc;;;;c0NNXK0OOxlcccc:,.':xKXK0xdxlokolc....'';;,,'. ....,,...;::,....:ddo:;clodxdxkOOOOOOOOkkkOOOOkOO0KKXXK0Oxold0XNNNNNXXKkc'.':oxkO0KKXXK0xccdKWWNNNNXXNNNNNNXKKKXKX0Oxo:.'loloolOWMMWNNNKocdOo',,..   ..   .'dKNNNWW0:.......   'd0KXKkdl'..';:;::..  
...............................................,lc,,'',;,;oxoc:;,,'''''''....;oO0dxX0cco'...... .'..    ..''.....',,.....:ddc:lcloddodxxxkkkkkkkxxxxxxkOOO000OO000kolokKXNNNNXK0x:,,cdkOO00Oxl;cxKNWWWWWWNXNWWNNNXXKKKKX0O0KKkd:,'',,lXMMWWWWKock0d'..,..        .:kKNWWNXx'   .....  ,dkxxOxoo;..',;ldc.   
................................................cl::;;'...... .,,'........ ....';,':o:... .,:;,..............''.',',,....:odl:cccloooodoodxkkxl:,'':llllldkOO00O0000OdlloxO0XNNX0kxl,';oxdl:cokXWMMMMMWXkddxkO0KXXK0000K000KkkOOxdc;''lOXWWW0c:oOX0:. ....       .oxOKNNX0c.   .',,,. 'ldolxdlo:..;oOOKk'   
...............................................':oc''',;'. ....;,'....  ......',.    ....,;;;:cc::,..,;;col;;olcol:coc. ..'...',,:cccloolodxl,.....,ldxdl::okkO000K000OOxdollooolcc:;..,clokXNWWMMWWW0l;;:clcc:;cd0K0000O0K0kkOOOOxlooc:co0KdododxOo..,,,,'......;ddxO0KKx,.    ..,;. 'colcoool:':kK0OKd.   
......................................... ....,odl,....'..   ....',;::,.  ....''.......,;:::::;;:clc:;;,,lol;:c:oollo;. ..:c...'',;;,:odood:.........;clol;;lxkkO0KXXXXNNXK0kdlccllllooo:;:xXNWMMWWXd,,ldddoc;....:k000OO0OkOOOkxdlxNWNKo'.;lxOOOxo,.';;lxxollc,,lodkOO0Oc.    .. .'..'colllll;;d0XX000:    
.......................................... ...cOKxc;,'.'.  ......;dKXXKk:.'ll:lxxl:okxc,...,:;;;;;:loooc;;;;'':;,:::c;.',cO0xdddodx:.,c:;::..,,.........,;;,'lkOKXXNWNNWNX0kxxxxOXXKKK00Oxc,ckXWWWWx';dkkxl;.......cO0O000OkOO0kl:dXWWWNx,...,:oxo,..',cx0XXKKx:loodxxxkd' .......',...:ll:::,,dKXNX0Kx'    
.............................................cONKkocccc,. ..;cc;'.'oOXNX0l,oOlckKOl:xKkxc..;;,;:::okOkxxxxoc,.''..'cxxddkOKXXNNNNXKOkxdxd;...ld:............'lOKNNNNNNXNXK0kkkkkOKNNNNNXKK0d:;:dKWWx'ckxc;.......;;:x0KKOOOkO0OdcdXWWNN0;..,:;...,clc:,,cdk00Ol:olloooxkc. ......,;'. .;:::;:oxOXNN000:.    
...........................................,o0XN0oc::cc,. .,ldlcc;..l0XXKk;.oo,:xdl;,lool',lc,..,:dOO00000KKKOxl;'';loddxkO0KXNWWWNNNWWWXo'..;ddc;'.........:k0XNNXXWWNXK0OxxddddxOKNNNXKKKK0xl,;xXx,','......':ol;:OK00OOkO0OdokXWNNNKd,':ox:..   .;clc,..';,;cccloodkd'..;cc:c:;:,...,;::cxO0KXNKO0o.     
..........................................ckKXX0l,..'''....:oxc';xx''dkxkkc..,.'ccc,.':c:..:c;.. ..,cdk00KXXNWWNX0d:',coddddxk0KNNWWWWWWWKl'..,clll;.......:x0KXNNNNNNKK00kl;,,:::ccdOKKKXXXKKKkl;:l:.......;lxkxllkXKKK0O0OOolxKNXXKOkl:ccox:.       .;c:'. .,:;:llcdx:..,lkKKXXXKkc',;,;lxO0KXNN00k;.     
........................................:xKNN0x;.......  ..:oxl'.cx,.loodd:.....;;;'.';,'..;;....  ...;cox0KNWWWWWWKxl;,,,',;:ccld0XWWWWWWXOd:.';;;;,'..,:oOKKXNWNNNXKKK0x;.,lxkxxdlclodOXXXXXXX0xl,''''..,lxOkdodOKKKK0000xllx0KK00Odc;lOxll,.          ';:;,;,:c::ldc...'cx0XNNNKOl'',:oO0KXXXNKO0o.      
......................................:d0XNKOkc...''...   .;ldl'....'ol:cc,. ..';,.. .,.  ... ...  ......':d0XNWWWWWNN0o:,...,::;;:o0NWWWWWXx,.','';coodxkOO0XNNNNXXKKKKk;..,cllll::;,'.:OXXXKK00K0kl,';:lodddxk0XKKKK00Okl:oOO00Okxl;;lxkl':;.            ..;:;;::;lo'......;lodxdo;.,cxOkoox0XXOkk;.      
................ ...................:x0KK0kddxc............'cdo;....:d:,,..   ..'..  ..        .  .':,......;lk0XXNWNNX0Oxdl;...,:cclONWWWWW0c...,clokOkxxkkO0KKKKKXXXKKd...............'xKK0OO0KKKK0kl;,;d0K0KKKK00K00OdclxOOOOdc'..cdoodc. .    ....';:ccccccc;'..;,. .':' .....''';oO0k:..'dXKkko.       
................     .............,;::cc::ldxkkd,......,;...'lddoccldl,....   ...  ............ ..:kOdl;.......,cdOKXXK00K0dol,..''::lKWWWWNXOo,.,cllodoodxxkkO00KKKKKK0l...............'x000000K000KKKOd;';ok0OOO0K0OxoldkOOOOxc.  .:doll'  ..':ldxdddk0XNWNNXKOkol:... .;,...,;,..cxOOOOxlcdKNOxx,        
.................  ............':c:,.......:dOKX0o,..',;'... .;oxOOl'....     .'. ...,;;,'......'lOOxo;.... .,,'.';clx000Occxl;,:l:',:kWWWWXK0d,..,cccllloddxkOO00KK0KKKx,.';,'''.......cO00000OO0KKKK0KKOl'.;lxk00koldk0KK0000d,........  ..:dOKKKOkxdxk0KK00OOOOkOOkxl,.',..,;,,;loodxk000KXK0Oxc.        
................   .    ......:dkOxl'...''...:kXNNOc''...,......''......    ...,'...,,.........;kKOxo;. ...'clcc::c,.':oxkl,,;l:cOOc,:kWWWWNKx,...',;:c:cooxkxkOkkOO00K0Oo;;coddoll:;;,lOKXKKK00KXXK0KKKK0ko;'.,cllldk0XNWWNXKxllc:lc'....,lk0K0kxkkOO0KNWWNNNXKK0OxxO0KOd;..;:';locclodkkkkOOkdol;.        
................. .... .....;d0KNNKd'..',,,...;kXNXKx:......;,. ............. ....''..........;OXOoc,.  ...,,;clolc:..'',::;;codk0x:cxKWWWNX0o;. ...',;:cldxdxkOOkkk0000OOOdc:cllcc::lx0KKXXKKKKXXXK00000O0Odc'...:xOKKKNN0ddl:ddccdo. .'lddOOxdkKXNXKKXNWMWMMMMMMN0dodOKKOl'.,:ll::coddoolc:::odo'         
..........................'o0XNWWWWXx:;:;;;;'..lKNXX0kl....,:'...''''.  ......................o0Odc,.......'..ckKOOOd;',:cc:;:cooc;cx0XNNNXKkdc.  .,;;;,;cllllddodkOOOOOO0000OxxkxkOO0KKK000000O0000OOkO0Oxlccodl,.;d0kxko' ..,xxdkx:..;xkxxdoOKKKKKKKKKXNWMWWMWWWWWXOlcx0K0d,.,;,,,',,'..',;lkOo,.         
........  ...   .........:kXNNKOOKX0kdolool:,..:OXNNXX0l...'....,:::'. ..','.  ..........  ...:oo:,....,:,...,lkXNNNNKxlcldoc:;,',cdxkO00K0d;..   .;coddlc::;:llcldxxkkkOO000000OkxxkxxxddxxxxxxxdddddoddlcldkOOOxc;,,cl;.  ..ckkxo'..;OK0OddKX0kxdox00KKXNNNNNKXWWWWXd,,ldxkl...... .....cdxOko,.          
........    .   ........c0XOdl;.'cxxoodxOkl,...;ONXKNNX0dc;,,,..:lcl, ..,,,:,. ..,;cdxxxdlc:;..........','.  ..;xXXNWNK0kdlc:;;;;:lolooodxd;.     .;coxkOko;,,,,,,;::codoooookkxxdddddxxxxxkOxxkxdo:;:cooddxkkxxxdxdl,.','.,oxxkOl. .'d000xdKXkl:;,,dKKXXXXXXKdoxk00kdll:;:codc..,;...,,..ckO0o'.           
..........        ....,dK0dc:,...codxO00Od;.''.:ONK0KXXK0xol:;';odol. .,,;cdd:..'codk0KXXNNXKOo;........,:;''...:kKKKKOxoollccllc:cllllc;;:;...  ..',,,;:c:::clllooxkO0OOOkOO00OkxxxxxxkkOKNXOkO00KO:.;odddxkdolcccdO0o'..:kKdcdO:. .ckOOdoOXK0xc,.'xKXNX0O0OdxXXKkxxkOkdc;codd,..'...'..'okkl.             
..   .....      .....cOKxcoo;...:dxkOOkxdo;....lKN0kOXKkoc:;,'.:xxxl..',;:oO0kl..,:clokO00000Odl:,. ..;clc,'.,,.:occlcc:;;;,,',,,,;:c::cccclooodxkkkOOOOOOkkOOOOOOkxxxxdxOOOOOOOOkxxxxxOxldKOxkkO0KKo.,oxxxkxo:;'.':oooo:..;dOOOd'...lxkdcd0KXNXKOdo0NXOdxkxolONNWWNXKK0Od;:dxx:......'';oxd,               
.      .         ..'o0Olcll,..':ooc:;,:llc:...:kX0xdOKkl;'.....oOOOl..',:ok0KXXx;':::clodxdlcllc,...,;:;'....,,',;;::ccloodddxkO0KKKXKKKKK0OOxxkxdddoodoooodxxkOOOOO0KXXNNNWWWWWWWNKK0OOxlxK0kOKK00k:.;ooodxxoc'     .ld'....'col,.',ldxocxKXNNNNNNNNN0okNWN0dlONWNNNNXKKk;;dkx:..';::clooc.                
 ..             ..:xKk:;c:'..,::;'.....':::,.,d0Oxclkd;..,'...:kKXKc..'.;d0XNNXKd;;cloooxkkdc:;;,',:ccloddxkkO0KXNNNNNNXXK0OOkkxdooddxdddddddddol::coxxxkOOO0OOO000KNWNNWWWWWNX0kxdooooodk0K0000kxo;',,'':x0Kk,    ....;cccc'  .;loc:dOOxckXKKXNNNNNXNOoOWWNKdoOXKXNWNXKKx,,x0k;.',,::coo;.                 
...            .'lxOd;.'..';:::,....''..,;;',dOxoc:c:....'',;,lKNNO;..'..;kKNN0kOo,;:ldkO00K0000KKXKKKKKK00OOkxdooollccccccllolodxk0KNNNNNNNNNKo;,;;';:lddddxdooodxkOOkxxkxxxxxxxxkkkkxdlc;''',;;:c;..   .'co:.  ..''.'ooccdl. ...;lodxkxldK00KXXNNXXX0olxkkxdOXOollx0KKKo';OKx'.,lllooo;.                  
.        ... ..,dkkOkol:,',;,,'....'''..',';dxdoc;;'. .':oxxc,oNWNx. ....':kX0xoxxkO0KNNNXNX0kxolccc::::;,'.....,codddxxk0KXNNNNWWWWWWWWWNWWXK0o,;c,..',:cccc:;;;::cclllldxxkkxdoc::::;.       .;cc'  .... .;,.  ..,;.'lc:ldl..,,...,codkdokOk0OxdxO00xdO0OOKNNXx:'..'l0k;;xKKl...cxxxxc.                   
....  ...  ...ckKXNNNNX0Oxxdl;,...'......,;ldlcc:,....;d0K0kc;kWWNd..';;;;,:dxoxKXXXXXXXK00Oo'..''';:ldkkc;oddxkdlloxOOO0KXXNNNXNNNNNNNWNNNNKOOx:,,:oc,......',;:lollll:;;;'....   .;c,.    .... .;. .::;,''...   .,;,:lodl;. .....  .;xOkolooodkOOkdoxKNNNWWNKOl;;;:oxx::xKKx;..;oddxo.                    
..... ......'o0NNXXXXNX0xoloddxoc:,.......,:;;;:;'..'cx0K0ko;c0WWNd..,lxxxxc;xKKK0000OO0OO000x;':cclodxkl,d0dlldKx',ldxxdxkO00KKKXXXXKKK0kxxdol:'';:lc;'.. ..''''''.....     .....  ';...  ..,,.  ...;xkxl::,;.   .,clxkc'.  ...,::'. .:x0kl:lOXXNNNXKXNNWWWX0OOkxxkOkl,:kK0o'.';:ooo:.                     
..... .....,d0XN0dc:lOXXkdll::ccc:,'':lddxko;...'...;looc:,..lXWWNo..,cdOkxlo0XXK00kc:ldx0KKKKx,,cclloxo''dOxoldKx;cc:odoodddxddddoooodxxxxk0Oko;;:;;::,...            .....;:ccc;.  ...... ..;:'. . ,ddc:ll:,.  .ckocld:.  .,ll:cl:'. .,oO0kod0XWWWWNNWWWWWNXKK0K0Oo:;lxxkl....',;;,.                      
..........;dKNNKd'...:OX0xoc;'....;oOXNWWWNKko;'....,,'......dNWNXc....:odl;dXNNNNKoodoolkKKXX0c;llllodd:..;ooooc',coc:;;;;;:::clooddxxkxxolccc;..,;;:cl:,'.          .;lodxkxxdo;. ........  .ldc'...;:oOOo,.   .oxc,;o:. .,codlccc:'.  .:x0Oxodk0XNNNWNNNWNNXKOxl::dO0ko;.   .......                      
.........,lkXNXKk:..'lO0ko:'....;oOKKXNK0Okxddoc:,.....,'...'OWWWK:....;,;,;kWWWWWXddkl;cx0KKK0c,clcclooo;. ....';:cooc;...':c:cc::;,'.....,;c;'...,;;:cc;,.          .:lddxxolc;.    ..';;..  .;c:;:cdxxo:.   ...:dkxdl'.'cdxdxxl:;'...   .ck00xolclodxkkOkxdoc;;:lkOkl;...'. ....,.                       
...... ...cOXNXXX0xxkOkxl,..,,,:kNNNKxoccdkoc;cdol;....:;...;0WWNx..,..coo:'lXWWWWN0kkkkkOkkOKk;;lcllccllc;'....,:clddol;'.......      .'clc;;col'..,clll:'..         .';;,;;;,'.        ..''.     ......   ..;:,...,,...,oxOkdo:,..    ..  ..:lxkkxdlccc;,,;;:lodxdo;..  .''...,'.,'                       
..........'o0KXXXXKKOdo:..'::;,oKNN0ldkl:d0X0c'cdoo;. .',...lXWWXc.,c;.'loc,'oKXKK00KXXK0OOOOkocoodxxxkkxol:,. .':ldxxxdodl'...,.... .,ll:;:lol;..  .,;;;:,....    .;,.....,......... .     ....        .':oxko;''''.   'dkdl;'. ...    .........,coooxOkdlloooolc:;'. .  .....,;..,'                       
............cx0KKOOko:,...'''',l0XXxcON0l:lOXx':k0k:.  ....,kNNN0;.,lc'.;oddc,:odxkkO0K0OOkkO000kxxdool:;'...    .;lxxxxkkxdc'';,'...clc::c:'.    .  .',coo;','.   .:l'..'lo;..;::.   ...     ....  .';lxOKXkccc:cl:.  .,:,...;:clodool;'..,:ll;.  ...',;,,,,;:;;:cll:'...  ..''...:'                       
.............':ooll:'.   ....'.:k0Kk:cOKOl::o:,dKKO:.......cKNXXk'.';;cd0NNKkl,..,:cloddoooodol;'....   ..     .   .cdxxk0000x:,,.  .';::'.    .....  ..';cc'',..  .'lollxKKxcdOko'...,,.       ..';lxO0K00Oc:dl;;dx.    .,lk0XX0OKNWWWNk:'';lc'........,,,;:lodddkxxxo:,.  .... .;c.                       
...................     . .....;dOOOxc:cll;'',cxkxl'..,''.'dKXXXd'..':kKWWWKo,.';c::::::;;;,'.. ...,'..''. ..  ......,lxxOKXXX0o'     '.    .... .;:;;;,',:ll,';.....:kO0KNNNNNNNKOkxdl,.     ...;lodxkOOOOd;;oxoc:'.  .,xKNNXNNK0KXNNX0Oxdl,,... ....'..';clloooolc;,..    ... ..;,.                       
................................,lxxxxkkxdxxkxdol;..';:::';kKKXKo..',:d0Kkl,....,:lldool:,'..  .,:llc::,. .... .;cc,. .;dOKNNXXXk:.'.        .'...:x0KKk:';:lc;;;..  'lk0XNNWWWWWWWWWWXl'..''....,cclodkOOkd:,cxd,.  ..;kKNNXKkooddoodxxxxkOkd:.   ...... .,;;,,..   .. ..     ..,,.                        
..................................;::cdKNNNXOxl;...,:clc:':kO0K0:..,:clc,..':ll::::;;;;,......'ccllccc,........,okkdl,.',lOKXNNNNXxc:;.      ..:oxOKXNNXk,.,;l:,;;.   'ld0NWN0dccclxKWWX0kko,....',:codxxdd:,;oxc.   .'okO0KOllkXWWKd:::cdk0KXk;. ................. ... ...    .',.                         
.............................     ..,:ooolc:,......,;dkdl;:lodxx, .,,.....,coxOOKXXKK0Ooc:,'.,lodoolc,...''....;dOOkkxdl'.,o0KXNWWWKx:.  .....,oOKXXKkddc'.',:oc,;,.  .:oONWKc.  ...,xXNXKKk;....'..,:;;::;;looxo.   .lO0000ol0NN0dclkKd,l0XNNk;....................... ...   ..'.                          
..........  ............           ..;c,.............l00l,,;dxc:.  .. .....',coxkOOO0Oxl;,.':oddoll:.. ........,dOO00OOOc. .:x0NWMMMWk,  ..';cdkKKKkc'......'coo:','.  .cONNx. .;'...c0NXKKK0xdoc,. ...  .;dl::cl'   'xNNWWXodK0o:cONWXx,cKNWNk:.........''................  ..':,.                         
..........    ... ..  .              .;ldoc;,........'xKd;:llll:. ..............,;,;,''...'lxxdooo;......''....,dOKXXKK0l.   .ckXWWMWW0c.  .,coxO00l'.....;,..,:l:,,'.  ,kNNO:..:c:''oKXXNNWWNX0c. ..     'llcc:,.   .oKXXNKxccloxOXNXOc,dXWWXd,.........''.......;::'... .:llldOo.                         
..........       ...                 .,dO0d,..'.......lKKl',;:;,,,;;::'..,,...',,'.......,dO0Oxdl,..'....'......c0XXXXK0d.... ..ckXWWWWNO:..,;cxOOOd,...;lo;..,:loc,,.  .cOK0OdccclokKXXNWWWNNXKxl:,'.    ......      ,k0O00kl;ldxxkko:;o0NWXx'..........,,...'..'ldo;,;. ;k000KKx.                         
..........                            ;k0Kd..,:' .,:..cKNOl;,'.',,,cdkk:..'...:l,... ...cOXNXKxc'..''...,'...:;.;OKXXXXXO:..'.  .'ckXWWWWXx,.;clodkkd:,;::ccoc;;;coc,,.  .'lkOKXXK00KNWWWWWWNNXK00x,..   .';.          ,dxdxkxolc::c:cx0NWW0o'  .........;;...'..,okxl:;' 'x00000d.                         
.............                        .c0K0l. .;,.,dc..dXNOdl,......'lOKOc..'.'ox:. ...'oKXXXXO:.  ....:o:... ...;kKKXXXK0c..,:.  ..,ckKNWN0o;';clodxxkOOOOOKKx;'',cdc'.   .;oookKK0KNWWNNXNXXNXXK0x:....',,'.           .,lllxkkkkkOKXWWNXx,...  ........,:' ....'okxc;;'.,kXK000x'                         
.........                            .dK0x,   .',oo..;ONKxc'.........:kKOc....ld;....;kXNNXXk:.    ..oOo'...    .o000K0OOd' .cc. .c;..;xKKOkd:',cooddkO0KXNXOl,'.';oo;,.. .oxxdllkKXNNXXKKKKXXXXXK0d;;l:;:lc.             ..'lO0OO0KK00kl,..'c:. ...'....,c;.... ,xOl',;..c0XK0OOd.                         
.......                             .;OK0l.    'l:. .dK0ko'......';;..:x0k;...,:,...:kNNNNKd,     .;xkl'....  ...cOO0OOkkd'  .l; .c:'. .;dOOkdl;'',:cxO0KNXdcc:;'.;ldc;'..;oxkO0l:kKXNXKK0KKKKXKKK0l,lxlcll;.            .'....,,,;;,'...;cdOKo.   ..'...'lc.... 'xOc'c;.,xKKKK0Oo.                         
 ...                                ,dOOo.     .'. .:Oxlc...''',cdl;...:xxc....''..cOXXXX0l..   ..,ld;.  .....::.'oxoll;,..   .. ... .....;dOkd:...;:lkOKXd,;::lc,;:,'''..'cxO00d,l0KXKKK0KK00KKKKOo;;lxkl'        ....  .;:..,:;,'.'.,o0XXXXXd......,,. .:o'....;xx::c'.lOKXK0Okc.                         
                                  .,lllllloooddollc:;:;;. ....;ll;......''........c0NNXXk:.  ...,:;,..     .,c;.. .'....     ....',,';:;;'..:c;:lc.,lc:o00l:lccldxc,;cc::'.:OKKKk:cOXX0dlolcdOKKK0ko,,ldd,      ..'',.....;c'.:xkxkkxll0WWNXX0o...  .:;. .cl'.'..:o;;:'.;OXXXKOOx;                          
                                  ,coOXNNNNXK0kxOKXXKOxc'....,,'........,col:,'.'oXWWNXx,    .',,...'.     ....     ..';cloddxxdoolc:::cc::'. .,c:.'c,.;k0lcoooodkxo::::;..o0K00k;c0XO:......:OKK0o;,;clo:.    .',,,'..,,',c;.,dKXNNKxlkNNXXKOo.    .c:. 'ol.....,,,:;..dXNXKOkOx,                          
                                  .,lkKNNNXKd'.:ld0KKKK0xc;,'.........,:odxoc,.;kNNNN0l.   ...........   ....',:lodkO0KKNWMWNKOOkkxxdlllcclc;,,..''.....l0xcoddxxkkOxoc;,:oO0OOkl,oKKo,::. ...l0Kx;:l;,;lo.    .;,,,',,::,,c:.,x0XNKOxclkxdooo:.   .':'..:o:.... .;;'..l0XXXKOkOx,                          
                                   .,:oOXXXKx;';:oO0OOkdddddlc:;'.......,''...;kNWWNO;.   ...    ....,;:lddxOKXNNWNNWWNXXNWWWNK0OOkxoc::;,,.....    .',.,k0l:odkOO0O0K0kxkO00kxc,lO00x:;'. ..'xXKx;;ll:::,.   .';,;,'';cl:;;,..;:;:;,'..... .      .,'..,c;.... .;,..'oKNNXX0Okkd'                          
                                    ..;ckXXXX0kxk00Okxdoolllc:;;;,,;;;;,..,;,cOXXNKo. ......'',;cloxOOO0KXKXNNWNNNNNNXK0Okxolc:;,'............;;.   ....:OKOl:cx0KKK000kxxxk0xccdO00KKOdl:;:d0NXOl'...'.     ..',:;'',codl,....  ':c:lxdoc,..    ..'...';,..,'..'....dXNNNNXKOkko.                          
                                      .':x0XXK0Okxxdl:;,,;,;;'.....',;coc,..:xKK00l. ...',;:odkOO00O000000Okxddolc:;,'....           ..;;;::'.';;,'.',,:x0KK0koloxO000K0kdolccoOO000KXXNWNNNWNKd:,'....      .,';;'';cldxxxo;:c..:O0kKNNNKxc'.  ......,'...',.......;ONWNNNNK0kko'                          
                                        ..',,'....clcloxkO0Okl,..,,;,..',;'.:lokk:. .';;;:ldxxxddocc:;;,''..........    .....    .     .,oxl;;;',:cooolok0KKXNXKkdoddddddlcodxOOkO0KKXXXNWWWNKoccclc;.  .'. .'';:;,;codkkkOk:;d:.;0Kk0NNNX0xl'  ....''.. .'''.. ..,;cONWNNNNX0Oko'                          
                                               ..ckOKNNXXXK0Okdcccccc::c;..'co;,'  .,,''''''....      .''.    .,,''.  .':loc.    ...  ...'dxccc:;;';ododO0KXNWWNXK000xllodxkxxO0O0KKKKXXNNNNXd;loddoo'.';;..',;c:,,:ldkkkkOk:,ll':KNOxXWWNX0k:.  ..'..  .,,'..  .:oox0NWNNNNX0OOd'                          
                                               .cOXWWXk:;:ccoxkOOkkxxdll:'.....    ...               .,:::' ....'..  'lxOkxl.     .''. ...:xl;:::l'.;xkOKKKXNNNXKK0Od,.,::;cdk0K00KKXXKKXX0Ox:,okdl:'.;lc' .;;c:,,:ldkxxkko,.'lo;;OWKx0WWWNKOl'. .......''. ....'lxkk0NNNNNNX0OOo'                          
         ..                                   .l0XNWNk,..''.;ldxdoolc:,'.....    ........      ..'';cc:,,;'. .       ,d0XKKx,      .,;.   .ldcccc;. 'okOKXNNNNXK000d:'';;;,.cO00KKKKXK000xc;,:lo:'. .cdo' .;;:c:,,cdOxdkd:. .'ld;,kWXxkNWWX0ko'. ...','......,..;okxx0XNNXXK0OOOd'                          
                                             .;xKXNNXOl'.'';ldxdl;'..........  .',;'..'.      .,:;;:c,....    ..     'd0XXKOc.      .;:.    ..,'.....';:okKXNNKK00Ol.....  .lkkk0000K0Od:;c:lcol.  .:kd, .,:cll;,cxOxdxo;,',;:lo;.oNNxxXWWX0ko,....''..  ...:c;;:xOdlOXNXKKK0OOOd'                          
                                             .:d0XXXKKK0OO00Oko;.......,cc::,..';:::'..     ...;;,,,'.        ..     .lkO0KOl.       .;,.        .''',,''':kKKKK0OOd:'....,lxxdlclc;:c:,.;doddxc.  'xk;. .;cdx:'cx0kooc:c;;:'':l:.:KWOxKWWNKOx;.......    .;lolcokOooOXXXXK0OOOOd'                          
                                             .;ldk0K0KXKK0Oko:.  ... ...;;','..;:::::. .''. ....'''..  ..  .. .''    .;ooool:.     ...''.  .....  .,loo:,;,,lxxxxxxdoolccldxko:;:cc;......':c:,.  .c0d. .;ldxc':kKOolcll:,.. .:l:.'kWKxOWWNX0xc.... ..   .'colccokklo0XXKKKK00OOd'                          
                                              .....''',;;;,'.....;do,..........;clodd:..,:,...         .'. .',..',.   .,,,,'..    .:,......,;:,.  .,okOxooc;,;:;''col:;::::cc;:ol:ccl,..'    ......o0c..:ldOd',xX0olclo,..,cc,:ll;.oNXxxNWWN0kl'.....    .,col::dOkoxXXXKKKK00OOo.                          
                                                              ...:k0Oo,........:x00K0x, .,,,.    .:;.  .,.  .,c'.,,.    .....     .,. ...,col,.    ..'',,;llcloo;..',:dl:cdxxxxkdcc:c'    .'::....'dx,.;ddkk;'dXKoc;;l,.,oxc..;ooc.:KNOdKWWNK0d,......  .',:ll::x0OokXNNXKKKK0OOo.                          
                                                                 .:x00kc,.. .;;;xXXXXXd. ......',:dc.  ...    ';.  ..,codxkxdol;,.    .;ldo:.      ...   .,lxkOOc.  'xo,;:lO0dlc;;,'.    .lxl'....cxl.,oxkkc,dNNxl:,c;.ckxc,. ,ool''kN0dOWWNXOo,....... .,:coo::xKOdONNNXK0KK0Okl.                          
                                                                  .'oO0dc. .;:,'lKNKKNKc.  .',:cclc.   ..        .'l0NWWWWXkdxdolc,..,lddl;,.    .,c:::,.  .;;;,.   .:doox0kc.......... 'oxc.....cdl,;oxkkc,oXNOdd;,c';kxc:;,,;loo,.cKKdkNNX0xl,...';'. .,:coo:ckKkd0NXNXKK000Ok:.                          
                                                                    .;l;. ..';;':OXXXNNk;. .,,;::ldo:;';l'      .:kXWWWWWX0kxxxxdc::ldo:'..:,...'ckd:clcc'       ..   .',;,.':oo:,.... .oo;.....coc';ldkOd,cKWKdkk''c',oc:;,c:,ldoc.,k0xxXN0Oxo;.....    ,:lol:l0Kxo0NNNXXK0000Oc.                          
                                                                     ,o:'...',,.'dXNNNWKd'..';,;:ldO0Kkl:.     .:dOKXXXKxoccc:clccd0k:.    .':lcdOkxxolol'      .::..     .:llc,.     .:c;.  .'cc;.'ldxkx::ONN0OK0;.c:..',.....cdl;..,;,':doooc,.       .,clol;o0Kxd0NNNXXXK000Oc.                          
                                                                    .dOkdo:.'loc,cOXNNNXOc. .,;:coxkKNNk,     .cxOKK0Od;;;;,;;,;d0Kd,.  .  .co;:do;,'''.       .:c;....  .;:,..      .':;.  .,c:...;oxkxl:kNN0k0XKo.,l,...  .::,,',;clll::lc'..         .;loxo;oK0ddKNNNXXXK000x:.                          
                                                                    ,kkdodc.'lxd:;d0XNNNNO, .'ccclox0NWW0c....,dxOXK0l,:ddc::;l0Xk;.  ..'. .';;::.            ..'..';:'. ........    .,,...,cc,.  ,oxkxc:kNWKdOXXN0:.,:,.   'l;.:x0XNNNX0kkxolc,.      .'codxo:dK0dxKNNNNXXK000x,.                          
                                                                    ,okOxc.,okkkd:dXNNXXNNd. .;'...;kNWWW0llc.,c:lool''k0c::',okl.  ..'....       ....'',''...',,'''...... .''''.   .....,cl;.   ,dk0Ol'lXWXxxXWWWW0;.',.    .;lkKNNX0kkxdoodxOOd;.    .;lodxockX0xxXNWWNXK0000x;..                         
                                                                    'okOd',x00OOkldXKd:;:co,  ..  .,dXWMMXdc,..;,,,,,',xKo;'',.. .',',;'''     ...,;coddxddxxkkxkOkkkkkkxxxxdolc:,... .,coc.    .lkOOx:;OWNxo0WWWWWWk' .... .,lkKKOdccc;',;:lOKK0k;    .:lodkockX0dkXNWWNNXK00Odclo,                        
                                                                   .:0kxx;,xKK0KKxlxd..,' .;. .::;cd0NWWWKc.  .;;,::lxocoxdc,....:l:;:;,,.    ..';;:lodddddkOOKXXXNNNNXXXXXXNX0xdl;..'co:.  .'..cxOOd:,dNW0okNWWWMWW0:..   .;dkKXOc:xKKo:dkc'l0K0Od.   .:ddkOdckX0dkNNWWWNXKOkkocxKk:.                      
                                                                   .lkdll:'cxl:lk0dox;.....c: .oO0XNNNNNN0:    .;:lxk0KOxooolcoxkxlcc:,'.      .',;:clllloxkxk0KKXNNNXXXXXXXXKkc;...,:;.   .,..:xkOx;.cKWKxxKWWWWWWNKl...  .o00NXd:kWWKldNXOc'dKK0O:   .cxxkko:ON0dONWWWWWXKOkkl:x0KO:.                     
                                                                   .':lll,':'. .;OOokOdcclxx,.cOXXXXXXXK0kc..   .:dO00XNNNXXXWWNXOddo:'.        .......',;;:::cloddxkOOOOOOxo;....,:;.    .;. ,xkOkc.,ONXxdKNWWWWWNXXk;... 'd0XWNo;OWNxl0WXKd'l000k:.  .cxxkkl;kXOdONNNNWNXKOkkl;okO0k:.                    
                                                                    .'....,dc...;OX0xxkkOkdc:oOXNNNXKK0Od:,:;.   .,ok0XWWWWWWWWNX0kdc'   ...   ..  ....... .................  .';c:'.     .. .cdxk:.'dKXkd0NWWWWWNNXK0o..'..c0KXXk;;k0coXNKx;,ldxxl'  ..cddkOl;kNOdONNNWNXXKOkxc.,ldOOd,                    
                                                                     ''.,ccoxdodOKXXK0Okxl::cdO0XNNN0Okd:.... ..,...':ok0XWWWWNX0d:..   .',. .,,....;;,. .;::.....   .,..;,  ,lc,....          .''. 'oOxokXNWWWWWNNXKOkc... .cdxkOxl:,'cxxoldkxxdl,.   .lddkkc,kXkdOXNWWWXKK0Ox:.'::c:.                     
                                                                     .:lccoxocdOO0OO00KKd.. .;kOO0KXXKx;';:::llc:,......';cllc:,..      ..   .,,'...':c:..:l:';:'..,.,l,.;:':l:.  .'.                .',ckKNNWWWNNXK0OK0o'    .:oxOK0xdkO0KXNX0x:..  ..'lddkk:,xXkokXNNNNKKK0Ox:..'....                     
                                                                     .:dllxOOl:ooooxxxO0d,...cxdlcoxxo;.:l,.,ooc;,'''.                .':;. .:ol'.   ..'.. .',c;..:o,.;'.'ldl'.   .'   .      ..         ..;cok0KXXKOOKK0l.     .,;lOKXNNXKK0x:.  .....'ldxOk:;kXkdOXWWNNNXKK0x;...  ...                    
                                                                      ..,;lx00xddo;:oddolc::cc;',,'..   ':;',,.. .......',,'''........';;;'..cc. ..'..      ';'. ..:c...,dxc.     ,;.        ,c,.   ....,..   ..';:loxO0k;          .;:ccc:,.... .,cc..'coxkx:;kXkdOXWNNNNXXKOd,.     ....                  
                                                                           .l0d:lOo..,clloddl;,,,;;'      ...  ..';cclodxkOOkkOO00OOkxdoc,. ... .;lol:,. . .... 'c:'...lxd;...   .lc.       ;xl.  .,'.,xOc:c,.      ..,:,...,:c;.       ....'cdd:..;;...:loxd::kKOxOKNNXXXKK0ko'  .';:;,...                 
                                                                            .:;;cl'  .oo;;ldllolc::'   .......';;;cllloxkO0KKKXXXXXXXNNX0o....'',:::coo:;;...    .,. 'x0x:':do'  .dd.     .lOd'  ,c;.,x0xcdOk;.        .':dkOKKO;.'.  .;:ldxdxO0o'..,. .,::cc'.o0Ox0XXXK0kxkxxo. .;odolol:'.                
                                                                                    ..,clld:...''..   .....',,;cclloodddxkkO0KKKKKKXXXX0x:...;::clodOKXKK0Okxdl;.   ,kOd;..'''.  .xx.    .dOd'  'c:.'dKOoxKKkc.     ...;lxOKXXXx,... .';;lxxo;,,.............  .,'',;:cc:;;::c;. 'clodlcldo:.               
                                                                                     ......               ..  .......''',,,;::::cclddllc'.   ..',:lokOOO00KKXXXKx' .xKO:.  .:c;. .xk:c, 'dd:.  .:c,.lK0odXNKkc.    .''';lxO0Oxl,... .,'',',........ ..'''..  .  ....              ,lcldddxkxc.              
                                                                                                                                  .;c;'.        ..........''',,,,. :KXd.   .:cc' .xO:c;,ol'',..;c,.c00ddKNX0d:.  ..  .'';cloodl,,,. 'c:'.  .';lxkxc....',,...,..:dd:'.          ....::cdkOOkxo,.            
                                                                                                                                   .';'   .... .,:,.   ..      .. .oNXc.     ... .oO; .;,. ...,c;.:O0xd0NXKko,. ..   ..,,:lx0KOc,'. 'c:'. .,:;cx0Oo,....''.';'..cdxlcl,.'.      .,..,ccldkOO00Oc.           
                                                                                                                                     .. ....'. .;c:,. .  .,.. .;l'.dNXc  .'...::..:xc. .     ':;.,x0xdOXXKOd;.      ..,;cloxKXkc;;.  ...'...,;,;::cldxc....,''.'okklcooll,      .,...:cllok0XKX0l.          
                                                                                                                                      ..,,..;,. .coo;.  .:c,.  'c;'dNXo. .:l'.,,. ,oc.   ...';;.,d0kokXXX0x:.       .';;:odxO0d',:.   .:xxc..',:lx0KXX0l...,,'.;k0Oooxdxx:.      ,:'.'cllloOXXXXKd'         
                                                                                                                                       .;o:....  .:oo;...lo;....,c':0NO:. ,c' .'. .cc.  .:c;:;.;x0OoxKXXKOl'         .,c:;lllc,..cc.  .cO0Oc.,::lOKXNXXO:..''..:k0OdxkxxOo.      .',..,looooOXXXXKx'        
                                                                                                                                        .,odl,.    .,;;.'okl... .;:'oKKk;  ..,;;. .;:.  ,l::c''d00ddKNXK0x;.      ..  .,,...',''.:o;.  'okko,.;::oOKK0kl,...''.cOKkdk000Od;.  ..   ....'ldddokKXXXKk;       
                                                                                                                                          ..;l:,'...  . .o0d.    .,''oOOl.  .'.... .,'. .,;c;.c0Kxo0XX0OOo' .... ';.       .';;'.'oc.  .';lxxo;;c:coo:'.  ..,;.cOKkdOKK0Od;.  ....  ..'..:odooxKXXXXO;      
                                                                                                                                            ..........  .lOd. ..   . .:dd;.     ....''. .'c;.:kKOdONXKOkx;. .;c';o,          .;;..;o'  .,:dOKKd,'....';:,..';;'l0KxxKNK0Ox;.    ....  ',..'lxdldKXXXXO:.    
                                                                                                                                             .'''....    ;kx,..'....  ..:o:.  .:;.  ... .;c'.oKOdOXNX0kxc.   ...od.           .,'.'oc. .;;ckKK0o;'.,ccokx:'.;:;o0OdkXXKOOx:.      ...  ';,..lkxoo0XXXX0c.   
                                                                                                                                              ..',;,,'''..:l;.     ...  .,ll'  ;o:. .. .,l;.:O0xkXXX0Oxl.      ,l,           ..';,.ld'  .,;lxkdc'...:lloxc',::,oKOd0NX000x;  .      ....'c;..ckxllkKXKXKl.  
                                                                                                                                                ..'',;;:'.'::'.   .,,.....'lc. .cdc.  .,cc,:k0xOXNXKOxc.      .lc.   .      .,:;;;.;dc. .',,'...'....:lcc;,:c;;xKkdKNXKK0x; ':.       ....;:'.;dkdlxKXXXKd' 
                                                                                                                                                 ...';:c:..;:,....,;,....  .,,. .cxc. ':;':k0xxXNNX0kl....    ':.   .,,.     .;;,'.,odc......,okOko'..,;;';:;':OKxxXNNXK0x,.,oc.          .;:,.,dkxod0XXXXx,
                                                                                                                                                   .',;:c;..;,...:c;....  ...,,. .c:..,,.:OKOx0NNX0ko'..''.   ',.    .:l,.    .,;'.,odo'  .',ckKKKKd.';::,;:..oK0xkNWNXK0d'.';;.   ..      .;c,.;xkxllkKXXKk
                                                                                                                                                    .,;;::'..'..;xo'  .  ':,..''  ...;:.,xKOxOXNX0ko, ..';;.  ..      .cdc.    .'..,dxl.  .;::okO0Oo;';:,';:.'xX0x0NNXXK0d' .      ..       .,:'.:dxxoox0KKK
                                                                                                                                                      .'::,.....ok:..   .clc;....  .,l;.o0OxOXNX0Ox;...'.',;.          .cxo'       'ldc.  .,;;;:cloddl;,,';;.'kXOkKWNXKKOo.         ...      .,c,.,okxdod0KK
                                                                                                                                                        .;c;'. ,kd'      ,olc:.... .c:'l0KkOXNX0kdc.  ..,;;,'.          .:kd.      ,od:.  ..',;ldOKKK0d;'',;.,kXOkKNNXXKOl.   ...    ..       .;l;.'okdoodkK
                                                                                                                                                         .'::;.:xl.       ':cl:.. .:c;c0KOOKNX0Okl. .    .,;;;,..        .:xl.     ;oo;   .,coxO0KXXXNKo'.;;';OXkkXNNXXKk:.   .,,. .  ...      .,c;.'lkdodox
                                                                                                                                                           .;:.;dc.  ...   ..,:, .:l;ckKOkKNNK0Oo'.....   ..',::;,..       ;d:.   .:oo,  .;ldxO0KKXXXXKx:',,.c0XkxXNNXXKx;    ..;codl. ...       .::.'okxxxo
                                                                                                                                                            .;',oc....,,,,'.  ...,c::x0kx0NNK0Od,..',;,'.   ...',;:::'.     ;l,   .:do,  .,cdxk0XKKKOxl;..,'.:0XxxXNXXXKx;  ..,:oOXXKd' .'..      .cc,'cxxxd
                                                                                                                                                             .,,c:''.  ..,:;.   .cccxKOoONNX00k:. .';;::;;.  .'...,cxkd;.    ,:'  .cxo;..,;,:dk00kl:'.....,,.:0XdxNNXXX0x,  .,:clxKXXKk,  ...      'oo,.cxxx
                                                                                                                                                             .',;c,',. ......  .clcd00dxXNN0OOl.   .';;;:ol. ':' .',;lO0x:.  .,:. .okd;..;cc;clc,..';ldd:',;':0KxkNNXXX0d.  .';clox0KKKx'  ..   ..  ,oo;';od
                                                                                                                                                              .,;:;''. .;,..  .:lcoO0xxKNXK0Od'   ....;clodc',,. .,:;,;okOxc. .,, .dkl'..',,......;loxxd;'::,l0KkkNNXXX0o.   .;;clodkOx:'      ...  .;odl,.c
                                                                                                                                                               .,,;,.. .::;,..;ollOKOx0NXK0Ox;.   ..'.':loodddl;.  .:l:,,cxOkc..  .oo'.      .::;;,:oxxo;'::,l0KOOXNXXKOl. .. .;;:c;,,..      .'...',.,ldo,'
                                                                                                                                                                ..''.. .;ll:':olcxK0xkXNK0Ok:...   .,;'';cloxkkko'  .;oo:.'oOOd'  ,c,.        ':::;;lll:'';:,l0KOOXNXX0kl.     ...  .,:;.     .'. .....'coc'
                                                                                                                                                                 ...'.  ,ld::doco00kkKXK0Oko.  ..  ..,;,',coddxkkx:.  ':;. .cO0d'.;,.          ':;;:cll:'';;'l0KOkXNXX0xc.         .cOKOo'   ...        .;lo
                                                                                                                                                                   .... .:c:oxllk0kxKNX0Okd,.   ..''..';;,':ldddxkx;.       .;k0o,'..          .';:okkkl',:,.o00OkXNXKOx:.  ...    .cx0K0d'.  .          .;l
                                                                                                                                                                    ...  .,cdl:x0xoONXK0kx;. ... ..''...,::;;cll:,..          ,kOl'.  .       ,cclclxkko;;c;.l00OkKNXK0kc.  .c;.   .:cdOkd:..''.          .;
                                                                                                                                                                         .,l:;d0klxXNK0Okc.  .':;,..    .'coc;''.              ,xOl. .;;.     .:lllclxxl;;c,.o00OOKNXK0kc.  .:c,....';:c:::cdxdc.          .
                                                                                                                                                                     ..  .:c;l0OoxXNK0OOo.  .,'':ll:'.    .,lo:,..              ,xkc..,cl'     .;cllclxl,;c,.o00kOKXK0Ox;.  .',:oo:.....:lox0KK0o.          
                                                                                                                                                                      ...,c::x0kkXXX0Okd,   .,;'.;ool:.     .;lc;.               :xo'  .'::.    .;cl:;;,,;c'.dKOkOKXX0Od;. .,:cd00x:. .;loodk0KK0o.         
                                                                                                                                                                      .lllc:oOOOXXK0Okk:.    .':;'''..   ..   .:lc.              .:c'.    ,lc'    ......'::''xKOkkKXXKOx, ..;lodk0Od,. ,clddxk0KK0d'.       
                                                                                                                                                                      .ldo;:xOOKXX0Okko....    'cl:.     .......':c,         ...  .;,.     .;ll:.     ..;lc',kKOxkKXXK0x, .'';lddxxo;..':clodxxO000k:.      
                                                                                                                                                                     .'cl;'lOOKXX0Okkd' .',.    'col:.  ......,'. ':,.       'c,  .,,.        .:l:'.   .;o:.;O0kxkKXXK0d'  .'';c:,......;ccloxddk00Kkc.     
                                                                                                                                                                     'cl;'lOO0XX0Okxo,    ..     .,lxd:.......'::. .;;.     .cc.  .','.          .,;,. .;c;.:O0OxkKXXKOd'    .....':loc,';::coxxdkO00Oo'.   
                                                                                                                                                                    .ld:.:kOOKKKOkxo,  ....        .:dxd:....',;lo,..',..  .:o,    .,'.             ....,::.;k0OxkKXK0Oo'       ':;cdkOd,.,:ccoxddxO00Od;.  
                                                                                                                                                                   .:dd,'dOOKK00kxd:.  .';;,'.       .:dkd;. .;::od;  ';.  'lo'    .,,.                ':lc.:O0OxkKXK0Oo'       ,l:,cxO0o..'::clddxkkO00x:. 
                                                                                                                                                                   ,dxl':xk0000Oxdc.     .,cll;.       .;dkd,..:l;cl. .,,..;l:.    .,'.                ,co:.cO0OxxKXK0kd;       .;cc:lxOOl...;ccodxxxkO00xc'
                                                                                                                                                                  .d0d:,lkkOkkkxdo,        .:oko.        .o0x, .;;,c:. .,..:l;     .,,.               .:oo:.:kOOxxKXK0Od;.       .:docokOOl..'loooxxxkkO0Oxl
&lt;/pre&gt;
Machine Head - Derek Hobbs 1995
&lt;p&gt;I grew up in the San Jose Bay Area. As of writing this, our company just graduated from the YC Fall 2025 batch. I'm not new to hustle-culture. I'm only where I am right now out of grit and the effort I invested into the things I loved in high school and college. Recently however, as a founder, I've become more attuned to Twitter (X) and LinkedIn, keeping up with &lt;em&gt;the vibes&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;There's a massive amount of hustle-culture being pushed on my timeline.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Performative posts from people showcasing themselves coding in the most absurd situations&lt;/li&gt;
&lt;li&gt;If you don't do X you're not going to make it (where X is some out of touch work hour target)&lt;/li&gt;
&lt;li&gt;Good morning posts &amp;amp; various rage-bait engagement farming tactics&lt;/li&gt;
&lt;li&gt;Ratio's and one-up's&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Every machine serves a purpose. People need &lt;em&gt;purpose&lt;/em&gt;. The temptation to &lt;em&gt;become the machine&lt;/em&gt; is higher than ever. The promise of the machine is alluring. If I can just keep chugging forward, I will end up somewhere that is not here. If I can turn myself into a mechanism that takes input and consistently works towards some goal, I will make it.&lt;/p&gt;
&lt;p&gt;I believe in hard work, but I think hustle-culture and the &lt;em&gt;vision&lt;/em&gt; being pushed on my timeline is a corrupted one. It's engineered for engagement, optimized by millions competing with one another with just one goal: to capture your attention.&lt;/p&gt;
&lt;p&gt;You're not working hard enough. You need to wake up at 5am. You need to be the first to arrive and the last to leave.&lt;/p&gt;
&lt;p&gt;This messaging works. Look at me. I feel the need to write a post about it. But it is completely wrong.&lt;/p&gt;
&lt;p&gt;Hustle-culture optimizes for work input because it's &lt;em&gt;sexy&lt;/em&gt;. It's easy to post the inputs. It's hard to face the output.&lt;/p&gt;
&lt;p&gt;The truth is you don't have to become the machine in order to succeed. The machine can't adapt. It can't learn the rules of the game. It is deterministic, set in place, chugging along at a linear pace.&lt;/p&gt;
&lt;p&gt;Instead, aim to be nimble. Adapt quick. Define your goal but don't let it become your purpose. Your purpose is sacred; only you truly understand it. Do what you need to do in order to achieve your goals. Don't optimize for sweat. Try to find the most rewarding solution. Optimize for what matters: speed, efficiency, or quality—whatever it may be.&lt;/p&gt;
&lt;p&gt;You're not a machine. You're a person. Play to your strengths. Be sharp and strategic like a scalpel, not blunt like a mallet. Stop fetishizing the grind. Dream bigger.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;You aren't a stupid blunt tool. Stop acting like one.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;[&lt;a href="https://armeet.bearblog.dev/blog"&gt;More Posts&lt;/a&gt;] [&lt;a href="https://armeet.bearblog.dev/web-mri-volume-renderer-in-rust"&gt;Previous&lt;/a&gt;] [&lt;a href="https://armeet.bearblog.dev/the-faster-shell"&gt;Next&lt;/a&gt;]&lt;/p&gt;
&lt;p&gt;
&lt;a href="https://armeet.bearblog.dev/blog/?q=pot-of-honey"&gt;#potofhoney&lt;/a&gt;
&lt;a href="https://armeet.bearblog.dev/blog/?q=thoughts"&gt;#thoughts&lt;/a&gt;
&lt;/p&gt;



&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://armeet.bearblog.dev/becoming-the-machine/</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 03:34:31 +0000</pubDate>
    </item>
    <item>
      <title>Correspondence Between Don Knuth and Peter van Emde Boas on Priority Deques 1977 [pdf]</title>
      <link>https://staff.fnwi.uva.nl/p.vanemdeboas/knuthnote.pdf</link>
      <description>&lt;a href="https://news.ycombinator.com/item?id=46371759"&gt;Comments&lt;/a&gt;</description>
      <guid isPermaLink="false">https://staff.fnwi.uva.nl/p.vanemdeboas/knuthnote.pdf</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 02:21:42 +0000</pubDate>
    </item>
    <item>
      <title>Show HN: Turn raw HTML into production-ready images for free</title>
      <link>https://html2png.dev</link>
      <description>The image generation API your LLM will love to use. Turn raw HTML into production-ready images for free. No sign up required.</description>
      <content:encoded>&lt;main class="flex-1"&gt;&lt;!--[--&gt;&lt;h1&gt; Convert HTML to PNG.&lt;/h1&gt;&lt;p&gt; The image generation API your LLM will love to use. Turn raw HTML into production-ready images for free. No sign up required. &lt;/p&gt;HTML EDITOR0 characters SETTINGS EXAMPLES&lt;!--[--&gt;OG Image1200×630GitHub Header1280×400Terminal Snippet800×600System Diagram1200×800Analytics Chart800×500Browser Mockup1200×900&lt;!--]--&gt;SIZE &amp;amp; FORMATWHPNGJPEGWebPPDFSOPTIONSDZTransparent BackgroundDEVELOPER API$_ COPY CURL  HTML PREVIEW1200×630 PNG&lt;!-- --&gt; HTML Preview ⚡GENERATE IMAGE&lt;h2&gt; Vibe-Ready Endpoint.&lt;/h2&gt;&lt;p&gt;Post https://html2png.dev&lt;/p&gt; The Request&lt;!-- --&gt; Parameters&lt;!--[--&gt;&lt;code&gt;html*&lt;/code&gt;&lt;p&gt;str Raw HTML string.&lt;/p&gt;&lt;code&gt;width&lt;!-- --&gt;&lt;/code&gt;&lt;p&gt;int Output width.&lt;/p&gt;&lt;code&gt;height&lt;!-- --&gt;&lt;/code&gt;&lt;p&gt;int Output height.&lt;/p&gt;&lt;code&gt;format&lt;!-- --&gt;&lt;/code&gt;&lt;p&gt;str png | jpeg | webp | pdf&lt;/p&gt;&lt;!--[--&gt;pngjpegwebppdf&lt;!--]--&gt;&lt;code&gt;deviceScaleFactor&lt;!-- --&gt;&lt;/code&gt;&lt;p&gt;int Retina scaling (1-4).&lt;/p&gt;&lt;!--[--&gt;1234&lt;!--]--&gt;&lt;code&gt;delay&lt;!-- --&gt;&lt;/code&gt;&lt;p&gt;int Wait time in ms.&lt;/p&gt;&lt;code&gt;zoom&lt;!-- --&gt;&lt;/code&gt;&lt;p&gt;num Viewport zoom (0.1-3.0).&lt;/p&gt;&lt;code&gt;omitBackground&lt;!-- --&gt;&lt;/code&gt;&lt;p&gt;bool Transparent background.&lt;/p&gt;&lt;!--[--&gt;truefalse&lt;!--]--&gt;&lt;!--]--&gt; The Response Fields&lt;code&gt;url&lt;/code&gt;&lt;p&gt;Public path to your generated asset. Immutable.&lt;/p&gt;&lt;code&gt;filename&lt;/code&gt;&lt;p&gt;Unique identifier generated for the file.&lt;/p&gt;&lt;code&gt;success&lt;/code&gt;&lt;p&gt;Boolean status of the render operation.&lt;/p&gt;Beyond MCP&lt;h2&gt; Not everything &lt;br/&gt;needs an MCP.&lt;/h2&gt;&lt;p&gt; Stop waiting for MCP server updates or proxy configurations. Your LLM agents are already capable of making HTTP requests. Give them the instructions, and let them render directly to the edge. &lt;/p&gt;01&lt;h4&gt;Zero Setup&lt;/h4&gt;&lt;p&gt;No plugins, no servers, no local tunnels.&lt;/p&gt;02&lt;h4&gt;Agent Native&lt;/h4&gt;&lt;p&gt;Works with Claude, GPT-5, and any tool-capable AI. &lt;/p&gt;A Single Prompt Paste into your Agent: &lt;!-- --&gt; Prompt &amp;amp; Vibe &lt;!--]--&gt;&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://html2png.dev</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 02:18:38 +0000</pubDate>
    </item>
    <item>
      <title>Autonomously navigating the real world: lessons from the PG&amp;E outage</title>
      <link>https://waymo.com/blog/2025/12/autonomously-navigating-the-real-world</link>
      <description>At Waymo, our mission is to be the world’s most trusted driver. We know trust is built through consistent behavior over time—earned through every mile we drive and every interaction we have with the community. This past Saturday, as a widespread PG&amp;E outage cut power to nearly one-third of San Francisco, our service was put to the test. With power now restored, we want to share an account of our operations during the outage and how we are evolving to better serve the city.</description>
      <content:encoded>&lt;article aria-labelledby="P0-0-title" class="_article_1d6j6_29 _type:blog_1d6j6_73"&gt;&lt;p&gt;At Waymo, our mission is to be the world’s most trusted driver. We know trust is built through consistent behavior over time—earned through every mile we drive and every interaction we have with the community. This past Saturday, as a widespread PG&amp;amp;E outage cut power to nearly one-third of San Francisco, our service was put to the test. With power now restored, we want to share an account of our operations during the outage and how we are evolving to better serve the city.&lt;/p&gt;&lt;p&gt;The scale of the outage and the sheer number of disabled traffic lights were the primary contributors to city-wide gridlock. As signals went dark across major corridors, the resulting congestion required law enforcement to manually manage intersections. The situation was severe enough that the San Francisco Department of Emergency Management advised residents to stay home, underscoring the extraordinary nature of the weekend’s disruptions.&lt;/p&gt;&lt;p&gt;Navigating an event of this magnitude presented a unique challenge for autonomous technology. While the Waymo Driver is designed to handle dark traffic signals as four-way stops, it may occasionally request a confirmation check to ensure it makes the safest choice. While we successfully traversed more than 7,000 dark signals on Saturday, the outage created a concentrated spike in these requests. This created a backlog that, in some cases, led to response delays contributing to congestion on already-overwhelmed streets.&lt;/p&gt;&lt;p&gt;We established these confirmation protocols out of an abundance of caution during our early deployment, and we are now refining them to match our current scale. While this strategy was effective during smaller outages, we are now implementing fleet-wide updates that provide the Driver with specific power outage context, allowing it to navigate more decisively.&lt;/p&gt;&lt;p&gt;As the outage persisted and City officials urged residents to stay off the streets to prioritize first responders, we temporarily paused our service in the area. We directed our fleet to pull over and park appropriately so we could return vehicles to our depots in waves. This ensured we did not further add to the congestion or obstruct emergency vehicles during the peak of the recovery effort.&lt;/p&gt;&lt;h4&gt;The path forward&lt;/h4&gt;&lt;p&gt;We’ve always focused on developing the Waymo Driver for the world as it is, including when infrastructure fails. We are analyzing the event, and are already integrating the lessons from this weekend’s PG&amp;amp;E outage. Here are some of the immediate steps we’re taking:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Integrating more information about outages: While our Driver already handles dark traffic signals as four-way stops, we are now rolling out fleet-wide updates that give our vehicles even more context about regional outages, allowing them to navigate these intersections more decisively.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Updating our emergency preparedness and response: We will improve our emergency response protocols, incorporating lessons from this event. In San Francisco, we’ll continue to coordinate with Mayor Lurie’s team to identify areas of greater collaboration in our existing emergency preparedness plans.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Expanding our first responder engagement: To date, we’ve trained more than 25,000 first responders in the U.S. and around the world on how to interact with Waymo. As we discover learnings from this and other widespread events, we’ll continue updating our first responder training.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h4&gt;Undaunted in our mission to make our streets safer&lt;/h4&gt;&lt;p&gt;We live and work in San Francisco, and we are grateful to the city’s first responders for their tireless work, and to Mayor Lurie for his leadership.&lt;/p&gt;&lt;p&gt;Backed by 100M+ miles of fully autonomous driving experience and a &lt;a href="https://waymo.com/safety/impact"&gt;record&lt;/a&gt; of improving road safety, we are undaunted by the opportunity to challenge the status quo of our roads, and we’re proud to continue serving San Franciscan residents and visitors.&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://waymo.com/blog/2025/12/autonomously-navigating-the-real-world</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 02:16:01 +0000</pubDate>
    </item>
    <item>
      <title>Open source USB to GPIB converter (for Test and Measurement instruments)</title>
      <link>https://github.com/xyphro/UsbGpib</link>
      <description>📰 Latest updates 🔨 Buy it or build it 👋 UsbGpib Introduction 🏠 Housing / Enclosure 💻 Software 🔌 Using the device ⚙️ Setting and getting parameters ✔️ Testing status 📓 Tutorials &lt;- New! ❤️ Support the Project</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;h1&gt;Table of contents&lt;/h1&gt;&lt;a href="#table-of-contents"&gt;&lt;/a&gt;
&lt;p&gt;📰 &lt;a href="https://github.com/xyphro/UsbGpib/blob/master/Updates.md"&gt;Latest updates&lt;/a&gt;
&lt;br/&gt; 🔨 &lt;a href="#buy-it-or-build-it"&gt;Buy it or build it&lt;/a&gt;
&lt;br/&gt; 👋 &lt;a href="#usbgpib-introduction"&gt;UsbGpib Introduction&lt;/a&gt;
&lt;br/&gt; 🏠 &lt;a href="#housings"&gt;Housing / Enclosure&lt;/a&gt;
&lt;br/&gt; 💻 &lt;a href="#software"&gt;Software&lt;/a&gt;
&lt;br/&gt;     🔌 &lt;a href="#using-the-device"&gt;Using the device&lt;/a&gt;
&lt;br/&gt;     ⚙️ &lt;a href="#setting-parameters"&gt;Setting and getting parameters&lt;/a&gt;
&lt;br/&gt; ✔️ &lt;a href="#testing-status"&gt;Testing status&lt;/a&gt;
&lt;br/&gt; 📓 &lt;a href="https://github.com/xyphro/UsbGpib/blob/master/Tutorials/README.md"&gt;Tutorials&lt;/a&gt; &amp;lt;- &lt;strong&gt;New!&lt;/strong&gt;
&lt;br/&gt; ❤️ &lt;a href="#support-the-project"&gt;Support the Project&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Summarized latest updates&lt;/h1&gt;&lt;a href="#summarized-latest-updates"&gt;&lt;/a&gt;
&lt;p&gt;For detailed visibility look under the Latest update link above!&lt;/p&gt;
&lt;p&gt;[30th Nov 2025]: &lt;strong&gt;Released new firmware version V2.2&lt;/strong&gt;. See &lt;a href="https://github.com/xyphro/UsbGpib/blob/master/Updates.md"&gt;Latest updates&lt;/a&gt; section.
[23rd Nov 2025]: Added a User manual for UsbGPIB V2 under the Tutorial section&lt;/p&gt;
&lt;h1&gt;V3 Preview&lt;/h1&gt;&lt;a href="#v3-preview"&gt;&lt;/a&gt;
&lt;p&gt;As I have an outstanding Betatestprogram for V3 I want to share some updates - on this main page.&lt;/p&gt;
&lt;p&gt;Here the "messy table view" during some later software development :-)&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/xyphro/UsbGpib/blob/master/pictures/V3SneakPreview.png?raw=true"&gt;&lt;img src="https://github.com/xyphro/UsbGpib/raw/master/pictures/V3SneakPreview.png?raw=true"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The schedule slipped a bit while getting the V2 adapter ready for sale, but V3 is converging and nearing completion. A batch of prototypes has been ordered with CNC aluminum housings, anodizing, and laser marking.&lt;/p&gt;
&lt;p&gt;Progress:&lt;/p&gt;



Item
Comment &amp;amp; State




Hardware
Optimized after two extra iterations; GPIB-compliant electrical characteristics; prevents back-powering from device GPIB bus


POE
Fully works. Challenging to get right, but finally working well and cost optimized


Mechanics
Six (!) 3D designs completed; 3D-printed housings with/without Ethernet; CNC machined housing prototypes ordered


GPIB stack
Fully up and running and "ruggedized"


USB Boot loader
Complete; UF2-like workflow for easy use without special software and tested functionality with Mac, Windows, Linux


USB high speed functionality
New MCU USB stack written from scratch for low latency and high throughput


USBTMC
USBTMC part fully works and passes several compliance / stress tests


Ethernet
Ethernet stack and low level driver is fully done and ready


VXI11 &amp;amp; HiSlip
VXI11 mostly complete with ongoing optimizations; HiSlip near finalization with minor polish remaining



&lt;p&gt;The prototypes will arrive approximately end of January.
Very keen on bringing them up and distributing!&lt;/p&gt;

&lt;h1&gt;Buy it or build it&lt;/h1&gt;&lt;a href="#buy-it-or-build-it"&gt;&lt;/a&gt;
&lt;p&gt;Tired of tinkering? Want to skip the hassle and get straight to using your GPIB setup?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I’ve teamed up with Elecrow to bring you ready-to-roll GPIB-USB converters – perfect for those who want results, not a weekend project.&lt;/li&gt;
&lt;li&gt;These adapters come fully assembled, programmed, housed, tested, and ready to go. No fuss. No build. Just plug it in and start working.&lt;/li&gt;
&lt;li&gt;The Adapters match 100% the V2 version described in this repository.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Grab yours now:&lt;/strong&gt; &lt;a href="https://www.elecrow.com/xyphrolabs-gpibusb.html"&gt;&lt;/a&gt;&lt;a href="https://www.elecrow.com/xyphrolabs-gpibusb.html"&gt;https://www.elecrow.com/xyphrolabs-gpibusb.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Let the data flow begin!&lt;/p&gt;
&lt;p&gt;This doesn’t mean I’m going fully commercial - far from it.
Offering pre-built adapters is simply a convenience for those who’d rather skip the build and get straight to using their gear.&lt;/p&gt;
&lt;p&gt;All sharing, support, and collaboration will remain fully open, just as before.
This is about choice, not change!&lt;/p&gt;
&lt;p&gt;The full design files are located in this repository in case you want to build the devices yourself.&lt;/p&gt;

&lt;h1&gt;UsbGpib Introduction&lt;/h1&gt;&lt;a href="#usbgpib-introduction"&gt;&lt;/a&gt;
&lt;p&gt;Versatile, cheap, portable and robust USB to GPIB converter (USBTMC class based).&lt;/p&gt;
&lt;p&gt;You'll find many projects like this, but this one is special (ok, everybody will claim this) :-)&lt;/p&gt;
&lt;p&gt;V1 Hardware:
&lt;a href="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/UsbGPIB.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/UsbGPIB.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;V2 Hardware:
&lt;a href="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/Upcoming_Rev2.png"&gt;&lt;img src="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/Upcoming_Rev2.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you have a lot of test equipment at home, you might know the issues: Lots of devices only have GPIB as interface and the GPIB adapters and GPIB cables on the market are very expensive and some of them even have many issues, when run under Windows 10 (device driver does not work). Or they e.g. are not able to be operated with VISA, because they are UART based, need special command sequences, ...&lt;/p&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/SizeComparison.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/SizeComparison.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;
The adapters are also typically very long, such that they extend the overall length of your test equipment by at least 10cm (~4 inches).
&lt;p&gt;Apart of the 2 very big manufacturers, other GPIB adapters, e.g. with Ethernet or also USB interface are not recognized by normal VISA providers or PyVisa, making the measurement control implementation specific for your GPIB adapter.&lt;/p&gt;
&lt;p&gt;I've got frustrated and tried to turn it into something positive. Here a video showing the final device in action - click to view:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=pZp1QZCXrF8"&gt;&lt;img src="https://camo.githubusercontent.com/6a01fcdef70d3788cbed2fa56192ddc2237c0213b8bc6ff54af353611be19348/68747470733a2f2f696d672e796f75747562652e636f6d2f76692f705a7031515a43587246382f302e6a7067"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Some goals of the project were:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Work based on the standard USBTMC protocol. This allows the GPIB test equipment to look like a normal USB based measurement device and work flawless with e.g. NI VISA, Labview, Matlab or PyVisa.&lt;/li&gt;
&lt;li&gt;Have a small length - otherwise my equipment has the risk of falling from the shelf :-) Also the USB cable should connect 90 degree angled, to make it very short. With V2 HW, the length got further reduced to the size of a GPIB connector.&lt;/li&gt;
&lt;li&gt;It should be cheap but still versatile (you can build a single one of these for only 14 USD!)&lt;/li&gt;
&lt;li&gt;It should support ALL my test equipment, from many different GPIB implementation generations and different GPIB flavors&lt;/li&gt;
&lt;li&gt;The Firmware should be upgradeable over USB&lt;/li&gt;
&lt;li&gt;It should be rock-solid (!) I don't want to end up in a very long measurement being interrupted because of a software issue of my USB GPIB converter.&lt;/li&gt;
&lt;li&gt;It should support additional features like serial poll, remote enabling/disabling&lt;/li&gt;
&lt;li&gt;If there is no GPIB device connected to the USBGpib converter, or the GPIB device is powered down, there should be no USB device visible on the PC.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All those goals are met.&lt;/p&gt;

&lt;h1&gt;Hardware&lt;/h1&gt;&lt;a href="#hardware"&gt;&lt;/a&gt;
&lt;h2&gt;Microcontroller choice&lt;/h2&gt;&lt;a href="#microcontroller-choice"&gt;&lt;/a&gt;
&lt;p&gt;Although I typically would prefer nowadays an ARM Cortex M0/3/4/7 controller, there is an issue with it. Available devices support only max. 3.3V supply voltages, such that there would be a requirement for a level-shifter towards the GPIB Bus.
GPIB is based on 5V (not exactly true, but a first iteration).&lt;/p&gt;
&lt;p&gt;This limited the microcontroller choice to e.g. AVR or PIC controllers. Because of very good availability I ended up in ATMEGA32U4 controllers.
Apart of the device supporting 5V I/O voltages, it also does not require a regulator to be part of the application - it has an internal 3.3V regulator. This minimizes the full application schematic and BOM.&lt;/p&gt;
&lt;p&gt;Apart from that, there is an excellent USB stack available &lt;a href="http://www.fourwalledcubicle.com/LUFA.php"&gt;http://www.fourwalledcubicle.com/LUFA.php&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The GPIB side of the schematic can be directly connected to the ATMega32U4 IO pins. The IO pins from the microcontroller side are only set to 2 different states: Tri-state (input) or output LOW, to talk over GPIB.&lt;/p&gt;
&lt;h2&gt;Component sourcing&lt;/h2&gt;&lt;a href="#component-sourcing"&gt;&lt;/a&gt;
&lt;p&gt;All components are easy to source, so I only specify the potential critical ones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;16 MHz Crystal: Farnell 2853867 - MCSJK-7E-16.00-8-30-100-B-30&lt;/li&gt;
&lt;li&gt;REV 1 GPIB connector: Farnell 2421095 - NORCOMP 112-024-113R001. For REV 2 use a straight 24P male solder type connector e.g. from AliExpress.&lt;/li&gt;
&lt;li&gt;USB connector for V1 HW: Farnell 2668483 - Amphenol ICC 61729-1011BLF&lt;/li&gt;
&lt;li&gt;USB connector for V2 HW: Best is to look on AliExpress for 57 series 24P connector as a starting point.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;PCB&lt;/h2&gt;&lt;a href="#pcb"&gt;&lt;/a&gt;
&lt;p&gt;The PCB can be ordered at nearly any PCB pool production service (e.g. 10 PCBs for 2 USD + shipping). The gerber files are included in the "HW/Gerber files" subdirectory.&lt;/p&gt;
&lt;h2&gt;Mounting the PCB &amp;amp; Flashing the firmware&lt;/h2&gt;&lt;a href="#mounting-the-pcb--flashing-the-firmware"&gt;&lt;/a&gt;
&lt;p&gt;The PCB is available in 2 revisions.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/xyphro/UsbGpib/blob/master/HW/REV1/README.md"&gt;REV 1&lt;/a&gt; is the most popularly used right now due to age. It has a USB Type-B connector and an L-shaped housing visible on a few photos of this page.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/xyphro/UsbGpib/blob/master/HW/REV2/README.md"&gt;REV 2&lt;/a&gt; has some improvements like being smaller, better fit and USB Type-C connector.&lt;/li&gt;
&lt;li&gt;A REV 3 is upcoming. It will be a major redesign with more speed, Ethernet and power over Ethernet support, but the same DNA: Standard protocols being used and ensure compatibility and stability!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Choose whatever you prefer. The software images, but also the external behavior is the same.&lt;/p&gt;

&lt;h1&gt;Housings&lt;/h1&gt;&lt;a href="#housings"&gt;&lt;/a&gt;
&lt;h2&gt;REV 1&lt;/h2&gt;&lt;a href="#rev-1"&gt;&lt;/a&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/housing.png"&gt;&lt;img src="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/housing.png"/&gt;&lt;/a&gt;&lt;a href="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/housing_snap.png"&gt;&lt;img src="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/housing_snap.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I created a sophisticated 3D printable housing for this adapter. The design was made with Fusion 360. The project file + the STL files are included in the "Housing" sub directory.&lt;/p&gt;
&lt;p&gt;The PCB fits perfectly into it. Optionally it can be fixed with 2 mounting screws (the GPIB connector has 2 threads, use 2 times 4-40 UNC x 3/8) and the TOP cover snaps onto the housing base.&lt;/p&gt;
&lt;p&gt;I printed this using an Ender 5 3D printer with black PLA, 0.15mm layer height, 1mm wall thickness, no support.
Take care, that you rotate the TOP part of the housing by 180 degrees, so that the flat side is located on the printer bed.
Printing works fine, several iterations of the design were made to ensure good printability.
I printed so far 15 housings, without a single fail.&lt;/p&gt;
&lt;p&gt;More information on this REV 1 can be found here: &lt;a href="https://github.com/xyphro/UsbGpib/blob/master/HW/REV1/README.md"&gt;REV 1&lt;/a&gt;.
Note, that also the programming/build instructions moved to this location.&lt;/p&gt;
&lt;h2&gt;REV 2&lt;/h2&gt;&lt;a href="#rev-2"&gt;&lt;/a&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/Upcoming_Rev2.png"&gt;&lt;img src="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/Upcoming_Rev2.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The REV 2 housing is a lot smaller, but requires 2 screws.
The housing is quite important to be able to connect and disconnect the board without breaking anything. It is key for mechanical stability of the adapter.
When operating the device without housing, take very well care when plugging in and out the board in case the GPIB connector has a very tight fit.&lt;/p&gt;
&lt;p&gt;Information on how to build it can be found in the HW/REV 2 folder: &lt;a href="https://github.com/xyphro/UsbGpib/blob/master/HW/REV2/README.md"&gt;REV 2&lt;/a&gt;.
Note, that also the programming/build instructions moved to this location.&lt;/p&gt;

&lt;h1&gt;Software&lt;/h1&gt;&lt;a href="#software"&gt;&lt;/a&gt;
&lt;h2&gt;Source code&lt;/h2&gt;&lt;a href="#source-code"&gt;&lt;/a&gt;
&lt;p&gt;The source code of the Boot loader (slightly modified LUFA MassStorage Boot loader) and the main USBGPIB converter are located in the "SW" subdirectory.
At the time of publication LUFA 170418 release was used, with GCC as compiler.&lt;/p&gt;
&lt;p&gt;Note: The Software is compatible with any HW revision in this repository. For REV 1 and REV 2 hardware you don't need different SW images.&lt;/p&gt;
&lt;h2&gt;Binaries&lt;/h2&gt;&lt;a href="#binaries"&gt;&lt;/a&gt;
&lt;p&gt;For those, that just want to create their own device, I've included the binary output in the "SW/binaries" subdirectory.&lt;/p&gt;

&lt;h1&gt;Using the device&lt;/h1&gt;&lt;a href="#using-the-device"&gt;&lt;/a&gt;
&lt;h2&gt;USB enumeration&lt;/h2&gt;&lt;a href="#usb-enumeration"&gt;&lt;/a&gt;
&lt;p&gt;You might be surprised initially, that the device does not show up in your device manager (or lsusb), when you connect only the USB side. This is a feature, not a bug (really!).
Only, if a GPIB device is connected, you can see the device on your PC too.&lt;/p&gt;
&lt;p&gt;The reason behind the feature is simple: Instead of having a standard GPIB wiring, where you have a single GPIB controller and lots of GPIB devices interconnected, USBGPIB supports only a direct connection of the USBGPIB device to your measurement device. If you have like me e.g. 14 Instruments you don't want all to show up in the device manager, if the measurement device itself is powered down - you won't anyway be able to communicate with a powered down device.&lt;/p&gt;
&lt;p&gt;When USB and the GPIB side is connected, the device enumerates. The USBGPIB device reads out the ID of the instrument and constructs a unique USB Serial number out of it. It is thus easily possible to assiate multiple connected USBGPIB devices with the measurement instrument.&lt;/p&gt;
&lt;p&gt;The VISA ressource name is constructed from this USB Serial number. You can identify easily e.g. in NiMax, which device is connected:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/NiMaxExample.png"&gt;&lt;img src="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/NiMaxExample.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you connect your USBGPIB device afterwards to another GPIB measurement device, it will disconnect and connect with a new serial number string, matching the other GPIB device *IDN? response again.&lt;/p&gt;
&lt;h2&gt;GPIB settings on your measurement device&lt;/h2&gt;&lt;a href="#gpib-settings-on-your-measurement-device"&gt;&lt;/a&gt;
&lt;p&gt;GPIBUSB does probe all GPIB primary addresses (and secondary address 0) for presence of a GPIB Talker/listener. It is thus not required to set a specific GPIB address - GPIBUSB will find it itself.&lt;/p&gt;
&lt;p&gt;The only importance setting on the measurement device is, that the GPIB interface is enabled, which is typically the case.&lt;/p&gt;
&lt;h2&gt;LED indicator&lt;/h2&gt;&lt;a href="#led-indicator"&gt;&lt;/a&gt;
&lt;p&gt;The LED indicates different states:&lt;/p&gt;
&lt;p&gt;LED blinking: The USBGPIB converter is connected to a measurement instrument, it is powered off or its GPIB port is disabled. In this state, the device is also not connected to USB and will not show up in the device manager or lsusb.
LED on: The device is connected to a measurement device and GPIB communication possible. It is also accessible over USB
LED off: The device is not connected over USB, or the PC powered off :-)&lt;/p&gt;
&lt;h2&gt;Controlling GPIB devices&lt;/h2&gt;&lt;a href="#controlling-gpib-devices"&gt;&lt;/a&gt;
&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/towerOfGpib.jpg"&gt;&lt;img src="https://raw.githubusercontent.com/xyphro/UsbGpib/master/pictures/towerOfGpib.jpg"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As this converter implements the standard USBTMC Test and measurement class, you can control your instrument from ANY of the normal VISA tools. I tried so far R&amp;amp;S VISA and NI Visa, using Python and Matlab to talk to the devices.&lt;/p&gt;
&lt;h1&gt;Testing status&lt;/h1&gt;&lt;a href="#testing-status"&gt;&lt;/a&gt;
&lt;p&gt;This project is actively maintained since more than 6 years and I personally consider it as very stable. It is proven by multiple users to operate on MacOSX, Linux and Windows and measurement equipment from several decades.&lt;/p&gt;
&lt;p&gt;In general I take bug reports very serious and want to "fix them all". In case you don't get an answer on-time on items you report in the issues section, please write me: &lt;a href="mailto:Xyphro@gmail.com"&gt;Xyphro@gmail.com&lt;/a&gt;.
I often miss seeing issue reports very quickly, as I don't get an email once they are filed.&lt;/p&gt;
&lt;h2&gt;Sucessfully tested measurement equipment:&lt;/h2&gt;&lt;a href="#sucessfully-tested-measurement-equipment"&gt;&lt;/a&gt;
&lt;p&gt;Below list is equipment I mainly myself tested. Many other users have other measurement equipment proven in use already.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;R&amp;amp;S FSEM30&lt;/li&gt;
&lt;li&gt;R&amp;amp;S SMIQ03&lt;/li&gt;
&lt;li&gt;R&amp;amp;S CMU200&lt;/li&gt;
&lt;li&gt;R&amp;amp;S SMW200A&lt;/li&gt;
&lt;li&gt;R&amp;amp;S FSW&lt;/li&gt;
&lt;li&gt;R&amp;amp;S FSV&lt;/li&gt;
&lt;li&gt;Keithley 199 multimeter&lt;/li&gt;
&lt;li&gt;HP 34401 DMM from different generations / with different FW versions&lt;/li&gt;
&lt;li&gt;HP 3325A synthesizer/frequency generator&lt;/li&gt;
&lt;li&gt;HP 3457A multimeter&lt;/li&gt;
&lt;li&gt;Agilent E4406A VSA transmitter tester&lt;/li&gt;
&lt;li&gt;Tektronix TDS7104 Digital Phosphor Oscilloscope&lt;/li&gt;
&lt;li&gt;HP 8596A spectrum analyzer&lt;/li&gt;
&lt;li&gt;Agilent E3648A dual power supply&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Scenarious&lt;/h2&gt;&lt;a href="#scenarious"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;It works under all popular operating systems like Windows 7 and 10, 11, Linux and MacOSX&lt;/li&gt;
&lt;li&gt;USB1.1, USB2.0 and USB3.x ports tested, with and without USB HUB in between.&lt;/li&gt;
&lt;li&gt;The connection stays responsive, when power cycling the PC, or hibernating/sleeping it&lt;/li&gt;
&lt;li&gt;Different connection cycles (GPIB side connected first, USB side connected first, swapping GPIB side equipment, ...)&lt;/li&gt;
&lt;li&gt;Extensive testing of timeout scenarious. E.g. making an illegal query and testing, if the USBTMC handles the timeouts properly. This was a very tricky part to get right.&lt;/li&gt;
&lt;li&gt;Tested special transfer modes. E.g. capturing screenshots from different equipment is usually something, which will drive other GPIB adapters to the limits, because binary data of unknown length needs to be transported successfully.&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;Setting Parameters&lt;/h1&gt;&lt;a href="#setting-parameters"&gt;&lt;/a&gt;
&lt;p&gt;The firmware version from 13th January 2024 onwards has the ability for human readable text base configuration of several parameters.
The previous methods are still supported, but won't be further documented. You can look them back in the history of this file.&lt;/p&gt;
&lt;p&gt;The command parser is quite simple. For that reason follow the exact syntax as shown below.
Don't add extra spaces or make other modifications or concatenate commands.&lt;/p&gt;
&lt;h2&gt;Read termination method&lt;/h2&gt;&lt;a href="#read-termination-method"&gt;&lt;/a&gt;
&lt;p&gt;While most GPIB interfaces use the hardware signal EOI to signal the end of a message, not all old equipment supports it. Some older instruments even don't have the EOI pin hardware wise wired and use \r or \n termination.&lt;/p&gt;
&lt;p&gt;The USB-TMC standard allows to set the read termination. While in firmware versions before &amp;lt; 2.0 I did not enable that method, it is now finally supported with standard compliance.&lt;/p&gt;
&lt;p&gt;I document here the older method (using pulse indicator request), but I add also the newer methods which are 100% UsbTmc compliant and portable across different equipments. You can choose which ones to use, but in some cases pulse indicator requests can be difficult to issue, for which reason it is likely better to use the standard compliant method.&lt;/p&gt;
&lt;h3&gt;Set read termination to CR (\r):&lt;/h3&gt;&lt;a href="#set-read-termination-to-cr-r"&gt;&lt;/a&gt;
&lt;p&gt;(old method)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!term cr')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Above setting is volatile. To make this a permanent setting call the below mentioned "!term store" command.&lt;/p&gt;
&lt;p&gt;(prefered method) Alternatively you can set the termination directly with visa means, e.g. using PyVisa:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.set_visa_attribute(visa.constants.VI_ATTR_TERMCHAR_EN, True)
dev.set_visa_attribute(visa.constants.VI_ATTR_TERMCHAR, ord('\r') )
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Set read termination to LF (\n):&lt;/h3&gt;&lt;a href="#set-read-termination-to-lf-n"&gt;&lt;/a&gt;
&lt;p&gt;(old method)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!term lf')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Above setting is volatile. To make this a permanent setting call the below mentioned "!term store" command.&lt;/p&gt;
&lt;p&gt;(prefered method) Alternatively you can set the termination directly with visa means, e.g. using PyVisa:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.set_visa_attribute(visa.constants.VI_ATTR_TERMCHAR_EN, True)
dev.set_visa_attribute(visa.constants.VI_ATTR_TERMCHAR, ord('\n') )
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Set read termination to EOI only (default setting):&lt;/h3&gt;&lt;a href="#set-read-termination-to-eoi-only-default-setting"&gt;&lt;/a&gt;
&lt;p&gt;(old method)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!term eoi')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Above setting is volatile. To make this a permanent setting call the below mentioned "!term store" command.&lt;/p&gt;
&lt;p&gt;(prefered method) Alternatively you can set the termination directly with visa means, e.g. using PyVisa:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.set_visa_attribute(visa.constants.VI_ATTR_TERMCHAR_EN, False)
dev.set_visa_attribute(visa.constants.VI_ATTR_TERMCHAR, ord('\0') )
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Save readtermination setting in eeprom (make them non-volatile)&lt;/h3&gt;&lt;a href="#save-readtermination-setting-in-eeprom-make-them-non-volatile"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!term store')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Above relates to the "old non prefered method". In general it is a good idea to set the read termination volatile and use the above suggested methods highlighted with (prefered method).&lt;/p&gt;
&lt;h3&gt;Query current termination setting from device&lt;/h3&gt;&lt;a href="#query-current-termination-setting-from-device"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
print(dev.query('!term?'))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This returns a text string containing "lf", "cr" or "eoi"&lt;/p&gt;
&lt;h2&gt;AutoID setting&lt;/h2&gt;&lt;a href="#autoid-setting"&gt;&lt;/a&gt;
&lt;p&gt;Default wise the GPIB adapter tries during power on of the instrument to query using *IDN? or ID? commands the instrument name automatically.
This is used to build the USB serial number, which finally gets part of the VISA ressource string.&lt;/p&gt;
&lt;p&gt;Not all instruments support this *IDN / ID? query. For this reason this feature can be turned off.
The serial number will then be built based on the GPIB address of the instrument.&lt;/p&gt;
&lt;h3&gt;Turn AutoID feature off&lt;/h3&gt;&lt;a href="#turn-autoid-feature-off"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!autoid off')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This setting is stored in eeprom = non volatile memory, so will survive a power cycle&lt;/p&gt;
&lt;h3&gt;Turn AutoID feature on&lt;/h3&gt;&lt;a href="#turn-autoid-feature-on"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!autoid on')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This setting is stored in eeprom = non volatile memory, so will survive a power cycle&lt;/p&gt;
&lt;h3&gt;turn auto ID on with delay&lt;/h3&gt;&lt;a href="#turn-auto-id-on-with-delay"&gt;&lt;/a&gt;
&lt;p&gt;Some instruments need after turn on some seconds before GPIB is responsive.&lt;/p&gt;
&lt;p&gt;With below 3 settings you can set a delay which is applied before the instrument ID is queried after power on.
Note that it will take then also more time, before the USB device is recognized by the PC.&lt;/p&gt;
&lt;p&gt;Also this setting is non-volatile.&lt;/p&gt;
&lt;p&gt;Delay 5 seconds:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!autoid slow')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delay 15 seconds:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!autoid slower')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Delay 30 seconds:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!autoid slowest')
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;read autoid setting&lt;/h3&gt;&lt;a href="#read-autoid-setting"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # 
print(dev.query('!autoid?'))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Returns as text string either: "off", "on", "slow", "slower" or "slowest".&lt;/p&gt;
&lt;h2&gt;Firmware version&lt;/h2&gt;&lt;a href="#firmware-version"&gt;&lt;/a&gt;
&lt;p&gt;Finally I implemented a command to query the USB adapters firmware version :-)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
print(dev.query('!ver?'))
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Shorten ressource strings (Matlab)&lt;/h2&gt;&lt;a href="#shorten-ressource-strings-matlab"&gt;&lt;/a&gt;
&lt;p&gt;A user discovered that Matlab has a limitation in the VISA ressource string length and shared a pull request to reduce the length.
I expose this now first time in the baseline firmware with the following options.&lt;/p&gt;
&lt;p&gt;This setting is stored in eeprom = non volatile.&lt;/p&gt;
&lt;h3&gt;Limit the USB serial number to a length of 20 characters&lt;/h3&gt;&lt;a href="#limit-the-usb-serial-number-to-a-length-of-20-characters"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!string short')
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;disable limitation of USB serial number length (default behavior)&lt;/h3&gt;&lt;a href="#disable-limitation-of-usb-serial-number-length-default-behavior"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
dev.write('!string normal')
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;query the string length setting.&lt;/h3&gt;&lt;a href="#query-the-string-length-setting"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); # USBTMC pulse indicator request (enables internal command processing)
print(dev.query('!string?'))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This returns as text string either "normal" or "short".&lt;/p&gt;
&lt;h2&gt;reset the adapter&lt;/h2&gt;&lt;a href="#reset-the-adapter"&gt;&lt;/a&gt;
&lt;pre&gt;&lt;code&gt;dev.control_in(0xa1, 0x40, 0, 0, 1); 
dev.write('!reset')
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Do a reset of the adapter. Note that due to the reset you have to close the visa session and start a new one as the device re-enumerates on the USB.&lt;/p&gt;

&lt;h1&gt;Support the project&lt;/h1&gt;&lt;a href="#support-the-project"&gt;&lt;/a&gt;
&lt;p&gt;&lt;a href="https://ko-fi.com/J3J7WPWSQ"&gt;&lt;img alt="ko-fi" src="https://camo.githubusercontent.com/201ef269611db7eb6b5d08e9f756ab8980df3014b64492770bdf13a6ed924641/68747470733a2f2f6b6f2d66692e636f6d2f696d672f676974687562627574746f6e5f736d2e737667"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Or support by buying a fully prebuilt adapter at: &lt;a href="https://www.elecrow.com/xyphrolabs-gpibusb.html"&gt;&lt;/a&gt;&lt;a href="https://www.elecrow.com/xyphrolabs-gpibusb.html"&gt;https://www.elecrow.com/xyphrolabs-gpibusb.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In general any email, post or feedback is also very valuable, and don't feel bad if you don't use the support options :-)
Feel free to contact me at &lt;a href="mailto:Xyphro@gmail.com"&gt;Xyphro@gmail.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This page is from XyphroLabs UsbGpib project: &lt;a href="https://github.com/xyphro/UsbGpib"&gt;&lt;/a&gt;&lt;a href="https://github.com/xyphro/UsbGpib"&gt;https://github.com/xyphro/UsbGpib&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/xyphro/UsbGpib</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 01:21:58 +0000</pubDate>
    </item>
    <item>
      <title>Nabokov's guide to foreigners learning Russian</title>
      <link>https://twitter.com/haravayin_hogh/status/2003299405907247502</link>
      <description>&lt;a href="https://news.ycombinator.com/item?id=46371423"&gt;Comments&lt;/a&gt;</description>
      <content:encoded>&lt;body style="background-color: #FFFFFF;"&gt;&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://twitter.com/haravayin_hogh/status/2003299405907247502</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 01:20:39 +0000</pubDate>
    </item>
    <item>
      <title>Unifi Travel Router</title>
      <link>https://blog.ui.com/article/travel-in-style-unifi-style-unifi-travel-router</link>
      <description>Slip it into your pocket, power it on, and your UniFi network follows you wherever you land. No reconfiguring, no rethinking, just the same environment you trust, now mobile.</description>
      <content:encoded>&lt;article class="sc-f9e446b9-0 jOZXg"&gt;&lt;p&gt;Slip it into your pocket, power it on, and your UniFi network follows you wherever you land. No reconfiguring, no rethinking, just the same environment you trust, now mobile.&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://blog.ui.com/article/travel-in-style-unifi-style-unifi-travel-router</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 24 Dec 2025 00:30:18 +0000</pubDate>
    </item>
    <item>
      <title>Is Northern Virginia Still the Least Reliable AWS Region?</title>
      <link>https://statusgator.com/blog/aws-least-reliable-region-in-2025/</link>
      <description>Published:</description>
      <content:encoded>&lt;article class="dynamic-content-template post-13389 post type-post status-publish format-standard has-post-thumbnail hentry category-outages tag-cloud-monitoring no-featured-image-padding" id="post-13389"&gt;

&lt;h1&gt;Is Northern Virginia Still the Least Reliable AWS Region in 2025? We Analyzed the Data&lt;/h1&gt;


&lt;p&gt;Published:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://statusgator.com/blog/aws-least-reliable-region-in-2025/"&gt;December 23, 2025&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;by &lt;a href="https://statusgator.com/blog/author/alibby/"&gt;Andy Libby&lt;/a&gt;&lt;/p&gt;



&lt;p&gt;Updated:&lt;/p&gt;
&lt;p&gt;&lt;a href="https://statusgator.com/blog/aws-least-reliable-region-in-2025/"&gt;December 23, 2025&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;by &lt;a href="https://statusgator.com/blog/author/alibby/"&gt;Andy Libby&lt;/a&gt;&lt;/p&gt;



&lt;img alt="AWS N.Virginia reliability in 2025 StatusGator" src="https://statusgator.com/blog/wp-content/uploads/2025/12/Blog-thumbnail-7.png"/&gt;



Table of content


&lt;p&gt;This updated analysis is based on StatusGator outage data collected from January 1 to December 9, 2025. We decided to review our &lt;a href="https://statusgator.com/blog/is-north-virginia-aws-region-the-least-reliable-and-why/"&gt;AWS analysis of outages in 2022&lt;/a&gt; due to several new AWS incidents, especially another widely discussed AWS outage in us-east-1 (N. Virginia) that occurred on October 20, 2025.&lt;/p&gt;
&lt;p&gt;We’ve expanded the report with fresh 2025 regional data as well as a new breakdown of affected AWS services.&lt;/p&gt;
&lt;h2&gt;The Data Behind the Study&lt;/h2&gt;
&lt;p&gt;StatusGator continuously monitors the official AWS status pages and aggregates incidents across every public AWS Region. This analysis reflects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Major, publicly acknowledged AWS outages&lt;/li&gt;
&lt;li&gt;All commercial AWS regions (GovCloud excluded)&lt;/li&gt;
&lt;li&gt;Data timeframe: January 1, 2025 – December 9, 2025&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;AWS Outage Ranking by Region&lt;/h2&gt;
&lt;p&gt;So let’s take a look at the number of outages, duration, and components affected.&lt;/p&gt;



RegionNumber of outagesDurationComponents Affected




Regionless1231:55:1914


Canada-Central13:49:5719


Hyderabad10:44:5946


Ireland10:44:5110


N. Virginia1033:49:33126


Ohio21:20:452


Oregon32:59:413


Osaka12:15:0111


Sao Paulo10:44:519


Singapore10:54:591


Stockholm211:54:4981


Sydney10:50:001


Tokyo31:24:5118


Zurich14:54:557



&lt;!-- #tablepress-44 from cache --&gt;
&lt;h3&gt;Key Findings&lt;/h3&gt;
&lt;p&gt;N. Virginia (us-east-1) is once again the least reliable AWS Region.&lt;/p&gt;
&lt;p&gt;It leads the dataset in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Total number of outages (10)&lt;/li&gt;
&lt;li&gt;Total downtime (33 hours, 49 minutes)&lt;/li&gt;
&lt;li&gt;Total components affected (126)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;No other region even comes close. Stockholm ranks second in downtime (11+ hours). Despite only 2 outages, each incident had a massive regional impact.&lt;/p&gt;
&lt;p&gt;Regionless outages were unusually high. This category recorded &lt;strong&gt;12 outages&lt;/strong&gt; and &lt;strong&gt;32 hours of downtime&lt;/strong&gt;, indicating:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;More widespread AWS service disruptions in 2025&lt;/li&gt;
&lt;li&gt;More failures affecting multiple regions simultaneously&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;AWS Services with the Most Outages&lt;/h2&gt;
&lt;p&gt;AWS doesn’t just experience regional outages. Service-level incidents are just as impactful.&lt;br/&gt;We analyzed the most frequently disrupted AWS services in 2025, ranked by the number of outages.&lt;/p&gt;



ServiceNumber of OutagesDuration




Amazon EC21419:14:01


Amazon SageMaker1120:40:21


AWS Glue1015:51:40


Amazon EMR1021:39:31


Amazon ECS1019:54:32



&lt;!-- #tablepress-45 from cache --&gt;
&lt;h3&gt;Key Findings&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compute services dominated the outage list&lt;/strong&gt;, especially:&lt;br/&gt;
&lt;ul&gt;
&lt;li&gt;Amazon EC2 (core compute)&lt;/li&gt;
&lt;li&gt;Amazon ECS (containers)&lt;/li&gt;
&lt;li&gt;Amazon EMR (big data)&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;EMR had &lt;strong&gt;the longest duration&lt;/strong&gt; among the top five (21 hours and 39 minutes).&lt;/li&gt;
&lt;li&gt;SageMaker experienced more outages than expected for an ML service, an emerging reliability trend.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;AWS Services With the Longest Outage Duration or Broadest Impact&lt;/h2&gt;
&lt;p&gt;These services didn’t always have the highest count, but had the longest or most severe incidents.&lt;/p&gt;



ServiceNumber of OutagesDuration




Amazon OpenSearch Service625:36:36


Amazon EMR Serverless725:30:08


Amazon CloudWatch624:58:49


Amazon Connect522:52:42


AWS STS522:48:39


Amazon VPC Lattice722:35:47


Amazon EMR1021:39:31


Amazon EventBridge521:24:32


Amazon Kinesis Data Streams521:15:00


AWS DataSync920:36:52


Amazon Elastic Load Balancing912:34:20


Amazon DynamoDB913:19:18


AWS Transit Gateway817:14:51


AWS Lambda813:50:15



&lt;!-- #tablepress-46 from cache --&gt;
&lt;h3&gt;Key Findings&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OpenSearch, EMR Serverless, and CloudWatch&lt;/strong&gt; each exceeded &lt;strong&gt;24+ hours&lt;/strong&gt; of cumulative downtime.&lt;/li&gt;
&lt;li&gt;Mission-critical systems like &lt;strong&gt;STS, DynamoDB, Lambda, and ELB&lt;/strong&gt; saw prolonged disruptions.&lt;/li&gt;
&lt;li&gt;EMR appears in &lt;strong&gt;both&lt;/strong&gt; spreadsheets, indicating it experienced frequent &lt;strong&gt;and&lt;/strong&gt; long-lasting ones.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Across Tables 1–3 above, we see a consistent pattern emerge:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Many of the affected components were concentrated in N. Virginia&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;With 126 components affected, us-east-1 experienced the widest service disruption footprint.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Region-level outages and service-level outages are correlated&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Major incidents involving:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;EC2&lt;/li&gt;
&lt;li&gt;SageMaker&lt;/li&gt;
&lt;li&gt;EMR&lt;/li&gt;
&lt;li&gt;CloudWatch&lt;/li&gt;
&lt;li&gt;OpenSearch&lt;/li&gt;
&lt;li&gt;STS&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;…almost always touch N. Virginia due to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Higher customer density&lt;/li&gt;
&lt;li&gt;More service deployment fronts&lt;/li&gt;
&lt;li&gt;More inter-service dependency points&lt;/li&gt;
&lt;li&gt;Heavier API traffic&lt;/li&gt;
&lt;li&gt;Higher multi-AZ coordination complexity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;3. The longest-running outages disproportionately affected us-east-1&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Duration-heavy outages (CloudWatch, OpenSearch, EMR Serverless) frequently included N. Virginia, driving up the region’s total downtime.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;N. Virginia is not only the region with the most outages, but it is also the region where service outages cascade the widest and run the longest.&lt;/p&gt;
&lt;h2&gt;AWS Outage on October 20, 2025&lt;/h2&gt;
&lt;p&gt;On October 20, 2025, AWS experienced one of the &lt;a href="https://statusgator.com/blog/statusgator-october-20-2025-outage-postmortem/"&gt;most significant cloud outages&lt;/a&gt; in its history. 76 individual AWS components in the N. Virginia region alone showed disruption, by far the most heavily affected region.&lt;/p&gt;
&lt;p&gt;Portions of Amazon Web Services were down for nearly 15 hours, causing cascading failures across thousands of SaaS platforms.&lt;/p&gt;
&lt;p&gt;StatusGator’s &lt;a href="https://statusgator.com/blog/october-2025-early-warning-signals/"&gt;Early Warning Signals&lt;/a&gt; detected the incident approximately ten minutes before AWS officially acknowledged it, ultimately identifying outages across more than 2,000 of the 6,000 services in our monitoring network.&lt;/p&gt;
&lt;p&gt;However, the magnitude of the event meant StatusGator was also impacted, experiencing two periods of dashboard and status page downtime due to a surge in global traffic and failures in upstream infrastructure.&lt;/p&gt;
&lt;p&gt;Despite these disruptions, StatusGator delivered over 100,000 outage notifications throughout the incident and has since implemented architectural improvements to strengthen reliability during future large-scale cloud failures.&lt;/p&gt;
&lt;h2&gt;Why Is N. Virginia Still the Least Reliable Region in 2025?&lt;/h2&gt;
&lt;p&gt;We revisited the three common theories from our &lt;a href="https://statusgator.com/blog/is-north-virginia-aws-region-the-least-reliable-and-why/"&gt;2023 AWS outage analysis&lt;/a&gt; and compared them against this year’s dataset.&lt;/p&gt;
&lt;h3&gt;Assumption 1: “N. Virginia Has More Services, So More Things Can Break”&lt;/h3&gt;
&lt;p&gt;In 2023, we found this explanation to be weak. But the 2025 “Components Affected” numbers tell a new story:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;N. Virginia affected 126 components&lt;/li&gt;
&lt;li&gt;Next highest: Stockholm with 81&lt;/li&gt;
&lt;li&gt;Most regions affected ≤ 20 components&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This indicates:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Broader blast when outages occur in N. Virginia&lt;/li&gt;
&lt;li&gt;More interconnected or high-density service dependency&lt;/li&gt;
&lt;li&gt;More potential points of failure&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Still, high service count alone doesn’t explain the full scale:&lt;br/&gt;Regions like Oregon and Ireland offer nearly as many services but have far fewer issues.&lt;/p&gt;
&lt;p&gt;So the number of components contributes to complexity, but not the root cause.&lt;/p&gt;
&lt;h3&gt;Assumption 2: “N. Virginia Is the Most Used and Most Heavily Loaded Region”&lt;/h3&gt;
&lt;p&gt;This remains the strongest and most likely explanation. StatusGator &lt;a href="https://statusgator.com/services/amazon-web-services/"&gt;monitoring AWS status&lt;/a&gt; data historically shows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;N. Virginia is monitored by &lt;strong&gt;almost 2× as many users&lt;/strong&gt; as Oregon&lt;/li&gt;
&lt;li&gt;And &lt;strong&gt;over 3× as many&lt;/strong&gt; as many other U.S. and global regions&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;More customers → heavier load → more real-world stress → more outages that reach public visibility.&lt;/p&gt;
&lt;p&gt;So this assumption is very likely true, and reinforced by 2025 data.&lt;/p&gt;
&lt;h3&gt;Assumption 3: “N. Virginia Is Older and Built Differently”&lt;/h3&gt;
&lt;p&gt;AWS provides no evidence that us-east-1 uses a fundamentally different architecture. And our 2025 numbers don’t suggest “old region issues”:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tokyo and Sydney (both older) had minimal downtime&lt;/li&gt;
&lt;li&gt;Newer regions, like Zurich and Hyderabad, had multi-hour outages&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Like in 2023, we still see no evidence supporting this theory.&lt;/p&gt;
&lt;h2&gt;Summary: AWS Reliability in 2025&lt;/h2&gt;
&lt;p&gt;With only weeks left in 2025, the data is clear:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Us-east-1 (N. Virginia) remains the least reliable AWS Region&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;Most outages&lt;/li&gt;
&lt;li&gt;Most downtime&lt;/li&gt;
&lt;li&gt;Most components affected&lt;/li&gt;
&lt;/ul&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Compute, analytics, and AI/ML services were the most outage-prone&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;EC2, SageMaker, Glue, EMR, and ECS led the list.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Several AWS services experienced extremely long-running disruptions&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;OpenSearch, CloudWatch, EMR Serverless, and STS had &lt;strong&gt;over 24 hours&lt;/strong&gt; of cumulative downtime.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Multi-region outages increased&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The Regionless category shows a notable rise in cross-region or global incidents in 2025.&lt;/p&gt;
&lt;h2&gt;Get Notified of AWS Outages Before AWS Reports Them&lt;/h2&gt;
&lt;p&gt;StatusGator aggregates every AWS service and region into a single unified dashboard.&lt;br/&gt;We alert you instantly, often before AWS posts the incident publicly.&lt;/p&gt;
&lt;p&gt;Get instant, account-specific AWS outage alerts through StatusGator’s unified dashboard, now enhanced with AWS Health integration for Enterprise customers. It delivers trusted, direct notifications about incidents, outages, and maintenance affecting your services, with built-in filtering to reduce noise, and seamless delivery to Slack, Microsoft Teams, Discord, Google Chat, and more.&lt;/p&gt;
&lt;p&gt;Monitor AWS outages in real time with StatusGator — &lt;a href="https://statusgator.com/users/sign_up"&gt;free to try&lt;/a&gt;.&lt;/p&gt;



&lt;a href="https://statusgator.com/blog/category/outages/"&gt;Outages&lt;/a&gt;



&lt;a href="https://statusgator.com/blog/microsoft-teams-outage-on-december-19-2025/"&gt;❮  Previous article&lt;/a&gt;






&lt;p&gt;Share this&lt;/p&gt;

&lt;a href="https://www.addtoany.com/add_to/copy_link?linkurl=https%3A%2F%2Fstatusgator.com%2Fblog%2Faws-least-reliable-region-in-2025%2F&amp;amp;linkname=Is%20Northern%20Virginia%20Still%20the%20Least%20Reliable%20AWS%20Region%20in%202025%3F%20We%20Analyzed%20the%20Data"&gt;&lt;/a&gt;&lt;a href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fstatusgator.com%2Fblog%2Faws-least-reliable-region-in-2025%2F&amp;amp;linkname=Is%20Northern%20Virginia%20Still%20the%20Least%20Reliable%20AWS%20Region%20in%202025%3F%20We%20Analyzed%20the%20Data"&gt;&lt;/a&gt;&lt;a href="https://www.addtoany.com/add_to/x?linkurl=https%3A%2F%2Fstatusgator.com%2Fblog%2Faws-least-reliable-region-in-2025%2F&amp;amp;linkname=Is%20Northern%20Virginia%20Still%20the%20Least%20Reliable%20AWS%20Region%20in%202025%3F%20We%20Analyzed%20the%20Data"&gt;&lt;/a&gt;&lt;a href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fstatusgator.com%2Fblog%2Faws-least-reliable-region-in-2025%2F&amp;amp;linkname=Is%20Northern%20Virginia%20Still%20the%20Least%20Reliable%20AWS%20Region%20in%202025%3F%20We%20Analyzed%20the%20Data"&gt;&lt;/a&gt;&lt;a href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fstatusgator.com%2Fblog%2Faws-least-reliable-region-in-2025%2F&amp;amp;linkname=Is%20Northern%20Virginia%20Still%20the%20Least%20Reliable%20AWS%20Region%20in%202025%3F%20We%20Analyzed%20the%20Data"&gt;&lt;/a&gt;


&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://statusgator.com/blog/aws-least-reliable-region-in-2025/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 23:12:03 +0000</pubDate>
    </item>
    <item>
      <title>Microspeak: North Star – The Old New Thing (2015)</title>
      <link>https://devblogs.microsoft.com/oldnewthing/20151103-00/?p=91861</link>
      <description>I noted it in the interview with the Defrag Tools show , but I’ll make a proper Microspeak for it. Today’s term is North star .</description>
      <content:encoded>&lt;article class="middle-column pe-xl-198" data-clarity-region="article" id="post-91861"&gt;

&lt;p&gt;I noted it &lt;a href="https://channel9.msdn.com/Shows/Defrag-Tools/Defrag-Tools-142-Raymond-Chen-Old-New-Thing"&gt;in the interview with the Defrag Tools show&lt;/a&gt;, but I’ll make a proper Microspeak for it. Today’s term is North star. &lt;/p&gt;
&lt;p&gt;This term rose quickly to prominence in October 2015. My research suggests that it had been simmering below the surface for about a year. For example, &lt;a href="http://blogs.msdn.com/b/eric_brechner/archive/2015/06/01/solving-the-whole-problem.aspx"&gt;here’s an isolated citation from May 2015&lt;/a&gt;: &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The best you can do is paint a compelling picture of an improved world (your north star), and plan the long journey to it. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This citation is interesting because it seems to give a definition for “north star”: It means “a compelling picture of an improved world”. &lt;/p&gt;
&lt;p&gt;The term has become wildly popular of late at Microsoft. I guess a major executive used the term recently, so now it’s suddenly the cool thing to say. &lt;/p&gt;
&lt;p&gt;We had a team meeting a little while ago. One of the agenda items was  “Longer term North star topics”, which was itself rather intriguing. During the meeting, I noted¹ the following uses of the term: &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;There may be changes along the way, but your north star of the feature is intact. &lt;/p&gt;&lt;/blockquote&gt;
&lt;blockquote&gt;&lt;p&gt;We have to decide where we want to go as a north star. &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;I raised my hand. “What do you mean by north star? Because if you follow the north star, you end up at the north pole, and not where you actually want to go.” &lt;/p&gt;
&lt;p&gt;The speaker seemed a bit frustrated by this question. “Who is this idiot who doesn’t know what a north star is? Certainly this person hasn’t been in &lt;a href="http://blogs.msdn.com/b/oldnewthing/archive/2013/12/11/10481036.aspx"&gt;all the meetings I’ve been in&lt;/a&gt;, where people are saying ‘north star’ all over the place.” &lt;/p&gt;
&lt;p&gt;The speaker noted that I might want to look it up in the dictionary, because it would have told me that the north star is the goal you have beyond your immediate goal. It’s a guiding principle that keeps you on the right path for your journey. (Curiously, this definition doesn’t appear anywhere in &lt;a href="http://www.merriam-webster.com/dictionary/north%20star"&gt;any&lt;/a&gt; &lt;a href="http://dictionary.reference.com/browse/north-star"&gt;online&lt;/a&gt; &lt;a href="http://www.oxforddictionaries.com/definition/english/North-Star"&gt;dictionary&lt;/a&gt; &lt;a href="https://en.wiktionary.org/wiki/North_Star"&gt;I could find&lt;/a&gt;. It also doesn’t match the citation at the top of this article.) &lt;/p&gt;
&lt;p&gt;So there you go. An explicit definition, as provided by somebody who used the term. I embarrassed myself in front of my whole team for you. &lt;/p&gt;
&lt;p&gt;Bonus chatter: Later that same day, a top executive sent mail to the entire company. It too used the term “north star”: &lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;With &lt;a href="http://www.microsoft.com/en-us/about/default.aspx"&gt;Microsoft’s mission&lt;/a&gt; as our north star—to empower every person and every organization on the planet to achieve more—we have a… &lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;¹ Yes, when I attend meetings, one of the things I pay particular attention to is new jargon, so I can add it to my collection of citations. If you see me pull out my phone and jot something down, it’s either because I’m writing down a question to ask later, or I’m preserving something you said so I can add it to my Microspeak citations. &lt;/p&gt;
&lt;!-- .entry-content --&gt;
&lt;!-- AI Disclaimer --&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://devblogs.microsoft.com/oldnewthing/20151103-00/?p=91861</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 22:23:49 +0000</pubDate>
    </item>
    <item>
      <title>Texas app store age verification law blocked by federal judge</title>
      <link>https://www.macrumors.com/2025/12/23/texas-app-store-law-blocked/</link>
      <description>A Texas federal judge today blocked an App Store age verification law that was set to go into effect on January 1, 2026, which means Apple may not have to support the changes after all.</description>
      <content:encoded>&lt;article class="article--2pJwZBkO js-article" expanded="true"&gt;&lt;h1&gt;Texas App Store Age Verification Law Blocked by Federal Judge&lt;/h1&gt;Tuesday December 23, 2025 12:36 pm PST by &lt;a href="https://www.macrumors.com/author/juli-clover/"&gt;Juli Clover&lt;/a&gt;&lt;p&gt;A Texas federal judge today blocked an &lt;a href="https://www.macrumors.com/guide/app-store/"&gt;App Store&lt;/a&gt; age verification law that was set to go into effect on January 1, 2026, which means Apple may not have to support the changes after all.&lt;/p&gt;
&lt;p&gt;&lt;img alt="iOS App Store General Feature Desaturated" src="https://images.macrumors.com/t/T5SjvgLdchGm5DEKzIfFVPQgFIQ=/400x0/article-new/2022/01/iOS-App-Store-General-Feature-Desaturated.jpg?lossy"/&gt;&lt;br/&gt;The Texas ‌App Store‌ Accountability Act (SB2420) requires Apple and other app marketplaces to confirm user age when a person creates an Apple Account. Apple Accounts for users under 18 would need to join a Family Sharing group, with new controls available for parents and restrictions for minors.&lt;/p&gt;
&lt;p&gt;In a preliminary injunction that delays the implementation of the act, Judge Robert Pitman said that it violates the First Amendment and is "more likely than not unconstitutional."&lt;br/&gt;
&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The Act is akin to a law that would require every bookstore to verify the age of every customer at the door and, for minors, require parental consent before the child or teen could enter and again when they try to purchase a book. As set out below, the Court finds a likelihood that, when considered on the merits, SB 2420 violates the First Amendment.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The injunction was in response to a motion filed by the Computer and Communications Industry Association (CCIA), a group that includes Apple and Google. Today's decision is a win for Apple, as Apple has been fighting against age assurance requirements in Texas and other states. Apple says that the Texas law impacts user privacy.&lt;br/&gt;
&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;While we share the goal of strengthening kids' online safety, we are concerned that SB2420 impacts the privacy of users by requiring the collection of sensitive, personally identifiable information to download any app, even if a user simply wants to check the weather or sports scores.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The court will move on to determining whether the law is facially invalid, which would mean that it is unconstitutional and will be entirely thrown out.&lt;/p&gt;
&lt;p&gt;Note: Due to the political or social nature of the discussion regarding this topic, the discussion thread is located in our &lt;a href="https://forums.macrumors.com/forums/political-news.218/"&gt;Political News&lt;/a&gt; forum.  All forum members and site visitors are welcome to read and follow the thread, but posting is limited to forum members with at least 100 posts.&lt;/p&gt;
Tag: &lt;a href="https://www.macrumors.com/guide/texas/"&gt;Texas&lt;/a&gt;[ &lt;a href="https://forums.macrumors.com/threads/texas-app-store-age-verification-law-blocked-by-federal-judge.2475130/"&gt;37 comments&lt;/a&gt; ]&lt;a href="https://twitter.com/share?url=http%3A%2F%2Fwww.macrumors.com%2F2025%2F12%2F23%2Ftexas-app-store-law-blocked%2F&amp;amp;text=Texas+App+Store+Age+Verification+Law+Blocked+by+Federal+Judge&amp;amp;related=macrumors"&gt;&lt;/a&gt;&lt;a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Fwww.macrumors.com%2F2025%2F12%2F23%2Ftexas-app-store-law-blocked%2F&amp;amp;amp;src=sdkpreparse"&gt;&lt;/a&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.macrumors.com/2025/12/23/texas-app-store-law-blocked/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 22:03:46 +0000</pubDate>
    </item>
    <item>
      <title>Show HN: Claude Wrapped in the terminal, with a WASM raymarcher</title>
      <link>https://spader.zone/wrapped/</link>
      <description>Run to compare your Claude Code usage against the rest of the world while enjoying a spirited holiday Santa Claude rendered in fully lit 3D in your terminal with the power of WASM.</description>
      <content:encoded>&lt;main&gt;&lt;h1&gt;» &lt;em&gt;tldr&lt;/em&gt;&lt;/h1&gt;&lt;p&gt;Run to compare your &lt;code&gt;Claude Code&lt;/code&gt; usage against the rest of the world while enjoying a spirited holiday Santa Claude rendered in fully lit 3D in your terminal with the power of WASM.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;bun x @spader/claude-wrapped
&lt;/code&gt;&lt;/pre&gt;&lt;h1&gt;» &lt;em&gt;slightly less tldr&lt;/em&gt;&lt;/h1&gt;cpu-destroying wasm claudeClick to load...&lt;p&gt;I wrote a raymarcher that can render scenes of SDF functions and lights in plain C, compiled it with WASM, jammed it all into a Bun executable that grabs your &lt;code&gt;~/.claude/stats-cache.json&lt;/code&gt;, uploads it to a SQLite database on The Cloud so you can see how your Claude Code usage stacks up with the rest of the world.&lt;/p&gt;&lt;p&gt;You can see the aforementioned raymarched Claude above, on this very web page! As far as the data collected, the code’s on &lt;a href="https://github.com/tspader/claude-wrapped/"&gt;GitHub&lt;/a&gt;. It’s a spit of TypeScript and a WASM module that’s as close to pure computation as you can get. Clone and run with &lt;code&gt;bun start&lt;/code&gt;; the WASM’s already compiled, so you shouldn’t even need a C compiler.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Please reach out to &lt;a href="mailto:spader@spader.zone"&gt;spader@spader.zone&lt;/a&gt; if anything bugs out for you.&lt;/strong&gt; I cranked this out in a manic weekend, I’m sure it’s got plenty of bugs.&lt;/p&gt;&lt;p&gt;Read on if you’re interested in the experience of cranking out some rendering code that felt quite real with WASM!&lt;/p&gt;&lt;h1&gt;» &lt;em&gt;shill&lt;/em&gt;&lt;/h1&gt;&lt;img alt="Boon Bane" src="https://spader.zone/images/boon_bane.png"/&gt;deep copyA hand-painted science fiction point and click; for fans of Disco Elysium, Philip K. Dick, Pentiment&lt;a href="https://store.steampowered.com/app/2639990/Deep_Copy/"&gt;Wishlist on Steam&lt;/a&gt;&lt;h1&gt;» &lt;em&gt;wrapped season&lt;/em&gt;&lt;/h1&gt;&lt;p&gt;It’s that time of year, folks. Here in Atlanta, the leaves are turning to beautiful taupes and crimsons. Winter air blows cold and sweet over a thousand lakes in a thousand counties and cleanses mind, body, and soul. And, of course, people everywhere are whipped into a frenzy over the ability to quantify and commodotize even their most basic humanity.&lt;/p&gt;&lt;p&gt;That’s right. It’s Wrapped season!&lt;/p&gt;&lt;p&gt;I usually use &lt;a href="https://github.com/sst/opencode"&gt;opencode&lt;/a&gt;, which constantly impresses me with its attention to detail and quality in the terminal. It is better than most web apps; not better &lt;em&gt;for a TUI&lt;/em&gt;, just better. But I dip into the acutal &lt;code&gt;claude&lt;/code&gt; CLI sometimes. On one such occasion, I noticed something new: &lt;code&gt;/stats&lt;/code&gt;.&lt;/p&gt;&lt;p&gt;&lt;img src="https://spader.zone/images/claude-stats.png"/&gt;&lt;/p&gt;&lt;p&gt;It’s fun! It looks good. It has a fun GitHub-style commit heatmap, and the silly Alex Horne comparative measurements. It’s the kind of thing that makes us love Claude Code. But…can we do better?&lt;/p&gt;&lt;h1&gt;» &lt;em&gt;we can do better&lt;/em&gt;&lt;/h1&gt;&lt;p&gt;I love a good Wrapped as much as the next person. I was a top 0.05% listener of the Grateful Dead last cycle. I don’t know what to &lt;em&gt;do&lt;/em&gt; with this information, but when did that ever stop me?&lt;/p&gt;&lt;p&gt;&lt;img alt="fortunately, spotify wasn’t able to detect that the time was split between me and mr. pig" src="https://spader.zone/images/dead-wrapped.png"/&gt;&lt;/p&gt;&lt;p&gt;A few minutes of poking around &lt;code&gt;$HOME/.claude&lt;/code&gt; unearthed &lt;code&gt;stats-cache.json&lt;/code&gt;! And while this file wasn’t quite as interesting as I’d hoped, it did have more than enough to make a decent wrapped:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Token and message counts by day and model&lt;/li&gt;&lt;li&gt;Invocations by hour-of-day&lt;/li&gt;&lt;li&gt;Costs&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The idea hit me like lightning. Grab these stats, make a wrapped. The stats were a little strange – they only went back a month or so. But I assumed this was because Arch wasn’t a first class citizen, and that some &lt;code&gt;paru -Syu&lt;/code&gt; had wiped some cache or something. Unfortunately, these stats were the best I had. There wasn’t an easy API to get these stats more rigorously. I’m still not entirely sure if they’re per machine or per user (I think the former).&lt;/p&gt;&lt;p&gt;But still, this was more than enough. I had a free weekend, so I slapped it all together.&lt;/p&gt;&lt;h1&gt;» &lt;em&gt;a very good stack&lt;/em&gt;&lt;/h1&gt;&lt;p&gt;This is my first serious (i.e. someone’s actually gonna use it) project with the web. And god damn it, I was &lt;em&gt;impressed&lt;/em&gt;. I had a fantastic experience writing this thing.&lt;/p&gt;&lt;h2&gt;» &lt;em&gt;opentui&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;The frontend is written in TypeScript using the excellent &lt;a href="https://github.com/sst/opentui"&gt;OpenTUI&lt;/a&gt;. It’s the renderer for OpenCode, but is completely decoupled. I’d used it once before for a frontend for a small personal utility, but there I’d used SolidJS since I was just rendering plain UI. They use Yoga to lay out your HTML and CSS, and for my simple cases everything worked flawlessly.&lt;/p&gt;&lt;p&gt;Thankfully, OpenTUI also exposes a plain frame buffer you can write whatever you want to. Which is exactly what I wanted! This had the benefit of being able to use HTML (i.e. flex box) on &lt;em&gt;top&lt;/em&gt; of my pseudo-canvas!&lt;/p&gt;&lt;h2&gt;» &lt;em&gt;wasm&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;The renderer is simple, purely computational C. I was surprised to learn that SIMD works just fine in WASM. The compilation experience was trivially easy; it worked out of the box with clang.&lt;/p&gt;&lt;p&gt;Ironically, when I swapped to my MacBook, the bundled clang was too old to have WASM as a target. I switched to &lt;code&gt;zig cc&lt;/code&gt;, and everything worked flawlessly. In general, &lt;code&gt;flawless&lt;/code&gt; is the word I would use to describe my WASM experience. It’s a great spec, and it has a great ecosystem. It’s ready!&lt;/p&gt;&lt;h2&gt;» &lt;em&gt;bun&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;Oh, Bun. I emailed their founder for a job on a whim after seeing a posting in his Twitter bio. And I got an interview! Unfortunately, my deepest tryhard instincts took over on the software part of the interview, and I added too many features before making sure the core was rock solid. Time slipped away, I submitted a piece of junk, and I rightfully didn’t hear back.&lt;/p&gt;&lt;p&gt;A week later, they got acquired by Anthropic. Did I mention the offer came with a little equity?&lt;/p&gt;&lt;p&gt;Ah, well. Life goes on. I had to get that one out. The fact remains that the reason I reached out in the first place is that Bun is in a very rare tier of universally beloved software. It is fast, it does just what you want, and it has clearly been designed with a love of software and a deep technical competence. Building and deploying the TypeScript stuff was a breeze. Unless pressed by, I don’t know, a Mossad agent with some incriminating photos of me from the Epstein files, I’m a Bun lifer. Interview be damned.&lt;/p&gt;&lt;h2&gt;» &lt;em&gt;cloudflare&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;I flirted with spinning up SQLite on an existing ultracheap VPS that I used for &lt;a href="https://store.steampowered.com/app/2639990/Deep_Copy/"&gt;Deep Copy&lt;/a&gt;. But I was worried that this might have five minutes of fame, and when I say cheap, I mean &lt;em&gt;cheap&lt;/em&gt;. So, I did the next best thing, which is spinning up SQLITE on someone &lt;em&gt;else’s&lt;/em&gt; server.&lt;/p&gt;&lt;p&gt;I am &lt;em&gt;thoroughly&lt;/em&gt; impressed. &lt;code&gt;wrangler&lt;/code&gt;, minus a brief hiccups with IPv6 on my Arch desktop, Just Worked. I manage my domains through Cloudflare, and it’s absolutely gorgeous inside this walled garden. Everything just slots together. It’s the same feeling I get when building a computer; I have no idea what these components &lt;em&gt;really&lt;/em&gt; do, but after you do it a few times you just know it’ll work when you snap it all together. Maybe when I have to do real engineering in this domain my feelings will change.&lt;/p&gt;&lt;p&gt;I’ve put up a D1 instance running in the ethereal hyperplane, a cron job to recalculate global stats every fifteen minutes, and I was off.&lt;/p&gt;&lt;h1&gt;» &lt;em&gt;i’m a moron&lt;/em&gt;&lt;/h1&gt;&lt;p&gt;Unfortunately, there was one fatal flaw. I was running a few tests, and I noticed my token count going down. When I checked the aforementioned &lt;code&gt;stats-cache.json&lt;/code&gt;, I had a horrifying realization. These stats are only for the last month!&lt;/p&gt;&lt;p&gt;I’d put probably 12 or 15 hours into the damn thing at this point. I thought the renderer was quite beautiful. The thought of having wasted all this effort, and to have been such a fool, was pretty rough.&lt;/p&gt;&lt;p&gt;But, as all of my problems resolve, I went downstairs to sort my screws into my new toolbox, which is where my wife found me; dejected, low, on the brink of abandoning life. But, sweet angel that she is, she told me that people wouldn’t care that it was just the last month.&lt;/p&gt;&lt;p&gt;Because, damn it, people like stats. People like Wrapped! And I hope you like mine.&lt;/p&gt;&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://spader.zone/wrapped/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 21:59:28 +0000</pubDate>
    </item>
    <item>
      <title>X-ray: a Python library for finding bad redactions in PDF documents</title>
      <link>https://github.com/freelawproject/x-ray</link>
      <description>GitHub - freelawproject/x-ray: A tool to detect whether a PDF has a bad redaction</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://raw.githubusercontent.com/freelawproject/x-ray/main/redacted.png"&gt;&lt;img alt="Image of REDACTED STAMP" src="https://raw.githubusercontent.com/freelawproject/x-ray/main/redacted.png"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;x-ray is a Python library for finding bad redactions in PDF documents.&lt;/p&gt;
&lt;h2&gt;Why?&lt;/h2&gt;&lt;a href="#why"&gt;&lt;/a&gt;
&lt;p&gt;At Free Law Project, we collect millions of PDFs. An ongoing problem
is that people fail to properly redact things. Instead of doing it the right
way, they just draw a black rectangle or a black highlight on top of black
text and call it a day. Well, when that happens you just select the text under
the rectangle, and you can read it again. Not great.&lt;/p&gt;
&lt;p&gt;After witnessing this problem for years, we decided it would be good to figure
out how common it is, so, with some help, we built this simple tool. You give
the tool the path to a PDF. It tells you if it has worthless redactions in it.&lt;/p&gt;
&lt;h2&gt;What next?&lt;/h2&gt;&lt;a href="#what-next"&gt;&lt;/a&gt;
&lt;p&gt;Right now, &lt;code&gt;x-ray&lt;/code&gt; works pretty well and we are using it to analyze documents
in our collections. It could be better though. Bad redactions take many forms.
See the issues tab for other examples we don't yet support. We'd love your
help solving some of tougher cases.&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;&lt;a href="#installation"&gt;&lt;/a&gt;
&lt;p&gt;With uv, do:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uv add x-ray
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With pip, that'd be:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install x-ray
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Usage&lt;/h2&gt;&lt;a href="#usage"&gt;&lt;/a&gt;
&lt;p&gt;&lt;code&gt;uvx&lt;/code&gt; lets you run this without even installing it. For example, here's an amicus brief we filed that doesn't have any bad redactions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;uvx --from x-ray xray https://storage.courtlistener.com/recap/gov.uscourts.ca3.125346/gov.uscourts.ca3.125346.45.0.pdf
{}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once you &lt;em&gt;do&lt;/em&gt; install x-ray, you can easily use it on the command line. Once installed, just:&lt;/p&gt;
&lt;pre&gt;% xray path/to/your/file.pdf
{
  "1": [
    {
      "bbox": [
        58.550079345703125,
        72.19873046875,
        75.65007781982422,
        739.3987426757812
      ],
      "text": "The Ring travels by way of Cirith Ungol"
    }
  ]
}&lt;/pre&gt;
&lt;p&gt;Or if you have the file on a server somewhere, give it a URL. If it starts with &lt;code&gt;https://&lt;/code&gt;, it will be interpreted as a PDF to download. Here's congressional testimony our directory made (it doesn't have any bad redactions):&lt;/p&gt;
&lt;pre&gt;% xray https://free.law/pdf/congressional-testimony-michael-lissner-free-law-project-hearing-on-ethics-and-transparency-2021-10-26.pdf
{}&lt;/pre&gt;
&lt;p&gt;A fun trick you can do is to make a file with one URL per line, call it &lt;code&gt;urls.txt&lt;/code&gt;. Then you can run this to check each URL:&lt;/p&gt;
&lt;pre&gt;xargs -n 1 xray  &amp;lt; urls.txt&lt;/pre&gt;
&lt;p&gt;However you run &lt;code&gt;xray&lt;/code&gt; on the command line, you'll get JSON as output. When you have that, you can use it with tools like &lt;a href="https://stedolan.github.io/jq/"&gt;&lt;code&gt;jq&lt;/code&gt;&lt;/a&gt;. The format is as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It's a dict.&lt;/li&gt;
&lt;li&gt;The keys are page numbers.&lt;/li&gt;
&lt;li&gt;Each page number maps to a list of dicts.&lt;/li&gt;
&lt;li&gt;Each of those dicts maps to two keys.&lt;/li&gt;
&lt;li&gt;The first key is &lt;code&gt;bbox&lt;/code&gt;. This is a four-tuple that indicates the x,y positions of the upper left corner and then lower right corners of the bad redaction.&lt;/li&gt;
&lt;li&gt;The second key is &lt;code&gt;text&lt;/code&gt;. This is the text under the bad rectangle.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Simple enough.&lt;/p&gt;
&lt;p&gt;You can also use it as a Python module, if you prefer the long-form:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% python -m xray some-file.pdf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But that's not as easy to remember.&lt;/p&gt;
&lt;p&gt;If you want a bit more, you can, of course, use &lt;code&gt;xray&lt;/code&gt; in Python:&lt;/p&gt;
&lt;pre&gt;from pprint import pprint
import xray
bad_redactions = xray.inspect("some/path/to/your/file.pdf")  # Pathlib works too
pprint(bad_redactions)
{1: [{'bbox': (58.550079345703125,
               72.19873046875,
               75.65007781982422,
               739.3987426757812),
      'text': 'Aragorn is the one true king.'}]}&lt;/pre&gt;
&lt;p&gt;The output is the same as above, except it's a Python object, not a JSON object.&lt;/p&gt;
&lt;p&gt;If you already have the file contents as a &lt;code&gt;bytes&lt;/code&gt; object, that'll work too:&lt;/p&gt;
&lt;pre&gt;some_bytes = requests.get("https://lotr-secrets.com/some-doc.pdf").content
bad_redactions = xray.inspect(some_bytes)&lt;/pre&gt;
&lt;p&gt;Note that because the &lt;code&gt;inspect&lt;/code&gt; method uses the same signature no matter what,
the type of the object you give it is essential:&lt;/p&gt;



Input
&lt;code&gt;xray&lt;/code&gt;'s Assumption




&lt;code&gt;str&lt;/code&gt; or Pathlib &lt;code&gt;Path&lt;/code&gt;
local file


&lt;code&gt;str&lt;/code&gt; that starts with &lt;code&gt;https://&lt;/code&gt;
URL to download


&lt;code&gt;bytes&lt;/code&gt;
PDF in memory



&lt;p&gt;This means that if you provide the filename on disk as a bytes object instead
of a &lt;code&gt;str&lt;/code&gt;, it's not going to work. This will fail:&lt;/p&gt;
&lt;pre&gt;xray.inspect(b"some-file-path.pdf")&lt;/pre&gt;
&lt;p&gt;That's pretty much it. There are no configuration files or other variables to
learn. You give it a file name. If there is a bad redaction in it, you'll soon
find out.&lt;/p&gt;
&lt;h2&gt;How it works&lt;/h2&gt;&lt;a href="#how-it-works"&gt;&lt;/a&gt;
&lt;p&gt;Under the covers, &lt;code&gt;xray&lt;/code&gt; uses the high-performant &lt;a href="https://pymupdf.readthedocs.io/"&gt;PyMuPDF project&lt;/a&gt; to parse PDFs. It has been a wonderful project to work with.&lt;/p&gt;
&lt;p&gt;You can read the source to see how it works, but the general idea is to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Find rectangles in a PDF.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Find letters in the same location&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Render the rectangle as an image&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Inspect the rectangle to see if it's all one color. If it is, then that's a
bad redaction. If not, then we assume you can see a mix of text and
drawings, indicating a redaction that's OK.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The PDF format is a big and complicated one, so it's difficult to do all this perfectly. We do our best, but there's always more to do to make it better. &lt;a href="https://free.law/donate/"&gt;Donations&lt;/a&gt; and sponsored work help.&lt;/p&gt;
&lt;h2&gt;Contributions&lt;/h2&gt;&lt;a href="#contributions"&gt;&lt;/a&gt;
&lt;p&gt;Please see the issues list on Github for things we need, or start a conversation if you have questions. Before you do your first contribution, we'll need a signed contributor license agreement. See the template in the repo.&lt;/p&gt;
&lt;h2&gt;Deployment&lt;/h2&gt;&lt;a href="#deployment"&gt;&lt;/a&gt;
&lt;p&gt;Releases happen automatically via Github Actions. To trigger an automated build:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Update CHANGES.md&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Update the version in pyproject.toml&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Tag the commit with something like "v0.0.0".&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If you wish to create a new version manually, the process is:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Update version info in &lt;code&gt;pyproject.toml&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Configure your Pypi credentials &lt;a href="https://python-poetry.org/docs/repositories/#configuring-credentials"&gt;with Poetry&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Build and publish the version:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;poetry publish --build&lt;/pre&gt;
&lt;h2&gt;License&lt;/h2&gt;&lt;a href="#license"&gt;&lt;/a&gt;
&lt;p&gt;This repository is available under the permissive BSD license, making it easy and safe to incorporate in your own libraries.&lt;/p&gt;
&lt;p&gt;Pull and feature requests welcome. Online editing in GitHub is possible (and easy!).&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/freelawproject/x-ray</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 21:54:30 +0000</pubDate>
    </item>
    <item>
      <title>Some Epstein file redactions are being undone with hacks</title>
      <link>https://www.theguardian.com/us-news/2025/dec/23/epstein-unredacted-files-social-media</link>
      <description>Un-redacted text from released documents began circulating on social media on Monday evening</description>
      <content:encoded>&lt;article class="dcr-1xdhyk6" style="background-color:var(--article-background)"&gt;&lt;img alt="A compilation of redacted pages from documents related to the Jeffrey Epstein case released by the Department of Justice." src="https://i.guim.co.uk/img/media/4c77e9fd23505a7cb1fd806c84613896c3478f05/0_0_3000_2400/master/3000.jpg?width=465&amp;amp;dpr=1&amp;amp;s=none&amp;amp;crop=none"/&gt; A compilation of redacted pages from documents related to the Jeffrey Epstein case released by the Department of Justice. Illustration: Guardian Design/Images via US Justice Department&lt;a href="#img-1"&gt;View image in fullscreen&lt;/a&gt;A compilation of redacted pages from documents related to the Jeffrey Epstein case released by the Department of Justice. Illustration: Guardian Design/Images via US Justice Department&lt;h1&gt;Some Epstein file redactions are being undone with hacks&lt;/h1&gt;&lt;p&gt;Un-redacted text from released documents began circulating on social media on Monday evening&lt;/p&gt;&lt;p&gt;People examining documents released by the Department of Justice in the &lt;a href="https://www.theguardian.com/us-news/jeffrey-epstein"&gt;Jeffrey Epstein&lt;/a&gt; case discovered that some of the file redaction can be undone with Photoshop techniques, or by simply highlighting text to paste into a word processing file.&lt;/p&gt;&lt;p&gt;Un-redacted text from these documents began circulating through social media on Monday evening. An &lt;a href="https://web.archive.org/web/20251219222621/https://www.justice.gov/multimedia/Court%20Records/Matter%20of%20the%20Estate%20of%20Jeffrey%20E.%20Epstein,%20Deceased,%20No.%20ST-21-RV-00005%20(V.I.%20Super.%20Ct.%202021)/2022.03.17-1%20Exhibit%201.pdf"&gt;exhibit &lt;/a&gt;in a civil case in the Virgin Islands against Darren K Indyke and Richard D Kahn, two executors of Epstein’s estate, contains redacted allegations explaining how Epstein and his associates had facilitated the sexual abuse of children. The exhibit was the second amended complaint in the state case against Indyke and Kahn.&lt;/p&gt;&lt;p&gt;In section 85, the redacted portion states: “Between September 2015 and June 2019, Indyke signed (FAC) for over $400,000 made payable to young female models and actresses, including a former Russian model who received over $380,000 through monthly payments of $8,333 made over a period of more than three and a half years until the middle of 2019.”&lt;/p&gt;&lt;p&gt;Prosecutors in the Virgin Islands settled its civil sex-trafficking case against Epstein’s estate, Indyke and Kahn in 2022 for $105m, plus one half of the proceeds from the sale of Little St James, the island on which Epstein resided and on which many of his crimes occurred. The justice department &lt;a href="https://usvidoj.com/u-s-virgin-islands-attorney-general-settles-sex-trafficking-case-against-estate-of-jeffrey-epstein-and-co-defendants-for-over-105-million/"&gt;press release&lt;/a&gt; announcing the settlement did not include an admission of liability.&lt;/p&gt;&lt;p&gt;Indyke, an attorney who represented Epstein for decades, has not been criminally indicted by federal authorities. He was hired by the Parlatore Law Group in 2022, before the justice department settled the Epstein case. That firm represents the defense secretary, Pete Hegseth, and previously represented Donald Trump in his defense against charges stemming from the discovery of classified government documents stored at Trump’s Florida estate. Calls and email seeking comment from Indyke and the Parlatore Law Group have not yet been returned.&lt;/p&gt;&lt;p&gt;Trump has repeatedly denied any knowledge of or involvement in Epstein’s criminal activities and any wrongdoing.&lt;/p&gt;&lt;p&gt;Other sections further allege how Epstein’s enterprise concealed crimes.&lt;/p&gt;&lt;p&gt;“Defendants also attempted to conceal their criminal sex trafficking and abuse, conduct by paying large sums of money to participant-witnesses, including by paying for their attorneys’ fees and case costs in litigation related to this conduct,” reads one redacted passage.&lt;/p&gt;&lt;p&gt;“Epstein also threatened harm to victims and helped release damaging stories about them to damage their credibility when they tried to go public with their stories of being trafficked and sexually abused. Epstein also instructed one or more Epstein Enterprise participant-witnesses to destroy evidence relevant to ongoing court proceedings involving Defendants’ criminal sex trafficking and abuse conduct.”&lt;/p&gt;&lt;p&gt;Redactions of sections 184 through 192 of the document describe property taxes paid by companies incorporated by Epstein on properties that were not on the balance sheet for those firms.&lt;/p&gt;&lt;p&gt;“For instance, Cypress’s Balance Sheet as of December 31, 2018 did not reflect any assets other than cash of $18,824. Further, Cypress reported only $301 in expenses for the year ended December 31, 2018, despite it paying $106,394.60 in Santa Fe property taxes on November 6, 2018,” reads one redacted passage.&lt;/p&gt;&lt;p&gt;“Similarly, in 2017, Cypress reported as its only asset cash in the amount of $29,736 and expenses of $150, despite it paying $55,770.41 and $113,679.56 in Santa Fe property taxes during 2017.”&lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.congress.gov/bill/119th-congress/house-bill/4405"&gt;Epstein Files Transparency Act&lt;/a&gt; signed into law last month permits the Department of Justice “to withhold certain information such as the personal information of victims and materials that would jeopardize an active federal investigation”.&lt;/p&gt;&lt;p&gt;It was unclear how property material complies with the redaction standard under the law. An inquiry to the Department of Justice has not yet been answered.&lt;/p&gt;Explore more on these topics&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/us-news/jeffrey-epstein"&gt;Jeffrey Epstein&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/us-news/us-politics"&gt;US politics&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/tone/news"&gt;news&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="mailto:?subject=Some Epstein file redactions are being undone with hacks&amp;amp;body=https://www.theguardian.com/us-news/2025/dec/23/epstein-unredacted-files-social-media?CMP=share_btn_url"&gt;Share&lt;/a&gt;&lt;a href="https://syndication.theguardian.com/?url=https%3A%2F%2Fwww.theguardian.com%2Fus-news%2F2025%2Fdec%2F23%2Fepstein-unredacted-files-social-media&amp;amp;type=article&amp;amp;internalpagecode=us-news/2025/dec/23/epstein-unredacted-files-social-media"&gt;Reuse this content&lt;/a&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.theguardian.com/us-news/2025/dec/23/epstein-unredacted-files-social-media</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 20:10:30 +0000</pubDate>
    </item>
    <item>
      <title>HTTP Caching, a Refresher</title>
      <link>https://danburzo.ro/http-caching-refresher/</link>
      <description>Published Dec 22, 2025</description>
      <content:encoded>&lt;article class="post" data-pagefind-body=""&gt;
&lt;h1&gt;HTTP caching, a refresher&lt;/h1&gt;
&lt;p&gt;
		Published
		Dec 22, 2025
&lt;/p&gt;
&lt;p&gt;This is a reading of &lt;a href="https://www.rfc-editor.org/rfc/rfc9111"&gt;RFC 9111&lt;/a&gt; (2022), the latest iteration of the HTTP Caching standard.&lt;/p&gt;
&lt;p&gt;It defines the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Cache-Control"&gt;&lt;code&gt;Cache-Control&lt;/code&gt;&lt;/a&gt; HTTP header as a way to prescribe how caches should store and reuse HTTP responses, with regards to not just the browser cache, but to any other intermediary caches, such as proxies and content delivery networks, that may exist between the client and the origin server.&lt;/p&gt;
&lt;img alt="A crude illustration depicting a browser with its private cache, two intermediary services with their shared caches, and the origin server" src="https://danburzo.ro/img/http-caching-refresher/cache-chain.png"/&gt;
&lt;p&gt;The &lt;code&gt;Cache-Control&lt;/code&gt; header accepts a set of comma-separated directives, some of which are meant to be added to HTTP requests, and others to HTTP responses. A typical response header:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;HTTP/2 200
Cache-Control: max-age=0, must-revalidate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some of these directives specifically target &lt;em&gt;shared caches&lt;/em&gt;, that is intermediary caches that serve the same cached responses to many users, while others also apply to &lt;em&gt;private caches&lt;/em&gt; such as the browser cache.&lt;/p&gt;
&lt;h2&gt;Whatâs fresh?&lt;/h2&gt;
&lt;p&gt;Whenever the cache receives a request, it must figure out if the cached response is still &lt;strong&gt;fresh&lt;/strong&gt; and can therefore be reused without incurring the performance tax of an HTTP request, or whether it has gone &lt;strong&gt;stale&lt;/strong&gt; and should be validated with the server.&lt;/p&gt;
&lt;p&gt;To decide on freshness, the cache compares the age of the response to the responseâs so-called freshness timeline.&lt;/p&gt;
&lt;p&gt;The age of a cached response is the time elapsed since it was last generated or revalidated by the origin server. To the time spent in its own cache, the browser will add any &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Age"&gt;&lt;code&gt;Age: &amp;lt;seconds&amp;gt;&lt;/code&gt;&lt;/a&gt; header received from intermediary caches.&lt;/p&gt;
&lt;p&gt;The freshness timeline is a duration beyond which the cached response is to be considered stale. Itâs usually signaled by the server via the appropriate response headers, but may also be guesstimated by the cache in the absence of explicit, valid cues. In order of precedence:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the server establishes a freshness timeline, in seconds, with the &lt;a href="#max-age-response"&gt;&lt;code&gt;Cache-Control: max-age=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/a&gt; directive on the response; otherwise,&lt;/li&gt;
&lt;li&gt;the cache falls back to computing the interval between the &lt;code&gt;Expires: &amp;lt;date&amp;gt;&lt;/code&gt; and &lt;code&gt;Date: &amp;lt;date&amp;gt;&lt;/code&gt; response headers, if available; otherwise,&lt;/li&gt;
&lt;li&gt;if thereâs no &lt;code&gt;Expires&lt;/code&gt; header, the response lacks an explicit expiration, and a heuristic freshness based on the &lt;code&gt;Last-Modified&lt;/code&gt; response header might be applicable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For shared caches, the special &lt;a href="#s-maxage-response"&gt;&lt;code&gt;s-maxage=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/a&gt; directive takes precedence over all others.&lt;/p&gt;
&lt;h2&gt;Going past expiration&lt;/h2&gt;
&lt;p&gt;Just because a response has gone stale, it doesnât mean it needs to be thrown out.&lt;/p&gt;
&lt;p&gt;When it receives a request for a stale cached response, the cache should validate it with its upstream server. Although validation always generates an HTTP request, it avoids a data transfer when thereâs no newer version of the cached response on the server, so it can still be faster than a regular request.&lt;/p&gt;
&lt;p&gt;Validation uses a mechanism known as a conditional HTTP request, which includes one or more special headers called preconditions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if the precondition with the highest precedence is met, the server responds with &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status/200"&gt;HTTP 200 OK&lt;/a&gt; and an updated response body; otherwise,&lt;/li&gt;
&lt;li&gt;it responds with &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status/304"&gt;HTTP 304 Not Modified&lt;/a&gt; and an empty body, confirming the existing response can be reused.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To generate the preconditions needed for these conditional requests, which the server uses to compare the cached response to the freshest version available, responses must be tagged in a way thatâs unique to each version:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;historically, this was done with the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Last-Modified"&gt;&lt;code&gt;Last-Modified: &amp;lt;date&amp;gt;&lt;/code&gt;&lt;/a&gt; header, corresponding to the latest update to the content;&lt;/li&gt;
&lt;li&gt;a more flexible and robust alternative is the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/ETag"&gt;&lt;code&gt;ETag: "&amp;lt;value&amp;gt;"&lt;/code&gt;&lt;/a&gt; header, which stores an arbitrary ASCII string that uniquely identifies the response. This string is usually a hash incorporating one or more aspects: the modification time, the file size, and the file content.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When performing the validation, the cached response headers are mirrored as preconditions for the conditional request:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;Last-Modified: &amp;lt;date&amp;gt;&lt;/code&gt; becomes &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/If-Modified-Since"&gt;&lt;code&gt;If-Modified-Since: &amp;lt;date&amp;gt;&lt;/code&gt;&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ETag: "&amp;lt;value&amp;gt;"&lt;/code&gt; becomes &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/If-None-Match"&gt;&lt;code&gt;If-None-Match: "&amp;lt;value&amp;gt;"&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When both preconditions are present, only &lt;code&gt;If-None-Match&lt;/code&gt; is evaluated.&lt;/p&gt;
&lt;p&gt;Regardless of the result of the validation request, the cached response headers are updated with the new values received from the server, and the fresh-o-meter on the cached response is reset.&lt;/p&gt;
&lt;p&gt;Certain caches may be set up to serve stale responses in some circumstances, such as when losing the connection to the server or in the event of an HTTP 5xx server error. There are also &lt;code&gt;Cache-Control&lt;/code&gt; directives that influence how stale responses are handled, covered in the next section.&lt;/p&gt;
&lt;h2&gt;Cache-Control response directives&lt;/h2&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;max-age=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;max-age&lt;/code&gt; response directive defines the responseâs freshness timeline in seconds, after which the response should be considered stale. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-max-age-2"&gt;â RFC 9111 Â§ 5.2.2.1&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;must-revalidate&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;must-revalidate&lt;/code&gt; response directive indicates that the cache must not reuse a stale response until itâs been successfully validated by the origin server. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-must-revalidate"&gt;â RFC 9111 Â§ 5.2.2.2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If the server throws an error, the cache must surface that instead of reusing a stale response. If the cache is disconnected, it must produce an error with the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status/504"&gt;HTTP 504 Gateway Timeout&lt;/a&gt; status code, or another more applicable error code.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Side effects:&lt;/strong&gt; &lt;code&gt;must-revalidate&lt;/code&gt; is one of the directives, along with &lt;code&gt;s-maxage&lt;/code&gt; and &lt;code&gt;public&lt;/code&gt;, that allow shared caches to &lt;a href="#caching-authenticated-responses"&gt;store and reuse a response to a request containing an &lt;code&gt;Authorization&lt;/code&gt; header&lt;/a&gt;, which they are generally prohibited from doing.&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;no-cache&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;no-cache&lt;/code&gt; response directive indicates that the cache must not reuse &lt;em&gt;any&lt;/em&gt; response until itâs successfully validated by the origin server. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-no-cache-2"&gt;â RFC 9111 Â§ 5.2.2.4&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;This is similar to &lt;code&gt;must-revalidate&lt;/code&gt; but refers to all cached responses, not just stale ones. In effect, &lt;code&gt;no-cache&lt;/code&gt; is a sort of &lt;code&gt;max-age=0, must-revalidate&lt;/code&gt;.&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;no-store&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;no-store&lt;/code&gt; response directive indicates that private and shared caches must not store any part of the request or the response, and to never reuse the response. The standard is quick to warn that the effect is not guaranteed:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;âMUST NOT storeâ in this context means that the cache MUST NOT intentionally store the information in non-volatile storage and MUST make a best-effort attempt to remove the information from volatile storage as promptly as possible after forwarding it. This directive is not a reliable or sufficient mechanism for ensuring privacy. In particular, malicious or compromised caches might not recognize or obey this directive, and communications networks might be vulnerable to eavesdropping. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-no-store-2"&gt;â RFC 9111 Â§ 5.2.2.4&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Side effects:&lt;/strong&gt; The directive can also influence non-HTTP caches. Most browsers will &lt;a href="https://web.dev/articles/bfcache#minimize-no-store"&gt;exclude from the back/forward cache&lt;/a&gt; pages having the &lt;code&gt;no-store&lt;/code&gt; response directive. Chrome, however, has recently started to make &lt;em&gt;some&lt;/em&gt; of these pages &lt;a href="https://developer.chrome.com/docs/web-platform/bfcache-ccns"&gt;eligible for bfcache&lt;/a&gt; when the browser deems it safe.&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;must-understand&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;must-understand&lt;/code&gt; response directive indicates that the cache shouldnât store or reuse responses with HTTP status codes whose semantics the cache doesnât understand and conform to. The directive is meant to future-proof existing implementations from status codes that might have special requirements in regards to caching. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-must-understand"&gt;â RFC 9111 Â§ 5.2.2.3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Itâs recommended to use &lt;code&gt;must-understand, no-store&lt;/code&gt; together as a fallback, and caches are encouraged to ignore the &lt;code&gt;no-store&lt;/code&gt; directive if they do understand the semantics of the HTTP status code. This ensures older caches that donât recognize the &lt;code&gt;must-understand&lt;/code&gt; directive donât cache the response at all, although by 2025 this should be an exceedingly rare sight.&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;private&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;private&lt;/code&gt; response directive indicates that the response is meant for a single user. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-private"&gt;â RFC 9111 Â§ 5.2.2.7&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Therefore:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a shared cache must not store the response; and&lt;/li&gt;
&lt;li&gt;a private cache may store the response even if the response wouldnât otherwise be heuristically cacheable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The &lt;code&gt;private&lt;/code&gt; directive can be used to guard against other directives that might inadvertently make &lt;a href="#caching-authenticated-responses"&gt;authenticated responses available to shared caches&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;public&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;public&lt;/code&gt; response directive indicates two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a shared cache may &lt;a href="#caching-authenticated-responses"&gt;store and reuse a response to a request containing an &lt;code&gt;Authorization&lt;/code&gt; header&lt;/a&gt;, which itâs generally prohibited from doing; and&lt;/li&gt;
&lt;li&gt;a private cache may store the response even if the response wouldnât otherwise be heuristically cacheable.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-public"&gt;â RFC 9111 Â§ 5.2.2.9&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;s-maxage=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;s-maxage=&amp;lt;number&amp;gt;&lt;/code&gt; response directive is analogous to &lt;code&gt;max-age&lt;/code&gt;, but only affects shared caches. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-s-maxage"&gt;â RFC 9111 Â§ 5.2.2.10&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The directive also incorporates the semantics of the &lt;code&gt;proxyârevalidate&lt;/code&gt; response directive, in that a shared cache must not use a stale response until it has been successfully validated with the origin server.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Side effects:&lt;/strong&gt; &lt;code&gt;s-maxage&lt;/code&gt; is one of the directives, along with &lt;code&gt;must-revalidate&lt;/code&gt; and &lt;code&gt;public&lt;/code&gt;, that allow shared caches to &lt;a href="#caching-authenticated-responses"&gt;store and reuse a response to a request containing an &lt;code&gt;Authorization&lt;/code&gt; header&lt;/a&gt;, which they are generally prohibited from doing.&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;proxy-revalidate&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;proxy-revalidate&lt;/code&gt; response directive is analogous to &lt;code&gt;must-revalidate&lt;/code&gt;, but only affects shared caches. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-proxy-revalidate"&gt;â RFC 9111 Â§ 5.2.2.8&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;no-transform&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;no-transform&lt;/code&gt; response directive indicates that intermediaries, regardless of whether they implement a cache or not, must not transform the response content, such as optimizing images or compressing stylesheets and scripts. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-no-transform-2"&gt;â RFC 9111 Â§ 5.2.2.6&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;stale-while-revalidate=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;stale-while-revalidate&lt;/code&gt; response directive was defined in &lt;a href="https://www.rfc-editor.org/rfc/rfc5861"&gt;RFC 5861: HTTP Cache-Control Extensions for Stale Content&lt;/a&gt; (2010). It indicates that the cache may use a cached response if it hasnât exceeded its freshness lifetime by more than the specified number of seconds.&lt;/p&gt;
&lt;p&gt;Whenever the presence of this directive causes a stale response to be served, the cache should trigger a background revalidation of the response.&lt;/p&gt;
&lt;p&gt;The author of the RFC, Mark Nottingham, &lt;a href="https://www.mnot.net/blog/2014/06/01/chrome_and_stale-while-revalidate"&gt;has written a rationale&lt;/a&gt; for this directive.&lt;/p&gt;
&lt;h3&gt;
&lt;p&gt;&lt;code&gt;stale-if-error=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;/h3&gt;
&lt;p&gt;Also defined in the RFC 5861 extension, the &lt;code&gt;stale-if-error&lt;/code&gt; response directive indicates that the cache may use a cached response if it hasnât exceeded its freshness lifetime by more than the specified number of seconds, if the attempt to validate the stale response results in an error.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://cache-tests.fyi/"&gt;HTTP Caching Tests&lt;/a&gt; suggests this directive is not well supported.&lt;/p&gt;
&lt;h2&gt;Cache-Control request directives&lt;/h2&gt;
&lt;p&gt;As web developers, we most often deal with &lt;code&gt;Cache-Control&lt;/code&gt; in HTTP responses, but this header can also be included on HTTP requests. Browsers, for example, use them when the user refreshes the page.&lt;/p&gt;
&lt;p&gt;When used in HTTP requests, &lt;code&gt;Cache-Control&lt;/code&gt; directives express the clientâs preference in regards to the freshness or age of the response. Caches reconcile these requests with the &lt;code&gt;Cache-Control&lt;/code&gt; response directives of its cached responses.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Note: the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/RequestInit#cache"&gt;&lt;code&gt;cache&lt;/code&gt; option&lt;/a&gt; for &lt;code&gt;fetch()&lt;/code&gt; has a separate set of values that map to &lt;code&gt;Cache-Control&lt;/code&gt; request directives, but the mappings are not always intuitive. For example, &lt;code&gt;cache: 'no-cache'&lt;/code&gt; maps to &lt;code&gt;Cache-Control: max-age=0&lt;/code&gt;. For the curious, the mappings are &lt;a href="https://fetch.spec.whatwg.org/#http-network-or-cache-fetch"&gt;defined here&lt;/a&gt;. You can always set your &lt;code&gt;Cache-Control&lt;/code&gt; headers directly with the &lt;code&gt;headers&lt;/code&gt; option.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;&lt;code&gt;max-age=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;max-age&lt;/code&gt; request directive indicates that the client wants a fresh response whose age is less than or equal to the specified number of seconds. When combined with &lt;code&gt;max-stale&lt;/code&gt;, the client will accept some stale responses. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-max-age"&gt;â RFC 9111 Â§ 5.2.1.1&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;max-stale=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;max-stale&lt;/code&gt; request directive indicates that the client will accept a stale response that has exceeded its freshness lifetime by no more than the specified number of seconds. When used without an argument, &lt;code&gt;max-stale&lt;/code&gt; indicates that the client will accept any stale response, no matter how old. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#section-5.2.1.2"&gt;â RFC 9111 Â§ 5.2.1.2&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;min-fresh=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;min-fresh&lt;/code&gt; request directive indicates that the client prefers a response that still has at least the specified number of seconds of freshness left. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-min-fresh"&gt;â RFC 9111 Â§ 5.2.1.3&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;no-cache&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;no-cache&lt;/code&gt; request directive indicates that the client prefers caches not to use a stored response without successfully validating it with the origin server. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-no-cache"&gt;â RFC 9111 Â§ 5.2.1.4&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;no-store&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;no-store&lt;/code&gt; request directive indicates that a cache must not store any part of either this request or any response to it. The same caveats as to &lt;a href="#no-store-response"&gt;its response counterpart&lt;/a&gt; apply. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-no-store"&gt;â RFC 9111 Â§ 5.2.1.5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If a cache serves this request with a response that was previously stored, the &lt;code&gt;no-store&lt;/code&gt; request directive doesnât cause the cache to remove the response after serving it.&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;no-transform&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;no-transform&lt;/code&gt; request directive indicates that the client is asking for intermediaries to avoid transforming the content. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-no-transform"&gt;â RFC 9111 Â§ 5.2.1.6&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;only-if-cached&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;only-if-cached&lt;/code&gt; request directive indicates that the client only wants a stored response. Caches should respond with either a stored response that satisfies all the other constraints, or an HTTP 504 Gateway Timeout status code. &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-only-if-cached"&gt;â RFC 9111 Â§ 5.2.1.7&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;&lt;code&gt;stale-if-error=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;Similarly to &lt;a href="#stale-if-error-response"&gt;its response counterpart&lt;/a&gt;, the &lt;code&gt;stale-if-error&lt;/code&gt; request directive indicates that the client will accept a stale response that has exceeded its freshness lifetime by no more than the specified number of seconds, if an attempt to validate it resulted in a server error.&lt;/p&gt;
&lt;h2&gt;Browser refresh mechanisms&lt;/h2&gt;
&lt;p&gt;Browsers typically offer two refresh mechanisms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;soft reloads&lt;/em&gt;, triggered by the reload button, a corresponding menu item and keyboard shortcut, and the pull-to-refresh gesture in mobile browsers, are meant to get an updated representation of the page, for example getting the latest posts on a social media timeline.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;hard reloads&lt;/em&gt;, enabled with a modifier key, skip the cache altogether and are meant to fix interrupted loads, outdated cached responses, and other broken states.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hereâs how some browsers on macOS implement these behaviors.&lt;/p&gt;
&lt;h3&gt;Soft reloads&lt;/h3&gt;
&lt;p&gt;Triggered by Ctrl + R on Windows/Linux and Command + R on macOS.&lt;/p&gt;
&lt;p&gt;Firefox triggers a conditional request to revalidate the cached response for the main resource (the HTML file). Sub-resources such as stylesheets, scripts, and images are reloaded as usual, according to their cache directives.&lt;/p&gt;
&lt;p&gt;Chrome behaves similarly, with the difference that the validation request for the main resource also includes a &lt;code&gt;Cache-Control: max-age=0&lt;/code&gt; directive (which canât hurt).&lt;/p&gt;
&lt;p&gt;Instead of revalidating its cached response, Safari performs a non-conditional request for the main resource, then loads sub-resources as usual.&lt;/p&gt;
&lt;h3&gt;Hard reloads&lt;/h3&gt;
&lt;p&gt;Triggered by Ctrl + Shift + R on Windows/Linux and Command + Shift + R on macOS except Safari, which uses Command + Option + R. (If youâve applied your muscle memory to Safari before, you know all too well that the common shortcut opens Reader Mode insteadâ¦)&lt;/p&gt;
&lt;p&gt;On a hard reload, all three browsers trigger non-conditional requests with the &lt;code&gt;Cache-Control: no-cache&lt;/code&gt; directive on the HTML page and its sub-resources.&lt;/p&gt;
&lt;p&gt;Curiously, once you perform a hard reload in Safari, subsequent soft reloads will still use the &lt;code&gt;Cache-Control: no-cache&lt;/code&gt; request directive to fetch the main resource, which is probably an unintended, but otherwise benign behavior.&lt;/p&gt;
&lt;h3&gt;The &lt;code&gt;immutable&lt;/code&gt; response directive&lt;/h3&gt;
&lt;p&gt;Reloading a web page didnât always work like this. Historically, when performing a soft reload, all the sub-resources would be revalidated along with the main resource, in effect freshening up the cache for the current page.&lt;/p&gt;
&lt;p&gt;Circa 2015, Facebook was seeing several HTTP 304 Not Modified responses on long-lived resources like scripts and stylesheets whenever a user would refresh their feed page with the browserâs reload button.&lt;/p&gt;
&lt;p&gt;To address this issue, Patrick McManus from Mozilla &lt;a href="https://bitsup.blogspot.com/2016/05/cache-control-immutable.html"&gt;proposed&lt;/a&gt; the &lt;code&gt;immutable&lt;/code&gt; response directive, which later became &lt;a href="https://www.rfc-editor.org/rfc/rfc8246"&gt;RFC 8246: HTTP Immutable Responses&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The directive indicates that the origin server wonât update a resource during the freshness lifetime of the cached response, so a cache shouldnât issue conditional requests for responses that are still fresh when the user reloads the page, unless the user really, really wants an updated response (e.g. a hard reload).&lt;/p&gt;
&lt;p&gt;Around the time that &lt;a href="https://hacks.mozilla.org/2017/01/using-immutable-caching-to-speed-up-the-web/"&gt;support for &lt;code&gt;immutable&lt;/code&gt;&lt;/a&gt; landed in Firefox 49 and Facebook began to use it to great effect, Chrome introduced a &lt;a href="https://blog.chromium.org/2017/01/reload-reloaded-faster-and-leaner-page_26.html"&gt;new way to perform reloads&lt;/a&gt; that solved the problem without introducing additional directives: instead of revalidating everything on a soft reload, just revalidate the main resource and load sub-resources as usual. Safari switched over to the new reload policy soon after [&lt;a href="https://bugs.webkit.org/show_bug.cgi?id=169756"&gt;Webkit#169756&lt;/a&gt;], and Firefox eventually did with &lt;a href="https://www.firefox.com/en-US/firefox/100.0/releasenotes/"&gt;Firefox 100&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;That leaves the &lt;code&gt;immutable&lt;/code&gt; directive in an awkward place. Safari added support [&lt;a href="https://bugs.webkit.org/show_bug.cgi?id=167497"&gt;Webkit#167497&lt;/a&gt;] but Chrome representatives remain unconvinced that it offers a significant benefit on top of the current reload behavior [&lt;a href="https://issues.chromium.org/issues/41253661"&gt;Chromium#41253661&lt;/a&gt;].&lt;/p&gt;
&lt;h2&gt;
Caching responses to authenticated requests
&lt;/h2&gt;
&lt;p&gt;One of the more confusing aspects of HTTP caching is how various &lt;code&gt;Cache-Control&lt;/code&gt; response directives affect the way shared caches treat responses to requests that contain an &lt;a href="https://www.rfc-editor.org/rfc/rfc9110#name-authorization"&gt;&lt;code&gt;Authorization&lt;/code&gt; header&lt;/a&gt;, which are understood as specific to a single user.&lt;/p&gt;
&lt;p&gt;As per &lt;a href="https://www.rfc-editor.org/rfc/rfc9111#name-storing-responses-to-authen"&gt;RFC 9111 Â§ 3.5&lt;/a&gt;, shared caches are not allowed to store these responses unless the response contains a Cache-Control field with a response directive that allows it to be stored by a shared cache, and the cache conforms to the requirements of that directive for that response.&lt;/p&gt;
&lt;p&gt;The three directives that enable shared caches to store authenticated responses, and which must therefore be carefully evaluated before deploying, are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#public-response"&gt;&lt;code&gt;public&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#s-maxage-response"&gt;&lt;code&gt;s-maxage=&amp;lt;number&amp;gt;&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#must-revalidate-response"&gt;&lt;code&gt;must-revalidate&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Conversely, a &lt;a href="#private-response"&gt;&lt;code&gt;private&lt;/code&gt;&lt;/a&gt; directive prevents any other directive from making authenticated responses eligible to shared caches.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;I wrote this article to clarify for myself what the various cache directives stand for and how they overlap and interact. It only covers the main ideas, without delving into the more obscure corners of HTTP semantics. I approached the subject with a âclear cacheâ, and mainly used the normative references (RFC 9111 and its extensions), aided by various guides from different eras:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.mnot.net/cache_docs/"&gt;Caching Tutorial for Web Authors and Webmasters&lt;/a&gt; (1998â) by Mark Nottingham;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://jakearchibald.com/2016/caching-best-practices/"&gt;Caching best practices &amp;amp; max-age gotchas&lt;/a&gt; (2016) by Jake Archibald;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://web.dev/articles/http-cache"&gt;Prevent unnecessary network requests with the HTTP Cache&lt;/a&gt; (2018) by Ilya Grigorik and Jeff Posnik;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://csswizardry.com/2019/03/cache-control-for-civilians/"&gt;Cache control for civilians&lt;/a&gt; (2019â2025) and &lt;a href="https://csswizardry.com/2025/03/why-do-we-have-a-cache-control-request-header/"&gt;Why Do We Have a Cache-Control Request Header?&lt;/a&gt; (2025) by Harry Roberts;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://grayduck.mn/2021/09/13/cache-control-recommendations/"&gt;Cache-Control Recommendations&lt;/a&gt; (2021) by April King;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Guides/Caching"&gt;Web Caching&lt;/a&gt; on MDN.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Whatâs interesting about these guides is that the recommendations donât just encode an interpretation of the specs, but also incorporate safeguards against non-conformant or outdated browser caches and intermediares.&lt;/p&gt;
&lt;p&gt;In light of developments as recent as 2022, it would be cool to figure out to what extent things have improved, and which of these safeguards can be discarded. &lt;a href="https://cache-tests.fyi/"&gt;HTTP Caching Tests&lt;/a&gt; seems to be a good resource for assessing the situation.&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://danburzo.ro/http-caching-refresher/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 19:41:39 +0000</pubDate>
    </item>
    <item>
      <title>Fixed-Wing Runway Design</title>
      <link>https://www.wbdg.org/building/aviation/fixed-wing-runway-design</link>
      <description>Runways are the primary operating surface at airfields and essential to fixed-wing aircraft operations.  Fixed-wing runways are built in a variety of lengths, widths, and pavement types depending on a large number of factors, including:</description>
      <content:encoded>&lt;article class="node node--type-wbdg-pages node--view-mode-full clearfix" data-history-node-id="1164"&gt;








&lt;h2&gt;Overview&lt;/h2&gt;

&lt;h4&gt;Within This Page&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#over"&gt;Overview&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#desc"&gt;Runway Design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#rcas"&gt;Relevant Codes and Standards&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Runways are the primary operating surface at airfields and essential to fixed-wing aircraft operations.  Fixed-wing runways are built in a variety of lengths, widths, and pavement types depending on a large number of factors, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Aircraft Type (Operating Characteristics, Wingspan, Weight)&lt;/li&gt;
&lt;li&gt;Mission&lt;/li&gt;
&lt;li&gt;Number of Operations&lt;/li&gt;
&lt;/ul&gt;


&lt;img alt="C-17 touching down on runway, Pope Army Airfield" src="https://www.wbdg.org/images/fixedwing_01.jpg"/&gt;
&lt;p&gt;C-17 touchdown on runway
&lt;em&gt;Source: Defense Visual Information Distribution Service&lt;/em&gt;&lt;/p&gt;


&lt;p&gt;The primary reference describing requirements for DoD Fixed Wing Runways is Chapter 3 of &lt;a href="https://www.wbdg.org/ffc/dod/unified-facilities-criteria-ufc/ufc-3-260-01"&gt;UFC 3-260-01, &lt;em&gt;Airfield and Heliport Planning and Design&lt;/em&gt;&lt;/a&gt;. Other special use runways (Landing Zones, STOVL Facilities and UAS runways) are defined in Chapters 7, 8 and 9 of the UFC.&lt;/p&gt;


&lt;img alt="typical airport diagram, JB Andrews" src="https://www.wbdg.org/images/fixedwing_02.png"/&gt;
&lt;p&gt;Typical airport diagram&lt;br/&gt;&lt;a href="https://www.wbdg.org/images/fixedwing_02_fullsize.png"&gt;&lt;em&gt;(View enlarged diagram)&lt;/em&gt;&lt;/a&gt;
&lt;em&gt;Source: Federal Aviation Administration&lt;/em&gt;&lt;/p&gt;


&lt;p&gt;Each DoD Service classifies fixed-wing runways into two primary categories—Class A or Class B—depending primarily on the type(s) of aircraft using the runway.  That classification drives many required construction features of the runway, including length, width, transverse slopes, and longitudinal grades.  It should be noted that civilian runways are classified by a very different system, defined in Federal Aviation Administration Advisory Circular 150/5300-13, &lt;em&gt;Airport Design&lt;/em&gt;, with a classification system based on the critical aircraft's wingspan and landing approach speed.&lt;/p&gt;
&lt;p&gt;Fixed-wing runways are usually constructed with a rigid pavement surface (Portland cement concrete) or flexible pavement surface (asphalt cement concrete), but in special cases may be surfaced with compacted soil, aggregates, or segmented aluminum mats, depending on the mission requirements.&lt;/p&gt;
&lt;p&gt;Taxiways are used by aircraft to enter and exit a runway and transit to an aircraft parking position.  Taxiways connect directly to runways, most often at the runway ends.&lt;/p&gt;
&lt;p&gt;In addition to the runway pavement surface, there are many ground surface areas immediately surrounding the runway that improve safety for the operating aircraft by limiting the risk of damage should an aircraft accidentally depart from the runway surface.&lt;/p&gt;
&lt;p&gt;Not only must objects be restricted from close proximity to the runway surface, the airspace surrounding a runway must also be protected from development that encroaches on the airspace needed for safe aircraft operations.  The protected areas are defined by what are known as "imaginary surfaces."  These are generally planar or conical surfaces in the air, defined by a length, width, and slope up to a specified elevation.&lt;/p&gt;
&lt;h2&gt;Runway Design&lt;/h2&gt;
&lt;p&gt;There are many different factors that impact runway design and are dependent on many different data inputs.  All components should be determined early in the planning process to avoid unexpected challenges or constraints later in the design development.
&lt;/p&gt;&lt;h3&gt;Runway Heading&lt;/h3&gt;
&lt;p&gt;Runways are oriented to provide the best conditions for an aircraft on takeoff and landing.  An aircraft moving directly into the wind has the highest airspeed across the wing, thereby increasing lift, and the least sideways forces on the aircraft.  Therefore, the ideal orientation of the runway (often referred to as the &lt;em&gt;heading&lt;/em&gt;) is determined by analyzing historical wind data (10 years or more) at a location.  Wind heading and speed data is graphically displayed on a &lt;em&gt;Wind Rose&lt;/em&gt;, and this tool can be used to determine a runway heading that provides the greatest percentage of time with favorable winds for aircraft operations.  The objective is to find a heading that allows operations more than 95% of the time with a crosswind less than 19.5 km/hr (10.5 knot).  When a single runway cannot provide this coverage, then a crosswind runway may be required.  UFC 3-260-01, Appendix B, Section 4 explains this process in detail.&lt;/p&gt;


&lt;img alt="windrose used for runway heading analysis" src="https://www.wbdg.org/images/fixedwing_03.png"/&gt;
&lt;p&gt;Windrose used for Runway Heading Analysis
&lt;em&gt;Source: UFC 3-260-01, Appendix B, Section 4&lt;/em&gt;&lt;/p&gt;


&lt;p&gt;In addition to prevailing winds, other factors may affect the selection of a runway heading, including terrain, obstructions, restricted airspace, noise effects, built-up areas, or operational procedures.&lt;/p&gt;
&lt;h3&gt;Runway Length&lt;/h3&gt;
&lt;p&gt;Each service determines the required runway length using their own procedures that generally take into account the mission aircraft performance requirements, altitude, and typical temperature range.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Air Force:&lt;/strong&gt; For both Class A and B runways, the length will be determined by the Major Command responsible for the airfield.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Army:&lt;/strong&gt; The Class A runway length requirement is listed in UFC 3-260-01, Table 3-3, but for Class B Runways, runway length is determined by the using aircraft operator, in conjunction with HQ Department of the Army.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Navy and Marine Corps:&lt;/strong&gt; UFC 2-000-05N describes the process for determining runway length to accommodate the critical aircraft in both takeoff and landing operations under stated load and environmental conditions.  Minimum lengths by aircraft type are listed in Table 11110-1; then adjusted for altitude, temperature, and effective gradient with a safety factor applied to the result.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Runway Width&lt;/h3&gt;
&lt;p&gt;For the DoD, the runway width is dependent on the type of aircraft planned to use the airfield.  Table 3-1 in UFC 3-260-01 classifies aircraft into Class A or B.  Then Table 3-2 defines the required runway width for each class.  There are some exceptions to the standard widths, as defined in Item 2.  Runways for Bombers like the B-52 are 300-ft wide, and some training runways for small aircraft are only 75-ft wide.  Special-use runways (&lt;a href="https://www.wbdg.org/building-types/aviation/landing-zone-design"&gt;Landing Zones&lt;/a&gt;, Short Takeoff and Vertical Landing (STOVL) facilities, and Unmanned Aircraft Systems (UAS) runways have their own requirements, defined in UFC 3-260-01, Chapters 7, 8 and 9.)&lt;/p&gt;
&lt;h3&gt;Clear Zones and Accident Potential Zones&lt;/h3&gt;
&lt;p&gt;Clear Zones are areas on the ground at the ends of runways that have a high potential for accidents.  Other uses of the clear zone are restricted to be compatible with aircraft operations.  Each DoD service defines clear zones differently, so UFC 3-260-01, Table 3-5 should be carefully considered to provide the appropriate dimensions.  Clear Zones should be owned and controlled by the agency to prevent incompatible development within the areas.&lt;/p&gt;
&lt;p&gt;Accident Potential Zones (APZs) are land-use control areas, mandated by the Air Installation Compatibility Use Zones (AICUZ) program, and intended to promote only compatible development in areas under the approach and departure surfaces for fixed-wing runways.  The APZs usually stretch beyond the base property boundaries, so coordination with the local communities is essential to avoid building high population development in these areas where an aircraft accident is more likely to occur.&lt;/p&gt;
&lt;h3&gt;Imaginary Surfaces and Obstructions&lt;/h3&gt;
&lt;p&gt;The area above the ground surrounding a runway that must be kept clear of objects that might damage an aircraft operating around the airfield (approach, departure or circling) is defined by Imaginary Surfaces (planar or conical surfaces in the airspace).  An object that projects above an imaginary surface is an obstruction.  Typical terminology for imaginary surfaces includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Primary surface&lt;/li&gt;
&lt;li&gt;Approach-departure surface&lt;/li&gt;
&lt;li&gt;Inner horizontal surface&lt;/li&gt;
&lt;li&gt;Conical surface&lt;/li&gt;
&lt;li&gt;Outer horizontal surface&lt;/li&gt;
&lt;li&gt;Transitional surface&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each of these surfaces is defined in UFC 3-260-01, Chapter 3.&lt;/p&gt;


&lt;img alt="isometric view of airspace around fixed-wing runway" src="https://www.wbdg.org/images/fixedwing_04.jpg"/&gt;
&lt;p&gt;Isometric view of airspace around Fixed-Wing Runway &lt;a href="https://www.wbdg.org/images/fixedwing_04_fullsize.jpg"&gt;&lt;em&gt;(View enlarged)&lt;/em&gt;&lt;/a&gt;
&lt;em&gt;Source: UFC 3-260-01, Chapter 3&lt;/em&gt;&lt;/p&gt;


&lt;h3&gt;Grades&lt;/h3&gt;
&lt;p&gt;There are strict requirements for the slope or grade of the runway pavement surfaces and ground surfaces surrounding the runway.  These surfaces are dependent on the performance requirements of the aircraft (Class A or B) and to promote good drainage as well as aircraft safety in the event that an aircraft accidentally departs from the runway surface.  UFC 3-260-01, Chapter 3 defines the requirements for the grades of the following items:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Longitudinal Grades and Rate of Grade Change for Runways, Shoulders, Overruns and Lateral Clearance Zone&lt;/li&gt;
&lt;li&gt;Transverse Slopes for Runway, Shoulders, Overruns and Lateral Clearance Zone&lt;/li&gt;
&lt;li&gt;Longitudinal and Transverse Grades in the Clear Zone&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Pavement Thickness Design&lt;/h3&gt;
&lt;p&gt;Runway pavements for military airfields are designed following the procedures described in UFC 3-260-02, &lt;em&gt;Pavement Design for Airfields&lt;/em&gt;.  Typically, runways are constructed with a flexible pavement structure (asphaltic concrete pavement) or rigid pavement structure (Portland cement concrete).&lt;/p&gt;
&lt;p&gt;For pavement thickness design, each Service divides an airfield and the runway into different types of traffic areas, (e.g., Type A, Type C, Primary, or Secondary).  The traffic type then correlates to different traffic patterns (aircraft load, number of repetitions, and the typical "wander" of the aircraft traffic).  When traffic is combined with the subgrade strength, the required pavement thickness can be determined.&lt;/p&gt;
&lt;h3&gt;Pavement Markings&lt;/h3&gt;
&lt;p&gt;To improve the visibility of runways during both day and night, standard markings are painted on the pavement surface.  There are three primary runway marking schemes—Visual, Non-Precision Instrument, and Precision Instrument—with progressively more markings.  Runway markings are white (as compared to yellow markings on taxiways) and include embedded glass beads to provide reflectivity.  At each end, the runway heading number is painted, and when there are one or more parallel runways, a left (L), right (R) or center (C) designation is also applied.&lt;/p&gt;


&lt;img alt="marking schemes for fixed-wing runways" src="https://www.wbdg.org/images/fixedwing_05.png"/&gt;
&lt;p&gt;Marking schemes for Fixed-Wing Runways&lt;br/&gt;&lt;a href="https://www.wbdg.org/images/fixedwing_05_fullsize.png"&gt;&lt;em&gt;(View enlarged)&lt;/em&gt;&lt;/a&gt;
&lt;em&gt;Source: UFC 3260-04, Chapter 5&lt;/em&gt;&lt;/p&gt;


&lt;p&gt;UFC 3-260-04, &lt;em&gt;Airfield and Heliport Marking&lt;/em&gt;, fully defines pavement marking requirements for Army and Air Force fixed-wing runways.  Navy and Marine Corps requirements are defined in NAVAIR 51-50AAA-2, &lt;em&gt;General Requirements for Shorebased Airfield Marking and Lighting&lt;/em&gt;.  Each Service's requirements very closely match the Federal Aviation Administration runway marking requirements.&lt;/p&gt;
&lt;h3&gt;Runway Lighting and Signs&lt;/h3&gt;
&lt;p&gt;For low visibility and night operations on runways, lights and signs are used to provide visibility of the runway to pilots when operating on the ground and in the air.  The most basic fixed-wing runway lighting system consists of edge lights, threshold lights and end lights, used to outline the lateral and longitudinal limits of the usable surface of the runway.  These lights are required for visual flight rules (VFR) night operations and for all categories of instrument operations.  In some cases where minimal visibility operational capability is needed, the runway perimeter lighting is augmented with touchdown zone and centerline lighting in-pavement light fixtures.&lt;/p&gt;


&lt;img alt="runway threshold lighting and markings" src="https://www.wbdg.org/images/fixedwing_06.jpg"/&gt;
&lt;p&gt;Runway threshold lighting and markings
&lt;em&gt;Source: Crawford, Murphy &amp;amp; Tilly, Inc.&lt;/em&gt;&lt;/p&gt;


&lt;p&gt;Approach light systems provide visual guidance to pilots aligning their aircraft with the runway and attempting final corrections before landing at night or during low visibility.  There are several different types of approach lighting systems (MALSR, SSALR, ALSF-1, ALSF-2), each with a different number of lights and different configurations.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.wbdg.org/ffc/dod/unified-facilities-criteria-ufc/ufc-3-535-01"&gt;UFC 3-535-01, &lt;em&gt;Visual Air Navigation Facilities&lt;/em&gt;&lt;/a&gt;, fully defines lighting and signage requirements for Army and Air Force fixed-wing runways.  Navy and Marine Corps requirements are defined in &lt;a href="https://www.wbdg.org/ffc/dod/supplemental-technical-documents/tsewg-navair-51-50AAA-2"&gt;NAVAIR 51-50AAA-2, &lt;em&gt;General Requirements for Shorebased Airfield Marking and Lighting&lt;/em&gt;&lt;/a&gt;.  Each Service's requirements very closely match the Federal Aviation Administration runway lighting and signage requirements.&lt;/p&gt;
&lt;h3&gt;Electronic Navigational Aids (NAVAIDs)&lt;/h3&gt;
&lt;p&gt;Some aircraft are equipped with electronic devices that can use radio signals to provide direction, distance, and glide slope data to help the pilot guide the aircraft to the runway.  These systems are called NAVAIDs and consist of a wide variety of antennas installed in various configurations surrounding the runway.  For example, an Instrument Landing System (ILS) consists of a Localizer antenna and Glide Slope antenna.  The Localizer transmits a radio signal down the centerline of the runway into the approach zone, and the pilot can use the signal to align on the runway.  The Glide Slope transmits a radio signal upwards from the runway surface at the correct approach angle the aircraft should follow to touchdown at the appropriate location on the runway surface.  Many different types of NAVAID systems have been developed over the years and are deployed at DoD installations.  UFC 4-141-10, Airfield Operations Support Facilities describes the different types of NAVAIDs, including installation requirements for each system.&lt;/p&gt;
&lt;h2&gt;Relevant Codes and Standards&lt;/h2&gt;
&lt;h3&gt;Federal Aviation Administration&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.faa.gov/airports/resources/advisory_circulars/index.cfm/go/document.current/documentNumber/150_5300-13"&gt;Advisory Circular 150/5300-13 &lt;em&gt;Airport Design&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Naval Air Systems Command&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.wbdg.org/ffc/dod/supplemental-technical-documents/tsewg-navair-51-50AAA-2"&gt;NAVAIR 51-50AAA-2 &lt;em&gt;General Requirements for Shorebased Airfield Marking and Lighting&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Unified Facility Criteria&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.wbdg.org/ffc/dod/unified-facilities-criteria-ufc/ufc-2-000-05n"&gt;UFC 2-000-05N &lt;em&gt;Facility Planning for Navy and Marine Corps Shore Installations&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.wbdg.org/ffc/dod/unified-facilities-criteria-ufc/ufc-3-260-01"&gt;UFC 3-260-01 &lt;em&gt;Airfield and Heliport Planning and Design&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.wbdg.org/ffc/dod/unified-facilities-criteria-ufc/ufc-3-260-02"&gt;UFC 3-260-02 &lt;em&gt;Pavement Design for Airfields&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.wbdg.org/ffc/dod/unified-facilities-criteria-ufc/ufc-3-260-04"&gt;UFC 3-260-04 &lt;em&gt;Airfield and Heliport Marking&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.wbdg.org/ffc/dod/unified-facilities-criteria-ufc/ufc-3-535-01"&gt;UFC 3-535-01 &lt;em&gt;Visual Air Navigation Facilities&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.wbdg.org/ffc/dod/unified-facilities-criteria-ufc/ufc-4-141-10"&gt;UFC 4-141-10 &lt;em&gt;Airfield Operations Support Facilities&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt; 













&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.wbdg.org/building/aviation/fixed-wing-runway-design</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 19:41:14 +0000</pubDate>
    </item>
    <item>
      <title>Terrence Malick's Disciples</title>
      <link>https://yalereview.org/article/bilge-ebiri-terrence-malick</link>
      <description>In the winter of 2024, the photographer and filmmaker RaMell Ross released Nickel Boys , a masterful adaptation of a novel by Colson Whitehead. In a fragmentary, impressionistic style, the film portrays the friendship of two African American teens at a brutal Florida reform academy during the Jim Crow era. Acclaimed as a visionary movie, it ended up on many critics’ best-of-the-year lists and earned an Oscar nomination for Best Picture.</description>
      <content:encoded>&lt;main&gt;






&lt;a href="https://yalereview.org/reviews"&gt;                Film
            &lt;/a&gt; 
&lt;h1&gt;Terrence Malick’s Disciples&lt;/h1&gt;
&lt;h2&gt;Why the auteur is the most influential director in Hollywood&lt;/h2&gt;
&lt;a href="https://yalereview.org/author/bilge-ebiri"&gt;Bilge Ebiri&lt;/a&gt;
















&lt;img src="https://d181q449nqu6en.cloudfront.net/content/craft/articles/_850xAUTO_crop_center-center_none/Ebiri-Hamnet.jpg"/&gt;
Paul Mescal in &lt;em&gt;Hamnet&lt;/em&gt;, directed by Chloé Zhao, 2025. Photo by Bruno Engler, courtesy Paramount Pictures


&lt;p&gt;In the winter of 2024, the photographer and filmmaker RaMell Ross released &lt;em&gt;&lt;a href="https://www.mgm.com/movies/nickel-boys"&gt;Nickel Boys&lt;/a&gt;&lt;/em&gt;, a masterful adaptation of a novel by Colson Whitehead. In a fragmentary, impressionistic style, the film portrays the friendship of two African American teens at a brutal Florida reform academy during the Jim Crow era. Acclaimed as a visionary movie, it ended up on many critics’ best-of-the-year lists and earned an Oscar nomination for Best Picture.&lt;/p&gt;
&lt;p&gt;Ross is a fiercely independent artist. His first film, the lyrical 2018 documentary &lt;em&gt;&lt;a href="https://www.halecountyfilm.com/"&gt;Hale County This Morning, This Evening&lt;/a&gt;&lt;/em&gt;, was also nominated for an Oscar. Afterward, he refused Hollywood’s overtures for years. So why did he take a meeting with the producers who reached out to him about making a studio-financed, big-budget adaptation of &lt;em&gt;Nickel Boys&lt;/em&gt;? Ross’s explanation was simple: because one of them had produced Terrence Malick’s 2011 film, &lt;em&gt;The Tree of Life&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Ross’s reverence for Malick is plain in his films, which, like Malick’s, rely on extended montages of the everyday and do away with the conventional rules of cinematic storytelling, hovering instead between distant, melancholy reverie and hyperfocused, lived-in specificity. And he is not the only recent filmmaker who has fallen under Malick’s spell. Indeed, Malick’s sensibility, visual style, and working methods have had a profound influence on some of today’s best and most interesting directors.&lt;/p&gt;


&lt;p&gt;Take Chloé Zhao, the director of the Oscar-winning &lt;em&gt;&lt;a href="https://youtu.be/6sxCFZ8_d84?si=Spz64UoSqoF2ynD5"&gt;Nomadland&lt;/a&gt;&lt;/em&gt; (2020). Her early films, all set in the American heartland, were regularly compared to Malick’s, and she herself pointed to &lt;em&gt;The Tree of Life&lt;/em&gt; and Malick’s 2005 film, &lt;em&gt;The New World&lt;/em&gt;, as influences on her 2021 Marvel superhero movie, &lt;em&gt;&lt;a href="https://youtu.be/x_me3xsvDgk?si=nL9gBh2F6ZqK9OVH"&gt;Eternals&lt;/a&gt;&lt;/em&gt;. Those overtones persist in her latest, &lt;em&gt;&lt;a href="https://youtu.be/xYcgQMxQwmk?si=l1wBmajhpCH-lJUM"&gt;Hamnet&lt;/a&gt;&lt;/em&gt;, a film about the death of William Shakespeare’s only son and his subsequent creation of &lt;em&gt;Hamlet&lt;/em&gt;. The movie may take place in Elizabethan England, but it is replete with lyrical passages and visions of nature that recall Malick’s work. &lt;/p&gt;
&lt;p&gt;The same is true of the director Clint Bentley’s newest film, &lt;em&gt;&lt;a href="https://youtu.be/_Nk8TrBHOrA?si=mO_kVRP4GGmDBk4S"&gt;Train Dreams&lt;/a&gt;&lt;/em&gt;, an adaptation of Denis Johnson’s 2011 novella about the unremarkable life of a logger and railroad worker in the early years of the twentieth century. Weaving episodes from its character’s life into an elegiac collage that incorporates domestic bliss, harrowing tragedy, and melancholic resignation, &lt;em&gt;Train Dreams&lt;/em&gt;—which premiered at the Sundance Film Festival in January and was quickly acquired by Netflix—unfolds across 102 minutes, yet seems to contain a whole world. Its protagonist, played by a reserved Joel Edgerton, is a simple man who occasionally questions his place in the universe but never understands it, save for a brief moment near the end when he takes a ride in an airplane—something he’s never done before—and, in one shining (and recognizably Malickian) instant, sees the shape of his life and feels something like transcendence.&lt;/p&gt;


&lt;p&gt;Malick’s influence is intriguing in part because he is not an obvious choice for filmmakers to emulate. He has had, to be sure, a fascinating career: a publicity-shy Harvard philosophy grad, Rhodes Scholar, former MIT lecturer, and &lt;em&gt;New Yorker&lt;/em&gt; writer, he made two brilliant and highly acclaimed films in the 1970s—the lovers-on-the-run drama &lt;em&gt;&lt;a href="https://www.criterion.com/films/28406-badlands?"&gt;Badlands&lt;/a&gt;&lt;/em&gt; and the visually striking romantic tragedy &lt;em&gt;&lt;a href="https://www.criterion.com/films/213-days-of-heaven?srsltid=AfmBOoouFpCvAOG7BaRoQWdFniUoq-h4H-iEFs6titI0gYDjrfT5PDjD"&gt;Days of Heaven&lt;/a&gt;&lt;/em&gt;—before stepping away from filmmaking for twenty years. In 1998, he returned with &lt;em&gt;&lt;a href="https://youtu.be/mKl5_OxKBn8?si=9kaWNR1ul8Ku1va6"&gt;The Thin Red Line&lt;/a&gt;&lt;/em&gt;, a dreamy, diffuse adaptation of James Jones’s World War II novel, and followed that with two more ruminative epics: &lt;em&gt;&lt;a href="https://www.criterion.com/films/28713-the-new-world?"&gt;The New World&lt;/a&gt;&lt;/em&gt;, about the settlement of Jamestown and the romance between John Smith and Pocahontas, and &lt;em&gt;&lt;a href="https://youtu.be/RrAz1YLh8nY?si=BuVLnECxS9cvJFjb"&gt;The Tree of Life&lt;/a&gt;&lt;/em&gt;, a massive autobiographical film that frames a mid-century Texas coming-of-age tale against the spectacular origins of the universe and of life on Earth. His films since then have been less ambitious in scope but, in some ways, more stylistically bold.&lt;/p&gt;
&lt;p&gt;Many of Malick’s films have been critically acclaimed, and two have received Oscar nominations for Best Picture (albeit without much chance of winning). But none could be called box-office hits, and some have been savaged by critics. Indeed, thanks to his fondness for oblique storytelling, poetic voice-over, and overt spiritual themes, Malick’s oeuvre has become one of the more contentious in cinema. Each new release inspires debate over whether the film at hand is a deep, philosophical masterpiece or boring, pretentious drivel. Young directors looking for heroes tend not to gravitate toward divisive religious artists whose movies don’t make money or win awards. So what accounts for Malick’s impact on twenty-first-century American film?&lt;/p&gt;


&lt;img src="https://d181q449nqu6en.cloudfront.net/content/craft/articles/_850xAUTO_crop_center-center_none/Ebiri_Tree-of-Life.jpg"/&gt;
Brad Pitt in &lt;em&gt;The Tree of Life&lt;/em&gt;, directed by Terrence Malick, 2011. Courtesy Fox Searchlight


&lt;p&gt;particularly since his return to filmmaking, Malick has sought to reconnect American cinema to a lost spirituality, earnestly tackling questions about faith and the design of the world at a time when most mainstream cinema has avoided such topics. Malick is a devout Episcopalian. But the spirituality in his films is rarely illustrative or prescriptive. He doesn’t use religion as a cudgel or a doctrinaire superstructure with which to explain the world. Rather, he sees it as an inner light in people. In &lt;em&gt;The Thin Red Line&lt;/em&gt;, for instance, soldiers, in voice-over, speak solemnly of inner longing. These otherwise inarticulate men’s voices read heartfelt love letters, or dabble in poetry, or edge their way into philosophical inquiries about the cruelty and redemptiveness of nature. A soldier remembers his mother reaching for an angel at the instant of her death; another recalls the serenity he experienced with his wife before he had to leave her behind. The effect is like eavesdropping on a kind of Emersonian oversoul. Malick endows even his most minor characters with humanity, which he views as a kind of holiness. Amid the gaunt and haunted faces of these soldiers, Malick finds grace.&lt;/p&gt;
&lt;p&gt;This kind of earnestness stood out in an age of relentless irony and snark. It served as a corrective to the glossy productions of Hollywood in its imperial phase, that period of the late 1990s and early 2000s, when budgets ballooned and American cinema, armed with state-of-the-art CGI and desperate to service a growing international market, became increasingly driven by fantasy spectacle and special effects. Malick’s films were a rebuke to even the hip grittiness of independent films of the era. He had an eye for light and an ear for music, he immersed viewers in color and texture, and he used his classical scores to underscore the glory of what he saw. Handcrafted, personal, achingly sincere, and at times proudly “flawed,” his pictures stood out against both the mainstream and the underground.&lt;/p&gt;


&lt;p&gt;
    By the end, we are overwhelmed with emotion for this unremarkable life lived in near anonymity.
    &lt;/p&gt;


&lt;p&gt;This proved irresistible for a certain kind of filmmaker frustrated with the options available to them. In 2000, for instance, the director David Gordon Green released &lt;em&gt;&lt;a href="https://www.criterionchannel.com/george-washington"&gt;George Washington&lt;/a&gt;&lt;/em&gt;, a drifting, multicharacter drama featuring young African American kids in a dead-end North Carolina steel town. Despite his impoverished setting, Green avoids miserabilist clichés and gives his characters a romantic grandeur. He takes their hopes and desires at face value. The title comes from the fact that one of the kids, named George, dreams of being president of the United States, a fact that Green does not treat with bitter irony or fashionable cynicism.&lt;/p&gt;
&lt;p&gt;Malick’s effect on &lt;em&gt;George Washington&lt;/em&gt; is undeniable—rare was the review that didn’t mention the connection—and it is also clear in Green’s second feature, &lt;em&gt;All the Real Girls&lt;/em&gt; (2003), an atmospheric and largely uneventful romance defined by the passions of the two shy lovers at its center. Noel (Zooey Deschanel) and Paul (Paul Schneider), like Malick’s characters in &lt;em&gt;Badlands&lt;/em&gt; and &lt;em&gt;Days of Heaven&lt;/em&gt;, are not extroverted or articulate. But Green’s film thrums with a visual splendor that reflects the characters’ longing, turning another depressed Southern town into a vibrant emotional landscape.&lt;/p&gt;
&lt;p&gt;Zhao’s films also highlight the great beauty of the otherwise unremarkable. Her masterpiece, 2017’s &lt;em&gt;&lt;a href="https://youtu.be/AlrWRttLTkg?si=vC0muaGpfuuiMNit"&gt;The Rider&lt;/a&gt;&lt;/em&gt;, follows a wounded rodeo cowboy (played by Brady Jandreau, a real-life rodeo star who sustained a career-ending head injury) from a Lakota Sioux reservation in South Dakota as he struggles with his inability to ride again. The film is made up of small moments, highlighting brief interactions and quotidian actions, but Zhao’s shooting and cutting, much like Malick’s, elevate these scenes toward the transcendent, finding a sacredness in the existence of a character who has lost his sense of purpose.&lt;/p&gt;
&lt;p&gt;The same could be said of Bentley’s &lt;em&gt;Train Dreams&lt;/em&gt;, which follows a man with very little direction in the world: he’s an orphan, raised in poverty, who finds work as a logger and spends his years felling trees and building railroads. Though he sees racism and murder around him, he can do nothing about it. He finds happiness by starting a family but then loses that family to a raging wildfire. The film’s rhythms are not those of a typical drama; for all the squalls of guilt and grief, the movie moves with a steady cadence that suggests that the mysteries, tragedies, and glories of life are all part of the same thing. This seems like it would result in a cold, opaque film, yet by the end, we are overwhelmed with emotion for this unremarkable life lived in near anonymity, a life that is more like our own than we might want to admit.&lt;/p&gt;
&lt;p&gt;You can also see Malick’s philosophical influence in three films directed by Laura Dunn (all of which he produced): &lt;em&gt;&lt;a href="https://twobirdsfilm.com/films/theunforeseen"&gt;The Unforeseen&lt;/a&gt;&lt;/em&gt; (2007), about the dire social and environmental consequences of a mining company’s development of a vast patch of Austin real estate,&lt;em&gt; &lt;a href="https://www.lookandseefilm.com/"&gt;Look &amp;amp; See: A Portrait of Wendell Berry&lt;/a&gt;&lt;/em&gt; (2016), about the life of the titular Kentucky farmer, writer, and activist, and &lt;em&gt;&lt;a href="https://allillusionsmustbebroken.com/"&gt;All Illusions Must Be Broken&lt;/a&gt;&lt;/em&gt; (2024), about the American cultural anthropologist Ernest Becker’s ideas around the human denial of mortality and self-knowledge. In each, Dunn portrays a society that is fraying at the seams owing to its increasing disconnection from the natural world and the organic patterns of life. Her films avoid the density of political and philosophical jargon. Instead, they create meaning through images of ordinary people: children playing, adults working in the fields, reconnecting viewers with a different state of being. The films’ form embodies her overall thesis that, despite our endless efforts to deny it, we humans are not separate from nature but inextricably part of it.&lt;/p&gt;


&lt;p&gt;&lt;br/&gt;malick’s humanism is refracted through his visual style—the aspect of his films that’s most obviously influential. He loves to shoot with natural light whenever possible: “Vermeer yourself ” is a common direction he gives to actors, indicating that they should lean into the available light during a take. His fondness for shooting at the “magic hour,” that time when the sun is setting and the sky emits a distinctive dark glow, is legendary. He also talks about “quail hunting”: capturing unscripted moments when the light happens to be perfect and you find something unexpected and real. Then there are “rabbit holes”: quick scenes and exchanges shot when the light isn’t perfect. Natural metaphors, found moments, a dogged pursuit of real light—the way Malick approaches the act of shooting enacts his philosophical view of the world.&lt;/p&gt;


&lt;p&gt;
    The lilting, fairy-tale surfaces of that film speak to a search for beauty that the characters cannot find.
    &lt;/p&gt;


&lt;p&gt;Malick’s influence on the way movies look has become a cliché. (A short 2015 video titled “&lt;a href="https://vimeo.com/144447762"&gt;Not Directed by Terrence Malick&lt;/a&gt;,” compiled by Jacob T. Swinney, features a collection of clips of films apparently influenced by Malick; it includes movies like &lt;em&gt;Up in the Air&lt;/em&gt;, &lt;em&gt;Beasts of No Nation&lt;/em&gt;, and &lt;em&gt;Ex Machina&lt;/em&gt;.) But anybody with some skill can shoot with natural light or cut away to a field of wheat. What distinguishes Malick’s work—what makes it truly revelatory to viewers—emerges from the harmony between a film’s images and its sensibility. In &lt;em&gt;George Washington&lt;/em&gt;, Green frames his characters in gorgeous light and scores their interactions with symphonic drones that suggest something heroic. And in &lt;em&gt;Nickel Boys&lt;/em&gt;, Ross tells a tale filled with injustice, racism, torture, and murder—a story that should be the very height of despair—yet finds an almost overwhelming humanity with his probing camera. Like Malick in &lt;em&gt;The Thin Red Line&lt;/em&gt;, Ross sees evidence of grace in the basest of places.&lt;/p&gt;
&lt;p&gt;By contrast, it’s jarring—if fascinating—when a film’s visual approach borrows from Malick but doesn’t match the sensibility at work. That’s the case with &lt;em&gt;&lt;a href="https://watch.afi.com/movie/the-assassination-of-jesse-james-by-the-coward-robert-ford"&gt;The Assassination of Jesse James by the Coward Robert Ford&lt;/a&gt;&lt;/em&gt; (2007), a remarkably beautiful Western directed by Andrew Dominik, who worked as an uncredited cameraman on &lt;em&gt;The New World&lt;/em&gt;. The film has a twilight grandeur and a fascination with the natural world that suggests Dominik learned quite a bit working for Malick. But despite the unmistakable surface similarities, Dominik’s dark moral vision bears little resemblance to Malick’s. The outlaws of the James gang live in a universe of endless, savage scrutiny, fearful of both the law and their own viral, panopticist distrust, with each member set against the others. The lilting, fairy-tale surfaces of that film speak to a search for beauty that the characters cannot find; Dominik longs for Malick’s vision of grace but sees no evidence of it. Or maybe he just doesn’t really want to find it.&lt;/p&gt;


&lt;img src="https://d181q449nqu6en.cloudfront.net/content/craft/articles/_850xAUTO_crop_center-center_none/Ebiri-Nickel-Boys.jpg"/&gt;
Ethan Herisse (&lt;em&gt;left&lt;/em&gt;) and Brandon Wilson in &lt;em&gt;Nickel Boys&lt;/em&gt;, directed by RaMell Ross, 2024. Courtesy Orion Pictures / Plan B Entertainment / Album


&lt;p&gt;malick’s working style is also appealing to many filmmakers. He shoots incessantly, improvises constantly, pays more attention to capturing footage of flora and fauna than he does to scripted scenes with actors, and then spends months in postproduction with teams of editors assembling his movies in unorthodox ways. This approach is inviting not just because it is unusually creative and collaborative but because it is rooted in the nature of cinema itself. &lt;/p&gt;
&lt;p&gt;Malick does not rely on the nineteenth-century theatrical conventions that most moviemakers remain bound to, with their focus on acts and protagonists and inciting incidents and A and B storylines. His films also avoid the novelistic, flowing instead like a series of thoughts, or memories, or maybe rivers. His is an intuitive and almost abstract filmmaking process that deprioritizes the presentational and the narrative. Malick focuses on collecting images, ideas, offhand moments, and sounds that can then be used during editing, applied almost like brushstrokes in a painting.&lt;/p&gt;
&lt;p&gt;He also welcomes spontaneous suggestions on set and encourages experimentation. There are three editors credited on &lt;em&gt;The Thin Red Line&lt;/em&gt;, four on &lt;em&gt;The New World&lt;/em&gt;, and five on &lt;em&gt;The Tree of Life&lt;/em&gt;; for the latter, the director reportedly invited students from the University of Southern California and the University of Texas at Austin to come in and try their hand at cutting footage. “Kids don’t censor themselves—their brains are in a different place,” the editor Billy Weber, one of Malick’s longtime collaborators, told me at the time. “So we had students give it a shot. And we’d have interns come in at night and cut scenes.” This is, to be clear, nothing like the way most other movies are put together. All too often, a film production is like a train that can’t be stopped or set on a different course once it leaves the station. But Malick has found ways to guide the train gently off the tracks—and in new, unexpected, undiscovered directions. It’s easy to see why other directors might be drawn to his less regimented approach.&lt;/p&gt;


&lt;img src="https://d181q449nqu6en.cloudfront.net/content/craft/articles/_850xAUTO_crop_center-center_none/Ebiri-Days-of-Heaven.jpg"/&gt;
Richard Gere in &lt;em&gt;Days of Heaven&lt;/em&gt;, directed by Terrence Malick, 1978. Courtesy Universal Pictures


&lt;p&gt;This working process re-creates the filmmaking method that Malick chanced upon with &lt;em&gt;Days of Heaven&lt;/em&gt;, which, for all the acclaim it garnered, was something of a salvage job. Coming off the critical success of &lt;em&gt;Badlands&lt;/em&gt;, Malick had gone into &lt;em&gt;Days of Heaven&lt;/em&gt; with a dense, detailed, ambitious script. But as described in John Bleasdale’s excellent 2024 biography, &lt;em&gt;&lt;a href="https://bookshop.org/a/16648/9781985901193"&gt;The Magic Hours: The Films and Hidden Life of Terrence Malick&lt;/a&gt;&lt;/em&gt;, the director found himself unhappy with the results he was getting over the course of production. He didn’t like how his dialogue sounded. His scenes felt phony. The shoot ran wildly over budget and behind schedule, as the Canada-based production team spent days trying to get the light perfect, and Malick’s original cinematographer, Néstor Almendros (who would go on to win an Oscar for the film), left halfway through and was replaced by Haskell Wexler. Meanwhile, Malick sent a photographer friend to capture nature footage that he could intersperse throughout the movie.&lt;/p&gt;
&lt;p&gt;Along the way, the director found himself fascinated with the off-the-cuff observations made by another one of his leads, fifteen-year-old Linda Manz, and recorded her describing scenes from the movie in her own words; he eventually shaped that into one of the most indelible voice-over narrations in cinema history, an offbeat series of childlike reflections that provide a poetic counterpoint to the elemental storyline. Everything about Malick’s evolving approach speaks to a heightened sense of possibility, and to a desire to reinvigorate the frustrating rhythm of film production with openness, spontaneity, and discovery.&lt;/p&gt;
&lt;p&gt;What’s remarkable about this approach is that despite his seemingly scattershot and impulsive methods, Malick’s films possess an aesthetic unity. Ross suggests something similar when talking about his own work. In an interview around the release of &lt;em&gt;Nickel Boys&lt;/em&gt;, he described to me the collage-like quality of his film: “It’s jumping time, and jumping textures, and jumping images, and points of view, and focal lengths, and sounds, but also it’s coherent.”&lt;/p&gt;


&lt;p&gt;&lt;br/&gt;influence can be a straitjacket. In 2014, A. J. Edwards, who had worked as an editor on two of Malick’s films, released &lt;em&gt;&lt;a href="https://youtu.be/NYYqvNW_c5M?si=Oac116TeEB97Q9NI"&gt;The Better Angels&lt;/a&gt;&lt;/em&gt;, a black-and-white meditation on Abraham Lincoln’s years as a young man living in rural Indiana. It’s a bold movie in many ways, almost confrontationally nonnarrative and context-free; aside from a brief coda set immediately after his assassination, we see almost nothing of Lincoln as a grown man or president. And yet there’s a curious emptiness at its heart. Filled with handheld reveries bathed in heavenly light, it replicates the yearning style of Malick’s work without the instances of genuine humanity that undergird his cinematic tapestries; though the characters in &lt;em&gt;The Better Angels&lt;/em&gt; are based on real historical personages, they never come across as real people.&lt;/p&gt;
&lt;p&gt;A similar emptiness afflicts David Lowery’s crime melodrama &lt;em&gt;&lt;a href="https://youtu.be/ga0c0v-stK0?si=4UxmyRoV840h_C_a"&gt;Ain’t Them Bodies Saints&lt;/a&gt;&lt;/em&gt; (2013), which has ravishing cinematography, ethereal music, and an elliptical narrative, all of which clearly owe something to Malick’s work. It follows the return of a fugitive to the woman he once loved and the child he has never met, and the tortured romance that ensues. Lowery explained at the time that he was not interested in another story about a crime but instead wanted to explore its emotional aftermath. But for all its loveliness, the film’s glancing storytelling has the opposite effect of Malick’s openness to the world; it dulls the senses, makes the characters and their feelings seem smaller and less significant. (Lowery’s more recent films owe little to Malick and are the better for it.)&lt;/p&gt;
&lt;p&gt;Think of it this way: What use is Malick’s liberated style of working if a filmmaker merely replicates it? The most successful Malickian films borrow from his work but find ways to transcend it and to convey new ideas. Take RaMell Ross. In his first film, he used fleeting, beautiful glimpses into mundane moments to convey, in just seventy-six short minutes, the arc of his subjects’ lives. In &lt;em&gt;Nickel Boys&lt;/em&gt;, he expanded the fragmented lyricism of his earlier film by crossing it with a first-person camera: the story is told almost entirely through shots that appropriate the perspectives of the two characters. The result is a work that is immersive and experiential, otherworldly and mythic. It’s also entirely his.&lt;/p&gt;


&lt;p&gt;&lt;br/&gt;malick has always been frustrated with the typical methods of making movies. In fact, he seems to become restless even with his own methods. If he’s helped liberate other filmmakers, he has also continuously sought to liberate himself. That may be why what has remained constant throughout his work has been &lt;em&gt;change&lt;/em&gt;. Even if certain aspects of his films—his love of natural light, his attention to found moments, his use of voice-over—have recurred, his subject matter, and his style, have never been fixed. The films that made his reputation in the 1970s—&lt;em&gt;Badlands&lt;/em&gt; and &lt;em&gt;Days of Heaven&lt;/em&gt;—are very different from the epics he made after his return to filmmaking, which are even less conventional in terms of narrative. The earlier pictures, compact and diamond-sharp, dance around their ideas, and their young protagonists don’t always grasp the gravity of their stories. Holly, the narrator of &lt;em&gt;Badlands&lt;/em&gt;, is just as likely to talk about a movie star or a photograph as she is to talk about the fact that her boyfriend is a serial killer; Linda, the narrator of &lt;em&gt;Days of Heaven&lt;/em&gt;, generally talks about everything and anything aside from the fact that her brother and his lover are cruelly betraying a dying man. This is very different from the prayerlike directness we find in the voice-overs for &lt;em&gt;The Thin Red Line&lt;/em&gt;, &lt;em&gt;The New World&lt;/em&gt;, and &lt;em&gt;The Tree of Life&lt;/em&gt;. Many-voiced and at times even rambling, those later period films are pointedly diffuse: each scene, each thought feels like it could expand into a whole other movie; all the characters seem so resolutely alive.&lt;/p&gt;
&lt;p&gt;Malick then pivoted again, following his trio of epics with a trilogy of low-budget works—&lt;em&gt;&lt;a href="https://youtu.be/52M41FF70Kc?si=qHFingfAW9JSZKmr"&gt;To the Wonder&lt;/a&gt;&lt;/em&gt; (2012), &lt;em&gt;&lt;a href="https://youtu.be/SI2j1FHCjtM?si=CrGqIqEbYZweTcoV"&gt;Knight of Cups&lt;/a&gt;&lt;/em&gt; (2015), and &lt;em&gt;&lt;a href="https://youtu.be/O4SrVkj84zc?si=zfAi4iLk5iXSt2YM"&gt;Song to Song&lt;/a&gt;&lt;/em&gt; (2017)—which seemed at times to be not-so-veiled dramatizations of events from the director’s own life. These works were Malick’s first films to be set in something like the present. They are messier, more frenzied. The characters in these later pictures are rootless, always searching. And the filmmaking in them is centered more on movement than meditations on nature.&lt;/p&gt;


&lt;p&gt;
    In his vision, our endless seeking makes us human and therefore holy.
    &lt;/p&gt;


&lt;p&gt;&lt;em&gt;To the Wonder&lt;/em&gt;, for instance, tells the story of the breakdown of the marriage between an American man and a Ukrainian woman after they return from Paris (where they met) to his home in Oklahoma. The film eschews dialogue, relying instead on characters’ movements to express their emotions and changing relationships. A mother and daughter, newly arrived in the United States, twirl and leap through the aisles of an enormous supermarket, the likes of which they’ve never seen before; the stolid shoulders of a frustrated husband dominate the foreground of the frame, while his effervescent wife moves daintily before him; a flirtation is expressed with a quick curtsy, shame with a penitent bow. It can almost be seen as a dance film. &lt;/p&gt;
&lt;p&gt;Instructing the film’s team of editors, Malick gave them copies of Margaret Anne Doody’s introduction to a Penguin Classics edition of Samuel Richardson’s 1740 epistolary novel, &lt;em&gt;Pamela&lt;/em&gt;, and pointed them to a line about how the author loved “the formless, the radiant zigzag becoming.” The phrase “radiant zigzag becoming” became their own unofficial title for the film, the editors told me; it spoke to the project’s energetic sense of movement. It also reflected the fact that Malick’s characters were always in the process of self-actualizing without ever fully doing so.&lt;/p&gt;


&lt;p&gt;Something similar could be said for Malick’s films themselves. &lt;em&gt;To the Wonder&lt;/em&gt;, in fact, led directly to one of the most intriguing of Malick-influenced movies, a hybrid on multiple levels. In 2018, the veteran photographer and documentarian Eugene Richards premiered a mesmerizing forty-three-minute film called &lt;em&gt;&lt;a href="https://eugenerichards.com/thykingdomcome"&gt;Thy Kingdom Come&lt;/a&gt;&lt;/em&gt;, which consists of footage Richards shot for &lt;em&gt;To the Wonder&lt;/em&gt;, featuring Javier Bardem as a priest who has lost his faith ministering to the impoverished residents of an Oklahoma town. &lt;/p&gt;
&lt;p&gt;Malick had Bardem go into real people’s lives—into trailer-park homes, a county jail, a homeless shelter—and had Richards document those people speaking to the actor’s clearly fictional priest. Only a small portion of the footage would be used in the finished feature, so Richards and Bardem developed a plan to make a separate film out of the material. In &lt;em&gt;Thy Kingdom Come&lt;/em&gt;, Bardem says little; most of the picture consists of these people—drug addicts, inmates, a homeless couple, a former Ku Klux Klan member, a woman grieving a dead baby, and more—describing their experiences and their thoughts. There is no narrative, nor even much of an emotional through line. Aside from a couple of brief exchanges, there is barely any mention of God. And yet spirituality is ever present. These people know the priest isn’t real, but they open up to him as if he were; they do not, in any way, seem to be acting. &lt;/p&gt;
&lt;p&gt;“Is this a true story?” Bardem asks in the opening narration. “Yes, I would say so. Is the priest a real priest? No. But it’s as if they were waiting for him.” The onrush of faces and lives that then ensues suggests the anticipation goes both ways: it’s as if the film were waiting for them. These people might not have found grace, but the camera eye—Richards’s but also Malick’s—finds grace in them. Thus, this riff on Malick reveals something essential about Malick’s work. In his vision, our endless seeking makes us human and therefore holy. The search for God is not a search for meaning; the meaning lies in the search itself. Through the films he’s made and the ways he’s made them, Malick has turned cinema into the vessel for that search.&lt;/p&gt;



&lt;a href="https://yalereview.org/author/bilge-ebiri"&gt;Bilge Ebiri&lt;/a&gt; is a film critic for &lt;em&gt;Vulture&lt;/em&gt; and &lt;em&gt;New York &lt;/em&gt;magazine. His work has also appeared in &lt;em&gt;The New York Times&lt;/em&gt; and the Criterion Collection.
                            


&lt;h2&gt;A Literary Gift in Print&lt;/h2&gt;
Give a year of &lt;em&gt;The Yale Review&lt;/em&gt;—four beautifully printed issues featuring new literature and ideas.
&lt;a href="https://shop.yalereview.org/products/the-yale-review-print-subscription"&gt;Give a Subscription&lt;/a&gt;





TAGS
&lt;a href="https://yalereview.org/search/?tag=32409"&gt;Film&lt;/a&gt;
&lt;a href="https://yalereview.org/search/?tag=16771"&gt;Arts &amp;amp; Culture&lt;/a&gt;
&lt;a href="https://yalereview.org/issues/winter-2025"&gt;Winter 2025&lt;/a&gt; 

Originally published:
December 15, 2025
&lt;a href="https://yalereview.org/issues/winter-2025"&gt;See this issue&lt;/a&gt; 

&lt;h2&gt;
            Featured
    &lt;/h2&gt;


&lt;a href="https://yalereview.org/reviews"&gt;            Books
        &lt;/a&gt; 
&lt;h3&gt;
&lt;a href="https://yalereview.org/article/elisa-gonzalez-searching-for-seamus-heaney"&gt;Searching for Seamus Heaney&lt;/a&gt;
&lt;/h3&gt;
What I found when I resolved to read him

Elisa Gonzalez





&lt;a href="https://yalereview.org/essays"&gt;            Essays
        &lt;/a&gt; 
&lt;h3&gt;
&lt;a href="https://yalereview.org/article/dan-fox-learning-welsh"&gt;What Happened When I Began to Speak Welsh&lt;/a&gt;
&lt;/h3&gt;
By learning my family's language, I hoped to join their conversation.

Dan Fox





&lt;a href="https://yalereview.org/essays"&gt;            Essays
        &lt;/a&gt; 
&lt;h3&gt;
&lt;a href="https://yalereview.org/article/anahid-nersessian-divorce"&gt;When Does a Divorce Begin?&lt;/a&gt;
&lt;/h3&gt;
Most people think of it as failure. For me it was an achievement.

Anahid Nersessian





&lt;h2&gt;
            You Might Also Like
    &lt;/h2&gt;


                    Film
            
&lt;h3&gt;
&lt;a href="https://yalereview.org/article/film-review-cinematic-afterlife-james-baldwin"&gt;The Cinematic Afterlife of James Baldwin&lt;/a&gt;
&lt;/h3&gt;
Film in review

Ayten Tartici





&lt;a href="https://yalereview.org/reviews"&gt;            Film
        &lt;/a&gt; 
&lt;h3&gt;
&lt;a href="https://yalereview.org/article/christopher-hawthorne-america-the-brutal"&gt;America the Brutal&lt;/a&gt;
&lt;/h3&gt;
Why &lt;em&gt;The Brutalist&lt;/em&gt; isn’t really about architecture

Christopher Hawthorne





&lt;a href="https://yalereview.org/essay-of-the-week"&gt;            Essay of the Week
        &lt;/a&gt; 
&lt;h3&gt;
&lt;a href="https://yalereview.org/article/wyman-what-after-the-hunt-gets-right"&gt;What “After the Hunt” Gets Right&lt;/a&gt;
&lt;/h3&gt;
I left academia. Luca Guadagnino’s new film reminds me why.

Annie Julia Wyman







&lt;h2&gt;A Literary Gift in Print&lt;/h2&gt;
Give a year of &lt;em&gt;The Yale Review&lt;/em&gt;—four beautifully printed issues featuring new literature and ideas.
&lt;a href="https://shop.yalereview.org/products/the-yale-review-print-subscription"&gt;Give a Subscription&lt;/a&gt;





&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://yalereview.org/article/bilge-ebiri-terrence-malick</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 19:35:20 +0000</pubDate>
    </item>
    <item>
      <title>Un-Redactor</title>
      <link>https://github.com/kvthweatt/unredactor</link>
      <description>A PDF editing tool that lets you put your own information over a redaction box.</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;h1&gt;Un-Redactor&lt;/h1&gt;&lt;a href="#un-redactor"&gt;&lt;/a&gt;
&lt;p&gt;A PDF editing tool that lets you put your own information over a redaction box.&lt;/p&gt;
&lt;p&gt;This tool is for forensics purposes. It does not "recover" data truly destroyed by redaction tools.&lt;/p&gt;
&lt;p&gt;What it &lt;strong&gt;does&lt;/strong&gt; do is allow you to &lt;strong&gt;write over&lt;/strong&gt; a redaction box. Like white-out.&lt;/p&gt;
&lt;p&gt;You can select a redaction box, and select all of the exact dimensions and replace at once.&lt;/p&gt;
&lt;p&gt;I am not responsible for your use of this tool.&lt;/p&gt;
&lt;p&gt;Republishing altered documents is illegal, and you should not use this to do so.&lt;/p&gt;
&lt;p&gt;By using this tool you claim all legal liability for any documents you create with it.&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/kvthweatt/unredactor</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 19:26:36 +0000</pubDate>
    </item>
    <item>
      <title>Help My c64 caught on fire</title>
      <link>https://c0de517e.com/026_c64fire.htm</link>
      <description>2025-12-22, Monday, December (updated: 2025-12-23, Tuesday, December) [Home]</description>
      <content:encoded>&lt;body&gt;
&lt;h1&gt;Help! My c64 caught on fire!A n00b weekend holiday project.&lt;/h1&gt;


&lt;a href="https://c0de517e.com/index.htm"&gt;&lt;img alt="logo: back home" src="https://c0de517e.com/logo.png"/&gt;&lt;/a&gt;
&lt;a href="https://twitter.com/intent/tweet?text=@kenpex%20http://c0de517e.com/./026_c64fire.htm"&gt;&lt;img alt="tweet" src="https://c0de517e.com/tweet.png"/&gt;&lt;/a&gt;
&lt;a href="https://s2f.kytta.dev/?text=@c0de517e@mastodon.gamedev.place%20http://c0de517e.com/./026_c64fire.htm"&gt;&lt;img alt="toot" src="https://c0de517e.com/toot.png"/&gt;&lt;/a&gt;

&lt;!-- BEGIN txt2web generated body --&gt;
I flew back to Italy for the Christmas holidays, as I usually do. Here I have my childhood c64, on which I learend how to program, and which in the last few years I took to refurbishing.&lt;br/&gt;
In general, everytime I'm back to my parent's place I spend some time fixing and sorting out things, and this is one of them.&lt;br/&gt;
&lt;br/&gt;
Now it works like a charm, and of course I also added some &lt;a href="https://c64os.com/buyersguide/"&gt;bells and whistles&lt;/a&gt;, mostly stuff that allows me to easily tranfer programs from a PC (a kung-fu cart and a pi1541) - so this year I thought it was time to actually do something with it! &lt;br/&gt;
&lt;br/&gt;
I decided to turn it into a cozy fireplace:&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/cozy.jpg"&gt;&lt;img alt="(click on the image for the full-color version)" src="https://c0de517e.com/026_c64fire/THUMBS/cozy.png"/&gt;&lt;/a&gt;(click on the image for the full-color version)&lt;br/&gt;
I was quite surprised that it worked, that I managed to complete this project in a few hours over two days, and that it was, most of all, fun! &lt;br/&gt;
&lt;br/&gt;
I expected... more friction, having to work with arcane cross-platform toolchains and the like, but instead I completed almost of all it in a web-based IDE/emulator combo!&lt;br/&gt;
&lt;br/&gt;
Moreover, I am far from being an expert when it comes to c64 coding. Yes, I used to program with one... when I was six or seven! And yes, I do follow its demoscene, and over the years I've read quite a bit about its chips and inner workings, but I've never written any demo effect for it. &lt;br/&gt;
&lt;br/&gt;
In other words... if I managed, you can too! That's what made me want to write this post...&lt;br/&gt;
&lt;br/&gt;
All you need for Christmas...&lt;br/&gt;
...is a 6502.&lt;br/&gt;
&lt;br/&gt;
Here, I'll give you a crash course on the c64 - the key points of what I knew before starting this.&lt;br/&gt;
&lt;br/&gt;
If you know how modern CPUs work, and how to optimize for them - try to forget all of that. The 64 comes from an era where RAM was faster than compute. Lookup tables are your friend, as it is fully unrolling loops / code generation. We have no caches!&lt;br/&gt;
&lt;br/&gt;
Don't be surprised then to learn that the famous 6502 CPU has only one arithmetic register, the "accumulator". There are also two "index" registers used to offset memory locations, a status register, and a program counter - but you can't do math on any of these, at best, test or increment/decrement.&lt;br/&gt;
Moreover, the program counter is the only 16-bit register, all the others are 8-bit.&lt;br/&gt;
&lt;br/&gt;
But who needs registers when you have fast RAM? Memory is your register file: pretty much all 6502 instructions operate between the accumulator and memory locations (or numeric constants, that are still memory, just part of the instruction itself).&lt;br/&gt;
&lt;br/&gt;
To further facilitate this, the 6502 comes with a rich set of addressing modes, most instructions can fetch memory in few different ways: at absolute addresses, at addresses offset with one of the two index registers or even at indirect addresses (addresses contained in memory locations).&lt;br/&gt;
There is also a special memory area, called the "zero page", the first 256 bytes of memory (a page is, unsurprisingly, 256 bytes), which has an extra optimization: addressing there takes one cycle less, because the address can be encoded in the instruction in a single byte instead of two.&lt;br/&gt;
&lt;br/&gt;
Have a look at the &lt;a href="https://www.masswerk.at/6502/6502_instruction_set.html"&gt;6502 instruction set&lt;/a&gt;, it's very simple! Won't take more than 15 minutes to skim over them all.&lt;br/&gt;
&lt;br/&gt;
The plan.&lt;br/&gt;
&lt;br/&gt;
Where things get less simple is to deal with all the c64 custom chips, the SID (sound) and the VIC-II (graphics). That's how demo-scene effects are done! Manipulating these chips in very precise ways to cause them to generate crazy stuff, most of which was never considered possible by the c64 designers back then!&lt;br/&gt;
&lt;br/&gt;
The average c64 demo effect is all about this - generating lookup tables and unrolled assembly to then be able to exactly time internal chip status changes as the video signal is being generated line by line ("racing the beam"). Usually, what is shown on screen is not at all what it seems - i.e. it's not how you would create a similar effect on a PC.&lt;br/&gt;
&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/demo.jpg"&gt;&lt;img alt="We won't be porting Second Reality..." src="https://c0de517e.com/026_c64fire/THUMBS/demo.png"/&gt;&lt;/a&gt;We won't be porting Second Reality...&lt;br/&gt;
I know almost nothing of any of this - so my plan was to avoid it all! I wanted to set the VIC-II in some graphic mode that gave me a decently simple, linear framebuffer, and from there on write the code like I would have done on any other computer, hoping that a fire effect is simple enough to compute that the 64 would just be able to cope with it.&lt;br/&gt;
&lt;br/&gt;
Luckily, there is one such mode. The default, vanilla, character mode! Here, we have 40x25 characters on screen, chosen from a set of 256. So, one byte per "pixel", and 1000 pixels in total - great!&lt;br/&gt;
&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/petscii.png"&gt;&lt;img alt='The default "petscii" character set.' src="https://c0de517e.com/026_c64fire/THUMBS/petscii.png"/&gt;&lt;/a&gt;The default "petscii" character set.&lt;br/&gt;
Now, the default character set does not really lean itself to creating a demo effect, but I knew I could create a custom one. My idea was to simply making a dither pattern, and as much as possible work like I had a 8-bit "grayscale" screen. &lt;br/&gt;
&lt;br/&gt;
C64 characters are 8x8, so I could create a dither pattern that has a number of "on" pixels in the character corresponding to its position in the charset: 0 being fully off (background color), 64 being fully on (foreground color), and everything in between being a mix.&lt;br/&gt;
Of course though this would give us only 64 values, ideally, I wanted to utilize the whole 8-bit space... On obvious idea is that we could add colors to the mix. For example, having the first 64 values go from black (background) to brown (foreground), then the next 64 have brown as background and red as foreground, then red and yellow, and finally yellow and white.&lt;br/&gt;
&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/chars.png"&gt;&lt;img alt="My custom charset. Made by hand in C64Studio." src="https://c0de517e.com/026_c64fire/THUMBS/chars.png"/&gt;&lt;/a&gt;My custom charset. Made by hand in C64Studio.&lt;br/&gt;
This can't be achieved in the default character mode, unfortunately, as only the foreground color is controllable per-character (via another memory location, still using one byte per character - easy), while the background is shared. Luckily though, there is an &lt;a href="https://www.c64-wiki.com/wiki/Extended_color_mode"&gt;"extended color mode"&lt;/a&gt; that fits the bill exactly. In this mode the character set is limited to 64, but the two high bits of each character can be used to control the background color, while the foreground remains in the separate memory location as usual.&lt;br/&gt;
&lt;br/&gt;
Implementation.&lt;br/&gt;
&lt;br/&gt;
All development was done in the &lt;a href="https://ide.retrogamecoders.com/"&gt;retrogamecoders c64 IDE&lt;/a&gt;, which handly couples the &lt;a href="https://cc65.github.io/"&gt;cc65 compiler&lt;/a&gt; with an emulator.&lt;br/&gt;
&lt;br/&gt;
Writing c64 code in C is generally a terrible idea, and cc65 is not even the "best" compiler out there (is quite old and barely does optimize the generated code - &lt;a href="https://llvm-mos.org/wiki/Welcome"&gt;llvm-mos&lt;/a&gt; might be better), but being able to test in C and then gradually "port" to assembly was crucial for a noob like me. If I were to keep working on this, I'd probably move to &lt;a href="https://theweb.dk/KickAssembler/Main.html#frontpage"&gt;Kick Assembler&lt;/a&gt;, which is particularly suited for the kind of code-generation that you want to do in demo-coding.&lt;br/&gt;
&lt;br/&gt;
Anyhow, here are the .c files, step by step, in chronological order. You can just copy and paste them in the retrogamecoders IDE and see how things work, start tinkering if you like! Enjoy!&lt;br/&gt;
&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/final.png"&gt;&lt;img src="https://c0de517e.com/026_c64fire/THUMBS/final.png"/&gt;&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/test.c"&gt;First test of the ECM charset idea.&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/slow.c"&gt;Slowest fire-effect ever in pure C.&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/fire_0.c"&gt;Still in C. Starting to "unroll".&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/fire_1.c"&gt;Starting to port to assembly.&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/fire_2.c"&gt;Ported to assembly, with side-by-side C.&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/fire_3.c"&gt;Assembly only, some more ECM tricks.&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://c0de517e.com/026_c64fire/fire_4.c"&gt;"Final" version.&lt;/a&gt;&lt;br/&gt;
&lt;!-- END txt2web generated body --&gt;

&lt;p&gt;2025-12-22, Monday, December (updated: 2025-12-23, Tuesday, December) &lt;a href="https://c0de517e.com/index.htm"&gt;[Home]&lt;/a&gt;&lt;/p&gt;
&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://c0de517e.com/026_c64fire.htm</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 19:09:45 +0000</pubDate>
    </item>
    <item>
      <title>LAVD: Meta's New Default Scheduler [pdf]</title>
      <link>https://lpc.events/event/19/contributions/2099/attachments/1875/4020/lpc-2025-lavd-meta.pdf</link>
      <description>&lt;a href="https://news.ycombinator.com/item?id=46368235"&gt;Comments&lt;/a&gt;</description>
      <guid isPermaLink="false">https://lpc.events/event/19/contributions/2099/attachments/1875/4020/lpc-2025-lavd-meta.pdf</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 19:04:13 +0000</pubDate>
    </item>
    <item>
      <title>Volvo Centum is Dalton Maag's new typeface for Volvo</title>
      <link>https://www.wallpaper.com/design-interiors/corporate-design-branding/volvo-new-font-volvo-centum</link>
      <description>Volvo will celebrate its centennial in 2027 and the company is already starting to ramp up the celebrations. Last year saw the opening of the World of Volvo in Gothenburg, a vast circular timber structure designed by Scandinavian design specialists Henning Larsen .</description>
      <content:encoded>&lt;article class="page-content-onecol flex-1 news-article article"&gt;
















&lt;img alt="Volvo Centum typeface by Dalton Maag" src="https://cdn.mos.cms.futurecdn.net/iozuxZhaSka6MXjkDUGXTC.jpg"/&gt;



Volvo Centum typeface by Dalton Maag
(Image credit: Volvo)










Share


Share by:
&lt;ul&gt;
&lt;li&gt;


Copy link

&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.wallpaper.com%2Fdesign-interiors%2Fcorporate-design-branding%2Fvolvo-new-font-volvo-centum"&gt;

Facebook
&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://twitter.com/intent/tweet?text=Volvo%E2%80%99s+quest+for+safety+has+resulted+in+this+new%2C+ultra-legible+in-car+typeface%2C+Volvo+Centum+&amp;amp;url=https%3A%2F%2Fwww.wallpaper.com%2Fdesign-interiors%2Fcorporate-design-branding%2Fvolvo-new-font-volvo-centum"&gt;

X
&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="whatsapp://send?text=Volvo%E2%80%99s+quest+for+safety+has+resulted+in+this+new%2C+ultra-legible+in-car+typeface%2C+Volvo+Centum++https%3A%2F%2Fwww.wallpaper.com%2Fdesign-interiors%2Fcorporate-design-branding%2Fvolvo-new-font-volvo-centum?fwa"&gt;

Whatsapp
&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://pinterest.com/pin/create/button/?url=https%3A%2F%2Fwww.wallpaper.com%2Fdesign-interiors%2Fcorporate-design-branding%2Fvolvo-new-font-volvo-centum&amp;amp;media=https%3A%2F%2Fcdn.mos.cms.futurecdn.net%2FBbk6idpyNNyVN9L889eenE.jpg"&gt;

Pinterest
&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://share.flipboard.com/bookmarklet/popout?title=Volvo%E2%80%99s+quest+for+safety+has+resulted+in+this+new%2C+ultra-legible+in-car+typeface%2C+Volvo+Centum+&amp;amp;url=https%3A%2F%2Fwww.wallpaper.com%2Fdesign-interiors%2Fcorporate-design-branding%2Fvolvo-new-font-volvo-centum"&gt;

Flipboard
&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;


Share this article




Join the conversation





&lt;a href="https://google.com/preferences/source?q=wallpaper.com"&gt;

Follow us
&lt;/a&gt;

Add us as a preferred source on Google



&lt;a href="https://www.wallpaper.com/newsletter"&gt;

Newsletter
&lt;/a&gt;

Subscribe to our newsletter




&lt;p&gt;&lt;a href="https://www.wallpaper.com/tag/volvo"&gt;Volvo&lt;/a&gt; will celebrate its centennial in 2027 and the company is already starting to ramp up the celebrations. Last year saw the opening of the &lt;a href="https://www.worldofvolvo.com/en/"&gt;World of Volvo&lt;/a&gt; in Gothenburg, a vast circular timber structure designed by &lt;a href="https://www.wallpaper.com/architecture/share-conversations-about-contemporary-architecture-the-nordic-architecture-book-launch"&gt;Scandinavian design&lt;/a&gt; specialists &lt;a href="https://henninglarsen.com/projects/world-of-volvo"&gt;Henning Larsen&lt;/a&gt;.&lt;/p&gt;&lt;p&gt; 

&lt;img alt="Volvo Centum typeface by Dalton Maag" src="https://cdn.mos.cms.futurecdn.net/T8HveULQDYZmY7zh2s3wk.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Volvo Centum typeface by Dalton Maag&lt;/p&gt;(Image credit: Volvo)&lt;p&gt;2026 will see another significant design upheaval, albeit on a much smaller and less obvious scale. The arrival of a new brand typeface, Volvo Centum, manages to combine the company’s obvious love of modernist design with its obsessive pursuit of safety.&lt;/p&gt;&lt;p&gt;The work of &lt;a href="https://www.wallpaper.com/tag/london"&gt;London&lt;/a&gt;-based type design studio Dalton Maag, the new typeface is designed ‘to improve readability, sharpen attention, and promote a calmer, safety-focused driving experience.’&lt;/p&gt;&lt;p&gt; 

&lt;img alt="Dalton Maag&amp;amp;#039;s team developing the Volvo Centum typeface" src="https://cdn.mos.cms.futurecdn.net/4k45rhJrYCPYJ43VitbkQK.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Dalton Maag's team developing the Volvo Centum typeface&lt;/p&gt;(Image credit: Volvo)&lt;p&gt; 

&lt;img alt="Dalton Maag&amp;amp;#039;s team developing the Volvo Centum typeface" src="https://cdn.mos.cms.futurecdn.net/Pi6ZXsYY96quzUvU8KWX5P.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Dalton Maag's team developing the Volvo Centum typeface&lt;/p&gt;(Image credit: Volvo)&lt;p&gt;With so much information conveyed via screens – especially capacitive touch screens – legibility and clarity have become an essential component of a modern car’s HMI. Volvo Centum is a sans serif of exceptional clarity and simplicity, designed for what the company calls ‘glance-driven environments.’&lt;/p&gt;&lt;p&gt; 

&lt;img alt="Dalton Maag&amp;amp;#039;s Volvo Centum typeface in use" src="https://cdn.mos.cms.futurecdn.net/PhaTaeNEMd3N3fYizBG3xS.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Dalton Maag's Volvo Centum typeface in use&lt;/p&gt;(Image credit: Volvo)&lt;p&gt;The first car to be installed with Volvo Centum is the &lt;a href="https://www.volvocars.com/uk/cars/xc60-hybrid/"&gt;newly revised XC60&lt;/a&gt; mid-size SUV and its upcoming all-new EX60 electric sibling. Over-the-air updates will then be used to roll out the typeface across millions of other cars.&lt;/p&gt;&lt;p&gt; 

&lt;img alt="The newly refreshed Volvo XC60" src="https://cdn.mos.cms.futurecdn.net/to2wkLukovhDM3Dfiqerqd.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;The newly refreshed Volvo XC60&lt;/p&gt;(Image credit: Volvo)&lt;p&gt; 

&lt;img alt="Inside the XC60, the interface shows Volvo&amp;amp;#039;s close relationship with Google" src="https://cdn.mos.cms.futurecdn.net/WKRbZuS97beSh63RgK5pBi.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Inside the XC60, the interface shows Volvo's close relationship with Google&lt;/p&gt;(Image credit: Volvo)&lt;p&gt;If there’s been one criticism of Volvo in recent years, it’s that the company has off-loaded huge amounts of information and driver input onto a central touchscreen. Volvo was ahead of the curve in adopting &lt;a href="https://www.wallpaper.com/tag/google"&gt;Google&lt;/a&gt;’s Android in 2017 and were a key partner in the development of Android Auto. How this system dovetails with the new typeface remains to be seen.&lt;/p&gt;&lt;p&gt; 

&lt;img alt="Volvo Centum typeface by Dalton Maag" src="https://cdn.mos.cms.futurecdn.net/WUzBksPhsuMyMkkSitDuR7.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Volvo Centum typeface by Dalton Maag&lt;/p&gt;(Image credit: Volvo)&lt;p&gt; 

&lt;img alt="Volvo Centum typeface by Dalton Maag" src="https://cdn.mos.cms.futurecdn.net/KBw3HhmJUgSEGMrzb4DjcA.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Volvo Centum typeface by Dalton Maag&lt;/p&gt;(Image credit: Volvo)&lt;p&gt;Dalton Maag faced a formidable challenge in ensuring Volvo Centum worked across the brand’s many platforms, as well as being legible in all driving conditions and in 35 different languages, including Chinese, Arabic, Japanese, and Korean.&lt;/p&gt;Wallpaper* Newsletter&lt;p&gt;Receive our daily digest of inspiration, escapism and design stories from around the world direct to your inbox.&lt;/p&gt;&lt;p&gt;By creating a set of distinct character shapes, the studio has striven to avoid any unintentional misreading, with clear spacing and a scaling system that simplifies detailed elements to retain legibility.&lt;/p&gt;&lt;p&gt; 

&lt;img alt="Volvo Centum typeface by Dalton Maag" src="https://cdn.mos.cms.futurecdn.net/Bbk6idpyNNyVN9L889eenE.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Volvo Centum typeface by Dalton Maag&lt;/p&gt;(Image credit: Volvo)&lt;p&gt; 

&lt;img alt="Volvo Centum typeface by Dalton Maag" src="https://cdn.mos.cms.futurecdn.net/ixF3C7isbiQypFG2YcBrfH.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Volvo Centum typeface by Dalton Maag&lt;/p&gt;(Image credit: Volvo)&lt;p&gt;The studio, founded in 1991 by Swiss typeface designer Bruno Maag, has worked across a number of industries, including media (BBC, Netflix, &lt;a href="https://www.wallpaper.com/tag/usa"&gt;USA&lt;/a&gt; Today), transportation (Ducati and Korean Air) and technology (Vodafone and Wix), amongst others.&lt;/p&gt;&lt;p&gt; 

&lt;img alt="Volvo Centum typeface by Dalton Maag" src="https://cdn.mos.cms.futurecdn.net/wM7n5cfkxZPxacua7naXjM.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Volvo Centum typeface by Dalton Maag&lt;/p&gt;(Image credit: Volvo)&lt;p&gt; 

&lt;img alt="Volvo Centum typeface by Dalton Maag" src="https://cdn.mos.cms.futurecdn.net/dqRnTESj6k2pgWFWPnzCTQ.jpg"/&gt;
&lt;/p&gt;&lt;p&gt;Volvo Centum typeface by Dalton Maag&lt;/p&gt;(Image credit: Volvo)&lt;p&gt;&lt;em&gt;&lt;/em&gt;&lt;a href="https://www.daltonmaag.com/"&gt;&lt;em&gt;DaltonMaag.com&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href="https://www.instagram.com/dalton.maag/"&gt;&lt;em&gt;@Dalton.Maag&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href="https://www.volvo.com/en/"&gt;&lt;em&gt;Volvo.com&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;&lt;a href="https://www.instagram.com/volvocars/"&gt;&lt;em&gt;@Volvocars&lt;/em&gt;&lt;/a&gt;&lt;em&gt;&lt;/em&gt;&lt;/p&gt;&lt;a&gt;&lt;/a&gt;

TOPICS











&lt;a href="https://www.wallpaper.com/author/jonathan-bell"&gt;Jonathan Bell&lt;/a&gt;&lt;p&gt;Jonathan Bell has written for Wallpaper* magazine since 1999, covering everything from architecture and transport design to books, tech and graphic design. He is now the magazine’s Transport and Technology Editor. Jonathan has written and edited 15 books, including Concept Car Design, 21st Century House, and The New Modern House. He is also the host of Wallpaper’s first podcast.&lt;/p&gt;





Latest








&lt;ul&gt;
&lt;li&gt;

&lt;a href="https://www.wallpaper.com/design-interiors/tiny-zaps-brooklyn-tattoo-parlour"&gt;


&lt;img alt="Tiny Zaps Brooklyn Tattoo" src="https://cdn.mos.cms.futurecdn.net/43HdL6nKmvDFvfxeQqSoqd.jpg"/&gt;




Terrified to get inked? This inviting Brooklyn tattoo parlour is for people who are 'a little bit nervous'

&lt;p&gt;
With minty-green walls and an option to 'call mom', Tiny Zaps' Williamsburg location was designed to tame jitters
&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;

&lt;/a&gt;

&lt;/li&gt;
&lt;li&gt;

&lt;a href="https://www.wallpaper.com/watches-jewellery/lets-hear-it-for-the-chopard-l-u-c-grand-strike-chiming-watch"&gt;


&lt;img alt="silver watch" src="https://cdn.mos.cms.futurecdn.net/hDnKk8a94mw4xGxp6MZTCC.jpg"/&gt;




Let’s hear it for the Chopard L.U.C Grand Strike chiming watch

&lt;p&gt;
The Swiss watchmaker’s most complicated timepiece to date features an innovative approach to producing a crystal-clear sound
&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;

&lt;/a&gt;

&lt;/li&gt;
&lt;li&gt;

&lt;a href="https://www.wallpaper.com/travel/restaurants/best-restaurant-design-of-2025"&gt;


&lt;img alt="best restaurant design 2025" src="https://cdn.mos.cms.futurecdn.net/ZYrxWFchScg5hsByRkYBaa.jpg"/&gt;




Form... and flavour? The best design-led restaurant debuts of 2025

&lt;p&gt;
A Wallpaper* edit of the restaurant interiors that shaped how we ate, gathered and lingered this year
&lt;/p&gt;
&lt;p&gt;
&lt;/p&gt;

&lt;/a&gt;

&lt;/li&gt;
&lt;/ul&gt;




&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.wallpaper.com/design-interiors/corporate-design-branding/volvo-new-font-volvo-centum</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 18:33:01 +0000</pubDate>
    </item>
    <item>
      <title>We replaced H.264 streaming with JPEG screenshots (and it worked better)</title>
      <link>https://blog.helix.ml/p/we-mass-deployed-15-year-old-screen</link>
      <description>Part 2 of our video streaming saga. Read Part 1: How we replaced WebRTC with WebSockets →</description>
      <content:encoded>&lt;article class="typography newsletter-post post"&gt;&lt;h1&gt;We Mass-Deployed 15-Year-Old Screen Sharing Technology and It's Actually Better&lt;/h1&gt;&lt;h3&gt;Or: How JPEG Screenshots Defeated Our Beautiful H.264 WebCodecs Pipeline&lt;/h3&gt;&lt;a href="https://substack.com/@lewq"&gt;&lt;img alt="Luke Marsden's avatar" src="https://substackcdn.com/image/fetch/$s_!fz2p!,w_36,h_36,c_fill,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe83a5474-4943-4f2d-ae84-070ba6dd2042_400x400.jpeg"/&gt;&lt;/a&gt;&lt;a href="https://substack.com/@lewq"&gt;Luke Marsden&lt;/a&gt;Dec 18, 2025311Share&lt;p&gt;&lt;em&gt;Part 2 of our video streaming saga. &lt;a href="https://blog.helix.ml/p/we-killed-webrtc-and-nobody-noticed"&gt;Read Part 1: How we replaced WebRTC with WebSockets →&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;h2&gt;The Year is 2025 and We’re Sending JPEGs&lt;/h2&gt;&lt;p&gt;Let me tell you about the time we spent three months building a gorgeous, hardware-accelerated, WebCodecs-powered, 60fps H.264 streaming pipeline over WebSockets...&lt;/p&gt;&lt;p&gt;Thanks for reading HelixML! Subscribe for free to receive new posts and support my work.&lt;/p&gt;&lt;p&gt;...and then replaced it with &lt;code&gt;grim | curl&lt;/code&gt; when the WiFi got a bit sketchy.&lt;/p&gt;&lt;p&gt;I wish I was joking.&lt;/p&gt;&lt;h2&gt;Act I: Hubris (Also Known As “Enterprise Networking Exists”)&lt;/h2&gt;&lt;p&gt;We’re building &lt;a href="https://github.com/helixml/helix"&gt;Helix&lt;/a&gt;, an AI platform where autonomous coding agents work in cloud sandboxes. Users need to watch their AI assistants work. Think “screen share, but the thing being shared is a robot writing code.”&lt;/p&gt;&lt;p&gt;Last week, we explained how we replaced WebRTC with a custom WebSocket streaming pipeline. This week: why that wasn’t enough.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The constraint that ruined everything:&lt;/strong&gt; It has to work on enterprise networks.&lt;/p&gt;&lt;p&gt;You know what enterprise networks love? HTTP. HTTPS. Port 443. That’s it. That’s the list.&lt;/p&gt;&lt;p&gt;You know what enterprise networks hate?&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;UDP&lt;/strong&gt; — Blocked. Deprioritized. Dropped. “Security risk.”&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;WebRTC&lt;/strong&gt; — Requires TURN servers, which requires UDP, which is blocked&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Custom ports&lt;/strong&gt; — Firewall says no&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;STUN/ICE&lt;/strong&gt; — NAT traversal? In &lt;em&gt;my&lt;/em&gt; corporate network? Absolutely not&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Literally anything fun&lt;/strong&gt; — Denied by policy&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We tried WebRTC first. Worked great in dev. Worked great in our cloud. Deployed to an enterprise customer.&lt;/p&gt;&lt;p&gt;“The video doesn’t connect.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;checks network&lt;/em&gt; — Outbound UDP blocked. TURN server unreachable. ICE negotiation failing.&lt;/p&gt;&lt;p&gt;We could fight this. Set up TURN servers. Configure enterprise proxies. Work with IT departments.&lt;/p&gt;&lt;p&gt;Or we could accept reality: &lt;strong&gt;Everything must go through HTTPS on port 443.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;So we built a &lt;strong&gt;pure WebSocket video pipeline&lt;/strong&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;H.264 encoding via GStreamer + VA-API (hardware acceleration, baby)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Binary frames over WebSocket (L7 only, works through any proxy)&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;WebCodecs API for hardware decoding in the browser&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;60fps at 40Mbps with sub-100ms latency&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;We were so proud. We wrote Rust. We wrote TypeScript. We implemented our own binary protocol. We measured things in microseconds.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Then someone tried to use it from a coffee shop.&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;Act II: Denial&lt;/h2&gt;&lt;p&gt;“The video is frozen.”&lt;/p&gt;&lt;p&gt;“Your WiFi is bad.”&lt;/p&gt;&lt;p&gt;“No, the video is definitely frozen. And now my keyboard isn’t working.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;checks the video&lt;/em&gt;&lt;/p&gt;&lt;p&gt;It’s showing what the AI was doing 30 seconds ago. And the delay is growing.&lt;/p&gt;&lt;p&gt;Turns out, 40Mbps video streams don’t appreciate 200ms+ network latency. Who knew.&lt;/p&gt;&lt;p&gt;When the network gets congested:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;Frames buffer up in the TCP/WebSocket layer&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;They arrive in-order (thanks TCP!) but increasingly delayed&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Video falls further and further behind real-time&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;You’re watching the AI type code from 45 seconds ago&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;By the time you see a bug, the AI has already committed it to main&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Everything is terrible forever&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;“Just lower the bitrate,” you say. Great idea. Now it’s 10Mbps of blocky garbage that’s &lt;em&gt;still&lt;/em&gt; 30 seconds behind.&lt;/p&gt;&lt;h2&gt;Act III: Bargaining&lt;/h2&gt;&lt;p&gt;We tried everything:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“What if we only send keyframes?”&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This was our big brain moment. H.264 keyframes (IDR frames) are self-contained. No dependencies on previous frames. Just drop all the P-frames on the server side, send only keyframes, get ~1fps of corruption-free video. Perfect for low-bandwidth fallback!&lt;/p&gt;&lt;p&gt;We added a &lt;code&gt;keyframes_only&lt;/code&gt; flag. We modified the video decoder to check &lt;code&gt;FrameType::Idr&lt;/code&gt;. We set GOP to 60 (one keyframe per second at 60fps). We tested.&lt;/p&gt;&lt;p&gt;We got exactly ONE frame.&lt;/p&gt;&lt;p&gt;One single, beautiful, 1080p IDR frame. Then silence. Forever.&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;code&gt;[WebSocket] Keyframe received (frame 121), sending
[WebSocket] ...
[WebSocket] ...
[WebSocket] It's been 14 seconds why is nothing else coming
[WebSocket] Failed to send audio frame: Closed&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;checks Wolf logs&lt;/em&gt; — encoder still running&lt;/p&gt;&lt;p&gt;&lt;em&gt;checks GStreamer pipeline&lt;/em&gt; — frames being produced&lt;/p&gt;&lt;p&gt;&lt;em&gt;checks Moonlight protocol layer&lt;/em&gt; — &lt;strong&gt;nothing coming through&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;We’re using &lt;a href="https://games-on-whales.github.io/wolf/stable/"&gt;Wolf&lt;/a&gt;, an excellent open-source game streaming server (seriously, the documentation is great). But our WebSocket streaming layer sits on top of the Moonlight protocol, which is reverse-engineered from NVIDIA GameStream. Somewhere in that protocol stack, &lt;em&gt;something&lt;/em&gt; decides that if you’re not consuming P-frames, you’re not ready for more frames. Period.&lt;/p&gt;&lt;p&gt;We poked around for an hour or two, but without diving deep into the Moonlight protocol internals, we weren’t going to fix this. The protocol wanted all its frames, or no frames at all.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“What if we implement proper congestion control?”&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;looks at TCP congestion control literature&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;closes tab&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“What if we just... don’t have bad WiFi?”&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;stares at enterprise firewall that’s throttling everything&lt;/em&gt;&lt;/p&gt;&lt;h2&gt;Act IV: Depression&lt;/h2&gt;&lt;p&gt;One late night, while debugging why the stream was frozen again, I opened our screenshot debugging endpoint in a browser tab:&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;code&gt;GET /api/v1/external-agents/abc123/screenshot?format=jpeg&amp;amp;quality=70&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The image loaded instantly.&lt;/p&gt;&lt;p&gt;A pristine, 150KB JPEG of the remote desktop. Crystal clear. No artifacts. No waiting for keyframes. No decoder state. Just... pixels.&lt;/p&gt;&lt;p&gt;I refreshed. Another instant image.&lt;/p&gt;&lt;p&gt;I mashed F5 like a degenerate. 5 FPS of perfect screenshots.&lt;/p&gt;&lt;p&gt;I looked at my beautiful WebCodecs pipeline. I looked at the JPEGs. I looked at the WebCodecs pipeline again.&lt;/p&gt;&lt;p&gt;No.&lt;/p&gt;&lt;p&gt;No, we are not doing this.&lt;/p&gt;&lt;p&gt;We are professionals. We implement proper video codecs. We don’t spam HTTP requests for individual frames like it’s 2009.&lt;/p&gt;&lt;h2&gt;Act V: Acceptance&lt;/h2&gt;&lt;p&gt;typescript&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;code&gt;// Poll screenshots as fast as possible (capped at 10 FPS max)
const fetchScreenshot = async () =&amp;gt; {
  const response = await fetch(`/api/v1/external-agents/${sessionId}/screenshot`)
  const blob = await response.blob()
  screenshotImg.src = URL.createObjectURL(blob)
  setTimeout(fetchScreenshot, 100) // yolo
}&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We did it. We’re sending JPEGs.&lt;/p&gt;&lt;p&gt;And you know what? &lt;strong&gt;It works perfectly.&lt;/strong&gt;&lt;/p&gt;&lt;h2&gt;Why JPEGs Actually Slap&lt;/h2&gt;&lt;p&gt;Here’s the thing about our fancy H.264 pipeline:&lt;/p&gt;&lt;p&gt;PropertyH.264 StreamJPEG SpamBandwidth40 Mbps (constant)100-500 Kbps (varies with complexity)StateStateful (corrupt = dead)Stateless (each frame independent)Latency sensitivityVery highDoesn’t careRecovery from packet lossWait for keyframe (seconds)Next frame (100ms)Implementation complexity3 months of Rust&lt;code&gt;fetch()&lt;/code&gt; in a loop&lt;/p&gt;&lt;p&gt;A JPEG screenshot is &lt;strong&gt;self-contained&lt;/strong&gt;. It either arrives complete, or it doesn’t. There’s no “partial decode.” There’s no “waiting for the next keyframe.” There’s no “decoder state corruption.”&lt;/p&gt;&lt;p&gt;When the network is bad, you get... fewer JPEGs. That’s it. The ones that arrive are perfect.&lt;/p&gt;&lt;p&gt;And the size! A 70% quality JPEG of a 1080p desktop is like &lt;strong&gt;100-150KB&lt;/strong&gt;. A single H.264 keyframe is 200-500KB. We’re sending LESS data per frame AND getting better reliability.&lt;/p&gt;&lt;h2&gt;The Hybrid: Have Your Cake and Eat It Too&lt;/h2&gt;&lt;p&gt;We didn’t throw away the H.264 pipeline. We’re not &lt;em&gt;complete&lt;/em&gt; animals.&lt;/p&gt;&lt;p&gt;Instead, we built adaptive switching:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Good connection&lt;/strong&gt; (RTT &amp;lt; 150ms): Full 60fps H.264, hardware decoded, buttery smooth&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Bad connection detected&lt;/strong&gt;: Pause video, switch to screenshot polling&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Connection recovers&lt;/strong&gt;: User clicks to retry video&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;The key insight: &lt;strong&gt;we still need the WebSocket for input&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;Keyboard and mouse events are tiny. Like, 10 bytes each. The WebSocket handles those perfectly even on a garbage connection. We just needed to stop sending the massive video frames.&lt;/p&gt;&lt;p&gt;So we added one control message:&lt;/p&gt;&lt;p&gt;json&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;code&gt;{"set_video_enabled": false}&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Server receives this, stops sending video frames. Client polls screenshots instead. Input keeps flowing. Everyone’s happy.&lt;/p&gt;&lt;p&gt;15 lines of Rust. I am not joking.&lt;/p&gt;&lt;p&gt;rust&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;code&gt;if !video_enabled.load(Ordering::Relaxed) {
    continue; // skip frame, it's screenshot time baby
}&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;h2&gt;The Oscillation Problem (Lol)&lt;/h2&gt;&lt;p&gt;We almost shipped a hilarious bug.&lt;/p&gt;&lt;p&gt;When you stop sending video frames, the WebSocket becomes basically empty. Just tiny input events and occasional pings.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The latency drops dramatically.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Our adaptive mode sees low latency and thinks: “Oh nice! Connection recovered! Let’s switch back to video!”&lt;/p&gt;&lt;p&gt;Video resumes. 40Mbps floods the connection. Latency spikes. Mode switches to screenshots.&lt;/p&gt;&lt;p&gt;Latency drops. Mode switches to video.&lt;/p&gt;&lt;p&gt;Latency spikes. Mode switches to screenshots.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Forever. Every 2 seconds.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The fix was embarrassingly simple: once you fall back to screenshots, &lt;strong&gt;stay there until the user explicitly clicks to retry&lt;/strong&gt;.&lt;/p&gt;&lt;p&gt;typescript&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;code&gt;setAdaptiveLockedToScreenshots(true) // no oscillation for you
```

We show an amber icon and a message: "Video paused to save bandwidth. Click to retry."

Problem solved. User is in control. No infinite loops.

---

## Ubuntu Doesn't Ship JPEG Support in grim Because Of Course It Doesn't

Oh, you thought we were done? Cute.

`grim` is a Wayland screenshot tool. Perfect for our needs. Supports JPEG output for smaller files.

Except Ubuntu compiles it without libjpeg.
```
$ grim -t jpeg screenshot.jpg
error: jpeg support disabled&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;em&gt;incredible&lt;/em&gt;&lt;/p&gt;&lt;p&gt;So now our Dockerfile has a build stage that compiles grim from source:&lt;/p&gt;&lt;p&gt;dockerfile&lt;/p&gt;&lt;pre&gt;&lt;code&gt;&lt;code&gt;FROM ubuntu:25.04 AS grim-build
RUN apt-get install -y meson ninja-build libjpeg-turbo8-dev ...
RUN git clone https://git.sr.ht/~emersion/grim &amp;amp;&amp;amp; \
    meson setup build -Djpeg=enabled &amp;amp;&amp;amp; \
    ninja -C build
```

We're building a screenshot tool from source so we can send JPEGs in 2025. This is fine.

---

## The Final Architecture
```
┌─────────────────────────────────────────────────────────────┐
│                     User's Browser                          │
├─────────────────────────────────────────────────────────────┤
│  WebSocket (always connected)                               │
│  ├── Video frames (H.264) ──────────── when RTT &amp;lt; 150ms    │
│  ├── Input events (keyboard/mouse) ── always               │
│  └── Control messages ─────────────── {"set_video_enabled"} │
│                                                              │
│  HTTP (screenshot polling) ──────────── when RTT &amp;gt; 150ms    │
│  └── GET /screenshot?quality=70                             │
└─────────────────────────────────────────────────────────────┘&lt;/code&gt;&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;strong&gt;Good connection:&lt;/strong&gt; 60fps H.264, hardware accelerated, beautiful &lt;strong&gt;Bad connection:&lt;/strong&gt; 2-10fps JPEGs, perfectly reliable, works everywhere&lt;/p&gt;&lt;p&gt;The screenshot quality adapts too:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Frame took &amp;gt;500ms? Drop quality by 10%&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Frame took &amp;lt;300ms? Increase quality by 5%&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Target: minimum 2 FPS, always&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h2&gt;Lessons Learned&lt;/h2&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Simple solutions often beat complex ones.&lt;/strong&gt; Three months of H.264 pipeline work. One 2am hacking session the night before production deployment: “what if we just... screenshots?”&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Graceful degradation is a feature.&lt;/strong&gt; Users don’t care about your codec. They care about seeing their screen and typing.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;WebSockets are for input, not necessarily video.&lt;/strong&gt; The input path staying responsive is more important than video frames.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Ubuntu packages are missing random features.&lt;/strong&gt; Always check. Or just build from source like it’s 2005.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;strong&gt;Measure before optimizing.&lt;/strong&gt; We assumed video streaming was the only option. It wasn’t.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h2&gt;Try It Yourself&lt;/h2&gt;&lt;p&gt;Helix is open source: &lt;a href="https://github.com/helixml/helix"&gt;github.com/helixml/helix&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The shameful-but-effective screenshot code:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;api/cmd/screenshot-server/main.go&lt;/code&gt; — 200 lines of Go that changed everything&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;MoonlightStreamViewer.tsx&lt;/code&gt; — React component with adaptive logic&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;websocket-stream.ts&lt;/code&gt; — WebSocket client with &lt;code&gt;setVideoEnabled()&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The beautiful H.264 pipeline we’re still proud of:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;code&gt;moonlight-web-stream/&lt;/code&gt; — Rust WebSocket server&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Still used when your WiFi doesn’t suck&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;em&gt;We’re building Helix, open-source AI infrastructure that works in the real world — even on terrible WiFi. We started by &lt;a href="https://blog.helix.ml/p/LINK-TO-PART-1"&gt;killing WebRTC&lt;/a&gt;, then we killed our replacement. Sometimes the 15-year-old solution is the right one.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Star us on GitHub: &lt;a href="https://github.com/helixml/helix"&gt;github.com/helixml/helix&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;Thanks for reading HelixML! Subscribe for free to receive new posts and support my work.&lt;/p&gt;311Share&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://blog.helix.ml/p/we-mass-deployed-15-year-old-screen</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 18:00:31 +0000</pubDate>
    </item>
    <item>
      <title>Towards a secure peer-to-peer app platform for Clan</title>
      <link>https://clan.lol/blog/towards-app-platform-vmtech/</link>
      <description>While most of the existing Clan framework is dedicated to machine and service management, there’s more on the horizon. Our mission is to make sure peer-to-peer, user-controlled, community software can beat Big Tech solutions. That’s why we’re working on platform fundamentals that would open the way for our FOSS stack to match the usability and convenience of proprietary platforms.</description>
      <content:encoded>&lt;article class="article"&gt;


&lt;img src="https://clan.lol/blog/towards-app-platform-vmtech/post-hero-image_hu_300d99c55181014e.webp"/&gt;


&lt;p&gt;While most of the existing Clan framework is dedicated to machine and service management, there’s more on the horizon. Our mission is to make sure peer-to-peer, user-controlled, community software can beat Big Tech solutions. That’s why we’re working on platform fundamentals that would open the way for our FOSS stack to match the usability and convenience of proprietary platforms.&lt;/p&gt;
&lt;p&gt;Unfortunately, the FOSS world is still lagging behind commercial platforms in some important aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Web and mobile apps are strongly sandboxed, so while they can get very aggressive in snooping on the data they &lt;em&gt;are&lt;/em&gt; allowed to access, the enforcement of the isolation model is very robust — and there is a model for &lt;em&gt;sharing&lt;/em&gt; data that makes the isolated applications actually useful..
&lt;ul&gt;
&lt;li&gt;Meanwhile in the FOSS world, it’s still extremely common to run software with full access to the user’s account. The only project that has built anything close to a similar platform for local software is Flatpak, which is still not perfect and its main repo has a very lax policy;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Centralized Web services can have “multiple instances” simply by switching accounts; self-hosting Web services is trivially multi-instance; even Android now provides a multi-instance facility..
&lt;ul&gt;
&lt;li&gt;Meanwhile local software often doesn’t have a global database, but when it does, it can be impossible to make it multi-instance without advanced knowledge;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Commercial apps come with their own always-online remote servers. Users don’t have to think about connecting the clients to the servers, it’s all pre-connected!
&lt;ul&gt;
&lt;li&gt;Meanwhile decentralized community software is stuck between various bad options. Supporting multiple commercial backends is tedious and defeats the point anyway. Self-hosting traditional web servers can get complex and unreliable, and exposes attack surface to the public Web. Direct peer-to-peer connections can be hard to set up and unreliable too, and typically don’t provide asynchronous communication.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So… What do we need to make it possible for communities to share apps install and load &lt;strong&gt;quickly&lt;/strong&gt;, already &lt;strong&gt;pre-connected&lt;/strong&gt; to network services; are isolated to a &lt;strong&gt;worry-free&lt;/strong&gt; level of security, and yet allow for enough &lt;strong&gt;sharing&lt;/strong&gt; via explicit permissions to make them useful?&lt;/p&gt;
&lt;p&gt;The first piece of the puzzle is, unsurprisingly, Nix. The entire Clan project is built on Nix, and the future app platform is no exception. Nix makes it possible to quickly fetch and run any software – thanks to caching, as long as we steer everyone towards using very few common versions of the nixpkgs tree, most downloads could be almost as fast as web app loads.&lt;/p&gt;
&lt;p&gt;Then we have to add a &lt;strong&gt;microVM hypervisor&lt;/strong&gt; with &lt;strong&gt;Wayland and GPU virtualization&lt;/strong&gt; and a side of &lt;strong&gt;D-Bus portals&lt;/strong&gt;… and we can finally get a glimpse of the future!&lt;/p&gt;





&lt;h2&gt;microVMs&lt;/h2&gt;
&lt;p&gt;Secure isolation is essential for any modern app platform. Hardware-based virtualization is a lot more confidence-inspiring than shared-kernel isolation mechanisms like Linux namespaces. But it’s not &lt;em&gt;only&lt;/em&gt; a security measure. Running apps in VMs also improves environment consistency/reproducibility by ensuring everyone runs the same kernel — which can also give us portability, since it enables running on completely different host OSes as well.&lt;/p&gt;
&lt;p&gt;If your experience with virtualization on desktop has only been with booting entire Linux distros under something like VirtualBox, you might be very skeptical of the same technology being involved in launching applications all the time. But that’s not at all inherent to the use of KVM!&lt;/p&gt;
&lt;p&gt;Conventional VMs feel “heavy” —slow to launch, big RAM footprint, extra background CPU usage, fixed storage allocation, usually not very well integrated with the host desktop— only because their goal is to simulate a whole another computer within your existing computer. For app isolation, we don’t need that, so the whole stack can be vastly simplified and optimized for high performance and low overhead. The microVM idea was first popularized by AWS’s &lt;a href="https://firecracker-microvm.github.io/"&gt;Firecracker&lt;/a&gt; on the server side, powering instantly-launching event/request handlers in Lambda. A microVM boots directly into the kernel (skipping firmware) and does not emulate any legacy PC hardware, which results in &lt;em&gt;very&lt;/em&gt; fast boot times, on the order of a couple hundred milliseconds.&lt;/p&gt;
&lt;p&gt;Now, has this been used on the client side already? Yes, most prominently by Asahi Linux, motivated by a technical restriction that was preventing Apple machines from playing legacy Windows games. That’s the &lt;a href="https://github.com/AsahiLinux/muvm"&gt;muvm&lt;/a&gt; project, powered by &lt;a href="https://github.com/containers/libkrun"&gt;libkrun&lt;/a&gt; – a Firecracker-like VMM provided as a dynamic library so that different frontends could be built. For our platform development, we have indeed adopted muvm (after submitting &lt;a href="https://github.com/AsahiLinux/muvm/pull/192"&gt;some changes&lt;/a&gt; that make it more useful for us), combining it with namespace-based &lt;a href="https://github.com/containers/bubblewrap"&gt;Bubblewrap&lt;/a&gt; to make a script that &lt;a href="https://git.clan.lol/clan/munix"&gt;runs NixOS system closures&lt;/a&gt; in microVMs.&lt;/p&gt;
&lt;p&gt;…Wait, did someone mention playing games– like, highly GPU-demanding games? In a VM? Without a dedicated GPU?&lt;/p&gt;
&lt;h2&gt;Desktop and GPU support&lt;/h2&gt;





&lt;p&gt;In the Beginning (of virtio-gpu), there was the Framebuffer. An emulated computer monitor, a single rectangle representing the entire graphical output of the VM. Then there was &lt;a href="https://docs.mesa3d.org/drivers/virgl.html"&gt;VirGL&lt;/a&gt;, a way to forward the OpenGL API across the VM boundary to make the host render on its GPU on behalf of the VM, so that 3D graphics could be displayed on the emulated monitor. It wasn’t super fast, it wasn’t compatible with the latest GL extensions, it wasn’t very secure, but it was something. With the advent of Vulkan, &lt;a href="https://docs.mesa3d.org/drivers/venus.html"&gt;Venus&lt;/a&gt; was started as the Vulkan version of the same thing.&lt;/p&gt;
&lt;p&gt;Meanwhile, the Chrome OS team was working on adding support for Linux apps. While it was initially based on namespaces, they quickly started working on switching to hardware virtualization. The virtio-gpu device was extended to support arbitrary “cross-domain” protocols, making it possible —with some wrapping-unwrapping— to forward Unix domain sockets that pass certain types of file descriptors (shared memory and DMA-BUF) to the guest. (Well, initially it was a whole separate virtual device but let’s skip over that.) Google’s crosvm supports &lt;a href="https://crosvm.dev/book/devices/wayland.html"&gt;connecting to the host Wayland socket&lt;/a&gt; to that facility, and the team wrote &lt;a href="https://chromium.googlesource.com/chromiumos/platform2/+/refs/heads/main/vm_tools/sommelier/README.md"&gt;Sommelier&lt;/a&gt; as the guest-side proxy that exposes a normal Wayland socket to guest apps.&lt;/p&gt;
&lt;p&gt;The part of crosvm responsible for handling the virtio-gpu device was written as a reusable library called Rutabaga (now &lt;a href="https://github.com/magma-gpu/rutabaga_gfx"&gt;living outside of the CrOS repos&lt;/a&gt;), and integrated into other VMMs such as good old Qemu. Sommelier was packaged by various Linux distros as well, and one enthusiast wrote &lt;a href="https://roscidus.com/blog/blog/2021/03/07/qubes-lite-with-kvm-and-wayland/"&gt;an entire alternative to Sommelier&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Meanwhile, there was also a lot to improve in terms of accessing the GPU. As we’ve mentioned already, API forwarding solutions like VirGL/Venus leave a lot to be desired. PCIe passthrough requires a dedicated GPU, or SR-IOV support which GPU vendors have mostly restricted to enterprise models. However… of course a better way was possible! Rob Clark presented &lt;a href="https://indico.freedesktop.org/event/2/contributions/53/attachments/76/121/XDC2022_%20virtgpu%20drm%20native%20context.pdf"&gt;DRM native contexts&lt;/a&gt; at XDC 2022: this approach essentially paravirtualizes the kernel-space GPU driver, letting the guest submit hardware-specific commands that the host would run in separate contexts (relying on the same separation as between programs on the host). That’s the approach that was picked up by the Asahi Linux project for gaming because of the amazing performance it allows for, but it’s also intended to be a stronger security boundary due to providing way less attack surface on the host (it’s all I/O management rather than implementing complex APIs).&lt;/p&gt;
&lt;p&gt;So, was it possible to take all of this technology and use it? Well… it required quite a bit of debugging and fixing everywhere – but that’s exactly why I joined! So far I’ve discovered that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the rutabaga_gfx integration in QEMU (which was the thing we tried to use initially) and other C consumers was broken with the latest versions due to &lt;a href="https://issuetracker.google.com/issues/440386997"&gt;an &lt;code&gt;ifdef&lt;/code&gt; mistake&lt;/a&gt; (&lt;a href="https://github.com/magma-gpu/rutabaga_gfx/pull/9"&gt;fixed&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;it’s not documented everywhere that &lt;a href="https://gitlab.com/qemu-project/qemu/-/issues/2574"&gt;kernel &amp;gt;= 6.13 is required&lt;/a&gt; to be able to touch AMD GPU memory from KVM guests in any way&lt;/li&gt;
&lt;li&gt;Sommelier was &lt;a href="https://issuetracker.google.com/u/2/issues/441537635"&gt;assuming Chromium OS kernel patches&lt;/a&gt; and misinterpreting &lt;code&gt;ioctl&lt;/code&gt; responses on regular mainline Linux&lt;/li&gt;
&lt;li&gt;libkrun’s internal version of rutabaga_gfx contained a tiny strange API modification incompatible with Sommelier/proxy-virtwl and didn’t handle memfd seals (&lt;a href="https://github.com/containers/libkrun/pull/407"&gt;fixed&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;RADV (Radeon Vulkan driver in Mesa) only recognized PCI devices including for virtgpu, ignoring the &lt;code&gt;virtio-mmio&lt;/code&gt; setup used by libkrun (&lt;a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/37281"&gt;fixed&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And we’re continuing with more work in this area.&lt;/p&gt;
&lt;h2&gt;D-Bus / XDG Desktop Portals&lt;/h2&gt;





&lt;p&gt;Application isolation is great, but completely isolated applications tend to have limited usefulness. That’s why we’re also integrating &lt;a href="https://flatpak.github.io/xdg-desktop-portal/"&gt;desktop portals&lt;/a&gt; that Flatpak uses —at least the file-opening / document portal— into the microVM-based platform.&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://git.clan.lol/clan/sidebus"&gt;sidebus&lt;/a&gt; project is inspired by &lt;a href="https://spectrum-os.org/"&gt;Spectrum&lt;/a&gt;’s setup for using the document portal with virtiofs to dynamically expose chosen files to the guest, using vsock as the D-Bus transport. It is based on the &lt;a href="https://github.com/dbus2/busd"&gt;busd&lt;/a&gt; broker library, and uses the portal frontend on the host for perfect integration with arbitrary desktop environments.&lt;/p&gt;
&lt;p&gt;With the switch to libkrun however, we are looking at the possibility of making the Camera and Screencast portals working, with full hardware acceleration – by switching to virtgpu cross-domain as the transport instead of vsock. Currently libkrun already has added some PipeWire support to its copy of rutabaga_gfx, however that’s fixed to one system-wide socket. How these portals work is that for every request they pass a new restricted PipeWire remote socket over D-Bus. So we’re looking to make rutabaga’s cross-domain sockets more generic, to be able to just pass through that whole chain of file descriptor passing.&lt;/p&gt;
&lt;p&gt;(And yes, lots of people are worried about PipeWire attack surface — it’s definitely possible to mitigate that with a proxy on the host that would only allow a small validated subset of the PipeWire protocol.)&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;We’re looking to finally make a peer-to-peer community software platform that’s competitive with commercial ones in terms of security, usability and convenience.
If you want to try it out now, you can! Just follow the installation instructions on our &lt;a href="https://git.clan.lol/clan/munix"&gt;munix project&lt;/a&gt;.
Note that it’s still actively being developed, so if you find any issues, please open up a bug report!&lt;/p&gt;

&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://clan.lol/blog/towards-app-platform-vmtech/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 17:34:22 +0000</pubDate>
    </item>
    <item>
      <title>Fabrice Bellard Releases MicroQuickJS</title>
      <link>https://github.com/bellard/mquickjs/blob/main/README.md</link>
      <description>mquickjs/README.md at main · bellard/mquickjs · GitHub</description>
      <content:encoded>&lt;main id="js-repo-pjax-container"&gt;






&lt;a href="https://github.com/bellard"&gt;
        bellard
&lt;/a&gt; 
/
&lt;strong&gt;
&lt;a href="https://github.com/bellard/mquickjs"&gt;mquickjs&lt;/a&gt;
&lt;/strong&gt;
Public



&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://github.com/login?return_to=%2Fbellard%2Fmquickjs"&gt; Notifications
&lt;/a&gt; You must be signed in to change notification settings
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://github.com/login?return_to=%2Fbellard%2Fmquickjs"&gt; Fork
    11
&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;

&lt;a href="https://github.com/login?return_to=%2Fbellard%2Fmquickjs"&gt; 
          Star
 539
&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;













&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/bellard/mquickjs/blob/main/README.md</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 17:33:42 +0000</pubDate>
    </item>
    <item>
      <title>Meta is using the Linux scheduler designed for Valve's Steam Deck on its servers</title>
      <link>https://www.phoronix.com/news/Meta-SCX-LAVD-Steam-Deck-Server</link>
      <description>Meta Is Using The Linux Scheduler Designed For Valve's Steam Deck On Its Servers - Phoronix</description>
      <content:encoded>&lt;article class="full"&gt;
&lt;h1&gt;Meta Is Using The Linux Scheduler Designed For Valve's Steam Deck On Its Servers&lt;/h1&gt;
Written by &lt;a href="https://www.michaellarabel.com/"&gt;Michael Larabel&lt;/a&gt; in &lt;a href="https://www.phoronix.com/linux/Linux+Kernel"&gt;Linux Kernel&lt;/a&gt; on 23 December 2025 at 06:10 AM EST. &lt;a href="https://www.phoronix.com/forums/node/1601261"&gt;13 Comments&lt;/a&gt;

&lt;img alt="LINUX KERNEL" src="https://www.phoronix.com/assets/categories/linuxkernel.webp"/&gt;
An interesting anecdote from this month's Linux Plumbers Conference in Tokyo is that Meta (Facebook) is using the Linux scheduler originally designed for the needs of Valve's Steam Deck... On Meta Servers. Meta has found that the scheduler can actually adapt and work very well on the hyperscaler's large servers.&#13;
&lt;br/&gt;
&lt;br/&gt;SCX-LAVD as the Latency-criticality Aware Virtual Deadline scheduler has &lt;a href="https://www.phoronix.com/news/LAVD-Scheduler-Linux-Gaming"&gt;worked out very well for the needs of Valve's Steam Deck&lt;/a&gt; with similar or better performance than &lt;a href="https://www.phoronix.com/search/EEVDF"&gt;EEVDF&lt;/a&gt;. SCX-LAVD has been worked on by Linux consulting firm Igalia under contract for Valve. SCX-LAVD has also seen varying use by the CachyOS Handheld Edition, Bazzite, and other Linux gaming software initiatives.&#13;
&lt;br/&gt;&lt;p&gt;&lt;a href="https://www.phoronix.com/image-viewer.php?id=2025&amp;amp;image=meta_lavd_1_lrg"&gt;&lt;img alt="Steam Deck and Server" src="https://www.phoronix.net/image.php?id=2025&amp;amp;image=meta_lavd_1_med"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;br/&gt;It turns out that besides working well on handhelds, SCX-LAVD can also end up working well on large servers too. The presentation at LPC 2025 by Meta engineers was in fact titled "&lt;em&gt;How do we make a Steam Deck scheduler work on large servers&lt;/em&gt;." At Meta they have explored SCX_LAVD as a "default" fleet scheduler for their servers that works for a range of hardware and use-cases for where they don't need any specialized scheduler.&#13;
&lt;br/&gt;&lt;p&gt;&lt;img alt="Meta SCX LAVD" src="https://www.phoronix.net/image.php?id=2025&amp;amp;image=meta_lavd_2_med"/&gt;&lt;/p&gt;
&lt;br/&gt;They call this scheduler built atop sched_ext as "Meta's New Default Scheduler". LAVD they found to work well across the growing CPU and memory configurations of their servers, nice load balancing between CCX/LLC boundaries, and more. Those wishing to learn more about Meta's use and research into SCX-LAVD can find the Linux Plumbers Conference presentation embedded below along with the &lt;a href="https://lpc.events/event/19/contributions/2099/attachments/1875/4020/lpc-2025-lavd-meta.pdf"&gt;slide deck&lt;/a&gt;.&#13;
&lt;br/&gt;&lt;p&gt;&lt;/p&gt;









&lt;a href="https://www.phoronix.com/forums/node/1601261"&gt;13 Comments&lt;/a&gt; 

&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.phoronix.com/news/Meta-SCX-LAVD-Steam-Deck-Server</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 17:08:34 +0000</pubDate>
    </item>
    <item>
      <title>When irate product support customers demand to speak to Bill Gates</title>
      <link>https://devblogs.microsoft.com/oldnewthing/20251223-00/?p=111896</link>
      <description>A colleague of mine who used to work in product support told me that they had a procedure if a customer became irate and demanded to speak with Bill Gates. (This was, of course, back in the days when Bill Gates still ran the company.)</description>
      <content:encoded>&lt;article class="middle-column pe-xl-198" data-clarity-region="article" id="post-111896"&gt;

&lt;p&gt;A colleague of mine who used to work in product support told me that they had a procedure if a customer became irate and demanded to speak with Bill Gates. (This was, of course, back in the days when Bill Gates still ran the company.)&lt;/p&gt;
&lt;p&gt;The product support technician would apologize for not resolving the problem to the customer’s satisfaction, but if the customer continued to demand to speak with The Boss, the technician would indeed transfer the customer.&lt;/p&gt;
&lt;p&gt;The customer was transferred to a special internal phone number, and when the operators saw a call on that line, they took the call and said, “Bill Gates’s office.” They weren’t actually in Bill Gates’s office. They were just pretending to be Bill Gates’s secretary. Their job was to tell the caller that Mr. Gates is currently unavailable, but if the customer leaves a message and their contact information, they will pass the information to Mr. Gates.&lt;/p&gt;
&lt;p&gt;Of course, the information was never actually passed along to Bill. The information went back into the product support channel with a note that the customer was escalated to “Bill Gates’s office.” The technician who returned the call would probably say something like “Bill Gates asked me to contact you to follow up on an issue you had earlier.”&lt;/p&gt;
&lt;!-- .entry-content --&gt;
&lt;!-- AI Disclaimer --&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://devblogs.microsoft.com/oldnewthing/20251223-00/?p=111896</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 16:43:03 +0000</pubDate>
    </item>
    <item>
      <title>Stop Slopware</title>
      <link>https://stopslopware.net/</link>
      <description>Stop Slopware</description>
      <guid isPermaLink="false">https://stopslopware.net/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 15:51:17 +0000</pubDate>
    </item>
    <item>
      <title>Quake's Player Speed (2017)</title>
      <link>https://rome.ro/quakes-player-speed-1</link>
      <description>We were in crunch mode working to get Quake finished. We had to establish a few guidelines to make sure the levels were next-gen, fast, and not too big since people will be downloading the game back during the early internet days.</description>
      <content:encoded>&lt;main id="page" role="main"&gt;
&lt;!--
--&gt;&lt;!--
--&gt;&lt;!--
--&gt;


&lt;h1&gt;Quake's Player Speed&lt;/h1&gt;






&lt;img src="https://images.squarespace-cdn.com/content/v1/566d855a841abafcc8ed19c4/1500921400183-9KOGHP7CCVB832LRSL1Q/doom-dos-front-cover.jpg"/&gt;




  

&lt;h3&gt;In 1996...&lt;/h3&gt;&lt;p&gt;We were in crunch mode working to get Quake finished. We had to establish a few guidelines to make sure the levels were next-gen, fast, and not too big since people will be downloading the game back during the early internet days.&lt;/p&gt;&lt;p&gt;We decided that map BSP files can't be bigger than 1.4 megabytes. The final complied state of a map was called a BSP file. So we had to make sure we stayed under that value. If a map got too big we had to delete some brushes and try to get the BSP under that size.&lt;/p&gt;&lt;p&gt;To keep the game fast we put a red flickering screen up when the polygon count for world polygons went over 350. Yes, 350. This was at the beginning of using polygons in an FPS and 350 was not too bad of a number back then. If the screen flickered at any time during play we would find the offending view and then start blocking off visibility with new geometry to keep the poly count low and the framerate fast. Also making sure to keep the size under 1.4 megabytes.&lt;/p&gt;&lt;p&gt;The QuakeEd tool that I made was not the best 3D level editor at all – not by a long shot. We tried to keep it as simple as possible because smoothly flying around in 3D space like cameras do nowadays was never done back then. We were figuring it out as we went.&lt;/p&gt;&lt;p&gt;So, QuakeEd made making 3D levels actually painful. We used a primitive called a "brush" that was a 3D rectangle we could drag out into the world and move around. Maps were completely made out of brushes.&lt;/p&gt;&lt;p&gt;There were only three views: a top-down line view, a sideways line Z-view, and a small, fully-rendered 3D view so we could see what the brushes looked like with textures on them. We could see if they were in the right positions.&lt;/p&gt;&lt;p&gt;There was an X that we could drag around and any brushes that were under the X were displayed in the Z-view. That's how we moved brushes up and down in the Z plane.&lt;/p&gt;





View fullsize


&lt;img src="https://images.squarespace-cdn.com/content/v1/566d855a841abafcc8ed19c4/1501354529861-4IEEZFZKK7MTFVH97OHL/image-asset.png"/&gt;




&lt;p&gt;NeXTSTEP Operating System &amp;amp; QuakeEd, 1995&lt;/p&gt;





&lt;p&gt;To create diagonal surfaces from the rectangular brush we would place two points that could slice any geometry that the line between them intersected. Every angle in the game was made this way. For example, on E1M1 (the first level), you step off the slipgate and go down a ramp to the first hallway. To create that ramp I dragged a brush that was left-to-right the length of the ramp, and top-to-bottom the height of the ramp. Keep in mind, I'm working in a view that is looking straight down into the level from above, so I'm creating a ramp in a different rotation than it should be. Then I put one cutting point at the top-left corner and the other cutting point at the bottom-right corner and pressed a key to slice it. Then, I selected the brush and had to rotate it so it was facing the correct way in the world, then used the Z-view to drag it down into place. Finally, I could now drag the edge of the ramp brush to stretch it so it was the correct width of the hallway.&lt;/p&gt;&lt;p&gt;Now imagine doing that for every brush in a level. It took &lt;em&gt;forever&lt;/em&gt; to make levels, but we got good at it. The problem was, however, that our levels were never very big. Our 1.4 megabyte size limit was capping the size of the levels.&lt;/p&gt;&lt;p&gt;John Carmack decided that we could get more gameplay out of the levels if he slowed down the player's running speed. In DOOM the player went at crazy-fast speeds and it was incredible. In DOOM we could make huge maps and player speed was not a problem. With Quake's maps, the hallways, rooms, and outdoor areas were all smaller because of the file size. So slowing down the player meant it took longer to finish a level, and longer to finish the game overall.&lt;/p&gt;&lt;p&gt;That's how it happened.&lt;/p&gt;

  
&lt;!--
--&gt;
&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://rome.ro/quakes-player-speed-1</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 14:04:10 +0000</pubDate>
    </item>
    <item>
      <title>Test, don't (just) verify</title>
      <link>https://alperenkeles.com/posts/test-dont-verify/</link>
      <description>AI is making formal verification go mainstream.</description>
      <content:encoded>&lt;article&gt;


        Test, don't (just) verify.


                    
                        Posted on 2025-12-22
                    

                    

                    :: 
  
  
  
  13 min read


                    
                    
                             :: Tags:

&lt;a href="https://alperenkeles.com/tags/software-engineering/"&gt;🏷software engineering&lt;/a&gt;, 
                                
                                    &lt;a href="https://alperenkeles.com/tags/testing/"&gt;🏷testing&lt;/a&gt;, 
                                
                                    &lt;a href="https://alperenkeles.com/tags/formal-methods/"&gt;🏷formal methods&lt;/a&gt;




&lt;p&gt;AI &lt;em&gt;is&lt;/em&gt; making formal verification go mainstream.&lt;/p&gt;
&lt;p&gt;AI-assisted mechnical proving companies are raising funds on billion dollar &lt;a href="https://www.reuters.com/business/robinhood-ceos-math-focused-ai-startup-harmonic-valued-145-billion-latest-2025-11-25/"&gt;valuations&lt;/a&gt;, new people are trying proof assistants,
overwhelmingly Lean, at unprecedented rates. Models achieve fascinating results in competitions previously considered to contain
some of the hardest problems in the world, such as IMO, ICPC, Putnam; as well as open problems in mathematics such as Erdös Problems.
It's not just the hobbyists that are excited about AI-assisted proofs, from &lt;a href="https://terrytao.wordpress.com/wp-content/uploads/2024/03/machine-jan-3.pdf"&gt;Terry Tao&lt;/a&gt;, to &lt;a href="https://martin.kleppmann.com/2025/12/08/ai-formal-verification.html"&gt;Martin Kleppman&lt;/a&gt;, to &lt;a href="https://x.com/ilyasergey/status/1989053674552004749"&gt;Ilya Sergey&lt;/a&gt;, prominent researchers around the world are excited and hopeful about the effects.&lt;/p&gt;
&lt;h2&gt;&lt;a href="#formal-verification-the-goods"&gt;Formal Verification: The Goods&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Let me quickly give you a run down of the argument:&lt;/p&gt;
&lt;p&gt;There are multiple complex challenges in formal verification. The first one, and the one that is very hard to solve technically,
is that most software in the world does not have a formal specification. A formal specification is a simpler mathematical description
of the system we build. Algorithms have formal specifications. Data structures, protocols, data formats, safety-critical systems typically
have formal specifications. The majority of the programs in the world doesn't have a formal specification, hell, most of them don't even have
informal specifications. At the limit, which is where we actually are, the specification of a program is itself, the implementation is the
specification. The lack of a formal specification makes it very hard to formally verify some piece of software, because what would you even
verify?&lt;/p&gt;
&lt;p&gt;The second issue is, proof engineering, the practice of writing proofs for theorems about your systems, is very hard. The proofs have many domain
specific elements to them, a proof of a mathematical theorem will be very different from a proof about a programming language, and a proof about the programming
language will highly depend on the underlying constructs of its theoretical framework. The widest taught proof engineering book
is &lt;a href="https://softwarefoundations.cis.upenn.edu"&gt;Software Foundations&lt;/a&gt;, and every chapter has a different style of proofs. Someone that went through
Volume 2: Programming Language Foundations will not find the problems in Volume 6: Separation Logic Foundations intuitive or obvious. There are other problems
such as the tooling for proof automation, brittleness of proofs, reusability of proofs etc. but I don't find them particularly fundamental to proof engineering
itself but rather problems of the current generation, so we can leave those aside for now.&lt;/p&gt;
&lt;p&gt;The rise of LLMs in programming vastly affects both of these points. It affects point number 1 because AI-assisted programming is a very natural fit
fot specification-driven development. AI-assisted programming pushes the limits of programming from what you can implement to what you can specify and
what you can &lt;a href="https://alperenkeles.com/posts/verifiability-is-the-limit/"&gt;verify&lt;/a&gt;. This is a great incentive for writing executable specifications,
because then you can put the LLM inside a loop until it achieves the said objective, irrespective of the means of the achievement.
&lt;a href="https://alperenkeles.com/posts/verifiable-abstractions/"&gt;I predict that&lt;/a&gt; this will give rise to program optimizers and translators that will
be transformative of our work in those domains. However, tests are, as infamously they are, incomplete. Tests are great at finding bugs (actually
they are not so great most of the time, but that's another discussion), but they &lt;strong&gt;cannot&lt;/strong&gt; prove the absence of bugs. SQLite famously has
millions of tests, but researchers still find bugs in SQLite, similar situations arise in almost all software.&lt;/p&gt;
&lt;p&gt;The only way to prove the absence of bugs is formal verification, and industry has seen great examples of this. Highly cited formal verification
projects include CompCert C Compiler, &lt;a href="https://users.cs.utah.edu/~regehr/papers/pldi11-preprint.pdf"&gt;the random testing of which against GCC and Clang&lt;/a&gt;
has led to finding 79 bugs in GCC and 202 bugs in Clang, and only 2 bugs in CompCert in its &lt;em&gt;unverified&lt;/em&gt; parser, finding no bugs in its verified compilation
pass, a striking win for formal verification. (Thanks to &lt;a href="https://emptysqua.re/blog/"&gt;A. Jesse Jiryu Davis&lt;/a&gt; informing me, I learned that researchers have
&lt;a href="https://www.cs.purdue.edu/homes/pfonseca/papers/eurosys2017-dsbugs.pdf"&gt;studied&lt;/a&gt; the source of failures in formally verified distributed systems, and
found that wrong assumptions about the unverified parts of the system are the likely culprit.)&lt;/p&gt;
&lt;p&gt;This makes formal verification a prime target for AI-assisted programming. Given that we have a formal specification, we can just let the machine wander around
for hours, days, even weeks. If it comes back with a solution, we shall trust not to the probabilistic predictions of the so-called artificial intelligence,
but the symbolic proof checker that verifies the solution. This idea has always been at the core of formal verification, the ability to have unsound proof
generation coupled with sound proof checking has given rise to complex tactics, algorithms that produce proofs by searching them, to enable proof engineers
in great capacity.&lt;/p&gt;
&lt;p&gt;This is not the end of the good news. AI is also very good at writing proofs, at least much better than the average software engineer. Given that we have
a perfect oracle, we can also turn the problem into an RLVR (Reinforcement Learning with Verifiable Rewards), which means we should expect the models to get
even better at it as time goes on as they did in chess, go, and many other similar problems. This is the promise behind the billion dollar valuations,
the companies started with impressive autoformalization techniques and automated provers for tackling competition problems and open conjectures, but
the real industrial value is at the core of automating software engineering by letting the engineer write a verbal description, autoformalized into a Lean
theorem, proven by the automated prover, and voila, we have our program that we can fully trust.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;or do we?&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;&lt;a href="#formal-verification-the-bads"&gt;Formal Verification: The Bads&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I see the appeal, I like the idea, I trust the researchers building these systems, but I don't love the overarching promises. This blog post
is my attempt at building a reasonable middle ground by laying out the goods (as I already did), and the bads (as I now will), and make my closing
remarks by reiterating the position of testing in this space, and in the future.&lt;/p&gt;
&lt;h3&gt;&lt;a href="#autoformalization-is-a-shaky-ground"&gt;Autoformalization is a shaky ground&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I started this post by stating most programs in the world do not have formal specifications, followed by how AI is incentivizing us to write specifications,
and autoformalization takes the specifications, and makes them &lt;strong&gt;formal&lt;/strong&gt;. In formal verification, there's this concept of a &lt;em&gt;trusted computing base (TCB)&lt;/em&gt;. TCB
is your Achilles' Heel, it's the bottom of the ladder, where layers over layers of verification is built on, trusting a small core without verifying it, because
there must be a bottom of the ladder, we cannot build a circular verification argument, and the system cannot verify itself. (please fact check me on this
if I'm wrong, which is possible)&lt;/p&gt;
&lt;p&gt;Autoformalization is part of the TCB in this AI-assisted verified programming paradigm, because one cannot mechanically verify that the verbally stated
specification indeed corresponds to the formalized one. There are several modes of usage, one issue is soundness, there might be mechanically verified scenarios
that would be rejected by the verbal specification. Another issue is completeness, the formalized model might reject valid scenarios in our descriptions.
Autoformalization part of the process requires and deserves our special attention as it's one of the crucial points of failure in this verification process.&lt;/p&gt;
&lt;h3&gt;&lt;a href="#proof-assistants-are-slow"&gt;Proof assistants are slow&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In a proof assistant, the primary goal is reasoning about programs and ease of verification. For instance, proof assistants, traditionally, don't use our classic
two's complement integers packed into words in our memory, they use Peano numbers, an encoding of natural numbers as inductive data structures:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Inductive Nat : Type :=
| zero : Nat
| succ : Nat -&amp;gt; Nat.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This encoding doesn't possess the concept of an integer overflow. Its inductive structure allows us to build theorems that hold for all natural numbers, not
just the ones that can fit in a word. It is also painfully slow, the computational complexity of &lt;code&gt;a + b&lt;/code&gt;, an operation so fast in CPU that it's literally
an instant, is &lt;code&gt;O(a + b)&lt;/code&gt;, addition is linear in time to the added values instead of a constant operation. However, we would like to run verified code on
real life workloads, so we cannot wait for a million cycles to add 1M + 1M = 2M. There are 2 solutions to this problem, the first one is that you build a
more efficient encoding in the proof assistant, prove equivalence of the efficient but hard to reason encoding to the inefficient but simpler to reason one,
and use the efficient one in your computations. The other is once again, axiomatization, or broadening the TCB. Proof assistants offer a mechanism called
&lt;strong&gt;extraction&lt;/strong&gt; that allows for extracting a piece of code in the language of the proof assistant (e.g Rocq) to a language with a larger ecosystem optimized
for running production workloads (e.g OCaml). Much of the extraction is a one-to-one correspondence between the languages via syntactic transformations,
but we can hijack the extraction to axiomatize our own types. We can turn Nat into unsigned integers, where &lt;code&gt;Nat.add&lt;/code&gt; becomes &lt;code&gt;u64 + u64&lt;/code&gt;. For instance,
in Rocq, Nats are extracted to BigInts, which should have the same semantics, but the "should" in this sentence carries the heavyweight. Without an accompanying
proof of correctness, we just put BigInt into the TCB.&lt;/p&gt;
&lt;p&gt;Without broadening the TCB, the speed of a proof assistant will be limited by the large amount of pointer chasing that arises naturally with the use of
inductive types and their tree-inducing characteristics. There are many domains in which speed isn't that big of a deal, but I think there's also a
concern between speed and the requirement for correctness, as faster code tends to involve more complex language constructs such as concurrency,
bit manipulation, layout awareness, which leads to more bugs than their simpler counterparts. If we cannot reason about programs that are more likely
to have bugs, how much of the overarching problem are we tackling?&lt;/p&gt;
&lt;h3&gt;&lt;a href="#verification-requires-models-and-models-are-very-hard-to-come-by"&gt;Verification requires models, and models are very hard to come by&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In order to verify some property of a system, one needs a model of the system. These models don't grow on trees, they are crafted by domain
experts over a number of years. People have been building models for programs with pointers (separation logic), as well as programs with
concurrency, programs with randomness, programs with algebraic effects, and perhaps many more that I haven't even heard of. In proving a property
of the system, we need a foundation for our reasoning process, which these theories give us for their respective domains. However, there are many
domains we don't have good models for, one example is runtime performance. This has been a contentious issue in the computer science curriculum, the
asymptotic complexity does not translate to program behavior in real hardware. Modern CPUs have cache lines, speculative execution, branch prediction
that makes the plain old abstract machine used in asymptotical analysis obsolete for many scenarios. We do not even have a single hardware to conform
our model to, we have tens of different configurations of hardware, each of which will give different results in our measurements. If we tried to prove
that some piece of code has a better result for a specific memory/processor pair than another one, we would have a massive job on our hands, I personally
don't even know where I would start with.&lt;/p&gt;
&lt;p&gt;Contrast this to testing, where you can just spin up the same algorithm on both machines, run our benchmarks, which will be our final ground truth. Testing
is almost universally considered inferior to formal verification, it is what you do when you don't have the resources to justify verification, because if you
had the opportunity to spend the time, proving absence of bugs, or universal facts about your system, would be much more valuable than codifiying the results
of singular measurements. I am here to tell you that there are tests we can write that could not be formally verified, because while building the underlying
models for verification might be hard, just using the real hardware for our measurements can be much easier.&lt;/p&gt;
&lt;h3&gt;&lt;a href="#verification-doesn-t-tell-you-that-you-are-going-down-the-wrong-path"&gt;Verification doesn't tell you that you are going down the wrong path&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;In games, there are clear winners and losers. In verification, you can prove that your theorem is correct, you can prove that your theorem is incorrect, but
absence of a proof for a theorem does not imply that the theorem is incorrect, it is possible that you just haven't found the proof. This means the feedback
you get when writing a proof is limited as you cannot rely on your inability to progress as a signal about your theorem, it is plausible that you are the problem.
This is why QuickChick, a testing tool descending from the famous QuickCheck of Haskell that introduced Property-Based Testing to the world, exists in Rocq
ecosystem as one of the three most popular packages. If verification was strictly superior to testing, QuickChick would have no reason to exist, but it serves
a very crucial role that the verification process needs, &lt;strong&gt;falsification&lt;/strong&gt;. I had said that the absence of a proof does not imply that a theorem is wrong, but the witness of a violation of the theorem definitely does. Random testing is the prime suspect for finding such counterexamples, pulling the verifier out of the
rabbit hole of going through many useless paths in the proof search before giving up, because the theorem is ultimately wrong, there is no proof to be found.&lt;/p&gt;
&lt;h2&gt;&lt;a href="#random-testing-and-formal-verification"&gt;Random Testing and Formal Verification&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I have given examples of tests that formal verification is incapable of modeling, and examples of tests that complement formal verification process by creating
a short that falsifies false theorems instead of trying to prove them in vain. The synergy between testing and formal verification doesn't end here, I am a firm
supporter of &lt;a href="https://aws.amazon.com/blogs/opensource/lean-into-verified-software-development/"&gt;Verification-Guided Development (VGD)&lt;/a&gt;, which in addition to leveraging this synergy, solves the problem of proof
assistants being too slow. In verification
guided development, we implement two versions of the same system, one is the simpler to reason, verified version, the other is the complex, production one. We then
test the property that the production system conforms to the reference implementation that is verified by running them with the same inputs and asserting that
the result is the same every single time. VGD &lt;em&gt;lifts&lt;/em&gt; the proof to the production implementation from the slower one implemented in the proof assistant by leveraging
differential random testing, which allows for building a best-of-both-worlds system that is both correct and fast. Below is an image taken from &lt;a href="https://arxiv.org/abs/2407.01688"&gt;the paper&lt;/a&gt;
that (as far as I know) introduced the notion of VGD, explaining their workflow.&lt;/p&gt;
&lt;p&gt;&lt;img alt="cedar vgd" src="https://alperenkeles.com/posts/test-dont-verify/image.png"/&gt;&lt;/p&gt;
&lt;p&gt;VGD doesn't solve all the issues I mention in the rest of the post, but it removes the slowness out of the mix. As we have a production implementation ready to be tested thoroughly,
we can make all kinds of measurements that fall out of the purview of verification, but into the realm of testing. It levels the playing field between the verified realm of computing
and the unverified one, reducing the downsides of the verification leveraging testing.&lt;/p&gt;
&lt;h2&gt;&lt;a href="#closing-remarks"&gt;Closing Remarks&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;I would like to state it once more for everyone:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;I see the appeal, I like the idea, I trust the researchers building these systems, but I don't love the overarching promises. This blog post
is my attempt at building a reasonable middle ground by laying out the goods, and the bads, and make my closing
remarks by reiterating the position of testing in this space, and in the future.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;I believe random testing plays as important of a role as formal verification in the future of software engineering. We will not have magically formally verified systems
in many domains, but as autoformalization tools get better, we will have many, many more formal specifications. Random testing benefits from these formal specifications
in different ways than formal verification, but both have their places. Proof systems will be incomplete without the accompanying testing tools, and the testing tools
will be incomplete without proofs of correctness, it is only possible via some combination of verification and testing that we can achieve our ideals of the future of
software engineering, live in a world where bugs are considered anomalies instead of the norm, where correctness is a virtue, and the bugs in our systems are as old and
as forgotten as the diseases we learned to cure and put away.&lt;/p&gt;

&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://alperenkeles.com/posts/test-dont-verify/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 12:56:50 +0000</pubDate>
    </item>
    <item>
      <title>Ryanair fined €256M over ‘abusive strategy’ to limit ticket sales by OTAs</title>
      <link>https://www.theguardian.com/business/2025/dec/23/ryanair-fined-limit-online-travel-agencies-ticket-sales-ota</link>
      <description>Italy’s competition authority says Irish airline implemented technical obstacles to force sales through its own website</description>
      <content:encoded>&lt;article class="dcr-1xdhyk6" style="background-color:var(--article-background)"&gt;&lt;img alt="Passengers board a Ryanair Boeing 737 MAX in Cagliari, Italy, through its rear entrance; a wing of the plane with gold lettering reading Ryanair looms over the photographer." src="https://i.guim.co.uk/img/media/0c0d402539470b70559e972804fa15cf214418f2/0_0_3780_3024/master/3780.jpg?width=465&amp;amp;dpr=1&amp;amp;s=none&amp;amp;crop=none"/&gt; Ryanair has reached a record valuation of €31bn (£27bn), making it the world’s second most valuable airline behind Delta. Photograph: John Keeble/Getty Images&lt;a href="#img-1"&gt;View image in fullscreen&lt;/a&gt;Ryanair has reached a record valuation of €31bn (£27bn), making it the world’s second most valuable airline behind Delta. Photograph: John Keeble/Getty Images&lt;h1&gt;Ryanair fined €256m over ‘abusive strategy’ to limit ticket sales by online travel agencies&lt;/h1&gt;&lt;p&gt;Italy’s competition authority says Irish airline implemented technical obstacles to force sales through its own website&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://www.theguardian.com/business/live/2025/dec/23/tesla-sales-fall-europe-byd-surges-car-industry-stock-market-ftse-business-live-news-updates"&gt;Business live – latest updates&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;Ryanair has been fined €256m (£223m) by Italy’s competition authority for abusing its dominant market position to limit sales of tickets by online travel agents.&lt;/p&gt;&lt;p&gt;The authority said Europe’s largest airline had “implemented an abusive strategy to hinder travel agencies” via an “elaborate strategy” of technical obstacles for agents and passengers to make it difficult for online travel agents to sell Ryanair tickets and instead force sales through its own website.&lt;/p&gt;&lt;p&gt;The fine related to Ryanair’s conduct between April 2023 and at least until April 2025, the authority said on Tuesday. It said Ryanair had prevented online travel agents from selling tickets on its flights in combination with other airlines and services, weakening competition.&lt;/p&gt;&lt;p&gt;Ryanair said it would immediately appeal against the “legally flawed” ruling.&lt;/p&gt;&lt;p&gt;The Ryanair chief executive, &lt;a href="https://www.theguardian.com/business/michael-oleary"&gt;Michael O’Leary&lt;/a&gt;, had decided to wage war on what he &lt;a href="https://www.theguardian.com/business/2024/jan/29/ryanair-cuts-profits-forecast-flights-lastminute-opodo"&gt;described as “pirate” travel agents&lt;/a&gt;, such as Booking.com, Kiwi and Kayak. O’Leary accused the travel agent industry of scamming and ripping off unsuspecting consumers by charging extra fees and markups on ticket prices.&lt;/p&gt;&lt;p&gt;O’Leary was prepared to accept lower ticket sales as he tried to prevent travel agents from selling tickets, forcing their passengers to fill out extra forms supposedly as a security measure. The abrupt removal of Ryanair flights from agents’ websites in late 2023 &lt;a href="https://www.theguardian.com/business/2024/jan/03/ryanair-ticket-sales-hit-after-travel-agent-websites-delist-airline"&gt;caused a drop in sales for the airline&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The lower sales &lt;a href="https://www.theguardian.com/business/2024/jan/29/ryanair-cuts-profits-forecast-flights-lastminute-opodo"&gt;dented Ryanair’s profits&lt;/a&gt;, although they have not prevented the Irish airline from rising to a record valuation of €31bn (£27bn). That has made it the world’s second most valuable airline, behind only the US’s Delta Air Lines.&lt;/p&gt;&lt;p&gt;O’Leary – who is known for his combative and often sweary criticisms of airports, rivals and regulators – is planning to hand over control of the business to a successor within the next five to 10 years. He will be &lt;a href="https://www.theguardian.com/business/2023/dec/18/ryanair-boss-michael-oleary-heads-for-100m-bonus"&gt;given shares worth €111m&lt;/a&gt; (£97m) if he stays at the airline until the end of July 2028. He was already a billionaire on paper because of his shareholding.&lt;/p&gt;&lt;p&gt;Responding to the ruling, O’Leary said it was “an affront to consumer protection and competition law”.&lt;/p&gt;&lt;p&gt;He added: “The internet and the ryanair.com website have enabled Ryanair to distribute directly to consumers, and Ryanair has passed on these 20% cost savings in the form of the lowest air fares in &lt;a href="https://www.theguardian.com/world/italy"&gt;Italy&lt;/a&gt; and Europe.&lt;/p&gt;&lt;p&gt;“Ryanair looks forward to successfully overturning this legally flawed ruling and its absurd €256m fine in the courts.”&lt;/p&gt;&lt;p&gt;The vast majority of Ryanair’s sales took place through its website even before the battle against online travel agents. However, the Italian authority said Ryanair had been guilty of “abuse of a dominant position” and using its “significant market power” in trying to stamp out the business.&lt;/p&gt;&lt;p&gt;Ryanair’s tactics included rolling out facial recognition procedures for people who bought tickets via a third party, claiming that was necessary for security. It then “totally or intermittently blocked booking attempts by travel agencies”, including by blocking payment methods and mass-deleting accounts.&lt;/p&gt;&lt;p&gt;The airline then “imposed partnership agreements” on agencies that banned sales of Ryanair flights in combinations with other carriers, and blocked bookings to force them to sign up. Only in April this year did it allow agencies’ websites to link up with its own services, allowing effective competition.&lt;/p&gt;&lt;p&gt;The competition authority said Ryanair’s actions had “blocked, hindered or made such purchases more difficult and/or economically or technically burdensome when combined with flights operated by other carriers and/or other tourism and insurance services”.&lt;/p&gt;Explore more on these topics&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/business/ryanair"&gt;Ryanair&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/business/michael-oleary"&gt;Michael O'Leary&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/business/theairlineindustry"&gt;Airline industry&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/world/ireland"&gt;Ireland&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/world/italy"&gt;Italy&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/world/europe-news"&gt;Europe&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/business/regulators"&gt;Regulators&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.theguardian.com/tone/news"&gt;news&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="mailto:?subject=Ryanair fined €256m over ‘abusive strategy’ to limit ticket sales by online travel agencies&amp;amp;body=https://www.theguardian.com/business/2025/dec/23/ryanair-fined-limit-online-travel-agencies-ticket-sales-ota?CMP=share_btn_url"&gt;Share&lt;/a&gt;&lt;a href="https://syndication.theguardian.com/?url=https%3A%2F%2Fwww.theguardian.com%2Fbusiness%2F2025%2Fdec%2F23%2Fryanair-fined-limit-online-travel-agencies-ticket-sales-ota&amp;amp;type=article&amp;amp;internalpagecode=business/2025/dec/23/ryanair-fined-limit-online-travel-agencies-ticket-sales-ota"&gt;Reuse this content&lt;/a&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.theguardian.com/business/2025/dec/23/ryanair-fined-limit-online-travel-agencies-ticket-sales-ota</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 10:53:07 +0000</pubDate>
    </item>
    <item>
      <title>Font with Built-In Syntax Highlighting (2024)</title>
      <link>https://blog.glyphdrawing.club/font-with-built-in-syntax-highlighting/</link>
      <description>I have been trying to identify practical reasons why hand-coding websites with HTML and CSS is so hard ( by hand-coding, I mean not relying on frameworks, generators or 3rd party scripts that modify the DOM ).</description>
      <content:encoded>&lt;article class="container"&gt;

&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://blog.glyphdrawing.club/tags/Blog"&gt;#Blog&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://blog.glyphdrawing.club/tags/Type Design"&gt;#Type Design&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://blog.glyphdrawing.club/tags/Fonts"&gt;#Fonts&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://blog.glyphdrawing.club/tags/CSS"&gt;#CSS&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://blog.glyphdrawing.club/tags/Typography"&gt;#Typography&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Syntax Highlighting in Hand-Coded Websites&lt;/h2&gt;
&lt;h3&gt;The problem&lt;/h3&gt;
&lt;p&gt;I have been trying to identify practical reasons why hand-coding websites with HTML and CSS is so hard (&lt;em&gt;by hand-coding, I mean not relying on frameworks, generators or 3rd party scripts that modify the DOM&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;Let's say, I want to make a blog. What are the &lt;strong&gt;actual&lt;/strong&gt; things that prevent me from making—and maintaining—it by hand? What would it take to clear these roadblocks?&lt;/p&gt;
&lt;p&gt;There are many, of course, but for a hand-coded programming oriented blog one of these roadblocks is &lt;strong&gt;syntax highlighting&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;When I display snippets of code, I want to make the code easy to read and understand by highlighting it with colors. To do that, I would normally need to use a complex syntax highlighter library, like &lt;a href="https://prismjs.com/"&gt;Prism&lt;/a&gt; or &lt;a href="https://highlightjs.org/"&gt;highlight.js&lt;/a&gt;. These scripts work by scanning and chopping up the code into small language-specific patterns, then wrapping each part in tags with special styling that creates the highlighted effect, and then injecting the resulting HTML back into the page.&lt;/p&gt;
&lt;p&gt;But, I want to write code by hand. I don't want any external scripts to inject things I didn't write myself. Syntax highlighters also add to the overall complexity and bloat of each page, which I'm trying to avoid. I want to keep things as simple as possible.&lt;/p&gt;
&lt;h3&gt;Leveraging OpenType features to build a simple syntax highlighter inside the font&lt;/h3&gt;
&lt;p&gt;This lead me to think: &lt;strong&gt;could it be possible to build syntax highlighting directly into a font&lt;/strong&gt;, skipping JavaScript altogether? Could I somehow leverage OpenType features, by creating colored glyphs with the COLR table, and identifying and substituting code syntax with contextual alternates?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;div class="spoilers"&amp;gt;
  &amp;lt;strong&amp;gt;Yes, it's possible!&amp;lt;/strong&amp;gt;
  &amp;lt;small&amp;gt;...to some extent =)&amp;lt;/small&amp;gt;
&amp;lt;/div&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The colors in the HTML snippet above &lt;strong&gt;comes from within the font itself&lt;/strong&gt;, the code is &lt;strong&gt;plain text&lt;/strong&gt;, and requires &lt;strong&gt;no JavaScript&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;To achieve that, I modified an open source font Monaspace Krypton to include colored versions of each character, and then used OpenType contextual alternates to essentially find &amp;amp; replace specific strings of text based on HTML, CSS and JS syntax. The result is a simple syntax highlighter, &lt;strong&gt;built-in&lt;/strong&gt; to the font itself.&lt;/p&gt;
&lt;p&gt;If you want to try it yourself, download the font: &lt;a href="https://blog.glyphdrawing.club/assets/fonts/FontWithASyntaxHighlighter-Regular.woff2"&gt;FontWithASyntaxHighlighter-Regular.woff2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And include the following bits of CSS:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@font-face {
  font-family: 'FontWithASyntaxHighlighter';
  src: 
    url('/FontWithASyntaxHighlighter-Regular.woff2') 
    format('woff2')
  ;
}
code {
  font-family: "FontWithASyntaxHighlighter", monospace;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that's it!&lt;/p&gt;
&lt;h2&gt;What are the Pros and Cons of this method?&lt;/h2&gt;
&lt;p&gt;This method opens up some interesting possibilities...&lt;/p&gt;
&lt;h3&gt;Pros&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Install is as easy as using any custom font.&lt;/li&gt;
&lt;li&gt;Works without JavaScript.&lt;/li&gt;
&lt;li&gt;Works without CSS themes.&lt;/li&gt;
&lt;li&gt;...but can be themed with CSS.&lt;/li&gt;
&lt;li&gt;It's fast.&lt;/li&gt;
&lt;li&gt;Snippets of code can be put into &lt;code&gt;&amp;lt;pre&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;code&amp;gt;&lt;/code&gt;, with no extra classes or &lt;code&gt;&amp;lt;span&amp;gt;&lt;/code&gt;s.&lt;/li&gt;
&lt;li&gt;Clean HTML source code.&lt;/li&gt;
&lt;li&gt;Works everywhere that supports OpenType features, like InDesign.&lt;/li&gt;
&lt;li&gt;Doesn't require maintenance or updating.&lt;/li&gt;
&lt;li&gt;Works in &lt;code&gt;&amp;lt;textarea&amp;gt;&lt;/code&gt; and &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt;! Syntax highlighting inside &lt;code&gt;&amp;lt;textarea&amp;gt;&lt;/code&gt; has been &lt;a href="https://css-tricks.com/creating-an-editable-textarea-that-supports-syntax-highlighted-code/"&gt;previously impossible&lt;/a&gt;, because textareas and inputs can only contain plain text. This is where the interesting possibilities lie. As a demo, I made this tiny HTML, CSS &amp;amp; JS sandbox, with native undo and redo, in a single, &lt;a href="https://blog.glyphdrawing.club/assets/webcomponents/tinybox.js"&gt;web component&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;




&lt;!-- Edit the content! --&gt;
&lt;p&gt;
          tiny HTML &amp;amp; CSS sandbox =)
        &lt;/p&gt;




&lt;h3&gt;Cons&lt;/h3&gt;
&lt;p&gt;There are, of course, some limitations to this method. It is not a direct replacement to the more robust syntax highligting libraries, but works well enough for simple needs.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Making modifications to the syntax highligher, like adding more language supports or changing the look of the font, requires modifying the font file. This requires some knowledge of font production, which most people don't have.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It only works where OpenType is supported. Fortunately, that's all major browsers and most modern programs. However, something like PowerPoint doesn't support OpenType.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Finding patterns in text with OpenType contextual alternates is quite basic, and is no match for scripts that use regular expressions. For example, words within &lt;code&gt;&amp;lt;p&amp;gt;&lt;/code&gt; tags that are JS keywords will be always highlighted: &lt;code&gt;&amp;lt;p&amp;gt;if I throw this Object through the window, catch it, for else it’ll continue to Infinity &amp;amp; break&amp;lt;/p&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Multiline highlighting with manual line breaks will sadly not work.&lt;/p&gt;
&lt;p&gt;This is common, for example, in comment blocks and template literals:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; &amp;lt;!-- This line gets highlighted...
 but not this, because I made a manual line break...
 --&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;How does it actually work?&lt;/h2&gt;
&lt;p&gt;Here's roughly how it works. There are two features in OpenType that make this possible: OpenType COLR table and contextual alternates.&lt;/p&gt;
&lt;h3&gt;OpenType COLR table&lt;/h3&gt;
&lt;p&gt;OpenType COLR table makes multi-colored fonts possible. &lt;a href="https://glyphsapp.com/learn/creating-a-microsoft-color-font"&gt;There is a good guide on creating a color font using Glyphs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I made a palette with 8 colors.&lt;/p&gt;
&lt;p&gt;I duplicated letters &lt;code&gt;A&lt;/code&gt; &lt;code&gt;–&lt;/code&gt; &lt;code&gt;Z&lt;/code&gt;, numbers &lt;code&gt;0&lt;/code&gt; &lt;code&gt;–&lt;/code&gt; &lt;code&gt;9&lt;/code&gt; and the characters &lt;code&gt;.&lt;/code&gt; &lt;code&gt;#&lt;/code&gt; &lt;code&gt;*&lt;/code&gt; &lt;code&gt;-&lt;/code&gt; and &lt;code&gt;_&lt;/code&gt; four times. Each duplicated character is then suffixed with .alt, .alt2, .alt3 or .alt4, and then assigned a color from the palette. For example, all .alt1 glyphs are &lt;code&gt;this&lt;/code&gt; color.&lt;/p&gt;
&lt;p&gt;I also duplicated all characters twice, and gave them suffices .alt1 and .alt5 and assigned them colors used in &lt;code&gt;&amp;lt;!-- comment blocks --&amp;gt;&lt;/code&gt; and &lt;code&gt;"strings within quotes"&lt;/code&gt;&lt;/p&gt;

&lt;img src="https://blog.glyphdrawing.club/assets/kmFZTjkTcx-320.jpeg"/&gt;
View from Glyps app. Each alternate character has a different color.

&lt;p&gt;The two other colors I used for symbols &lt;code&gt;&amp;amp; | $ + − = ~ [] () {} / ; : " @ %&lt;/code&gt; and &lt;code&gt;'&lt;/code&gt;, and they are always in one color. Numbers &lt;code&gt;0 1 2 3 4 5 6 7 8 9&lt;/code&gt; are also always a certain color, unless overriden by other rules.&lt;/p&gt;
&lt;h3&gt;OpenType contextual alternates&lt;/h3&gt;
&lt;p&gt;The second required feature is OpenType contextual alternates. &lt;a href="https://glyphsapp.com/learn/features-part-3-advanced-contextual-alternates"&gt;Here's a great introductory guide to advanced contextual alternates for Glyphs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Contextual alternates makes characters "aware" of their adjacent characters. An example would be fonts that emulate continuous hand writing, where &lt;em&gt;how&lt;/em&gt; a letter connects depends on which letter it connects to. There is a &lt;a href="https://ilovetypography.com/2011/04/01/engaging-contextuality/"&gt;nice article covering possible uses here&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;JavaScript syntax rules&lt;/h4&gt;
&lt;p&gt;The core feature of contextual alternates is substituting glyphs. Here is a simplified code for finding the JavaScript keyword &lt;code&gt;if&lt;/code&gt; and substituting the letters i and f with their colored variant:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sub i' f by i.alt2;
sub i.alt2 f' by f.alt2;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In English:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;When i is followed by f, substitute the default i with an alternate (i.alt2).&lt;/li&gt;
&lt;li&gt;When i.alt2 is followed by f, substitute the default f with an alternate (f.alt2).&lt;/li&gt;
&lt;li&gt;As a result, every "if" in text gets substituted with &lt;code&gt;if&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;OpenType doesn't support many-to-many substitutions directly, but &lt;a href="https://typo.social/@behdad/112967180363218632"&gt;@behdad&lt;/a&gt; on Mastodon had a great suggestion: keywords could be elegantly colored by &lt;em&gt;chaining&lt;/em&gt; contextual substitutions.&lt;/p&gt;
&lt;p&gt;To do this, I made a lookup which substitutes each letter with its colored variant.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lookup ALT_SUBS {
    sub a by a.alt; 
    sub b by b.alt; 
    sub c by c.alt; 
    [etc.]
    sub Y by Y.alt;
    sub Z by Z.alt;
} ALT_SUBS;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I moved this lookup rule to the &lt;a href="https://handbook.glyphsapp.com/layout/standalone-lookups/"&gt;Prefix&lt;/a&gt; section, which just means it doesn't get applied automatically unlike the other lookups.&lt;/p&gt;
&lt;p&gt;Then, I made a lookup rule for each keyword in the contextual alternates section. Here's one for &lt;code&gt;console&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lookup console {
    ignore sub @AllLetters c' o' n' s' o' l' e';
    ignore sub c' o' n' s' o' l' e' @AllLetters;
    sub c' lookup ALT_SUBS
        o' lookup ALT_SUBS
        n' lookup ALT_SUBS
        s' lookup ALT_SUBS
        o' lookup ALT_SUBS
        l' lookup ALT_SUBS
        e' lookup ALT_SUBS;
} console;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;First two lines tells it to ignore strings like &lt;code&gt;Xconsole&lt;/code&gt; or &lt;code&gt;consoles&lt;/code&gt;, but not if there's a period like &lt;code&gt;console.log()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The third line starts by replacing the first letter 'c' with its colored variant &lt;code&gt;c&lt;/code&gt;, by using definitions from the other lookup table "ALT_SUBS". This repeats until each letter is replaced by its color variant, and the result is &lt;code&gt;console&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Identifying JavaScript keywords is fairly straightforward. Logic is the same for each keyword, and I used a python script to generate them.&lt;/p&gt;
&lt;h4&gt;HTML &amp;amp; CSS syntax rules&lt;/h4&gt;
&lt;p&gt;But for HTML and CSS... I had to get a bit more creative. There are simply too many keywords for both HTML and CSS combined. Making a separate rule for each keyword would inflate the file size.&lt;/p&gt;
&lt;p&gt;Instead, I came up with this monstrosity. Here's how I find CSS value functions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lookup CssParamCalt useExtension {
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' @CssParam parenleft by @CssParamAlt4;
  sub @CssParam' parenleft by @CssParamAlt4;
} CssParamCalt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;@CssParam is a custom OpenType glyph class I've set up. It includes the characters &lt;code&gt;A&lt;/code&gt; &lt;code&gt;–&lt;/code&gt; &lt;code&gt;Z&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt; &lt;code&gt;–&lt;/code&gt; &lt;code&gt;z&lt;/code&gt;, and &lt;code&gt;-&lt;/code&gt;, which are all the possible characters used in CSS value function names. Because the longest possible CSS value function name is &lt;code&gt;repeating-linear-gradient()&lt;/code&gt;, with 25 letters, the first line of the lookup starts with @CssParam repeated 25 times, followed by parenleft (&lt;code&gt;(&lt;/code&gt;). This lookup will match any word up to 25 letters long, if it's immediately followed by an opening parenthesis. When a match occurs, it substitutes the matched text with its alternate color form (@CssParamAlt4).&lt;/p&gt;
&lt;p&gt;This lookup works for both CSS and JavaScript. It will colorize standard CSS functions like &lt;code&gt;rgb()&lt;/code&gt; as well as custom JavaScript functions like &lt;code&gt;myFunction()&lt;/code&gt;. The result is a semi-flexible syntax highlighter that doesn't require complex parsing. The downside is that if you have a really long function name, it stops working midway: &lt;code&gt;aReallyLongFunctionNameStopsWorkingMidway()&lt;/code&gt;. I've repeated the same principle for finding HTML tags and attributes, and for CSS selectors and parameters.&lt;/p&gt;
&lt;h4&gt;Unknown length rules&lt;/h4&gt;
&lt;p&gt;Comment blocks and strings between quotes also required extra care, because their length can be anything. OpenType doesn't support loops or anything resembling regular expressions. For example, I can't just tell it to simply substitute everything it finds between two quotes.&lt;/p&gt;
&lt;p&gt;However, I got a great suggestion from @penteract on &lt;a href="https://news.ycombinator.com/item?id=41259124"&gt;&lt;em&gt;Hacker News&lt;/em&gt;&lt;/a&gt; to use a finite state machine for these kinds of situations. Here our aim is to colorize eveything between /* and */ gray:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lookup CSScomment useExtension {
  // stop if we encounter a colored */
  ignore sub asterisk.alt1 slash.alt1 @All';

  // color first letter after /*
  sub slash asterisk @All' by @AllAlt1;
  sub slash asterisk space @All' by @AllAlt1;
  
  // color /* itself
  sub slash' asterisk by slash.alt1;
  sub slash.alt1 asterisk' by asterisk.alt1;
  
  // finite state machine to color rest of the characters
  // or until ignore condition is met
  sub @AllAlt1 @All' by @AllAlt1;
} CSScomment;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The last line is the important one. The lookup will just continue replacing characters if the previous character is already colored.&lt;/p&gt;
&lt;h3&gt;End note&lt;/h3&gt;
&lt;p&gt;The full process is a little bit too convoluted to go into step-by-step, but if you're a type designer who wants to do this with their own font, don't hesitate to contact me.&lt;/p&gt;
&lt;p&gt;I'm also not an OpenType expert, so I'm sure the substitution logics could be improved upon. If you're interested in learning more about OpenType, I recommend reading &lt;a href="https://opentypecookbook.com/"&gt;The OpenType Cookbook&lt;/a&gt; and the complete &lt;a href="https://adobe-type-tools.github.io/afdko/OpenTypeFeatureFileSpecification.html"&gt;OpenType™ Feature File Specification&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have any ideas, suggestions or feedback, let me know. You can reach me at &lt;code&gt;hlotvonen@gmail.com&lt;/code&gt; or leave a comment on &lt;a href="https://typo.social/@gdc/112959308500800771"&gt;Mastodon&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Changing the color theme&lt;/h2&gt;
&lt;p&gt;You can change the color theme with CSS &lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/@font-palette-values/override-colors"&gt;&lt;code&gt;override-colors&lt;/code&gt;&lt;/a&gt;! &lt;a href="https://caniuse.com/?search=font-palette"&gt;Browser support&lt;/a&gt; is great at ~94%.&lt;/p&gt;




&lt;!-- Edit the content! --&gt;
&lt;pre&gt;&lt;code&gt;
        var const let for while
        function() linear-gradient()
        .myDiv{ background-color: pink; }
        console.log("hello", true)
        /* comment */
        &amp;amp; | $ + − = ~ [] () {} / ; : " @ % 
        0 1 2 3 4 5 6 7 8 9
      &lt;/code&gt;&lt;/pre&gt;



&lt;h2&gt;Alternative built-in color themes&lt;/h2&gt;
&lt;p&gt;Additionally, two alternative color themes &lt;em&gt;Night Owl&lt;/em&gt;, and &lt;em&gt;Light Owl&lt;/em&gt; were added by &lt;a href="https://typo.social/@niutech@fosstodon.org"&gt;niutech&lt;/a&gt;. You can download them from the &lt;a href="https://github.com/hlotvonen/FontWithASyntaxHighlighter"&gt;FontWithASyntaxHighlighter GitHub page&lt;/a&gt;. &lt;a href="https://github.com/sdras/night-owl-vscode-theme"&gt;Night Owl theme&lt;/a&gt; is made by &lt;a href="https://github.com/sdras"&gt;Sarah Drasner&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In order to modify the built-in color palette, you have to edit the font source file. To do so, you can edit the color palettes values in lines 112-120 of the &lt;a href="https://github.com/hlotvonen/FontWithASyntaxHighlighter/blob/main/FontWithASyntaxHighlighter.glyphs"&gt;FontWithASyntaxHighlighter.glyphs&lt;/a&gt; file and then build the font with &lt;a href="https://github.com/googlefonts/fontmake"&gt;fontmake&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Projects using this font&lt;/h2&gt;
&lt;p&gt;Here's some cool projects that are using or are inspired by this font:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://www.holograph.so/"&gt;Holograph is a visual coding tool built on tldraw&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/dennishansen/holograph"&gt;its GitHub page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://maxbo.me/celine/"&gt;@celine/celine is library for building reactive HTML notebooks&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/MaxwellBo/celine"&gt;its GitHub page&lt;/a&gt; &amp;amp; &lt;a href="https://maxbo.me/a-html-file-is-all-you-need.html"&gt;blogpost&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://chenglou.me/pure-css-shaders-art/"&gt;Shaders art made with pure CSS&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/chenglou/pure-css-shaders-art"&gt;its GitHub Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://mdit.pages.dev/"&gt;Mdit, a simple Markdown previewer&lt;/a&gt; &amp;amp; &lt;a href="https://github.com/roblesdotdev/mdit"&gt;its GitHub Page&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/JRJurman/textarea-code-block"&gt;Web Component for making a Textarea element into a syntax highlighted codeblock&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;It might also be used as an example for displaying the potential uses for color fonts in the W3C &lt;a href="https://github.com/w3c/csswg-drafts/tree/main/css-fonts-4"&gt;CSS Fonts Module Level 4 specification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://codepen.io/daviddarnes/pen/poXpaLB?editors=1100"&gt; Web Component with syntax highlighting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://tug.org/tug2025/preprints/rajeesh-colorfont-syntax.pdf"&gt;An OpenType font with built-in TEX syntax highlighting&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://labelary.com/viewer.html"&gt;Labelary ZPL viewer &amp;amp; editor&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://garten.salat.dev/"&gt;garten.salat.dev blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ffoodd.fr/devfest.2024/jeu/"&gt;L’invasion du HTML mutant&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;(Did you make a project using this font, or know a project that uses it? Let me know please!)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Potential future&lt;/h2&gt;
&lt;p&gt;Many people suggested that this concept could be taken one step further with &lt;a href="https://github.com/harfbuzz/harfbuzz-wasm-examples"&gt;harfbuzz-wasm&lt;/a&gt;. With harfbuzz-wasm a real parser could be used instead of my crazy opentype lookup rules. Essentially, all the cons could be eliminated... Any harfbuzz-wasm experts who wants to take this on?&lt;/p&gt;
&lt;h2&gt;Licence&lt;/h2&gt;
&lt;p&gt;The original font (&lt;a href="https://monaspace.githubnext.com/"&gt;MonaSpace&lt;/a&gt;) has &lt;a href="https://github.com/githubnext/monaspace/blob/main/LICENSE"&gt;SIL open font license v1.1&lt;/a&gt;, which carries over to my modified version. So, you're free to use the font in any way that the SIL v1.1 license permits.&lt;/p&gt;
&lt;p&gt;As for the code examples, they are MIT licensed. The tiny sandbox web component can be found here: &lt;a href="https://github.com/hlotvonen/tinybox"&gt;https://github.com/hlotvonen/tinybox&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Source&lt;/h2&gt;
&lt;p&gt;The original source .glyphs file is &lt;a href="https://github.com/hlotvonen/FontWithASyntaxHighlighter"&gt;hosted in this GitHub repository&lt;/a&gt;. UFO files were kindly added by &lt;a href="https://typo.social/@niutech@fosstodon.org"&gt;niutech&lt;/a&gt;. Or, you can modify the font with &lt;a href="https://forum.glyphsapp.com/t/script-outside-glyphapp/22454"&gt;some scripting&lt;/a&gt; &amp;amp; build with &lt;a href="https://github.com/googlefonts/fontmake"&gt;fontmake&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;More examples&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;as, in, of, if, for, while, finally, var, new, function,
do, return, void, else, break, catch, instanceof, with,
throw, case, default, try, switch, continue, typeof, delete,
let, yield, const, class, get, set, debugger, async, await,
static, import, from, export, extends

true, false, null, undefined, NaN, Infinity

Object, Function, Boolean, Symbol, Math, Date, Number, BigInt, 
String, RegExp, Array, Float32Array, Float64Array, Int8Array, 
Uint8Array, Uint8ClampedArray, Int16Array, Int32Array, Uint16Array, 
Uint32Array, BigInt64Array, BigUint64Array, Set, Map, WeakSet,
WeakMap, ArrayBuffer, SharedArrayBuffer, Atomics, DataView, 
JSON, Promise, Generator, GeneratorFunction, AsyncFunction, 
Reflect, Proxy, Intl, WebAssembly, Error, EvalError, InternalError, 
RangeError, ReferenceError, SyntaxError, TypeError, URIError, 
setInterval, setTimeout, clearInterval, clearTimeout, require, 
exports, eval, isFinite, isNaN, parseFloat, parseInt, decodeURI, 
decodeURIComponent, encodeURI, encodeURIComponent, escape, 
unescape, arguments, this, super, console, window, document, 
localStorage, sessionStorage, module, global
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;!-- this is a comment! --&amp;gt;
/* and this */
// and this
&amp;lt;!-- however...
it breaks when your code goes to a newline.
there's no way to keep context line to line...
--&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;!-- can't disable highlighting JS keywords in between tags --&amp;gt;
&amp;lt;p&amp;gt;
  give me a break...
&amp;lt;/p&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;!DOCTYPE html&amp;gt;
&amp;lt;html lang="en"&amp;gt;
&amp;lt;head&amp;gt;
  &amp;lt;meta charset="UTF-8"&amp;gt;
  &amp;lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&amp;gt;
  &amp;lt;title&amp;gt;Syntax Highlighter Example&amp;lt;/title&amp;gt;
  &amp;lt;style&amp;gt;
    body {
      background-color: rgb(255, 0, 0);
      font-family: 'Arial Narrow', sans-serif;
      line-height: 1.44;
      color: #333;
    }
  &amp;lt;/style&amp;gt;
&amp;lt;/head&amp;gt;
&amp;lt;body&amp;gt;
  &amp;lt;header&amp;gt;
    &amp;lt;h1&amp;gt;Welcome to the Syntax Highlighter Test&amp;lt;/h1&amp;gt;
  &amp;lt;/header&amp;gt;
  &amp;lt;nav&amp;gt;
    &amp;lt;ul&amp;gt;
      &amp;lt;li&amp;gt;&amp;lt;a href="#section1"&amp;gt;Section 1&amp;lt;/a&amp;gt;
    &amp;lt;/ul&amp;gt;
  &amp;lt;/nav&amp;gt;
  &amp;lt;main&amp;gt;
    &amp;lt;section id="section1"&amp;gt;
      &amp;lt;h2&amp;gt;Section 1&amp;lt;/h2&amp;gt;
      &amp;lt;p&amp;gt;This is a &amp;lt;span class="highlight"&amp;gt;highlighted&amp;lt;/span&amp;gt; paragraph.&amp;lt;/p&amp;gt;
      &amp;lt;img src="/api/placeholder/300/200" alt="Placeholder image"&amp;gt;
    &amp;lt;/section&amp;gt;
  &amp;lt;/main&amp;gt;
  &amp;lt;script&amp;gt;
    console.log("This is a JavaScript comment");
    function greet(name) {
      return `Hello, ${name}!`;
    }
    document.addEventListener('DOMContentLoaded', () =&amp;gt; {
      console.log(greet('Syntax Highlighter'));
    });
  &amp;lt;/script&amp;gt;
&amp;lt;/body&amp;gt;
&amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;.crazyBackground {
  /* don't try this at home */
  background:
    radial-gradient(
      100% 50% at 50% 50%,
      hsl(90 90% 45%) 0% 5%,
      hsl(250 70% 40%) 50%,
      hsl(50 50% 50%)
    ),
    radial-gradient(
      100% 100% at 50% 25%,
      hsl(90 40% 85%) 30%,
      hsl(40 80% 20%) 60% 90%,
      transparent
    ),
    linear-gradient(
      90deg,
      hsl(150 90% 90%) 0 10%,
      hsl(10 10% 20%),
      hsl(150 90% 90%) 90% 100%
    )
  ;
  background-size:
    5% 10%,
    10% 200%,
    25% 100%
  ;
  background-blend-mode:
    color-dodge,
    difference,
    normal
  ;
  animation: fire2 60s linear infinite;
}

@keyframes fire2 {
  from {
    background-position: 0% 0%, 0 30%, 0 0;
  }

  to {
    background-position: 0% -100%, -100% 30%, 200% 0%;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;// Variables and constants
let variable = 'Hello';
const CONSTANT = 42;

// Template literals
const name = 'World';
console.log(`${variable}, ${name}!`);

// Function declaration
function greet(name) {
  return `Hello, ${name}!`;
}

// Arrow function
const multiply = (a, b) =&amp;gt; a * b;

// Class definition
class Person {
  constructor(name, age) {
    this.name = name;
    this.age = age;
  }
  sayHello() {
    console.log(`Hello, my name is ${this.name}`);
  }
}

// Object literal
const config = {
  apiKey: 'abc123',
  maxRetries: 3,
  timeout: 5000
};

// Array methods
const numbers = [1, 2, 3, 4, 5];
const doubled = numbers.map(num =&amp;gt; num * 2);
const sum = numbers.reduce((acc, curr) =&amp;gt; acc + curr, 0);

// Async/await
async function fetchData(url) {
  try {
    const response = await fetch(url);
    const data = await response.json();
    return data;
  } catch (error) {
    console.error('Error fetching data:', error);
  }
}

// Destructuring
const { apiKey, maxRetries } = config;
const [first, second, ...rest] = numbers;

// Spread operator
const newArray = [...numbers, 6, 7, 8];

// Conditional (ternary) operator
const isAdult = age &amp;gt;= 18 ? 'Adult' : 'Minor';

// Switch statement
function getDayName(dayNumber) {
  switch (dayNumber) {
    case 0: return 'Sunday';
    case 1: return 'Monday';
    // ... other cases
    default: return 'Invalid day';
  }
}

// Regular expression
const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;

// Symbol
const uniqueKey = Symbol('description');

// Set and Map
const uniqueNumbers = new Set(numbers);
const userRoles = new Map([['admin', 'full'], ['user', 'limited']]);

// Promises
const promise = new Promise((resolve, reject) =&amp;gt; {
  setTimeout(() =&amp;gt; resolve('Done!'), 1000);
});

// Export statement
export { greet, Person };
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;Discussion&lt;/h2&gt;
&lt;p&gt;I received a lot of great feedback from the discussions at &lt;a href="https://typo.social/@gdc/112959308500800771"&gt;Mastodon&lt;/a&gt; and &lt;a href="https://news.ycombinator.com/item?id=41245159"&gt;Hacker News&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Thanks to jfk13 on hn, and &lt;a href="https://typo.social/@kizu@front-end.social/112960336521542558"&gt;@pixelambacht&lt;/a&gt; on Mastodon for pointing out that 'calt' is turned on by default, and that 'colr' is not an opentype feature that needs to be "turned on".&lt;/p&gt;
&lt;p&gt;Thanks to &lt;a href="https://news.ycombinator.com/item?id=41259124"&gt;penteract&lt;/a&gt; on hn and &lt;a href="https://typo.social/@behdad/112967180363218632"&gt;@behdad&lt;/a&gt; on Mastodon for suggesting better substitution rules.&lt;/p&gt;
&lt;p&gt;Thanks to &lt;a href="https://typo.social/@kizu@front-end.social/112960336521542558"&gt;@kizu&lt;/a&gt; and &lt;a href="https://typo.social/@kizu@front-end.social/112960336521542558"&gt;@pixelambacht&lt;/a&gt; on Mastodon for suggesting color theming with &lt;code&gt;override-colors&lt;/code&gt; CSS rule.&lt;/p&gt;
&lt;p&gt;As said earlier, if you have any ideas, suggestions or feedback, let me know. You can reach me at &lt;code&gt;hlotvonen@gmail.com&lt;/code&gt; or leave a comment on &lt;a href="https://typo.social/@gdc/112959308500800771"&gt;Mastodon&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thanks to all who sent emails, messages and commented!&lt;/p&gt;

&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://blog.glyphdrawing.club/font-with-built-in-syntax-highlighting/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 10:28:09 +0000</pubDate>
    </item>
    <item>
      <title>Ask HN: What are the best engineering blogs with real-world depth?</title>
      <link>https://news.ycombinator.com/item?id=46363921</link>
      <description>Specifically interested in posts that:
1. Explain technical concepts clearly and concisely
2. Show real implementation details, trade-offs, and failures
3. Are well-structured and readable
4. Tie engineering decisions back to business or product outcomes Any standout blogs, posts, or platforms you regularly learn from?</description>
      <content:encoded>&lt;body&gt;&lt;a href="https://news.ycombinator.com"&gt;&lt;img src="https://news.ycombinator.com/y18.svg"/&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/news"&gt;Hacker News&lt;/a&gt;&lt;a href="https://news.ycombinator.com/newest"&gt;new&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/front"&gt;past&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/newcomments"&gt;comments&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/ask"&gt;ask&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/show"&gt;show&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/jobs"&gt;jobs&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/submit"&gt;submit&lt;/a&gt;&lt;a href="https://news.ycombinator.com/login?goto=item%3Fid%3D46363921"&gt;login&lt;/a&gt;&lt;a href="https://news.ycombinator.com/vote?id=46363921&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/item?id=46363921"&gt;Ask HN: What are the best engineering blogs with real-world depth?&lt;/a&gt;280 points by &lt;a href="https://news.ycombinator.com/user?id=nishilpatel"&gt;nishilpatel&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46363921"&gt;8 hours ago&lt;/a&gt;  | &lt;a href="https://news.ycombinator.com/hide?id=46363921&amp;amp;goto=item%3Fid%3D46363921"&gt;hide&lt;/a&gt; | &lt;a href="https://hn.algolia.com/?query=Ask%20HN%3A%20What%20are%20the%20best%20engineering%20blogs%20with%20real-world%20depth%3F&amp;amp;type=story&amp;amp;dateRange=all&amp;amp;sort=byDate&amp;amp;storyText=false&amp;amp;prefix&amp;amp;page=0"&gt;past&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/fave?id=46363921&amp;amp;auth=e95b7fed59a69774119812f886e8bd69edd1f2ec"&gt;favorite&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/item?id=46363921"&gt;87 comments&lt;/a&gt;I’m looking for examples of high-quality engineering blog posts—especially from tech company blogs, that go beyond surface-level explanations.&lt;p&gt;Specifically interested in posts that:
1. Explain technical concepts clearly and concisely
2. Show real implementation details, trade-offs, and failures
3. Are well-structured and readable
4. Tie engineering decisions back to business or product outcomes&lt;p&gt;Any standout blogs, posts, or platforms you regularly learn from?&lt;/p&gt;&lt;/p&gt;&lt;br/&gt;
&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364274&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=pella"&gt;pella&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364274"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&amp;gt; especially from tech company blogs,&lt;p&gt;&lt;a href="https://engineering.fb.com/"&gt;https://engineering.fb.com/&lt;/a&gt;&lt;p&gt;&lt;a href="https://netflixtechblog.com/"&gt;https://netflixtechblog.com/&lt;/a&gt;&lt;p&gt;&lt;a href="https://stripe.com/blog/engineering"&gt;https://stripe.com/blog/engineering&lt;/a&gt;&lt;p&gt;&lt;a href="https://eng.uber.com"&gt;https://eng.uber.com&lt;/a&gt;&lt;p&gt;&lt;a href="https://engineering.linkedin.com/"&gt;https://engineering.linkedin.com/&lt;/a&gt;&lt;p&gt;&lt;a href="https://engineering.atspotify.com/"&gt;https://engineering.atspotify.com/&lt;/a&gt;&lt;p&gt;&lt;a href="https://tailscale.com/blog"&gt;https://tailscale.com/blog&lt;/a&gt;&lt;p&gt;&lt;a href="https://careersatdoordash.com/engineering-blog/"&gt;https://careersatdoordash.com/engineering-blog/&lt;/a&gt;&lt;p&gt;&lt;a href="https://dropbox.tech/"&gt;https://dropbox.tech/&lt;/a&gt;&lt;p&gt;--&lt;p&gt;Aggregators:( &lt;a href="https://engineering.fyi/"&gt;https://engineering.fyi/&lt;/a&gt; ; &lt;a href="https://diff.blog/"&gt;https://diff.blog/&lt;/a&gt; )&lt;p&gt;+ &lt;a href="https://hn.algolia.com/?query=engineering%20blog"&gt;https://hn.algolia.com/?query=engineering%20blog&lt;/a&gt;&lt;p&gt;---&lt;p&gt;create a public engineering-blog SKILL.md.
( ~ collect the writing patterns that work on HN )&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364274&amp;amp;goto=item%3Fid%3D46363921%2346364274"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364336&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=i_k"&gt;i_k&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364336"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;parent&lt;/a&gt; | &lt;a href="#46366609"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I am quite surprised and a bit disappointed that almost none of them have RSS.&lt;p&gt;But thank you!&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364336&amp;amp;goto=item%3Fid%3D46363921%2346364336"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366119&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=reallydoubtful"&gt;reallydoubtful&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366119"&gt;3 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;root&lt;/a&gt; | &lt;a href="#46364336"&gt;parent&lt;/a&gt; | &lt;a href="#46364494"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Most of them have feeds.&lt;p&gt;* &lt;a href="https://engineering.fb.com/feed"&gt;https://engineering.fb.com/feed&lt;/a&gt;&lt;p&gt;* &lt;a href="https://netflixtechblog.com/feed"&gt;https://netflixtechblog.com/feed&lt;/a&gt;&lt;p&gt;* No feed for stripe&lt;p&gt;* &lt;a href="https://www.uber.com/en-GB/blog/london/engineering/rss/"&gt;https://www.uber.com/en-GB/blog/london/engineering/rss/&lt;/a&gt;&lt;p&gt;* No feed for LinkedIn&lt;p&gt;* &lt;a href="https://engineering.atspotify.com/feed"&gt;https://engineering.atspotify.com/feed&lt;/a&gt;&lt;p&gt;* &lt;a href="https://tailscale.com/blog/index.xml"&gt;https://tailscale.com/blog/index.xml&lt;/a&gt;&lt;p&gt;* &lt;a href="https://careersatdoordash.com/engineering-blog/feed"&gt;https://careersatdoordash.com/engineering-blog/feed&lt;/a&gt;&lt;p&gt;* &lt;a href="https://dropbox.tech/feed"&gt;https://dropbox.tech/feed&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366119&amp;amp;goto=item%3Fid%3D46363921%2346366119"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364494&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=petercooper"&gt;petercooper&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364494"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;root&lt;/a&gt; | &lt;a href="#46364336"&gt;parent&lt;/a&gt; | &lt;a href="#46366119"&gt;prev&lt;/a&gt; | &lt;a href="#46364511"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Not RSS exactly but this OPML has feeds for several hundred such blogs if you can filter down from there: &lt;a href="https://peterc.org/misc/engblogs.opml"&gt;https://peterc.org/misc/engblogs.opml&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364494&amp;amp;goto=item%3Fid%3D46363921%2346364494"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365958&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=phrotoma"&gt;phrotoma&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365958"&gt;3 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;root&lt;/a&gt; | &lt;a href="#46364494"&gt;parent&lt;/a&gt; | &lt;a href="#46364511"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Your website is a work of art. Bravo &amp;lt;3&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365958&amp;amp;goto=item%3Fid%3D46363921%2346365958"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364511&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=onion2k"&gt;onion2k&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364511"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;root&lt;/a&gt; | &lt;a href="#46364336"&gt;parent&lt;/a&gt; | &lt;a href="#46364494"&gt;prev&lt;/a&gt; | &lt;a href="#46364514"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Spotify and Tailscale do...&lt;p&gt;&lt;a href="https://engineering.atspotify.com/feed"&gt;https://engineering.atspotify.com/feed&lt;/a&gt;&lt;p&gt;&lt;a href="https://tailscale.com/blog/index.xml"&gt;https://tailscale.com/blog/index.xml&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364511&amp;amp;goto=item%3Fid%3D46363921%2346364511"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364514&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=embedding-shape"&gt;embedding-shape&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364514"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;root&lt;/a&gt; | &lt;a href="#46364336"&gt;parent&lt;/a&gt; | &lt;a href="#46364511"&gt;prev&lt;/a&gt; | &lt;a href="#46366609"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&amp;gt; I am quite surprised and a bit disappointed that almost none of them have RSS.&lt;p&gt;I think it's on purpose. It is to signal that these (those without RSS) aren't really "engineering" blogs at all, they're marketing websites aimed to help with recruiting and making the organization seem "engineering-like".&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364514&amp;amp;goto=item%3Fid%3D46363921%2346364514"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364750&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=zbentley"&gt;zbentley&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364750"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;root&lt;/a&gt; | &lt;a href="#46364514"&gt;parent&lt;/a&gt; | &lt;a href="#46366609"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
What? That makes no sense. RSS is beloved and known among engineers. Marketers? Not so much.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364750&amp;amp;goto=item%3Fid%3D46363921%2346364750"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364756&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=embedding-shape"&gt;embedding-shape&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364756"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;root&lt;/a&gt; | &lt;a href="#46364750"&gt;parent&lt;/a&gt; | &lt;a href="#46366609"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Exactly, so if the blog doesn't have RSS, you know they're probably made from marketers with no input from engineering, otherwise they'd have RSS on the blogs.&lt;p&gt;Edit: Ah, noticed I made a without/with typo, fixed that, should make about 2% more sense now for the ones who the original meaning was unclear :)&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364756&amp;amp;goto=item%3Fid%3D46363921%2346364756"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364764&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=zbentley"&gt;zbentley&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364764"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;root&lt;/a&gt; | &lt;a href="#46364756"&gt;parent&lt;/a&gt; | &lt;a href="#46366609"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Oh, I read your post backwards (thought you said RSS == more likely fluff). My fault, sorry!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364764&amp;amp;goto=item%3Fid%3D46363921%2346364764"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364858&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=embedding-shape"&gt;embedding-shape&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364858"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;root&lt;/a&gt; | &lt;a href="#46364764"&gt;parent&lt;/a&gt; | &lt;a href="#46366609"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
To be fair to you, my original comment did say:&lt;p&gt;&amp;gt; It is to signal that these (those with RSS) aren't really "engineering" blogs at all&lt;p&gt;So now when I corrected that with/without typo, it looks like your previous comment doesn't make sense, but it kind of did, at the time. Sorry about that and thanks for making me realize the typo!&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364858&amp;amp;goto=item%3Fid%3D46363921%2346364858"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366609&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=iancmceachern"&gt;iancmceachern&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366609"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46364274"&gt;prev&lt;/a&gt; | &lt;a href="#46367852"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
It's so interesting to me as a Mechanical Engineer and Hardware designer/architect how on HN "Engineering" almost always means "Software engineering" here.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366609&amp;amp;goto=item%3Fid%3D46363921%2346366609"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367920&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sp4nner"&gt;sp4nner&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367920"&gt;3 minutes ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;parent&lt;/a&gt; | &lt;a href="#46367406"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Agreed, though I understand the YC bias. I'm in biotech and mostly follow HN just to see what the software people are interested in these days.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367920&amp;amp;goto=item%3Fid%3D46363921%2346367920"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367406&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=throwaway4PP"&gt;throwaway4PP&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367406"&gt;47 minutes ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;parent&lt;/a&gt; | &lt;a href="#46367920"&gt;prev&lt;/a&gt; | &lt;a href="#46367412"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
It is funny, almost as funny as an entire cadre of people with “engineer” in their title who've never had to draw a free body diagram, learn circuit analysis, understand the basics of thermodynamics, or the mechanics of materials.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367406&amp;amp;goto=item%3Fid%3D46363921%2346367406"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367501&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=p2detar"&gt;p2detar&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367501"&gt;38 minutes ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;root&lt;/a&gt; | &lt;a href="#46367406"&gt;parent&lt;/a&gt; | &lt;a href="#46367412"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I hold a CS master degree from an Eastern European university and everything you listed was in our Bachelor degree program. It’s pretty funny because while studying material properties back then I always wondered how and when am I gonna use that. It kind of makes sense now that I think about it - some students preferred branching out to hardware.&lt;p&gt;edit: typo&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367501&amp;amp;goto=item%3Fid%3D46363921%2346367501"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367412&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=jupin"&gt;jupin&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367412"&gt;47 minutes ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;parent&lt;/a&gt; | &lt;a href="#46367406"&gt;prev&lt;/a&gt; | &lt;a href="#46366717"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I thought the same. Check out this mechanical engineering channel - &lt;a href="https://youtu.be/8yUsDnBXo_g?si=CXzWV9D5OvHcCBm3"&gt;https://youtu.be/8yUsDnBXo_g?si=CXzWV9D5OvHcCBm3&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367412&amp;amp;goto=item%3Fid%3D46363921%2346367412"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366717&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=jvanderbot"&gt;jvanderbot&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366717"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;parent&lt;/a&gt; | &lt;a href="#46367412"&gt;prev&lt;/a&gt; | &lt;a href="#46367472"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I would love more blogs on mechanical, hardware, and especially industrial engineering, but the demographics in those areas skew stereo-typically older and also likely less blog-oriented, right?&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366717&amp;amp;goto=item%3Fid%3D46363921%2346366717"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366933&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=georgeburdell"&gt;georgeburdell&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366933"&gt;1 hour ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;root&lt;/a&gt; | &lt;a href="#46366717"&gt;parent&lt;/a&gt; | &lt;a href="#46367560"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Blogs are almost 30 years old at this point, but yes, I do associate a nearly compulsive need to show off one's work in meticulously-crafted blog posts with younger people.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366933&amp;amp;goto=item%3Fid%3D46363921%2346366933"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367560&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=wheelinsupial"&gt;wheelinsupial&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367560"&gt;33 minutes ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;root&lt;/a&gt; | &lt;a href="#46366717"&gt;parent&lt;/a&gt; | &lt;a href="#46366933"&gt;prev&lt;/a&gt; | &lt;a href="#46367472"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Depending on what you're looking for in industrial engineering, there are a lot of blogs on lean manufacturing and the Toyota Production System. INFORMS, may be paywalled, also publishes a lot of pretty interesting articles on applications of operations research to industry.&lt;p&gt;In general, though, my very limited experience working in manufacturing was that much of the blog equivalents were covered in things like white papers from hardware manufacturers or articles in trade publications. We always had a bunch of magazines delivered each month and there were usually some interesting articles to review.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367560&amp;amp;goto=item%3Fid%3D46363921%2346367560"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367472&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=tekno45"&gt;tekno45&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367472"&gt;40 minutes ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;parent&lt;/a&gt; | &lt;a href="#46366717"&gt;prev&lt;/a&gt; | &lt;a href="#46367852"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
people building physical things are probably too busy to blog about it lol&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367472&amp;amp;goto=item%3Fid%3D46363921%2346367472"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367852&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=Swizec"&gt;Swizec&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367852"&gt;9 minutes ago&lt;/a&gt;  | &lt;a href="#46366609"&gt;prev&lt;/a&gt; | &lt;a href="#46367782"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
While not exactly a blog, I've collected ~16 years of [startup] engineering lessons into a book and I think it came out fantastic. People are saying super nice things.&lt;p&gt;&lt;a href="https://scalingfastbook.com"&gt;https://scalingfastbook.com&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367852&amp;amp;goto=item%3Fid%3D46363921%2346367852"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367782&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=bodash"&gt;bodash&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367782"&gt;15 minutes ago&lt;/a&gt;  | &lt;a href="#46367852"&gt;prev&lt;/a&gt; | &lt;a href="#46364321"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&amp;gt; &lt;a href="https://lessnews.dev"&gt;https://lessnews.dev&lt;/a&gt;&lt;p&gt;A while ago I felt this "information fatigue" due to the overwhelming updates from the typical news sources (reddit, twitter, even hn).&lt;p&gt;So I built a _slow_ webdev newsfeed aggregator that doesn't overwhelm you of constant updates, so you focus on reading the actual blog contents and enjoy other things.&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367782&amp;amp;goto=item%3Fid%3D46363921%2346367782"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364321&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=xnorswap"&gt;xnorswap&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364321"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46367782"&gt;prev&lt;/a&gt; | &lt;a href="#46365543"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
You might be more interested in books than a blog.&lt;p&gt;For example: The Architecture of Open Source Applications&lt;p&gt;&lt;a href="https://aosabook.org/en/index.html"&gt;https://aosabook.org/en/index.html&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364321&amp;amp;goto=item%3Fid%3D46363921%2346364321"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364479&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=alhirzel"&gt;alhirzel&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364479"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364321"&gt;parent&lt;/a&gt; | &lt;a href="#46365543"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Such a great resource!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364479&amp;amp;goto=item%3Fid%3D46363921%2346364479"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365543&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=simonw"&gt;simonw&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365543"&gt;4 hours ago&lt;/a&gt;  | &lt;a href="#46364321"&gt;prev&lt;/a&gt; | &lt;a href="#46365655"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
This post by Jay Kreps that introduced Kafka to the world remains one of my favorite pieces of engineering blog content of all time: &lt;a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying"&gt;https://engineering.linkedin.com/distributed-systems/log-wha...&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365543&amp;amp;goto=item%3Fid%3D46363921%2346365543"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365655&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sateesh"&gt;sateesh&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365655"&gt;3 hours ago&lt;/a&gt;  | &lt;a href="#46365543"&gt;prev&lt;/a&gt; | &lt;a href="#46367429"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://jvns.ca/"&gt;https://jvns.ca/&lt;/a&gt;
Not a tech. company blog. Explains technical concepts clearly and top notch technical posts. Fits 1,2, 3 criteria of what you ask, though not the 4th one.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365655&amp;amp;goto=item%3Fid%3D46363921%2346365655"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367180&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=skywhopper"&gt;skywhopper&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367180"&gt;1 hour ago&lt;/a&gt;  | &lt;a href="#46365655"&gt;parent&lt;/a&gt; | &lt;a href="#46367429"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Yes! Julia is fantastic at explaining concepts, and creating ways to learn about them. She produces a great series of “zines” summarizing a bunch of technical topics, her blog archives are really fascinating, and she’s created really useful tools like Mess With DNS (&lt;a href="https://messwithdns.net"&gt;https://messwithdns.net&lt;/a&gt;) which gives you your own DNS subdomain and the means to update records so you can try things out in an easy, harmless way.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367180&amp;amp;goto=item%3Fid%3D46363921%2346367180"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367429&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=jupin"&gt;jupin&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367429"&gt;45 minutes ago&lt;/a&gt;  | &lt;a href="#46365655"&gt;prev&lt;/a&gt; | &lt;a href="#46367631"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
To balance all of the computer engineering blogs, check out this mechanical engineering channel: &lt;a href="https://youtu.be/8yUsDnBXo_g?si=CXzWV9D5OvHcCBm3"&gt;https://youtu.be/8yUsDnBXo_g?si=CXzWV9D5OvHcCBm3&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367429&amp;amp;goto=item%3Fid%3D46363921%2346367429"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367631&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=vishnuharidas"&gt;vishnuharidas&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367631"&gt;28 minutes ago&lt;/a&gt;  | &lt;a href="#46367429"&gt;prev&lt;/a&gt; | &lt;a href="#46366390"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://engineeringblogs.xyz/"&gt;https://engineeringblogs.xyz/&lt;/a&gt; is a good place listing more than 500 (and adding more) engineering blogs.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367631&amp;amp;goto=item%3Fid%3D46363921%2346367631"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366390&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=aranw"&gt;aranw&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366390"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46367631"&gt;prev&lt;/a&gt; | &lt;a href="#46364152"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://samwho.dev"&gt;https://samwho.dev&lt;/a&gt; has some fantastic blog posts with great visualisations&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366390&amp;amp;goto=item%3Fid%3D46363921%2346366390"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366733&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=samwho"&gt;samwho&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366733"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46366390"&gt;parent&lt;/a&gt; | &lt;a href="#46364152"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Thank you &amp;lt;3&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366733&amp;amp;goto=item%3Fid%3D46363921%2346366733"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364152&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=yrand"&gt;yrand&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364152"&gt;8 hours ago&lt;/a&gt;  | &lt;a href="#46366390"&gt;prev&lt;/a&gt; | &lt;a href="#46364405"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Encountered one specific example about a month ago here on HackerNews - All about automotive lidar.
&lt;a href="https://news.ycombinator.com/item?id=46110395"&gt;https://news.ycombinator.com/item?id=46110395&lt;/a&gt;&lt;p&gt;Blog posts where I find quality really shows are usually about something I know next to nothing about how it works. A badly written article usually either goes really shallow or skips some facts when going into depth and requires catchup elsewhere to actually understand it. The lidar article from Main Street Autonomy goes beyond basics and explained everything from the ground up in such a connected way that it was a real pleasure reading it.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364152&amp;amp;goto=item%3Fid%3D46363921%2346364152"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364405&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=Okkef"&gt;Okkef&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364405"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364152"&gt;prev&lt;/a&gt; | &lt;a href="#46364159"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Armin Ronacher's blog (of flask/jinja fame) &lt;a href="https://lucumr.pocoo.org/"&gt;https://lucumr.pocoo.org/&lt;/a&gt;&lt;p&gt;Antirez' blog (of Redis fame) &lt;a href="https://antirez.com/"&gt;https://antirez.com/&lt;/a&gt;&lt;p&gt;Simon Willison's blog (about AI) &lt;a href="https://simonwillison.net/"&gt;https://simonwillison.net/&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364405&amp;amp;goto=item%3Fid%3D46363921%2346364405"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364159&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=qznc"&gt;qznc&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364159"&gt;8 hours ago&lt;/a&gt;  | &lt;a href="#46364405"&gt;prev&lt;/a&gt; | &lt;a href="#46366497"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Sounds like you look for an intersection of academic papers (1.), tech blogs (2.), text books (3.), and confidential business strategies (4.)? A very high ambition.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364159&amp;amp;goto=item%3Fid%3D46363921%2346364159"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367699&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=cess11"&gt;cess11&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367699"&gt;23 minutes ago&lt;/a&gt;  | &lt;a href="#46364159"&gt;parent&lt;/a&gt; | &lt;a href="#46364194"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Corporations commonly describe some of their internal processes and achievements because it builds reputation and that can be important for both sales and recruitment.&lt;p&gt;Sometimes they do it in the form of free or open source software releases.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367699&amp;amp;goto=item%3Fid%3D46363921%2346367699"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364194&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=gchamonlive"&gt;gchamonlive&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364194"&gt;8 hours ago&lt;/a&gt;  | &lt;a href="#46364159"&gt;parent&lt;/a&gt; | &lt;a href="#46367699"&gt;prev&lt;/a&gt; | &lt;a href="#46366497"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
A very high ambition?&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364194&amp;amp;goto=item%3Fid%3D46363921%2346364194"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366497&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=nsm"&gt;nsm&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366497"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46364159"&gt;prev&lt;/a&gt; | &lt;a href="#46364190"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://randomascii.wordpress.com/"&gt;https://randomascii.wordpress.com/&lt;/a&gt; - former Chrome engineer about all things performance engineering and particularly focused on Windows.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366497&amp;amp;goto=item%3Fid%3D46363921%2346366497"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364190&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=nchmy"&gt;nchmy&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364190"&gt;8 hours ago&lt;/a&gt;  | &lt;a href="#46366497"&gt;prev&lt;/a&gt; | &lt;a href="#46364537"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
You're probably looking for something that is more focused on specific software decisions/implementations, but &lt;a href="https://infrequently.org"&gt;https://infrequently.org&lt;/a&gt; is the best web development blog out there.&lt;p&gt;It's not "technical" so much as it just educates you on how to be a good web developer/run a team. There's zero fluff and considerable detail (footnotes are practically blog posts themselves).&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364190&amp;amp;goto=item%3Fid%3D46363921%2346364190"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364537&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=bzGoRust"&gt;bzGoRust&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364537"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364190"&gt;prev&lt;/a&gt; | &lt;a href="#46366909"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://discord.com/blog"&gt;https://discord.com/blog&lt;/a&gt;
&lt;a href="https://blog.cloudflare.com/"&gt;https://blog.cloudflare.com/&lt;/a&gt;
&lt;a href="https://netflixtechblog.com/"&gt;https://netflixtechblog.com/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364537&amp;amp;goto=item%3Fid%3D46363921%2346364537"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366909&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=mitthrowaway2"&gt;mitthrowaway2&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366909"&gt;1 hour ago&lt;/a&gt;  | &lt;a href="#46364537"&gt;prev&lt;/a&gt; | &lt;a href="#46367369"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I always enjoyed Jason Sachs' blog at embedded related.&lt;p&gt;&lt;a href="https://www.embeddedrelated.com/showarticle/152.php"&gt;https://www.embeddedrelated.com/showarticle/152.php&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366909&amp;amp;goto=item%3Fid%3D46363921%2346366909"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367369&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=mad44"&gt;mad44&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367369"&gt;50 minutes ago&lt;/a&gt;  | &lt;a href="#46366909"&gt;prev&lt;/a&gt; | &lt;a href="#46364206"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
MongoDB Engineering Blog is shaping up well&lt;p&gt;&lt;a href="https://www.mongodb.com/company/blog/channel/engineering-blog"&gt;https://www.mongodb.com/company/blog/channel/engineering-blo...&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367369&amp;amp;goto=item%3Fid%3D46363921%2346367369"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364206&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=tekichan"&gt;tekichan&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364206"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46367369"&gt;prev&lt;/a&gt; | &lt;a href="#46366325"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="http://highscalability.squarespace.com/all-time-favorites/"&gt;http://highscalability.squarespace.com/all-time-favorites/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364206&amp;amp;goto=item%3Fid%3D46363921%2346364206"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366325&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=NickJLange"&gt;NickJLange&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366325"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46364206"&gt;prev&lt;/a&gt; | &lt;a href="#46364182"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
A lot of great links here to the firehose (or at least for working parents). Unless someone has built it - anything that aggregates and shows beyond the first click of the by-line. (i.e. a first paragraph, or LLM-summary of the content)?&lt;p&gt;Otherwise... coming soon from a vibe-coding session near you...&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366325&amp;amp;goto=item%3Fid%3D46363921%2346366325"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366840&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=soulofmischief"&gt;soulofmischief&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366840"&gt;1 hour ago&lt;/a&gt;  | &lt;a href="#46366325"&gt;parent&lt;/a&gt; | &lt;a href="#46366721"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
A friend and I worked on a startup together that did this back when only the GPT-3 API was available. Sucked up everything we could think of, including HN and traditionally opaque sources such as Telegram&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366840&amp;amp;goto=item%3Fid%3D46363921%2346366840"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366721&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=SleepySteve_sk"&gt;SleepySteve_sk&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366721"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46366325"&gt;parent&lt;/a&gt; | &lt;a href="#46366840"&gt;prev&lt;/a&gt; | &lt;a href="#46364182"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
We're currently building something to solve this problem.&lt;p&gt;&lt;a href="https://joinheader.com/"&gt;https://joinheader.com/&lt;/a&gt;&lt;p&gt;We'll filter an RSS feed based on the topic and description that you provide. Feel free to reach out to me at s.kufuor@&amp;lt;domain&amp;gt; if you have any questions or feedback.&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366721&amp;amp;goto=item%3Fid%3D46363921%2346366721"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364182&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=tester756"&gt;tester756&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364182"&gt;8 hours ago&lt;/a&gt;  | &lt;a href="#46366325"&gt;prev&lt;/a&gt; | &lt;a href="#46366537"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Maybe&lt;p&gt;&lt;a href="https://projectzero.google/archive.html"&gt;https://projectzero.google/archive.html&lt;/a&gt;&lt;p&gt;&lt;a href="https://netflixtechblog.medium.com/"&gt;https://netflixtechblog.medium.com/&lt;/a&gt;&lt;p&gt;&lt;a href="https://www.uber.com/en-US/blog/engineering/"&gt;https://www.uber.com/en-US/blog/engineering/&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364182&amp;amp;goto=item%3Fid%3D46363921%2346364182"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366537&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=agumonkey"&gt;agumonkey&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366537"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46364182"&gt;prev&lt;/a&gt; | &lt;a href="#46364444"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Often enjoyed article by chris wellons &lt;a href="https://nullprogram.com/"&gt;https://nullprogram.com/&lt;/a&gt;&lt;p&gt;quite diverse, often challenging, sometimes mind bending&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366537&amp;amp;goto=item%3Fid%3D46363921%2346366537"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364444&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=noam_k"&gt;noam_k&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364444"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46366537"&gt;prev&lt;/a&gt; | &lt;a href="#46364885"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://lcamtuf.substack.com/"&gt;https://lcamtuf.substack.com/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364444&amp;amp;goto=item%3Fid%3D46363921%2346364444"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364885&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=avisk"&gt;avisk&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364885"&gt;5 hours ago&lt;/a&gt;  | &lt;a href="#46364444"&gt;prev&lt;/a&gt; | &lt;a href="#46366959"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://technology.riotgames.com/"&gt;https://technology.riotgames.com/&lt;/a&gt;
&lt;a href="https://fabiensanglard.net/"&gt;https://fabiensanglard.net/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364885&amp;amp;goto=item%3Fid%3D46363921%2346364885"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366959&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=jonstewart"&gt;jonstewart&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366959"&gt;1 hour ago&lt;/a&gt;  | &lt;a href="#46364885"&gt;prev&lt;/a&gt; | &lt;a href="#46364625"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Not corporate, but two of the best individual developer blogs are Eli Bendersky's and Rachel by the Bay. They've both been blogging prolifically for a decade+, Eli with a focus on, broadly, compilers and Rachel on SRE/debugging.&lt;p&gt;Raymond Chen's The Old New Thing is also required reading for anyone that works with Windows.&lt;p&gt;&lt;a href="https://eli.thegreenplace.net/"&gt;https://eli.thegreenplace.net/&lt;/a&gt;&lt;p&gt;&lt;a href="https://rachelbythebay.com/w/"&gt;https://rachelbythebay.com/w/&lt;/a&gt;&lt;p&gt;&lt;a href="https://devblogs.microsoft.com/oldnewthing/"&gt;https://devblogs.microsoft.com/oldnewthing/&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366959&amp;amp;goto=item%3Fid%3D46363921%2346366959"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364625&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=thundergolfer"&gt;thundergolfer&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364625"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46366959"&gt;prev&lt;/a&gt; | &lt;a href="#46364681"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
- &lt;a href="https://modal.com/blog/vprox"&gt;https://modal.com/blog/vprox&lt;/a&gt;
- &lt;a href="https://modal.com/blog/host-overhead-inference-efficiency"&gt;https://modal.com/blog/host-overhead-inference-efficiency&lt;/a&gt;
- &lt;a href="https://modal.com/blog/resource-solver"&gt;https://modal.com/blog/resource-solver&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364625&amp;amp;goto=item%3Fid%3D46363921%2346364625"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364681&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=mkosmul"&gt;mkosmul&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364681"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364625"&gt;prev&lt;/a&gt; | &lt;a href="#46364335"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Allegro Tech Blog: &lt;a href="https://blog.allegro.tech/"&gt;https://blog.allegro.tech/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364681&amp;amp;goto=item%3Fid%3D46363921%2346364681"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364335&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=pveierland"&gt;pveierland&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364335"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364681"&gt;prev&lt;/a&gt; | &lt;a href="#46364395"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Tweag has many interesting entries with good technical depth:&lt;p&gt;&lt;a href="https://www.tweag.io/blog"&gt;https://www.tweag.io/blog&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364335&amp;amp;goto=item%3Fid%3D46363921%2346364335"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364395&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=ludicity"&gt;ludicity&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364395"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364335"&gt;prev&lt;/a&gt; | &lt;a href="#46364971"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I'm a huge fan of &lt;a href="https://eblog.fly.dev/index.html"&gt;https://eblog.fly.dev/index.html&lt;/a&gt;. The author, Efron, very graciously advises me on a lot of little things around my engineering practice, and I've learned a huge amount about weird holes in my practice from industry dysfunction in a very short period of time from him.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364395&amp;amp;goto=item%3Fid%3D46363921%2346364395"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364971&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=alzamos"&gt;alzamos&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364971"&gt;5 hours ago&lt;/a&gt;  | &lt;a href="#46364395"&gt;prev&lt;/a&gt; | &lt;a href="#46364815"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Francesco Mazzoli’s blog on &lt;a href="https://mazzo.li/archive.html"&gt;https://mazzo.li/archive.html&lt;/a&gt;. His blog has topped HN a few times with various low-level/linux topics, some deep dives into algorithms etc.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364971&amp;amp;goto=item%3Fid%3D46363921%2346364971"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364815&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sevazhidkov"&gt;sevazhidkov&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364815"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364971"&gt;prev&lt;/a&gt; | &lt;a href="#46365128"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
It’s not a traditional blog, but Oxide’s RFDs cover exactly what you asked — implementation details and trade-offs: &lt;a href="https://rfd.shared.oxide.computer/"&gt;https://rfd.shared.oxide.computer/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364815&amp;amp;goto=item%3Fid%3D46363921%2346364815"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365128&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sdairs"&gt;sdairs&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365128"&gt;5 hours ago&lt;/a&gt;  | &lt;a href="#46364815"&gt;prev&lt;/a&gt; | &lt;a href="#46365215"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://clickhouse.com/blog?category=engineering"&gt;https://clickhouse.com/blog?category=engineering&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365128&amp;amp;goto=item%3Fid%3D46363921%2346365128"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365215&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=robofanatic"&gt;robofanatic&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365215"&gt;5 hours ago&lt;/a&gt;  | &lt;a href="#46365128"&gt;prev&lt;/a&gt; | &lt;a href="#46364526"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.makingsoftware.com/"&gt;https://www.makingsoftware.com/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365215&amp;amp;goto=item%3Fid%3D46363921%2346365215"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364526&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=louiechristie"&gt;louiechristie&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364526"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46365215"&gt;prev&lt;/a&gt; | &lt;a href="#46364874"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://dora.dev/research/2025/dora-report/"&gt;https://dora.dev/research/2025/dora-report/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364526&amp;amp;goto=item%3Fid%3D46363921%2346364526"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364874&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=nickmonad"&gt;nickmonad&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364874"&gt;5 hours ago&lt;/a&gt;  | &lt;a href="#46364526"&gt;prev&lt;/a&gt; | &lt;a href="#46365166"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
TigerBeetle: &lt;a href="https://tigerbeetle.com/blog/"&gt;https://tigerbeetle.com/blog/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364874&amp;amp;goto=item%3Fid%3D46363921%2346364874"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365166&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=GeoAtreides"&gt;GeoAtreides&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365166"&gt;5 hours ago&lt;/a&gt;  | &lt;a href="#46364874"&gt;prev&lt;/a&gt; | &lt;a href="#46366569"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Seems to me you're describing books.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365166&amp;amp;goto=item%3Fid%3D46363921%2346365166"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366569&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=corbet"&gt;corbet&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366569"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46365166"&gt;prev&lt;/a&gt; | &lt;a href="#46364305"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I feel obligated to mention LWN - &lt;a href="https://lwn.net/"&gt;https://lwn.net/&lt;/a&gt; - since that is exactly what we aspire to.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366569&amp;amp;goto=item%3Fid%3D46363921%2346366569"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364305&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=vogu66"&gt;vogu66&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364305"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46366569"&gt;prev&lt;/a&gt; | &lt;a href="#46364264"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
not software engineering, but &lt;a href="https://practical.engineering/"&gt;https://practical.engineering/&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364305&amp;amp;goto=item%3Fid%3D46363921%2346364305"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364264&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=Agingcoder"&gt;Agingcoder&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364264"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364305"&gt;prev&lt;/a&gt; | &lt;a href="#46365415"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Cloudflare, google project zero.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364264&amp;amp;goto=item%3Fid%3D46363921%2346364264"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365415&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=rramadass"&gt;rramadass&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365415"&gt;4 hours ago&lt;/a&gt;  | &lt;a href="#46364264"&gt;prev&lt;/a&gt; | &lt;a href="#46364525"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Not a blog, but books detailing real-world experiences from Indian Engineers/Scientists/Researchers; Quite inspiring to see how people strive unceasingly towards a goal in spite of all the limitations and hurdles (viz. Political/Financial/Material etc.) imposed on them.&lt;p&gt;There is much to learn, in these books.&lt;p&gt;The Mind of an Engineer by Purnendu Ghosh et al. - &lt;a href="https://link.springer.com/book/10.1007/978-981-10-0119-2"&gt;https://link.springer.com/book/10.1007/978-981-10-0119-2&lt;/a&gt;&lt;p&gt;The Mind of an Engineer: Volume 2 by Purnendu Ghosh et al. - &lt;a href="https://link.springer.com/book/10.1007/978-981-15-1330-5"&gt;https://link.springer.com/book/10.1007/978-981-15-1330-5&lt;/a&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365415&amp;amp;goto=item%3Fid%3D46363921%2346365415"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364525&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=louiechristie"&gt;louiechristie&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364525"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46365415"&gt;prev&lt;/a&gt; | &lt;a href="#46364307"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://youtube.com/@modernsoftwareengineeringyt"&gt;https://youtube.com/@modernsoftwareengineeringyt&lt;/a&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364525&amp;amp;goto=item%3Fid%3D46363921%2346364525"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364307&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=mitjam"&gt;mitjam&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364307"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364525"&gt;prev&lt;/a&gt; | &lt;a href="#46364917"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Maybe it's just because I'm LLMing a bit too much, recently, but this question sounds to me like a prompt.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364307&amp;amp;goto=item%3Fid%3D46363921%2346364307"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365433&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=x187463"&gt;x187463&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365433"&gt;4 hours ago&lt;/a&gt;  | &lt;a href="#46364307"&gt;parent&lt;/a&gt; | &lt;a href="#46364572"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Some people act like the use of an LLM immediately invalidates or lowers the value of a piece of content. But the case of a question or simple post, especially by somebody for whom English is second language, using an LLM to rephrase or clean-up some text seems like an innocent and practical use case for LLMs.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365433&amp;amp;goto=item%3Fid%3D46363921%2346365433"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364572&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=runlaszlorun"&gt;runlaszlorun&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364572"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364307"&gt;parent&lt;/a&gt; | &lt;a href="#46365433"&gt;prev&lt;/a&gt; | &lt;a href="#46364509"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I'm not beating up on OP but I chuckled when I read the question. Literally the only place I see the phrase "no fluff" with any frequency is with Deepseek lol.&lt;p&gt;Nothing wrong with the phrase itself of course, other than the fact that it's like literally in every other reply for me lol.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364572&amp;amp;goto=item%3Fid%3D46363921%2346364572"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364509&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=atoav"&gt;atoav&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364509"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364307"&gt;parent&lt;/a&gt; | &lt;a href="#46364572"&gt;prev&lt;/a&gt; | &lt;a href="#46364917"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Had the same thought. ChatGPT often tells me things like: "This is the hard truth" or "I am telling it to you as it is (no fluff)" or whatever. Just because my initial prompt contains a line about it not making things up and telling me how things are instead of what would please me to hear. I added a line to specifically tell it to not phrase out these things, but it appears to be surprisingly hard to get rid of those phrases.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364509&amp;amp;goto=item%3Fid%3D46363921%2346364509"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364917&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=snvzz"&gt;snvzz&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364917"&gt;5 hours ago&lt;/a&gt;  | &lt;a href="#46364307"&gt;prev&lt;/a&gt; | &lt;a href="#46364271"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
For deeper understanding of seL4's developments and the historical context in which it appeared, Gernot Heiser's blog[0].&lt;p&gt;0. &lt;a href="https://microkerneldude.org/"&gt;https://microkerneldude.org/&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364917&amp;amp;goto=item%3Fid%3D46363921%2346364917"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364271&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=throw_await"&gt;throw_await&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364271"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364917"&gt;prev&lt;/a&gt; | &lt;a href="#46364394"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
oldnewthing&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364271&amp;amp;goto=item%3Fid%3D46363921%2346364271"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364394&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=vibesareoff"&gt;vibesareoff&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364394"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364271"&gt;prev&lt;/a&gt; | &lt;a href="#46364716"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Ask the LLM you wrote this post with!&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364394&amp;amp;goto=item%3Fid%3D46363921%2346364394"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366786&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=voxleone"&gt;voxleone&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366786"&gt;1 hour ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;parent&lt;/a&gt; | &lt;a href="#46364684"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
No judgement here whatsoever, but i think LLM would be "the" tool for this job. I also wonder if there's any point to "Ask" sections in websites after LLM's.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366786&amp;amp;goto=item%3Fid%3D46363921%2346366786"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364684&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=bell-cot"&gt;bell-cot&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364684"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;parent&lt;/a&gt; | &lt;a href="#46366786"&gt;prev&lt;/a&gt; | &lt;a href="#46364467"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
OP is asking a good question.  There's no dishonor if he is not fluent in English, and used an LLM to translate.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364684&amp;amp;goto=item%3Fid%3D46363921%2346364684"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364808&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=vibesareoff"&gt;vibesareoff&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364808"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;root&lt;/a&gt; | &lt;a href="#46364684"&gt;parent&lt;/a&gt; | &lt;a href="#46364467"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
"OP" couldn't even be bothered to reformat the numbered list to run on separate fucking lines.&lt;p&gt;But sure, cheer on the homogenization of online spaces into beige slop staccato bullshit!&lt;p&gt;˙ ͜ʟ˙&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364808&amp;amp;goto=item%3Fid%3D46363921%2346364808"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46367743&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=CamperBob2"&gt;CamperBob2&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46367743"&gt;18 minutes ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;root&lt;/a&gt; | &lt;a href="#46364808"&gt;parent&lt;/a&gt; | &lt;a href="#46366648"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Other sites beckon.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46367743&amp;amp;goto=item%3Fid%3D46363921%2346367743"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46366648&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=loloquwowndueo"&gt;loloquwowndueo&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46366648"&gt;2 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;root&lt;/a&gt; | &lt;a href="#46364808"&gt;parent&lt;/a&gt; | &lt;a href="#46367743"&gt;prev&lt;/a&gt; | &lt;a href="#46365355"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
How do you reformat a list so it runs on separate fucking lines?&lt;p&gt;Always happens to me (and I don’t use fucking LLMs) so I’d really like to know.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46366648&amp;amp;goto=item%3Fid%3D46363921%2346366648"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365355&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=fnordlord"&gt;fnordlord&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365355"&gt;4 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;root&lt;/a&gt; | &lt;a href="#46364808"&gt;parent&lt;/a&gt; | &lt;a href="#46366648"&gt;prev&lt;/a&gt; | &lt;a href="#46364934"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
I will always cheer on anyone who shares their curiosity.&lt;p&gt;It was a great question and now I have a ton of new things on my reading list.&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365355&amp;amp;goto=item%3Fid%3D46363921%2346365355"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364934&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=bell-cot"&gt;bell-cot&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364934"&gt;5 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;root&lt;/a&gt; | &lt;a href="#46364808"&gt;parent&lt;/a&gt; | &lt;a href="#46365355"&gt;prev&lt;/a&gt; | &lt;a href="#46364467"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
You seem to be picking metrics for their utility in angrily excluding people who you a priori despise.  :(&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364934&amp;amp;goto=item%3Fid%3D46363921%2346364934"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364467&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sieste"&gt;sieste&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364467"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;parent&lt;/a&gt; | &lt;a href="#46364684"&gt;prev&lt;/a&gt; | &lt;a href="#46365859"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
The LLM instructed him to gather training data.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364467&amp;amp;goto=item%3Fid%3D46363921%2346364467"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364488&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=ozim"&gt;ozim&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364488"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;root&lt;/a&gt; | &lt;a href="#46364467"&gt;parent&lt;/a&gt; | &lt;a href="#46365859"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
So prompt injection on humans&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364488&amp;amp;goto=item%3Fid%3D46363921%2346364488"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364516&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=sieste"&gt;sieste&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364516"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;root&lt;/a&gt; | &lt;a href="#46364488"&gt;parent&lt;/a&gt; | &lt;a href="#46365859"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Polluting the internet with meat slop.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364516&amp;amp;goto=item%3Fid%3D46363921%2346364516"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364585&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=themafia"&gt;themafia&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364585"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;root&lt;/a&gt; | &lt;a href="#46364516"&gt;parent&lt;/a&gt; | &lt;a href="#46365859"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
"What if we used more energy and got worse results?"&lt;p&gt;Sort of makes you miss "move fast and break things."&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364585&amp;amp;goto=item%3Fid%3D46363921%2346364585"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46365859&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=asupkay"&gt;asupkay&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46365859"&gt;3 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;parent&lt;/a&gt; | &lt;a href="#46364467"&gt;prev&lt;/a&gt; | &lt;a href="#46364716"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
Maybe the LLM is the one asking&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46365859&amp;amp;goto=item%3Fid%3D46363921%2346365859"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364716&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=Joel_Mckay"&gt;Joel_Mckay&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364716"&gt;6 hours ago&lt;/a&gt;  | &lt;a href="#46364394"&gt;prev&lt;/a&gt; | &lt;a href="#46364243"&gt;next&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
These should be read at least once in your life if interested in building industrial grade electrical, mechanical, and or software.&lt;p&gt;1. &lt;a href="https://nepp.nasa.gov/whisker/"&gt;https://nepp.nasa.gov/whisker/&lt;/a&gt;&lt;p&gt;2. &lt;a href="https://standards.nasa.gov/standard/NASA/NASA-STD-87394"&gt;https://standards.nasa.gov/standard/NASA/NASA-STD-87394&lt;/a&gt;&lt;p&gt;3. &lt;a href="https://standards.nasa.gov/NASA-Technical-Standards"&gt;https://standards.nasa.gov/NASA-Technical-Standards&lt;/a&gt;&lt;p&gt;4. &lt;a href="https://sma.nasa.gov/sma-disciplines/workmanship"&gt;https://sma.nasa.gov/sma-disciplines/workmanship&lt;/a&gt;&lt;p&gt;5. &lt;a href="https://www.stroustrup.com/JSF-AV-rules.pdf"&gt;https://www.stroustrup.com/JSF-AV-rules.pdf&lt;/a&gt;&lt;p&gt;6. &lt;a href="https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Developing_Safety-Critical_Code"&gt;https://en.wikipedia.org/wiki/The_Power_of_10:_Rules_for_Dev...&lt;/a&gt;&lt;p&gt;7. &lt;a href="https://www.nist.gov/pml/owm/laboratory-metrology/metrology-training"&gt;https://www.nist.gov/pml/owm/laboratory-metrology/metrology-...&lt;/a&gt;&lt;p&gt;8. &lt;a href="https://www.mitutoyo.com/training-education/"&gt;https://www.mitutoyo.com/training-education/&lt;/a&gt;&lt;p&gt;9. "Memoirs of extraordinary popular delusions and the madness of crowds" (Charles Mackay, 1852, &lt;a href="https://www.gutenberg.org/files/24518/24518-h/24518-h.htm"&gt;https://www.gutenberg.org/files/24518/24518-h/24518-h.htm&lt;/a&gt; )&lt;p&gt;The artifacts are usually beautiful from good Workmanship Standards, Design For Manufacturability, and systematic Metrology.  Dragging us all into the future one project at a time.&lt;p&gt;Note that training an ML model with such data would be pointless, as statistical saliency forms a paradox with consumer product design compromises. Note, there are _always_ tradeoffs in every problem domain.&lt;p&gt;'What it actually means to be "AI Generated"' ( &lt;a href="https://www.youtube.com/watch?v=ERiXDhLHxmo"&gt;https://www.youtube.com/watch?v=ERiXDhLHxmo&lt;/a&gt; )&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=iXbzktx1KfU"&gt;https://www.youtube.com/watch?v=iXbzktx1KfU&lt;/a&gt;&lt;p&gt;Have a nice day, and note &amp;gt;52% of the web is LLM slop now. YMMV =3&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364716&amp;amp;goto=item%3Fid%3D46363921%2346364716"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;a href="https://news.ycombinator.com/vote?id=46364243&amp;amp;how=up&amp;amp;goto=item%3Fid%3D46363921"&gt;&lt;/a&gt;&lt;a href="https://news.ycombinator.com/user?id=gethly"&gt;gethly&lt;/a&gt; &lt;a href="https://news.ycombinator.com/item?id=46364243"&gt;7 hours ago&lt;/a&gt;  | &lt;a href="#46364716"&gt;prev&lt;/a&gt; &lt;a href="javascript:void(0)"&gt;[–]&lt;/a&gt;&lt;br/&gt;
There are no such blogs. Usually companies, or individuals, will write these after they implement some feature into their products. Which makes them inherently little pieces of information scattered all over the internet and there is no one blog that is just about this.&lt;p&gt;&lt;a href="https://news.ycombinator.com/reply?id=46364243&amp;amp;goto=item%3Fid%3D46363921%2346364243"&gt;reply&lt;/a&gt;&lt;/p&gt;&lt;br/&gt;&lt;br/&gt;
&lt;img src="https://news.ycombinator.com/s.gif"/&gt;&lt;br/&gt;
&lt;a href="https://news.ycombinator.com/newsguidelines.html"&gt;Guidelines&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/newsfaq.html"&gt;FAQ&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/lists"&gt;Lists&lt;/a&gt; | &lt;a href="https://github.com/HackerNews/API"&gt;API&lt;/a&gt; | &lt;a href="https://news.ycombinator.com/security.html"&gt;Security&lt;/a&gt; | &lt;a href="https://www.ycombinator.com/legal/"&gt;Legal&lt;/a&gt; | &lt;a href="https://www.ycombinator.com/apply/"&gt;Apply to YC&lt;/a&gt; | &lt;a href="mailto:hn@ycombinator.com"&gt;Contact&lt;/a&gt;&lt;br/&gt;&lt;br/&gt;
&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://news.ycombinator.com/item?id=46363921</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 09:50:31 +0000</pubDate>
    </item>
    <item>
      <title>Carnap – A formal logic framework for Haskell</title>
      <link>https://carnap.io/</link>
      <description>A formal logic framework for Haskell</description>
      <content:encoded>&lt;body&gt;

&lt;h1&gt;Welcome to Carnap.io&lt;/h1&gt;
&lt;p&gt;A formal logic framework for Haskell&lt;/p&gt;


&lt;img src="https://static.carnap.io/img/russell2.png?etag=OWVOGUWw"/&gt;
&lt;h2&gt;Background&lt;/h2&gt;
&lt;p&gt; Carnap is a free and open software framework written in &lt;a href="https://haskell.org"&gt;Haskell&lt;/a&gt;
 for teaching and studying formal logic.  Carnap powers logic courses at &lt;a href="https://carnap.io/about#who"&gt;dozens of colleges and universities&lt;/a&gt;
 around the world.&lt;/p&gt;&lt;p&gt; If you're a student in a course that uses Carnap, please follow the links at the top of the page to log in and to access course materials.&lt;/p&gt;
&lt;p&gt; If you're just curious about Carnap, you can find some general information on our &lt;a href="https://carnap.io/about"&gt;about&lt;/a&gt;
 page.  If you're interested in the project, and would like to use Carnap in a class you're teaching, or get involved in some other way, please feel free to &lt;a href="mailto:gleachkr@ksu.edu"&gt;get in touch!&lt;/a&gt;
&lt;/p&gt;



&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://carnap.io/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 09:17:42 +0000</pubDate>
    </item>
    <item>
      <title>Instant database clones with PostgreSQL 18</title>
      <link>https://boringsql.com/posts/instant-database-clones/</link>
      <description>Have you ever watched long running migration script, wondering if it's about
to wreck your data? Or wish you can "just" spin a fresh copy of database for
each test run? Or wanted to have reproducible snapshots to reset between
runs of your test suite, (and yes, because you are reading boringSQL) needed
to reset the learning environment?</description>
      <content:encoded>&lt;article class="post-single"&gt;




Table of Contents


&lt;ul&gt;
&lt;li&gt;
&lt;a href="#create-database-strategy"&gt;CREATE DATABASE ... STRATEGY&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="#file-copy"&gt;FILE_COPY&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="#the-benchmark"&gt;The benchmark&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="#working-with-cloned-data"&gt;Working with cloned data&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="#xfs-proof"&gt;XFS proof&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="#things-to-be-aware-of"&gt;Things to be aware of&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;




&lt;p&gt;Have you ever watched long running migration script, wondering if it's about
to wreck your data? Or wish you can "just" spin a fresh copy of database for
each test run? Or wanted to have reproducible snapshots to reset between
runs of your test suite, (and yes, because you are reading boringSQL) needed
to reset the learning environment?&lt;/p&gt;
&lt;p&gt;When your database is a few megabytes, &lt;code&gt;pg_dump&lt;/code&gt; and restore works fine. But
what happens when you're dealing with hundreds of megabytes/gigabytes - or more?
Suddenly "just make a copy" becomes a burden.&lt;/p&gt;
&lt;p&gt;You've probably noticed that PostgreSQL connects to &lt;code&gt;template1&lt;/code&gt; by default. What
you might have missed is that there's a whole templating system hiding in plain
sight. Every time you run&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE DATABASE dbname;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;PostgreSQL quietly clones standard system database &lt;code&gt;template1&lt;/code&gt; behind the
scenes. Making it same as if you would use&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE DATABASE dbname TEMPLATE template1;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The real power comes from the fact that you can replace &lt;code&gt;template1&lt;/code&gt; with any
database. You can find more at &lt;a href="https://www.postgresql.org/docs/current/manage-ag-templatedbs.html"&gt;Template Database
documentation&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In this article, we will cover a few tweaks that turn this templating system
into an instant, zero-copy database cloning machine.&lt;/p&gt;
&lt;h2&gt;CREATE DATABASE ... STRATEGY&lt;a href="#create-database-strategy"&gt;&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Before PostgreSQL 15, when you created a new database from a template, it
operated strictly on the file level. This was effective, but to make it
reliable, Postgres had to flush all pending operations to disk (using
&lt;code&gt;CHECKPOINT&lt;/code&gt;) before taking a consistent snapshot. This created a massive I/O
spike - a "Checkpoint Storm" - that could stall your production traffic.&lt;/p&gt;
&lt;p&gt;Version 15 of PostgreSQL introduced new parameter &lt;code&gt;CREATE DATABASE ... STRATEGY = [strategy]&lt;/code&gt; and at the same time changed the default behaviour how the new
databases are created from templates. The new default become &lt;code&gt;WAL_LOG&lt;/code&gt; which
copies block-by-block via the Write-Ahead Log (WAL), making I/O sequential (and
much smoother) and support for concurrency without facing latency spike. This
prevented the need to CHECKPOINT but made the database cloning operation
potentially significantly slower. For an empty &lt;code&gt;template1&lt;/code&gt;, you won't notice the
difference. But if you try to clone a 500GB database using WAL_LOG, you are
going to be waiting a long time.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;STRATEGY&lt;/code&gt; parameter allows us to switch back to the original method
&lt;code&gt;FILE_COPY&lt;/code&gt; to keep the behaviour, and speed. And since PostgreSQL 18, this
opens the whole new set of options.&lt;/p&gt;
&lt;h2&gt;FILE_COPY&lt;a href="#file-copy"&gt;&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Because the &lt;code&gt;FILE_COPY&lt;/code&gt; strategy is a proxy to operating system file operations,
we can change how the OS handles those files.&lt;/p&gt;
&lt;p&gt;When using standard file system (like &lt;code&gt;ext4&lt;/code&gt;), PostgreSQL reads every byte of
the source file and writes it to a new location. It's a physical copy. However
starting with PostgreSQL 18 - &lt;code&gt;file_copy_method&lt;/code&gt; gives you options to switch
that logic; while default option remains &lt;code&gt;copy&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;With modern filesystems (like ZFS, XFS with reflinks, APFS, etc.) you can switch
it to &lt;code&gt;clone&lt;/code&gt; and leverage &lt;code&gt;CLONE&lt;/code&gt; (&lt;code&gt;FICLONE&lt;/code&gt; on Linux) operation for almost
instant operation. And it won't take any additional space.&lt;/p&gt;
&lt;p&gt;All you have to do is:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Linux with XFS or ZFS support (we will use XFS for the demostration) or similar
operating system. MacOS APFS is also fully supported. FreeBSD with ZFS also
supported (which normally would be my choice, but haven't got time to test so
far)&lt;/li&gt;
&lt;li&gt;PostgreSQL cluster on that file system&lt;/li&gt;
&lt;li&gt;update the configuration &lt;code&gt;file_copy_method = clone&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;and reload the configuration&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;The benchmark&lt;a href="#the-benchmark"&gt;&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;We need some dummy data to copy. This is the only part of the tutorial where you
have to wait. Let's generate a ~6GB database.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE DATABASE source_db;
\c source_db

CREATE TABLE boring_data (
    id serial PRIMARY KEY,
    payload text
);

-- generate 50m rows
INSERT INTO boring_data (payload)
SELECT md5(random()::text) || md5(random()::text)
FROM generate_series(1, 50000000);

-- force a checkpoint
CHECKPOINT;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can verify the database now has roughly 6GB of data.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Name              | source_db
Owner             | postgres
Encoding          | UTF8
Locale Provider   | libc
Collate           | en_US.UTF-8
Ctype             | en_US.UTF-8
Locale            |
ICU Rules         |
Access privileges |
Size              | 6289 MB
Tablespace        | pg_default
Description       |
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While enabling &lt;code&gt;\timing&lt;/code&gt; you can test the default (WAL_LOG) strategy. And on my
test volume (relatively slow storage) I get&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE DATABASE slow_copy TEMPLATE source_db;
CREATE DATABASE
Time: 67000.615 ms (01:07.001)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let's verify our configuration is set for speed:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;show file_copy_method;
 file_copy_method
------------------
 clone
(1 row)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let's request the semi-instant clone of the same database, without taking
extra disk space at the same time.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;CREATE DATABASE fast_clone TEMPLATE source_db STRATEGY=FILE_COPY;
CREATE DATABASE
Time: 212.053 ms
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That's a quite an improvement, isn't it?&lt;/p&gt;
&lt;h2&gt;Working with cloned data&lt;a href="#working-with-cloned-data"&gt;&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;That was the simple part. But what is happening behind the scenes?&lt;/p&gt;
&lt;p&gt;When you clone a database with &lt;code&gt;file_copy_method = clone&lt;/code&gt;, PostgreSQL doesn't
duplicate any data. The filesystem creates new metadata entries that point to
the same physical blocks. Both databases share identical storage.&lt;/p&gt;
&lt;p&gt;This can create some initial confusion. If you ask PostgreSQL for the size:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;SELECT pg_database_size('source_db') as source,
       pg_database_size('fast_clone') as clone;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;PostgreSQL reports both as ~6GB because that's the logical size - how much data
each database "contains" - i.e. logical size.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-[ RECORD 1 ]------
source | 6594041535
clone  | 6594041535
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The interesting part happens when you start writing. PostgreSQL doesn't update
tuples in place. When you UPDATE a row, it writes a new tuple version somewhere
(often a different page entirely) and marks the old one as dead. The filesystem
doesn't care about PostgreSQL internals - it just sees writes to 8KB pages. Any
write to a shared page triggers a copy of that entire page.&lt;/p&gt;
&lt;p&gt;A single UPDATE will therefore trigger copy-on-write on multiple pages:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the page holding the old tuple&lt;/li&gt;
&lt;li&gt;the page receiving the new tuple&lt;/li&gt;
&lt;li&gt;index pages if any indexed columns changed&lt;/li&gt;
&lt;li&gt;FSM and visibility map pages as PostgreSQL tracks free space&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And later, VACUUM touches even more pages while cleaning up dead tuples. In this
case diverging quickly from the linked storage.&lt;/p&gt;
&lt;h2&gt;XFS proof&lt;a href="#xfs-proof"&gt;&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Using the database OID and relfilenode we can verify the both databases are now
sharing physical blocks.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@clone-demo:/var/lib/postgresql# sudo filefrag -v /var/lib/postgresql/18/main/base/16402/16404
Filesystem type is: 58465342
File size of /var/lib/postgresql/18/main/base/16402/16404 is 1073741824 (262144 blocks of 4096 bytes)
 ext:     logical_offset:        physical_offset: length:   expected: flags:
   0:        0..    2031:   10471550..  10473581:   2032:             shared
   1:     2032..   16367:   10474098..  10488433:  14336:   10473582: shared
   2:    16368..   32751:   10497006..  10513389:  16384:   10488434: shared
   3:    32752..   65519:   10522066..  10554833:  32768:   10513390: shared
   4:    65520..  129695:   10571218..  10635393:  64176:   10554834: shared
   5:   129696..  195231:   10635426..  10700961:  65536:   10635394: shared
   6:   195232..  262143:   10733730..  10800641:  66912:   10700962: last,shared,eof
/var/lib/postgresql/18/main/base/16402/16404: 7 extents found
root@clone-demo:/var/lib/postgresql#
root@clone-demo:/var/lib/postgresql#
root@clone-demo:/var/lib/postgresql# sudo filefrag -v /var/lib/postgresql/18/main/base/16418/16404
Filesystem type is: 58465342
File size of /var/lib/postgresql/18/main/base/16418/16404 is 1073741824 (262144 blocks of 4096 bytes)
 ext:     logical_offset:        physical_offset: length:   expected: flags:
   0:        0..    2031:   10471550..  10473581:   2032:             shared
   1:     2032..   16367:   10474098..  10488433:  14336:   10473582: shared
   2:    16368..   32751:   10497006..  10513389:  16384:   10488434: shared
   3:    32752..   65519:   10522066..  10554833:  32768:   10513390: shared
   4:    65520..  129695:   10571218..  10635393:  64176:   10554834: shared
   5:   129696..  195231:   10635426..  10700961:  65536:   10635394: shared
   6:   195232..  262143:   10733730..  10800641:  66912:   10700962: last,shared,eof
/var/lib/postgresql/18/main/base/16418/16404: 7 extents found
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All it takes is to update some rows using&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;update boring_data set payload = 'new value' || id where id IN (select id from boring_data limit 20);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and the situation will start to change.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;root@clone-demo:/var/lib/postgresql# sudo filefrag -v /var/lib/postgresql/18/main/base/16402/16404
Filesystem type is: 58465342
File size of /var/lib/postgresql/18/main/base/16402/16404 is 1073741824 (262144 blocks of 4096 bytes)
 ext:     logical_offset:        physical_offset: length:   expected: flags:
   0:        0..      39:   10471550..  10471589:     40:
   1:       40..    2031:   10471590..  10473581:   1992:             shared
   2:     2032..   16367:   10474098..  10488433:  14336:   10473582: shared
   3:    16368..   32751:   10497006..  10513389:  16384:   10488434: shared
   4:    32752..   65519:   10522066..  10554833:  32768:   10513390: shared
   5:    65520..  129695:   10571218..  10635393:  64176:   10554834: shared
   6:   129696..  195231:   10635426..  10700961:  65536:   10635394: shared
   7:   195232..  262143:   10733730..  10800641:  66912:   10700962: last,shared,eof
/var/lib/postgresql/18/main/base/16402/16404: 7 extents found
root@clone-demo:/var/lib/postgresql# sudo filefrag -v /var/lib/postgresql/18/main/base/16418/16404
Filesystem type is: 58465342
File size of /var/lib/postgresql/18/main/base/16418/16404 is 1073741824 (262144 blocks of 4096 bytes)
 ext:     logical_offset:        physical_offset: length:   expected: flags:
   0:        0..      39:   10297326..  10297365:     40:
   1:       40..    2031:   10471590..  10473581:   1992:   10297366: shared
   2:     2032..   16367:   10474098..  10488433:  14336:   10473582: shared
   3:    16368..   32751:   10497006..  10513389:  16384:   10488434: shared
   4:    32752..   65519:   10522066..  10554833:  32768:   10513390: shared
   5:    65520..  129695:   10571218..  10635393:  64176:   10554834: shared
   6:   129696..  195231:   10635426..  10700961:  65536:   10635394: shared
   7:   195232..  262143:   10733730..  10800641:  66912:   10700962: last,shared,eof
/var/lib/postgresql/18/main/base/16418/16404: 8 extents found
root@clone-demo:/var/lib/postgresql#
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case extent 0 no longer has shared flag, first 40 blocks size (with
default size 4KB) now diverge, making it total of 160KB. Each database now has
its own copy at different physical address. The remaining extents are still
shared.&lt;/p&gt;
&lt;h2&gt;Things to be aware of&lt;a href="#things-to-be-aware-of"&gt;&lt;/a&gt;
&lt;/h2&gt;
&lt;p&gt;Cloning is tempting but there's one serious limitation you need to be aware if
you ever attempt to do it in production. The source database can't have any
active connections during cloning. This is a PostgreSQL limitation, not a
filesystem one. For production use, this usually means you create a dedicated
template database rather than cloning your live database directly. Or given the
relatively short time the operation takes you have to schedule the cloning in
times where you can temporary block/terminate all connections.&lt;/p&gt;
&lt;p&gt;Other limitation is that the cloning only works within a single filesystem. If
your databases spans multiple table spaces on different mount points, cloning
will fall back to regular physical copy.&lt;/p&gt;
&lt;p&gt;Finally, in most managed cloud environments (AWS RDS, Google Cloud SQL), you
will not have access to the underlying filesystem to configure this. You are
stuck with their proprietary (and often billed) functionality. But for your own
VMs or bare metal? Go ahead and try it.&lt;/p&gt;


&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://boringsql.com/posts/instant-database-clones/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 07:58:25 +0000</pubDate>
    </item>
    <item>
      <title>10 years bootstrapped: €6.5M revenue with a team of 13</title>
      <link>https://www.datocms.com/blog/a-look-back-at-2025</link>
      <description>Explore all the capabilities of the friendliest Headless CMS in town</description>
      <content:encoded>&lt;article class="_itemBody_11r63_114"&gt;  &lt;h4&gt;Meet DatoCMS!&lt;/h4&gt;  &lt;p&gt;Explore all the capabilities of the friendliest Headless CMS in town&lt;/p&gt; &lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.datocms.com/blog/a-look-back-at-2025</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 07:50:03 +0000</pubDate>
    </item>
    <item>
      <title>iOS 26.3 brings AirPods-like pairing to third-party devices in EU under DMA</title>
      <link>https://www.macrumors.com/2025/12/22/ios-26-3-dma-airpods-pairing/</link>
      <description>The European Commission today praised the interoperability changes that Apple is introducing in iOS 26.3, once again crediting the Digital Markets Act (DMA) with bringing "new opportunities" to European users and developers.</description>
      <content:encoded>&lt;article class="article--2pJwZBkO js-article" expanded="true"&gt;&lt;h1&gt;iOS 26.3 Brings AirPods-Like Pairing to Third-Party Devices in EU Under DMA&lt;/h1&gt;Monday December 22, 2025 3:20 pm PST by &lt;a href="https://www.macrumors.com/author/juli-clover/"&gt;Juli Clover&lt;/a&gt;&lt;p&gt;The European Commission today praised the interoperability changes that Apple is introducing in iOS 26.3, once again crediting the Digital Markets Act (DMA) with bringing "new opportunities" to European users and developers.&lt;/p&gt;
&lt;p&gt;&lt;img alt="iOS 26" src="https://images.macrumors.com/t/yhvXefawwRAhQDktpUWYQjx3MLI=/400x0/article-new/2025/12/iOS-26.3-Feature.jpg?lossy"/&gt;&lt;br/&gt;The Digital Markets Act requires Apple to provide third-party accessories with the same capabilities and access to device features that Apple's own products get. In iOS 26.3, EU wearable device makers can now test proximity pairing and improved notifications.&lt;/p&gt;
&lt;p&gt;Here are the new capabilities that Apple is adding:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Proximity pairing&lt;/strong&gt; - Devices like earbuds will be able to pair with an iOS device in an AirPods-like way by bringing the accessory close to an &lt;a href="https://www.macrumors.com/guide/iphone/"&gt;iPhone&lt;/a&gt; or &lt;a href="https://www.macrumors.com/roundup/ipad/"&gt;iPad&lt;/a&gt; to initiate a simple, one-tap pairing process. Pairing third-party devices will no longer require multiple steps.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Notifications&lt;/strong&gt; - Third-party accessories like smart watches will be able to receive notifications from the ‌iPhone‌. Users will be able to view and react to incoming notifications, which is functionality normally limited to the Apple Watch. Notifications can only be forwarded to one connected device at a time, and turning on notifications for a third-party device disables notifications to an Apple Watch.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The European Commission says that developers can test third-party TVs, smart watches, and headphones with the new features in iOS 26.3, with the functionality to be "fully available in Europe" in 2026.&lt;/p&gt;
&lt;p&gt;iOS 26.3 offers "another step towards a more inter-connected digital ecosystem to the benefit of all EU citizens," according to the European Commission. iOS 26.3 is expected to launch at the end of January.&lt;/p&gt;
&lt;p&gt;The changes to proximity pairing and notifications are only available for device makers and ‌iPhone‌ and ‌iPad‌ users in the European Union.&lt;/p&gt;
[ &lt;a href="https://forums.macrumors.com/threads/ios-26-3-brings-airpods-like-pairing-to-third-party-devices-in-eu-under-dma.2475090/"&gt;71 comments&lt;/a&gt; ]&lt;a href="https://twitter.com/share?url=http%3A%2F%2Fwww.macrumors.com%2F2025%2F12%2F22%2Fios-26-3-dma-airpods-pairing%2F&amp;amp;text=iOS+26.3+Brings+AirPods-Like+Pairing+to+Third-Party+Devices+in+EU+Under+DMA&amp;amp;related=macrumors"&gt;&lt;/a&gt;&lt;a href="https://www.facebook.com/sharer/sharer.php?u=http%3A%2F%2Fwww.macrumors.com%2F2025%2F12%2F22%2Fios-26-3-dma-airpods-pairing%2F&amp;amp;amp;src=sdkpreparse"&gt;&lt;/a&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.macrumors.com/2025/12/22/ios-26-3-dma-airpods-pairing/</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 06:22:21 +0000</pubDate>
    </item>
    <item>
      <title>Show HN: CineCLI – Browse and torrent movies directly from your terminal</title>
      <link>https://github.com/eyeblech/cinecli</link>
      <description>GitHub - eyeblech/cinecli: CineCLI is a cross-platform command-line movie browser built with Python.</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;p&gt;&lt;a href="https://camo.githubusercontent.com/d7a2a0757d30060c754de6e7b99cb5b4f0ffbc5ca1c30226c193693c606268c7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f63696e65636c69"&gt;&lt;img alt="PyPI" src="https://camo.githubusercontent.com/d7a2a0757d30060c754de6e7b99cb5b4f0ffbc5ca1c30226c193693c606268c7/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f63696e65636c69"/&gt;&lt;/a&gt;
&lt;a href="https://camo.githubusercontent.com/6095792cccbdf1e7ff3823e190b373efb89d3be5920ef7d442bffad7e06a46d4/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f63696e65636c69"&gt;&lt;img alt="Python" src="https://camo.githubusercontent.com/6095792cccbdf1e7ff3823e190b373efb89d3be5920ef7d442bffad7e06a46d4/68747470733a2f2f696d672e736869656c64732e696f2f707970692f707976657273696f6e732f63696e65636c69"/&gt;&lt;/a&gt;
&lt;a href="https://camo.githubusercontent.com/f8df3091bbe1149f398a5369b2c39e896766f9f6efba3477c63e9b4aa940ef14/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d677265656e"&gt;&lt;img alt="License" src="https://camo.githubusercontent.com/f8df3091bbe1149f398a5369b2c39e896766f9f6efba3477c63e9b4aa940ef14/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d4d49542d677265656e"/&gt;&lt;/a&gt;
&lt;a href="https://camo.githubusercontent.com/8016a83d8d76dafb654d0d0996f171069ef251332c073a69a63ea84549a1c9b6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f63696e65636c69"&gt;&lt;img alt="Downloads" src="https://camo.githubusercontent.com/8016a83d8d76dafb654d0d0996f171069ef251332c073a69a63ea84549a1c9b6/68747470733a2f2f696d672e736869656c64732e696f2f707970692f646d2f63696e65636c69"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://camo.githubusercontent.com/5714c1d3e40f657a117aa9c961de32bf3aa29c10f83ea590e736f48c08a628a5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657965626c6563682f63696e65636c693f7374796c653d666c61742d737175617265"&gt;&lt;img alt="Stars" src="https://camo.githubusercontent.com/5714c1d3e40f657a117aa9c961de32bf3aa29c10f83ea590e736f48c08a628a5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f657965626c6563682f63696e65636c693f7374796c653d666c61742d737175617265"/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2&gt;📡 YTS API Status&lt;/h2&gt;&lt;a href="#-yts-api-status"&gt;&lt;/a&gt;
&lt;p&gt;
&lt;a href="https://camo.githubusercontent.com/ee1c288267112cfd617cecbe2f9ec3209df0d2dbe299de8b1cd3fb4df4e3bfb5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f657965626c6563682f63696e65636c692f6170692d6865616c74682e796d6c3f6c6162656c3d595453253230415049267374796c653d666f722d7468652d6261646765"&gt;&lt;img alt="YTS API Status" src="https://camo.githubusercontent.com/ee1c288267112cfd617cecbe2f9ec3209df0d2dbe299de8b1cd3fb4df4e3bfb5/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f657965626c6563682f63696e65636c692f6170692d6865616c74682e796d6c3f6c6162656c3d595453253230415049267374796c653d666f722d7468652d6261646765"/&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;strong&gt;Status is automatically monitored every 15 minutes.&lt;/strong&gt;&lt;br/&gt;

    🟢 Green = Operational   •  
    🔴 Red = Outage / API Down
  
&lt;/p&gt;

&lt;h1&gt;🎬 CineCLI&lt;/h1&gt;&lt;a href="#-cinecli"&gt;&lt;/a&gt;
&lt;blockquote&gt;
&lt;p&gt;Browse, inspect, and launch movie torrents directly from your terminal.&lt;br/&gt;
Fast. Cross-platform. Minimal. Beautiful.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://github.com/eyeblech/cinecli/blob/master/demo.gif"&gt;&lt;img alt="Demo" src="https://github.com/eyeblech/cinecli/raw/master/demo.gif"/&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href="https://camo.githubusercontent.com/6bce8c074ba1847154d5448fa4b909b24bdc5e2dead78e01601b2388cba04190/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6c696e75782532302537432532306d61634f5325323025374325323077696e646f77732d626c7565"&gt;&lt;img alt="Platform" src="https://camo.githubusercontent.com/6bce8c074ba1847154d5448fa4b909b24bdc5e2dead78e01601b2388cba04190/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f706c6174666f726d2d6c696e75782532302537432532306d61634f5325323025374325323077696e646f77732d626c7565"/&gt;&lt;/a&gt;
&lt;a href="https://camo.githubusercontent.com/4d05de71d175fd180e6a54008bb655173476617f053e30cce46a2ae0c33139dc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e746572666163652d434c492d6f72616e6765"&gt;&lt;img alt="CLI" src="https://camo.githubusercontent.com/4d05de71d175fd180e6a54008bb655173476617f053e30cce46a2ae0c33139dc/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f696e746572666163652d434c492d6f72616e6765"/&gt;&lt;/a&gt;
&lt;a href="https://camo.githubusercontent.com/a875f41a2bd54510be00d5743cb13308c385a54e0b945c0c2d49622d786f1ddf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f776f726b73253230696e2d7465726d696e616c2d626c61636b"&gt;&lt;img alt="Terminal" src="https://camo.githubusercontent.com/a875f41a2bd54510be00d5743cb13308c385a54e0b945c0c2d49622d786f1ddf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f776f726b73253230696e2d7465726d696e616c2d626c61636b"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;✨ Features&lt;/h2&gt;&lt;a href="#-features"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;🔍 Search movies from &lt;strong&gt;YTS&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;🎥 View detailed movie information&lt;/li&gt;
&lt;li&gt;🧲 Launch magnet links directly into your torrent client&lt;/li&gt;
&lt;li&gt;📦 Download &lt;code&gt;.torrent&lt;/code&gt; files if preferred&lt;/li&gt;
&lt;li&gt;⚡ Auto-select best torrent (highest quality + healthy seeds)&lt;/li&gt;
&lt;li&gt;🖥 Cross-platform (Linux, macOS, Windows)&lt;/li&gt;
&lt;li&gt;🎨 Rich, clean terminal UI (powered by &lt;code&gt;rich&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;🧠 Smart defaults with full user control&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href="https://camo.githubusercontent.com/24291b36ca6bfe1e10b218fe428f13ad6a14a9ad12c9d0f814872d851314e944/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6275696c74253230776974682d54797065722d666636396234"&gt;&lt;img alt="Built with Typer" src="https://camo.githubusercontent.com/24291b36ca6bfe1e10b218fe428f13ad6a14a9ad12c9d0f814872d851314e944/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6275696c74253230776974682d54797065722d666636396234"/&gt;&lt;/a&gt;
&lt;a href="https://camo.githubusercontent.com/7a65b723320e5684e19ed5a6a8383a2f2722db455ae63eabb40f81d666aa1fdd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6275696c74253230776974682d526963682d626c756576696f6c6574"&gt;&lt;img alt="Built with Rich" src="https://camo.githubusercontent.com/7a65b723320e5684e19ed5a6a8383a2f2722db455ae63eabb40f81d666aa1fdd/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6275696c74253230776974682d526963682d626c756576696f6c6574"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;📦 Installation&lt;/h2&gt;&lt;a href="#-installation"&gt;&lt;/a&gt;
&lt;pre&gt;pip install cinecli
&lt;/pre&gt;
&lt;p&gt;Requires &lt;strong&gt;Python 3.9+&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;🚀 Usage&lt;/h2&gt;&lt;a href="#-usage"&gt;&lt;/a&gt;
&lt;h3&gt;🔎 Search for movies&lt;/h3&gt;&lt;a href="#-search-for-movies"&gt;&lt;/a&gt;
&lt;pre&gt;cinecli search matrix
&lt;/pre&gt;
&lt;p&gt;Displays matching movies with IDs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ID     Title                 Year   Rating
3525   The Matrix            1999   8.7
3526   The Matrix Reloaded   2003   7.2

&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;🎬 Watch a movie&lt;/h3&gt;&lt;a href="#-watch-a-movie"&gt;&lt;/a&gt;
&lt;pre&gt;cinecli watch 3525
&lt;/pre&gt;
&lt;p&gt;What happens:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Shows movie details&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lists available torrents&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Auto-selects the best option (you can override)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Launches magnet or downloads &lt;code&gt;.torrent&lt;/code&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;h3&gt;🧭 Interactive mode (recommended for exploration)&lt;/h3&gt;&lt;a href="#-interactive-mode-recommended-for-exploration"&gt;&lt;/a&gt;
&lt;pre&gt;cinecli interactive
&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Search → select movie → choose torrent&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Manual selection by design (safe &amp;amp; explicit)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;⚙️ How magnet launching works&lt;/h2&gt;&lt;a href="#️-how-magnet-launching-works"&gt;&lt;/a&gt;
&lt;p&gt;CineCLI delegates magnet handling to your OS.&lt;/p&gt;
&lt;p&gt;That means:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Whatever torrent client is registered (&lt;code&gt;qBittorrent&lt;/code&gt;, &lt;code&gt;Transmission&lt;/code&gt;, etc.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CineCLI will launch it directly&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Example (Linux):&lt;/p&gt;
&lt;pre&gt;xdg-mime query default x-scheme-handler/magnet
&lt;/pre&gt;

&lt;h2&gt;🎞 Demo Video&lt;/h2&gt;&lt;a href="#-demo-video"&gt;&lt;/a&gt;
&lt;p&gt;Full terminal walkthrough:&lt;/p&gt;



demo.mov






&lt;h2&gt;🛠 Tech Stack&lt;/h2&gt;&lt;a href="#-tech-stack"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Python&lt;/strong&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Typer&lt;/strong&gt; — CLI framework&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Rich&lt;/strong&gt; — terminal UI&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Requests&lt;/strong&gt; — API communication&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;YTS API&lt;/strong&gt; — movie data source&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;📄 License&lt;/h2&gt;&lt;a href="#-license"&gt;&lt;/a&gt;
&lt;p&gt;MIT—see &lt;a href="https://github.com/eyeblech/cinecli/blob/master/LICENSE"&gt;LICENSE&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Use it. Fork it. Improve it.&lt;/p&gt;

&lt;h2&gt;🙌 Author&lt;/h2&gt;&lt;a href="#-author"&gt;&lt;/a&gt;
&lt;p&gt;Built by &lt;strong&gt;eyeblech&lt;/strong&gt;&lt;br/&gt;
📧 &lt;a href="mailto:0x1123@proton.me"&gt;0x1123@proton.me&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;STAR the repo if you like it! ⭐&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://camo.githubusercontent.com/55adbef48125ea91f8864924c309ff1710b23c84e01b0670b45e467e795ae13b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e2d2d736f757263652d7965732d627269676874677265656e"&gt;&lt;img alt="Open Source" src="https://camo.githubusercontent.com/55adbef48125ea91f8864924c309ff1710b23c84e01b0670b45e467e795ae13b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6f70656e2d2d736f757263652d7965732d627269676874677265656e"/&gt;&lt;/a&gt;
&lt;a href="https://camo.githubusercontent.com/da21b16c25c3d396a17fe7ba748e0497a765b934030128e412161493c4ea5bec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d61696e7461696e65642d7965732d73756363657373"&gt;&lt;img alt="Maintained" src="https://camo.githubusercontent.com/da21b16c25c3d396a17fe7ba748e0497a765b934030128e412161493c4ea5bec/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6d61696e7461696e65642d7965732d73756363657373"/&gt;&lt;/a&gt;
&lt;a href="https://camo.githubusercontent.com/03fe1c696836c0a3e46f187fad3b80abadafb5f331737069810e10468871395f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d707572706c65"&gt;&lt;img alt="PRs Welcome" src="https://camo.githubusercontent.com/03fe1c696836c0a3e46f187fad3b80abadafb5f331737069810e10468871395f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5052732d77656c636f6d652d707572706c65"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;⭐ Star History&lt;/h2&gt;&lt;a href="#-star-history"&gt;&lt;/a&gt;
&lt;p&gt;&lt;a href="https://star-history.com/#eyeblech/cinecli&amp;amp;Date"&gt;&lt;img alt="Star History Chart" src="https://camo.githubusercontent.com/b96f697184e70f5a4a70e67126c617988ef3cbcab75c7d140ab123f6695090ab/68747470733a2f2f6170692e737461722d686973746f72792e636f6d2f7376673f7265706f733d657965626c6563682f63696e65636c6926747970653d44617465"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/eyeblech/cinecli</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 05:17:50 +0000</pubDate>
    </item>
    <item>
      <title>Snitch – A friendlier ss/netstat</title>
      <link>https://github.com/karol-broda/snitch</link>
      <description>a friendlier ss / netstat for humans. inspect network connections with a clean tui or styled tables.</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;h1&gt;snitch&lt;/h1&gt;&lt;a href="#snitch"&gt;&lt;/a&gt;
&lt;p&gt;a friendlier &lt;code&gt;ss&lt;/code&gt; / &lt;code&gt;netstat&lt;/code&gt; for humans. inspect network connections with a clean tui or styled tables.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/karol-broda/snitch/blob/master/demo/demo.gif"&gt;&lt;img alt="snitch demo" src="https://github.com/karol-broda/snitch/raw/master/demo/demo.gif"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;install&lt;/h2&gt;&lt;a href="#install"&gt;&lt;/a&gt;
&lt;h3&gt;go&lt;/h3&gt;&lt;a href="#go"&gt;&lt;/a&gt;
&lt;pre&gt;go install github.com/karol-broda/snitch@latest&lt;/pre&gt;
&lt;h3&gt;nixos / nix&lt;/h3&gt;&lt;a href="#nixos--nix"&gt;&lt;/a&gt;
&lt;pre&gt;# try it
nix run github:karol-broda/snitch

# install to profile
nix profile install github:karol-broda/snitch

# or add to flake inputs
{
  inputs.snitch.url = "github:karol-broda/snitch";
}
# then use: inputs.snitch.packages.${system}.default&lt;/pre&gt;
&lt;h3&gt;arch linux (aur)&lt;/h3&gt;&lt;a href="#arch-linux-aur"&gt;&lt;/a&gt;
&lt;pre&gt;# with yay
yay -S snitch-bin

# with paru
paru -S snitch-bin&lt;/pre&gt;
&lt;h3&gt;shell script&lt;/h3&gt;&lt;a href="#shell-script"&gt;&lt;/a&gt;
&lt;pre&gt;curl -sSL https://raw.githubusercontent.com/karol-broda/snitch/master/install.sh | sh&lt;/pre&gt;
&lt;p&gt;installs to &lt;code&gt;~/.local/bin&lt;/code&gt; if available, otherwise &lt;code&gt;/usr/local/bin&lt;/code&gt;. override with:&lt;/p&gt;
&lt;pre&gt;curl -sSL https://raw.githubusercontent.com/karol-broda/snitch/master/install.sh | INSTALL_DIR=~/bin sh&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;macos:&lt;/strong&gt; the install script automatically removes the quarantine attribute (&lt;code&gt;com.apple.quarantine&lt;/code&gt;) from the binary to allow it to run without gatekeeper warnings. to disable this, set &lt;code&gt;KEEP_QUARANTINE=1&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;binary&lt;/h3&gt;&lt;a href="#binary"&gt;&lt;/a&gt;
&lt;p&gt;download from &lt;a href="https://github.com/karol-broda/snitch/releases"&gt;releases&lt;/a&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;linux:&lt;/strong&gt; &lt;code&gt;snitch_&amp;lt;version&amp;gt;_linux_&amp;lt;arch&amp;gt;.tar.gz&lt;/code&gt; or &lt;code&gt;.deb&lt;/code&gt;/&lt;code&gt;.rpm&lt;/code&gt;/&lt;code&gt;.apk&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;macos:&lt;/strong&gt; &lt;code&gt;snitch_&amp;lt;version&amp;gt;_darwin_&amp;lt;arch&amp;gt;.tar.gz&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;tar xzf snitch_*.tar.gz
sudo mv snitch /usr/local/bin/&lt;/pre&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;macos:&lt;/strong&gt; if blocked with "cannot be opened because the developer cannot be verified", run:&lt;/p&gt;
&lt;pre&gt;xattr -d com.apple.quarantine /usr/local/bin/snitch&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;h2&gt;quick start&lt;/h2&gt;&lt;a href="#quick-start"&gt;&lt;/a&gt;
&lt;pre&gt;snitch              # launch interactive tui
snitch -l           # tui showing only listening sockets
snitch ls           # print styled table and exit
snitch ls -l        # listening sockets only
snitch ls -t -e     # tcp established connections
snitch ls -p        # plain output (parsable)&lt;/pre&gt;
&lt;h2&gt;commands&lt;/h2&gt;&lt;a href="#commands"&gt;&lt;/a&gt;
&lt;h3&gt;&lt;code&gt;snitch&lt;/code&gt; / &lt;code&gt;snitch top&lt;/code&gt;&lt;/h3&gt;&lt;a href="#snitch--snitch-top"&gt;&lt;/a&gt;
&lt;p&gt;interactive tui with live-updating connection list.&lt;/p&gt;
&lt;pre&gt;snitch                  # all connections
snitch -l               # listening only
snitch -t               # tcp only
snitch -e               # established only
snitch -i 2s            # 2 second refresh interval&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;keybindings:&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;j/k, ↑/↓      navigate
g/G           top/bottom
t/u           toggle tcp/udp
l/e/o         toggle listen/established/other
s/S           cycle sort / reverse
w             watch/monitor process (highlight)
W             clear all watched
K             kill process (with confirmation)
/             search
enter         connection details
?             help
q             quit
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;&lt;code&gt;snitch ls&lt;/code&gt;&lt;/h3&gt;&lt;a href="#snitch-ls"&gt;&lt;/a&gt;
&lt;p&gt;one-shot table output. uses a pager automatically if output exceeds terminal height.&lt;/p&gt;
&lt;pre&gt;snitch ls               # styled table (default)
snitch ls -l            # listening only
snitch ls -t -l         # tcp listeners
snitch ls -e            # established only
snitch ls -p            # plain/parsable output
snitch ls -o json       # json output
snitch ls -o csv        # csv output
snitch ls -n            # numeric (no dns resolution)
snitch ls --no-headers  # omit headers&lt;/pre&gt;
&lt;h3&gt;&lt;code&gt;snitch json&lt;/code&gt;&lt;/h3&gt;&lt;a href="#snitch-json"&gt;&lt;/a&gt;
&lt;p&gt;json output for scripting.&lt;/p&gt;
&lt;pre&gt;snitch json
snitch json -l&lt;/pre&gt;
&lt;h3&gt;&lt;code&gt;snitch watch&lt;/code&gt;&lt;/h3&gt;&lt;a href="#snitch-watch"&gt;&lt;/a&gt;
&lt;p&gt;stream json frames at an interval.&lt;/p&gt;
&lt;pre&gt;snitch watch -i 1s | jq '.count'
snitch watch -l -i 500ms&lt;/pre&gt;
&lt;h3&gt;&lt;code&gt;snitch upgrade&lt;/code&gt;&lt;/h3&gt;&lt;a href="#snitch-upgrade"&gt;&lt;/a&gt;
&lt;p&gt;check for updates and upgrade in-place.&lt;/p&gt;
&lt;pre&gt;snitch upgrade              # check for updates
snitch upgrade --yes        # upgrade automatically
snitch upgrade -v 0.1.7     # install specific version&lt;/pre&gt;
&lt;h2&gt;filters&lt;/h2&gt;&lt;a href="#filters"&gt;&lt;/a&gt;
&lt;p&gt;shortcut flags work on all commands:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-t, --tcp           tcp only
-u, --udp           udp only
-l, --listen        listening sockets
-e, --established   established connections
-4, --ipv4          ipv4 only
-6, --ipv6          ipv6 only
-n, --numeric       no dns resolution
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;for more specific filtering, use &lt;code&gt;key=value&lt;/code&gt; syntax with &lt;code&gt;ls&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;snitch ls proto=tcp state=listen
snitch ls pid=1234
snitch ls proc=nginx
snitch ls lport=443
snitch ls contains=google&lt;/pre&gt;
&lt;h2&gt;output&lt;/h2&gt;&lt;a href="#output"&gt;&lt;/a&gt;
&lt;p&gt;styled table (default):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  ╭─────────────────┬───────┬───────┬─────────────┬─────────────────┬────────╮
  │ PROCESS         │ PID   │ PROTO │ STATE       │ LADDR           │ LPORT  │
  ├─────────────────┼───────┼───────┼─────────────┼─────────────────┼────────┤
  │ nginx           │ 1234  │ tcp   │ LISTEN      │ *               │ 80     │
  │ postgres        │ 5678  │ tcp   │ LISTEN      │ 127.0.0.1       │ 5432   │
  ╰─────────────────┴───────┴───────┴─────────────┴─────────────────┴────────╯
  2 connections
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;plain output (&lt;code&gt;-p&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;PROCESS    PID    PROTO   STATE    LADDR       LPORT
nginx      1234   tcp     LISTEN   *           80
postgres   5678   tcp     LISTEN   127.0.0.1   5432
&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;configuration&lt;/h2&gt;&lt;a href="#configuration"&gt;&lt;/a&gt;
&lt;p&gt;optional config file at &lt;code&gt;~/.config/snitch/snitch.toml&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;[defaults]
numeric = false
theme = "auto"&lt;/pre&gt;
&lt;h2&gt;requirements&lt;/h2&gt;&lt;a href="#requirements"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;linux or macos&lt;/li&gt;
&lt;li&gt;linux: reads from &lt;code&gt;/proc/net/*&lt;/code&gt;, root or &lt;code&gt;CAP_NET_ADMIN&lt;/code&gt; for full process info&lt;/li&gt;
&lt;li&gt;macos: uses system APIs, may require sudo for full process info&lt;/li&gt;
&lt;/ul&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/karol-broda/snitch</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 01:03:57 +0000</pubDate>
    </item>
    <item>
      <title>Inside CECOT – 60 Minutes [video]</title>
      <link>https://archive.org/details/insidececot</link>
      <description>0 Views</description>
      <content:encoded>&lt;main id="maincontent"&gt;

&lt;!--HTML--&gt;
&lt;!--//.container-ia--&gt;






&lt;h1&gt;
    Inside CECOT | 60 Minutes  &lt;/h1&gt;
&lt;h2&gt;
    Video Item Preview
  &lt;/h2&gt;




&lt;a href="#"&gt;&lt;/a&gt;
&lt;a href="#"&gt;

&lt;/a&gt;
&lt;a href="#"&gt;&lt;/a&gt;
&lt;a href="#"&gt;


&lt;/a&gt;
&lt;!--/#theatre-controls--&gt;


&lt;!--/.xs-col-12--&gt;
&lt;!--/.row--&gt;






remove-circle 
&lt;h1&gt;Share or Embed This Item&lt;/h1&gt;
&lt;!--/.modal-header--&gt;




&lt;a href="https://twitter.com/intent/tweet?url=https://archive.org/details/insidececot&amp;amp;via=internetarchive&amp;amp;text=Inside+CECOT+%7C+60+Minutes+%3A+CBS+News+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive"&gt;

Share to Twitter
&lt;/a&gt;
&lt;a href="https://www.facebook.com/sharer/sharer.php?u=https://archive.org/details/insidececot"&gt;

Share to Facebook
&lt;/a&gt;
&lt;a href="http://www.reddit.com/submit?url=https://archive.org/details/insidececot&amp;amp;title=Inside+CECOT+%7C+60+Minutes+%3A+CBS+News+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive"&gt;

Share to Reddit
&lt;/a&gt;
&lt;a href="https://www.tumblr.com/widgets/share/tool?posttype=link&amp;amp;title=Inside+CECOT+%7C+60+Minutes+%3A+CBS+News+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive&amp;amp;caption=Inside+CECOT+%7C+60+Minutes+%3A+CBS+News+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive&amp;amp;content=https://archive.org/details/insidececot&amp;amp;canonicalUrl=https://archive.org/details/insidececot"&gt;

Share to Tumblr
&lt;/a&gt;
&lt;a href="http://www.pinterest.com/pin/create/button/?url=https://archive.org/details/insidececot&amp;amp;description=Inside+CECOT+%7C+60+Minutes+%3A+CBS+News+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive"&gt;

Share to Pinterest
&lt;/a&gt;
&lt;a href="mailto:?body=https://archive.org/details/insidececot&amp;amp;subject=Inside CECOT | 60 Minutes : CBS News : Free Download, Borrow, and Streaming : Internet Archive"&gt;

Share via email
&lt;/a&gt;
&lt;a href="#"&gt;

&lt;img src="https://archive.org/images/link.svg"&gt;
&lt;/img&gt;
Copy Link
&lt;/a&gt;

&lt;br&gt;
&lt;/br&gt;



Begin playing at:
&lt;br&gt;
&lt;/br&gt;







                Want more?
                &lt;a href="https://archive.org/help/video.php?identifier=insidececot"&gt;Advanced embedding details, examples, and help&lt;/a&gt;!
              
&lt;!--/#cher-body--&gt;
&lt;!--/.modal-content--&gt;

&lt;!--/.modal-dialog--&gt;
&lt;!--/#cher-modal--&gt;
&lt;!--//#theatre-ia--&gt;


&lt;!--//.container-ia--&gt;

&lt;!--/.container-ia--&gt;








Favorite 




Share 



Flag

&lt;h1&gt;Flag this item for&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://archive.org/login?referer=https%3A%2F%2Farchive.org%2Fdetails%2Finsidececot"&gt;
                  Graphic Violence                &lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://archive.org/login?referer=https%3A%2F%2Farchive.org%2Fdetails%2Finsidececot"&gt;
                  Explicit Sexual Content                &lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://archive.org/login?referer=https%3A%2F%2Farchive.org%2Fdetails%2Finsidececot"&gt;
                  Hate Speech                &lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://archive.org/login?referer=https%3A%2F%2Farchive.org%2Fdetails%2Finsidececot"&gt;
                  Misinformation/Disinformation                &lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://archive.org/login?referer=https%3A%2F%2Farchive.org%2Fdetails%2Finsidececot"&gt;
                  Marketing/Phishing/Advertising                &lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://archive.org/login?referer=https%3A%2F%2Farchive.org%2Fdetails%2Finsidececot"&gt;
                  Misleading/Inaccurate/Missing Metadata                &lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
 &lt;!-- /#flag-popover --&gt;
 &lt;!--/.dropdown --&gt;
 
&lt;!--/.thats-right--&gt;

movies
&lt;h1&gt;
Inside CECOT | 60 Minutes
&lt;/h1&gt;

by

&lt;a href="https://archive.org/search.php?query=creator%3A%22CBS+News%22"&gt;CBS News&lt;/a&gt; 

&lt;br&gt;
&lt;/br&gt;&lt;!--/.thats-left--&gt;











Publication date

&lt;a href="https://archive.org/search.php?query=date:2025-12-22"&gt;
2025-12-22
&lt;/a&gt;

Topics
&lt;a href="https://archive.org/search.php?query=subject%3A%2260+Minutes%22"&gt;60 Minutes&lt;/a&gt;
&lt;!-- contributor (also does usage rights, if specified for the contributor) --&gt;
&lt;!-- display Item Size in this position if theatre_type is not TV --&gt;
Item Size

            1.4G                

 &lt;!-- class="row metadata-list" --&gt;

Sharyn Alfonsi's "Inside CECOT" for 60 Minutes, which was censored by Bari Weiss, as it appeared on Canada's Global TV app.
&lt;!--/#descript--&gt;


Addeddate

2025-12-23 00:05:32 
Identifier

insidececot 
Scanner

            Internet Archive HTML5 Uploader 1.7.0                





&lt;h2&gt;


plus-circle Add Review

&lt;br&gt;
&lt;/br&gt;
comment
        Reviews (1)
&lt;/h2&gt;



&lt;!--/.thats-left--&gt;


&lt;p&gt;

0

        Views      &lt;/p&gt;
&lt;p&gt;
102
Favorites
&lt;/p&gt;
&lt;p&gt;
&lt;a href="#reviews"&gt;
1
            Review          &lt;/a&gt;
&lt;/p&gt;


&lt;h1&gt;
        DOWNLOAD OPTIONS
      &lt;/h1&gt;


&lt;a href="https://archive.org/download/insidececot/60minutesCECOTsegment.ia.mp4"&gt;

download                    1 file                  
&lt;/a&gt;

&lt;a href="https://archive.org/download/insidececot/60minutesCECOTsegment.ia.mp4"&gt;
                  H.264 IA                  download &lt;/a&gt;



&lt;a href="https://archive.org/download/insidececot/__ia_thumb.jpg"&gt;

download                    1 file                  
&lt;/a&gt;

&lt;a href="https://archive.org/download/insidececot/__ia_thumb.jpg"&gt;
                  ITEM TILE                  download &lt;/a&gt;



&lt;a href="https://archive.org/download/insidececot/60minutesCECOTsegment.mp4"&gt;

download                    1 file                  
&lt;/a&gt;

&lt;a href="https://archive.org/download/insidececot/60minutesCECOTsegment.mp4"&gt;
                  MPEG4                  download &lt;/a&gt;



&lt;a href="https://archive.org/download/insidececot/insidececot_archive.torrent"&gt;

download                    1 file                  
&lt;/a&gt;

&lt;a href="https://archive.org/download/insidececot/insidececot_archive.torrent"&gt;
                  TORRENT                  download &lt;/a&gt;



&lt;a href="https://archive.org/compress/insidececot"&gt;
download 24 Files
            &lt;/a&gt;&lt;br/&gt;
&lt;a href="https://archive.org/compress/insidececot/formats=MPEG4,ITEM TILE,ARCHIVE BITTORRENT,METADATA"&gt;download                7 Original&lt;/a&gt;&lt;br/&gt;

&lt;a href="https://archive.org/download/insidececot"&gt;SHOW ALL&lt;/a&gt;
&lt;br/&gt;




&lt;h1&gt;IN COLLECTIONS&lt;/h1&gt;
&lt;a href="https://archive.org/details/opensource_movies"&gt;
Community Video
&lt;img src="https://archive.org/services/img/opensource_movies"/&gt;
&lt;/a&gt;



&lt;p&gt;
        Uploaded by
                  &lt;a href="https://archive.org/details/@colin_haskins"&gt;
            Colin Haskins          &lt;/a&gt;
        
                  on December 23, 2025
&lt;/p&gt;

&lt;!--/.col-md-2--&gt;
&lt;!--/.thats-right--&gt;
&lt;!--/.row--&gt;
&lt;!--//.container-ia--&gt;



&lt;h1&gt;SIMILAR ITEMS (based on metadata)&lt;/h1&gt;



&lt;!--//.container-ia--&gt;

&lt;!--/.container--&gt;

&lt;a href="https://archive.org/about/terms"&gt;Terms of Service (last updated 12/31/2014)&lt;/a&gt;

&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://archive.org/details/insidececot</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 00:36:27 +0000</pubDate>
    </item>
    <item>
      <title>Local AI is driving the biggest change in laptops in decades</title>
      <link>https://spectrum.ieee.org/ai-models-locally</link>
      <description>Local AI is driving the biggest change in laptops in decades</description>
      <content:encoded>&lt;article class="clearfix image-article sm-mb-1 quality-HD post-2674288969" data-category="Computing" data-frozen-sections="[]" elid="2674288969"&gt;&lt;a href="https://spectrum.ieee.org/topic/computing/"&gt;Computing&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/topic/artificial-intelligence/"&gt;AI&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/magazine/"&gt;Magazine&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/type/feature/"&gt;Feature&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/magazine/2025/december/"&gt;December 2025&lt;/a&gt;&lt;h1&gt;
        Your Laptop Isn’t Ready for LLMs. That’s About to Change
    &lt;/h1&gt;&lt;h2&gt;&lt;p&gt;Local AI is driving the biggest change in laptops in decades&lt;/p&gt;&lt;/h2&gt;&lt;a href="https://spectrum.ieee.org/u/matthew-s-smith"&gt;Matthew S. Smith&lt;/a&gt;17 Nov 202510 min read&lt;!-- EMAIL --&gt;&lt;a href="mailto:?subject=Your%20Laptop%20Isn%E2%80%99t%20Ready%20for%20LLMs.%20That%E2%80%99s%20About%20to%20Change&amp;amp;body=https://spectrum.ieee.org/ai-models-locally"&gt;&lt;/a&gt;&lt;!-- COPY LINK --&gt;&lt;!-- TWITTER --&gt;&lt;!-- FACEBOOK --&gt;&lt;!-- LINKEDIN --&gt;Vertical&lt;img alt="Hands typing on laptop with a building scaffold shaped like a face on the screen." src="https://spectrum.ieee.org/media-library/hands-typing-on-laptop-with-a-building-scaffold-shaped-like-a-face-on-the-screen.jpg?id=62173854&amp;amp;width=1200&amp;amp;height=1587"/&gt;
        Dan Page
    Blue&lt;p&gt;&lt;strong&gt;Odds are the PC in &lt;/strong&gt;your office today isn’t ready to run AI &lt;a href="https://spectrum.ieee.org/large-language-model-performance"&gt;large language models&lt;/a&gt; (LLMs).&lt;/p&gt;&lt;p&gt;Today, most users interact with LLMs via an online, browser-based interface. The more technically inclined might use an application &lt;a href="https://spectrum.ieee.org/tag/programming"&gt;programming&lt;/a&gt; interface or command line interface. In either case, the queries are sent to a &lt;a href="https://spectrum.ieee.org/dcflex-data-center-flexibility"&gt;data center&lt;/a&gt;, where the model is hosted and run. It works well, until it doesn’t; a data-center outage can take a model offline for hours. Plus, some users might be unwilling to send &lt;a href="https://spectrum.ieee.org/tag/personal-data"&gt;personal data&lt;/a&gt; to an anonymous entity.&lt;/p&gt;&lt;p&gt;Running a model locally on your computer could offer significant benefits: lower latency, better understanding of your personal needs, and the privacy that comes with keeping your data on your own machine.&lt;/p&gt;&lt;p&gt;However, for the average laptop that’s over a year old, the number of useful &lt;a href="https://spectrum.ieee.org/tag/ai-models"&gt;AI models&lt;/a&gt; you can run locally on your PC is close to zero. This laptop might have a four- to eight-core processor (&lt;a href="https://en.wikipedia.org/wiki/Central_processing_unit"&gt;CPU&lt;/a&gt;), no dedicated &lt;a href="https://spectrum.ieee.org/tag/graphics"&gt;graphics&lt;/a&gt; chip (&lt;a href="https://en.wikipedia.org/wiki/Graphics_processing_unit"&gt;GPU&lt;/a&gt;) or neural-processing unit (&lt;a href="https://en.wikipedia.org/wiki/Neural_processing_unit"&gt;NPU&lt;/a&gt;), and 16 gigabytes of &lt;a href="https://en.wikipedia.org/wiki/Random-access_memory"&gt;RAM&lt;/a&gt;, leaving it underpowered for LLMs.&lt;/p&gt;&lt;p&gt;Even new, high-end PC &lt;a href="https://spectrum.ieee.org/tag/laptops"&gt;laptops&lt;/a&gt;, which often include an NPU and a GPU, can struggle. The largest AI models have over a trillion parameters, which requires memory in &lt;a href="https://snowkylin.github.io/blogs/a-note-on-deepseek-r1.html#:~:text=Note-,Models,Studio%20(%245.6k)!"&gt;the hundreds of gigabytes&lt;/a&gt;. Smaller versions of these models are available, even prolific, but they often lack the intelligence of larger models, which only dedicated AI &lt;a href="https://spectrum.ieee.org/tag/data-centers"&gt;data centers&lt;/a&gt; can handle.&lt;/p&gt;&lt;p&gt;The situation is even worse when other AI features aimed at making the model more capable are considered. &lt;a href="https://huggingface.co/blog/jjokah/small-language-model"&gt;Small language models (SLMs)&lt;/a&gt; that run on local hardware either scale back these features or omit them entirely. Image and video generation are difficult to run locally on laptops, too, and until recently they were reserved for high-end tower desktop PCs.&lt;/p&gt;&lt;p&gt;That’s a problem for AI adoption.&lt;/p&gt;&lt;p&gt;To make running AI models locally possible, the hardware found inside laptops and the software that runs on it will need an upgrade. This is the beginning of a shift in laptop design that will give engineers the opportunity to abandon the last vestiges of the past and reinvent the PC from the ground up.&lt;/p&gt;&lt;h2&gt;NPUs enter the chat&lt;/h2&gt;&lt;p&gt;The most obvious way to boost a PC’s AI performance is to place a powerful NPU alongside the CPU.&lt;/p&gt;&lt;p&gt;An NPU is a specialized chip &lt;a href="https://penntoday.upenn.edu/what-is-an-NPU-in-computing"&gt;designed for the matrix multiplication calculations&lt;/a&gt; that most AI models rely on. These matrix operations are highly parallelized, which is why &lt;a href="https://spectrum.ieee.org/tag/gpus"&gt;GPUs&lt;/a&gt; (which were already better at highly parallelized tasks than CPUs) became the go-to option for AI data centers.&lt;/p&gt;&lt;p&gt;However, because NPUs are designed specifically to handle these matrix operations—and not other tasks, like 3D graphics—&lt;a href="https://www.ibm.com/think/topics/npu-vs-gpu"&gt;they’re more power efficient than GPUs&lt;/a&gt;. That’s important for accelerating AI on portable consumer technology. NPUs also tend to provide better support for low-precision arithmetic than laptop GPUs. AI models often use low-precision arithmetic to reduce computational and memory needs on portable hardware, such as laptops.&lt;/p&gt;&lt;p&gt;&lt;h3&gt;
            
                Laptops Are Being Rebuilt to Run LLMs
            
            
        &lt;/h3&gt;&lt;img alt="Open laptop showing numbered internal components and hands at edges, with a screwdriver nearby." src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%202120%201414'%3E%3C/svg%3E"/&gt;&lt;p&gt;Your laptop today is probably not equipped to run large language models. But future laptops might. Chasing the dream of locally run LLMs, laptop architects are rethinking many aspects of current designs, leading to changes that are only now starting to take hold. &lt;/p&gt;&lt;p&gt;iStockphoto&lt;/p&gt;&lt;p&gt;1. &lt;strong&gt;Addition of NPUs.&lt;/strong&gt; Neural processing units (NPUs)—specialized accelerator chips that can run large language models (LLMs) and other AI models faster than CPUs and GPUs can—are being incorporated into laptops.&lt;/p&gt;&lt;p&gt;2. &lt;strong&gt;Addition of more—and faster—memory.&lt;/strong&gt; The largest language models take up hundreds of gigabytes of memory. To host these models, and serve them quickly to the number-crunching processing units, laptops are increasing their memory capacity and speed.&lt;/p&gt;&lt;p&gt;3. &lt;strong&gt;Consolidation of memory.&lt;/strong&gt; Most laptops today have a divided memory architecture, with a separate pool of memory to serve the GPUs. This made sense when the design first came out: GPUs needed faster memory access than could be supplied by the common bus. Now, to feed AI’s data appetite, laptop architects are rethinking this decision, and now they’re pooling memory together with faster &lt;a href="https://spectrum.ieee.org/tag/interconnects"&gt;interconnects&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;4. &lt;strong&gt;Combination of chips on the same silicon.&lt;/strong&gt; To help shorten the path to pooled memory, all the processing units—CPUs, GPUs, and NPUs—are now being integrated into the same silicon chip. This helps them connect to one another and to memory, but it will make maintenance more challenging.&lt;/p&gt;&lt;p&gt;5. &lt;strong&gt;&lt;a href="https://spectrum.ieee.org/tag/power-management"&gt;Power management&lt;/a&gt;.&lt;/strong&gt; AI models can see heavy use when they power always-on features like Microsoft’s Windows Recall, or the AI-powered Windows Search. Power-sipping NPUs help laptops run these models without excessive battery drain.&lt;/p&gt;&lt;/p&gt;&lt;p&gt;“With the NPU, the entire structure is really designed around the data type of tensors [a multidimensional array of numbers],” said &lt;a href="https://www.microsoft.com/applied-sciences/people/steven-bathiche"&gt;Steven Bathiche&lt;/a&gt;, technical fellow at &lt;a href="https://spectrum.ieee.org/tag/microsoft"&gt;Microsoft&lt;/a&gt;. “NPUs are much more specialized for that workload. And so we go from a CPU that can handle three [trillion] operations per second (TOPS), to an NPU” in &lt;a href="https://www.qualcomm.com"&gt;Qualcomm’s&lt;/a&gt; &lt;a href="https://spectrum.ieee.org/tag/snapdragon"&gt;Snapdragon&lt;/a&gt; X chip, which can power &lt;a href="https://www.microsoft.com/en-us/"&gt;Microsoft’s&lt;/a&gt; &lt;a href="https://blogs.microsoft.com/blog/2024/05/20/introducing-copilot-pcs/"&gt;Copilot+&lt;/a&gt; features. This includes &lt;a href="https://support.microsoft.com/en-us/windows/retrace-your-steps-with-recall-aa03f8a0-a78b-4b3e-b0a1-2eb8ac48701c"&gt;Windows Recall&lt;/a&gt;, which uses AI to create a searchable timeline of a user’s usage history by analyzing screenshots, and &lt;a href="https://blogs.windows.com/windows-insider/2024/02/22/windows-photos-gets-generative-erase-and-recent-ai-editing-features-now-available-on-arm64-devices-and-windows-10/"&gt;Windows Photos’ Generative erase&lt;/a&gt;, which can remove the background or specific objects from an image.&lt;/p&gt;&lt;p&gt;While &lt;a href="https://qualcomm.com"&gt;Qualcomm&lt;/a&gt; was arguably the first to provide an NPU for Windows laptops, it kickstarted an NPU TOPS arms race that also includes &lt;a href="https://www.amd.com/en.html"&gt;AMD&lt;/a&gt; and &lt;a href="https://www.intel.com/content/www/us/en/homepage.html"&gt;Intel&lt;/a&gt;, and the competition is already pushing NPU performance upward.&lt;/p&gt;&lt;p&gt;In 2023, prior to Qualcomm’s Snapdragon X, &lt;a href="https://spectrum.ieee.org/tag/amd"&gt;AMD&lt;/a&gt; chips with NPUs were uncommon, and those that existed delivered about 10 TOPS. Today, AMD and &lt;a href="https://spectrum.ieee.org/tag/intel"&gt;Intel&lt;/a&gt; have NPUs that are competitive with Snapdragon, &lt;a href="https://www.pcworld.com/article/2806864/intel-vs-amd-vs-qualcomm-which-copilot-pc-cpu-is-best-for-you.html"&gt;providing 40 to 50 TOPS&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.lifewire.com/dell-pro-max-plus-ai-laptop-11739880"&gt;Dell’s upcoming Pro Max Plus AI PC&lt;/a&gt; will up the ante with a &lt;a href="https://spectrum.ieee.org/tag/qualcomm"&gt;Qualcomm&lt;/a&gt; AI 100 NPU that promises up to 350 TOPS, improving performance by a staggering 35 times compared with that of the best available NPUs just a few years ago. Drawing that line up and to the right implies that NPUs capable of thousands of TOPS are just a couple of years away.&lt;/p&gt;&lt;p&gt;How many TOPS do you need to run state-of-the-art models with hundreds of millions of parameters? No one knows exactly. It’s not possible to run these models on today’s consumer hardware, so real-world tests just can’t be done. But it stands to reason that we’re within throwing distance of those capabilities. It’s also worth noting that LLMs are not the only use case for NPUs. &lt;a href="https://www.qualcomm.com/news/onq/2024/05/from-olympic-table-tennis-to-ai-product-manager-meet-dr-vinesh-sukumar"&gt;Vinesh Sukumar&lt;/a&gt;, Qualcomm’s head of AI and &lt;a href="https://spectrum.ieee.org/tag/machine-learning"&gt;machine learning&lt;/a&gt; product management, says &lt;a href="https://spectrum.ieee.org/tag/ai-image-generation"&gt;AI image generation&lt;/a&gt; and manipulation is an example of a task that’s difficult without an NPU or high-end GPU.&lt;/p&gt;&lt;h2&gt;Building balanced chips for better AI&lt;/h2&gt;&lt;p&gt;Faster NPUs will handle more tokens per second, which in turn will deliver a faster, more fluid experience when using AI models. Yet there’s more to running AI on local hardware than throwing a bigger, better NPU at the problem.&lt;/p&gt;&lt;p&gt;&lt;a href="https://ieeexplore.ieee.org/author/37089001134"&gt;Mike Clark&lt;/a&gt;, corporate fellow design engineer at AMD, says that companies that design chips to accelerate AI on the PC can’t put all their bets on the NPU. That’s in part because AI isn’t a replacement for, but rather an addition to, the tasks a PC is expected to handle.&lt;/p&gt;&lt;p&gt;“We must be good at low latency, at handling smaller data types, at branching code—traditional workloads. We can’t give that up, but we still want to be good at AI,” says Clark. He also noted that “the CPU is used to prepare data” for AI workloads, which means an inadequate CPU could become a bottleneck.&lt;/p&gt;&lt;p&gt;NPUs must also compete or cooperate with GPUs. On the PC, that often means a high-end AMD or &lt;a href="https://spectrum.ieee.org/tag/nvidia"&gt;Nvidia&lt;/a&gt; GPU with large amounts of built-in memory. The &lt;a href="https://signal65.com/research/ai/nvidia-geforce-rtx-5090-founders-edition-performance-analysis/"&gt;Nvidia GeForce RTX 5090&lt;/a&gt;’s specifications quote an AI performance up to 3,352 TOPS, which leaves even the Qualcomm AI 100 in the dust.&lt;/p&gt;&lt;p&gt;That comes with a big caveat, however: power. Though extremely capable, the RTX 5090 is designed to draw up to &lt;a href="https://signal65.com/research/ai/nvidia-geforce-rtx-5090-founders-edition-performance-analysis/"&gt;575 watts&lt;/a&gt; on its own. Mobile versions for laptops are more miserly but still draw up to &lt;a href="https://www.notebookcheck.net/Nvidia-GeForce-RTX-5090-Laptop-Benchmarks-and-Specs.934947.0.html"&gt;175 W&lt;/a&gt;, which can quickly drain a laptop battery.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.linkedin.com/in/simonng39/?originalSubdomain=ca"&gt;Simon Ng&lt;/a&gt;, client AI product manager at Intel, says the company is “seeing that the NPU will just do things much more efficiently at lower power.”&lt;a href="https://www.linkedin.com/in/rakesh-s-anigundi/"&gt; Rakesh Anigundi&lt;/a&gt;, AMD’s director of product management for Ryzen AI, agrees. He adds that &lt;a href="https://spectrum.ieee.org/tag/low-power"&gt;low-power&lt;/a&gt; operation is particularly important because AI workloads tend to take longer to run than other demanding tasks, like encoding a video or rendering graphics. “You’ll want to be running this for a longer period of time, such as an AI personal assistant, which could be always active and listening for your command,” he says.&lt;/p&gt;&lt;p&gt;These competing priorities mean chip architects and system designers will need to make tough calls about how to allocate silicon and power in AI PCs, especially those that often rely on battery power, such as laptops.&lt;/p&gt;&lt;p&gt;“We have to be very deliberate in how we design our &lt;a href="https://spectrum.ieee.org/tag/system-on-a-chip"&gt;system-on-a-chip&lt;/a&gt; to ensure that a larger &lt;a href="https://spectrum.ieee.org/tag/soc"&gt;SoC&lt;/a&gt; can perform to our requirements in a thin and light form factor,” said&lt;a href="https://www.linkedin.com/in/mahesh-subramony-a0ba60/"&gt; Mahesh Subramony&lt;/a&gt;, senior fellow design engineer at AMD.&lt;/p&gt;&lt;h2&gt;When it comes to AI, memory matters&lt;/h2&gt;&lt;p&gt;Squeezing an NPU alongside a CPU and GPU will improve the average PC’s performance in AI tasks, but it’s not the only revolutionary change AI will force on PC architecture. There’s another that’s perhaps even more fundamental: memory.&lt;/p&gt;&lt;p&gt;Most modern PCs have a divided memory architecture &lt;a href="https://www.electronicdesign.com/technologies/embedded/article/55300900/jon-peddie-research-what-came-before-pcie-the-evolution-of-pc-graphics-buses"&gt;rooted in decisions made over 25 years ago&lt;/a&gt;. Limitations in bus bandwidth led GPUs (and other add-in cards that might require high-bandwidth memory) to move away from accessing a PC’s system memory and instead rely on the GPU’s own dedicated memory. As a result, powerful PCs typically have two pools of memory, system memory and graphics memory, which operate independently.&lt;/p&gt;&lt;p&gt;That’s a problem for AI. Models require large amounts of memory, and the entire model must load into memory at once. The legacy PC architecture, which splits memory between the system and the GPU, is at odds with that requirement.&lt;/p&gt;&lt;p&gt;“When I have a discrete GPU, I have a separate memory subsystem hanging off it,” explained &lt;a href="https://www.linkedin.com/in/joseph-macri-9a288a55/"&gt;Joe Macri, &lt;/a&gt; vice president and chief technology officer at AMD. “When I want to share data between our [CPU] and GPU, I’ve got to take the data out of my memory, slide it across the PCI Express bus, put it in the GPU memory, do my processing, then move it all back.” Macri said this increases power draw and leads to a sluggish &lt;a href="https://spectrum.ieee.org/tag/user-experience"&gt;user experience&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The solution is a unified memory architecture that provides all system resources access to the same pool of memory over a fast, interconnected memory bus. Apple’s in-house silicon is perhaps the most well-known recent example of a chip with a unified memory architecture. However, unified memory is otherwise rare in modern PCs.&lt;/p&gt;&lt;p&gt;AMD is following suit in the laptop space. The company announced a new line of APUs targeted at high-end laptops, &lt;a href="https://www.amd.com/en/products/processors/laptop/ryzen/ai-300-series/amd-ryzen-ai-max-plus-395.html"&gt;Ryzen AI Max&lt;/a&gt;, at &lt;a href="https://spectrum.ieee.org/tag/ces"&gt;CES&lt;/a&gt; (&lt;a href="https://spectrum.ieee.org/topic/consumer-electronics/"&gt;Consumer Electronics&lt;/a&gt; Show) 2025.&lt;/p&gt;&lt;p&gt;Ryzen AI Max places the company’s Ryzen CPU cores on the same silicon as Radeon-branded GPU cores, plus an NPU rated at 50 TOPS, on a single piece of silicon with a unified memory architecture. Because of this, the CPU, GPU, and NPU can all access up to a maximum of &lt;a href="https://www.amd.com/en/developer/resources/technical-articles/2025/amd-ryzen-ai-max-395--a-leap-forward-in-generative-ai-performanc.html"&gt;128 GB of system memory&lt;/a&gt;, which is shared among all three. AMD believes this strategy is ideal for memory and performance management in consumer PCs. “By bringing it all under a single thermal head, the entire power envelope becomes something that we can manage,” said Subramony.&lt;/p&gt;&lt;p&gt;The Ryzen AI Max is already available in several laptops, including&lt;a href="https://www.pcworld.com/article/2650073/hands-on-the-hp-zbook-ultra-g1a-smashes-the-work-laptop-paradigm.html"&gt; the HP Zbook Ultra G1a&lt;/a&gt; and the &lt;a href="https://rog.asus.com/laptops/rog-flow/rog-flow-z13-2025/"&gt;Asus ROG Flow Z13&lt;/a&gt;. It also powers the&lt;a href="https://frame.work/marketplace/desktops"&gt; Framework Desktop&lt;/a&gt; and several mini desktops from less well-known brands, such as the &lt;a href="https://www.gmktec.com/products/amd-ryzen%E2%84%A2-ai-max-395-evo-x2-ai-mini-pc?srsltid=AfmBOooME4uCrsnIh5mOf98eGHteIzsi-DAPl6E5xhNrTzG94qr3Tjf6"&gt;GMKtec EVO-X2 AI mini PC&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Intel and Nvidia will also join this party, though in an unexpected way. In September, the former rivals announced an alliance to sell chips that pair Intel CPU cores with Nvidia GPU cores. While the details are still under wraps, the chip architecture will likely include unified memory and an Intel NPU.&lt;/p&gt;&lt;p&gt;Chips like these stand to drastically change PC architecture if they catch on. They’ll offer access to much larger pools of memory than before and integrate the CPU, GPU, and NPU into one piece of silicon that can be closely monitored and controlled. These factors should make it easier to shuffle an AI workload to the hardware best suited to execute it at a given moment.&lt;/p&gt;&lt;p&gt;Unfortunately, they’ll also make PC upgrades and repairs more difficult, as chips with a unified memory architecture typically bundle the CPU, GPU, NPU, and memory into a single, physically inseparable package on a PC mainboard. That’s in contrast with traditional PCs, where the CPU, GPU, and memory can be replaced individually.&lt;/p&gt;&lt;h2&gt;Microsoft’s bullish take on AI is rewriting Windows&lt;/h2&gt;&lt;p&gt;MacOS is well regarded for its attractive, intuitive &lt;a href="https://spectrum.ieee.org/tag/user-interface"&gt;user interface&lt;/a&gt;, and Apple Silicon chips have a unified memory architecture that can prove useful for AI. However, Apple’s GPUs aren’t as capable as the best ones used in PCs, and its AI tools for developers are less widely adopted.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.linkedin.com/in/chrissiecremers/?originalSubdomain=nl"&gt;Chrissie Cremers&lt;/a&gt;, cofounder of the AI-focused marketing firm Aigency Amsterdam, told me earlier this year that although she prefers macOS, her agency doesn’t use Mac computers for AI work. “The GPU in my Mac desktop can hardly manage [our AI workflow], and it’s not an old computer,” she said. “I’d love for them to catch up here, because they used to be the creative tool.”&lt;/p&gt;&lt;p&gt; &lt;img alt="Laptop beneath glass dome shaped like human head on striped orange and blue background." src="data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%201200%201200'%3E%3C/svg%3E"/&gt;  Dan Page&lt;/p&gt;&lt;p&gt;That leaves an opening for competitors to become the go-to choice for AI on the PC—and Microsoft knows it.&lt;/p&gt;&lt;p&gt;Microsoft launched &lt;a href="https://blogs.microsoft.com/blog/2024/05/20/introducing-copilot-pcs/"&gt;Copilot+ PCs&lt;/a&gt; at the company’s 2024 Build developer conference. The launch had problems, most notably the &lt;a href="https://www.theverge.com/2024/6/13/24178144/microsoft-windows-ai-recall-feature-delay"&gt;botched&lt;/a&gt; release of its key feature,&lt;a href="https://spectrum.ieee.org/microsoft-copilot"&gt; Windows Recall&lt;/a&gt;, which uses AI to help users search through anything they’ve seen or heard on their PC. Still, the launch was successful in pushing the PC industry toward NPUs, as AMD and Intel both introduced new laptop chips with upgraded NPUs in late 2024.&lt;/p&gt;&lt;p&gt;At Build 2025, Microsoft also revealed &lt;a href="https://devblogs.microsoft.com/foundry/foundry-local-a-new-era-of-edge-ai/"&gt;Windows’ AI Foundry Local&lt;/a&gt;, a “runtime stack” that includes a catalog of popular open-source &lt;a href="https://spectrum.ieee.org/tag/large-language-models"&gt;large language models&lt;/a&gt;. While Microsoft’s own models are available,&lt;a href="https://azure.microsoft.com/en-us/products/ai-model-catalog#tabs-pill-bar-oc92d8_tab0"&gt; the catalog includes thousands of open-source models&lt;/a&gt; from &lt;a href="https://spectrum.ieee.org/tag/alibaba"&gt;Alibaba&lt;/a&gt;, DeepSeek, &lt;a href="https://spectrum.ieee.org/tag/meta"&gt;Meta&lt;/a&gt;, Mistral AI, Nvidia, &lt;a href="https://spectrum.ieee.org/tag/openai"&gt;OpenAI&lt;/a&gt;, Stability AI, xAI, and more.&lt;/p&gt;&lt;p&gt;Once a model is selected and implemented into an app, Windows executes AI tasks on local hardware through the Windows ML runtime, which automatically directs AI tasks to the CPU, GPU, or NPU hardware best suited for the job.&lt;/p&gt;&lt;p&gt;AI &lt;a href="https://spectrum.ieee.org/tag/foundry"&gt;Foundry&lt;/a&gt; also provides APIs for local knowledge retrieval and low-rank adaptation (LoRA), advanced features that let developers customize the data an AI model can reference and how it responds. Microsoft also announced support for on-device semantic search and retrieval-augmented generation, features that help developers build AI tools that reference specific on-device information.&lt;/p&gt;&lt;p&gt;“[AI Foundry] is about being smart. It’s about using all the &lt;a href="https://spectrum.ieee.org/tag/processors"&gt;processors&lt;/a&gt; at hand, being efficient, and prioritizing workloads across the CPU, the NPU, and so on. There’s a lot of opportunity and runway to improve,” said Bathiche.&lt;/p&gt;&lt;h3&gt;Toward &lt;a href="https://en.wikipedia.org/wiki/Artificial_general_intelligence"&gt;AGI&lt;/a&gt; on PCs&lt;/h3&gt;&lt;p&gt;The rapid evolution of AI-capable PC hardware represents more than just an incremental upgrade. It signals a coming shift in the PC industry that’s likely to wipe away the last vestiges of the PC architectures designed in the ’80s, ’90s, and early 2000s.&lt;/p&gt;&lt;p&gt;The combination of increasingly powerful NPUs, unified memory architectures, and sophisticated software-optimization techniques is closing the performance gap between local and cloud-based AI at a pace that has surprised even industry insiders, such as Bathiche.&lt;/p&gt;&lt;p&gt;It will also nudge chip designers toward ever-more-integrated chips that have a unified memory subsystem and to bring the CPU, GPU, and NPU onto a single piece of silicon—even in high-end laptops and desktops. AMD’s Subramony said the goal is to have users “carrying a mini workstation in your hand, whether it’s for AI workloads, or for high compute. You won’t have to go to the cloud.”&lt;/p&gt;&lt;p&gt;A change that massive won’t happen overnight. Still, it’s clear that many in the PC industry are committed to reinventing the computers we use every day in a way that optimizes for AI. Qualcomm’s Vinesh Sukumar even believes affordable consumer laptops, much like data centers, should aim for &lt;a href="https://spectrum.ieee.org/tag/agi"&gt;AGI&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;“I want a complete &lt;a href="https://spectrum.ieee.org/tag/artificial-general-intelligence"&gt;artificial general intelligence&lt;/a&gt; running on Qualcomm devices,” he said. “That’s what we’re trying to push for.” &lt;/p&gt;&lt;p&gt;&lt;em&gt;This article appears in the December 2025 print issue.&lt;/em&gt;&lt;/p&gt;From Your Site Articles&lt;ul&gt;&lt;li&gt;&lt;a href="https://spectrum.ieee.org/personal-ai-assistant"&gt;When AI Unplugs, All Bets Are Off ›&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://spectrum.ieee.org/agentic-ai-opera-mini"&gt;Opera Includes AI Agents in Latest Web Browser ›&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;Related Articles Around the Web&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/16y95hk/a_starter_guide_for_playing_with_your_own_local_ai/"&gt;A Starter Guide for Playing with Your Own Local AI! : r/LocalLLaMA ›&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://medium.com/@springrod/why-you-should-use-local-models-a3fce1124c94"&gt;Why You Should Use Local Models. When building Gen AI ... ›&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="https://spectrum.ieee.org/tag/large-language-models"&gt;large language models&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/tag/laptops"&gt;laptops&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/tag/amd"&gt;amd&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/tag/apple"&gt;apple&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/tag/microsoft"&gt;microsoft&lt;/a&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://spectrum.ieee.org/ai-models-locally</guid>
      <category>Hacker News</category>
      <pubDate>Tue, 23 Dec 2025 00:12:16 +0000</pubDate>
    </item>
    <item>
      <title>It's Always TCP_NODELAY</title>
      <link>https://brooker.co.za/blog/2024/05/09/nagle.html</link>
      <description>It's not the 1980s anymore, thankfully.</description>
      <content:encoded>&lt;body&gt;


&lt;h1&gt;&lt;a href="https://brooker.co.za/blog/"&gt;Marc's Blog&lt;/a&gt;&lt;/h1&gt;


&lt;h1&gt;About Me&lt;/h1&gt;
    My name is Marc Brooker. I've been writing code, reading code, and living vicariously through computers for as long as I can remember. I like to build things that work. I also dabble in machining, welding, cooking and skiing.&lt;br/&gt;&lt;br/&gt;

    I'm currently an engineer at Amazon Web Services (AWS) in Seattle, where I work on databases, serverless, and serverless databases. Before that, I worked on EC2 and EBS.&lt;br/&gt;

All opinions are my own.
    &lt;h1&gt;Links&lt;/h1&gt;
&lt;a href="https://brooker.co.za/blog/publications.html"&gt;My Publications and Videos&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://fediscience.org/@marcbrooker"&gt;@marcbrooker on Mastodon&lt;/a&gt;
&lt;a href="https://twitter.com/MarcJBrooker"&gt;@MarcJBrooker on Twitter&lt;/a&gt;


&lt;h1&gt;Itâs always TCP_NODELAY. Every damn time.&lt;/h1&gt;
&lt;p&gt;It's not the 1980s anymore, thankfully.&lt;/p&gt;
&lt;p&gt;The first thing I check when debugging latency issues in distributed systems is whether &lt;a href="https://linux.die.net/man/7/tcp"&gt;TCP_NODELAY&lt;/a&gt; is enabled. And itâs not just me. Every distributed system builder I know has lost hours to latency issues quickly fixed by enabling this simple socket option, suggesting that the default behavior is wrong, and perhaps that the whole concept is outmoded.&lt;/p&gt;
&lt;p&gt;First, letâs be clear about what weâre talking about. Thereâs no better source than John Nagleâs &lt;a href="https://datatracker.ietf.org/doc/html/rfc896"&gt;RFC896&lt;/a&gt; from 1984&lt;a href="#foot1"&gt;1&lt;/a&gt;. First, the problem statement:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;There is a special problem associated with small  packets.   When TCP  is  used  for  the transmission of single-character messages originating at a keyboard, the typical result  is  that  41  byte packets (one  byte  of data, 40 bytes of header) are transmitted for each byte of useful data.  This 4000%  overhead  is  annoying but tolerable on lightly loaded networks.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In short, Nagle was interested in better amortizing the cost of TCP headers, to get better throughput out of the network. Up to 40x better throughput! These tiny packets had two main causes: human-interactive applications like shells, where folks were typing a byte at a time, and poorly implemented programs that dribbled messages out to the kernel through many &lt;code&gt;write&lt;/code&gt; calls. Nagleâs proposal for fixing this was simple and smart:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A  simple and elegant solution has been discovered.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;The solution is to inhibit the sending of new TCP  segments  when new  outgoing  data  arrives  from  the  user  if  any previously transmitted data on the connection remains unacknowledged.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;When many people talk about Nagleâs algorithm, they talk about timers, but RFC896 doesnât use any kind of timer other than the round-trip time on the network.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Nagleâs Algorithm and Delayed Acks&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Nagleâs nice, clean, proposal interacted poorly with another TCP feature: delayed &lt;code&gt;ACK&lt;/code&gt;. The idea behind delayed &lt;code&gt;ACK&lt;/code&gt; is to delay sending the acknowledgement of a packet at least until thereâs some data to send back (e.g. a &lt;code&gt;telnet&lt;/code&gt; session echoing back the userâs typing), or until a timer expires. &lt;a href="https://datatracker.ietf.org/doc/html/rfc813"&gt;RFC813&lt;/a&gt; from 1982 is that first that seems to propose delaying &lt;code&gt;ACKs&lt;/code&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The receiver of data will   refrain   from   sending   an   acknowledgement   under   certain circumstances, in which case it must set a timer which  will  cause  the acknowledgement  to be sent later.  However, the receiver should do this only where it is a reasonable guess that some other event will intervene and prevent the necessity of the timer  interrupt.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;which is then formalized further in &lt;a href="https://datatracker.ietf.org/doc/html/rfc1122"&gt;RFC1122&lt;/a&gt; from 1989. The interaction between these two features causes a problem: Nagleâs algorithm is blocking sending more data until an &lt;code&gt;ACK&lt;/code&gt; is received, but delayed ack is delaying that &lt;code&gt;ack&lt;/code&gt; until a response is ready. Great for keeping packets full, not so great for latency-sensitive pipelined applications.&lt;/p&gt;
&lt;p&gt;This is a point Nagle has made himself several times. For example in this &lt;a href="https://news.ycombinator.com/item?id=10608356"&gt;Hacker News comment&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;That still irks me. The real problem is not tinygram prevention. Itâs ACK delays, and that stupid fixed timer. They both went into TCP around the same time, but independently. I did tinygram prevention (the Nagle algorithm) and Berkeley did delayed ACKs, both in the early 1980s. The combination of the two is awful.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As systems builders this is should be a familiar situation: two reasonable features of the system that interact to create an undesirable behavior. This kind of interaction is one of the things that makes protocol design so hard.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Is Nagle blameless?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Unfortunately, itâs not just delayed ACK&lt;a href="#foot2"&gt;2&lt;/a&gt;. Even without delayed ack and that &lt;em&gt;stupid fixed timer&lt;/em&gt;, the behavior of Nagleâs algorithm probably isnât what we want in distributed systems. A single in-datacenter RTT is typically around 500Î¼s, then a couple of milliseconds between datacenters in the same region, and up to hundreds of milliseconds going around the globe. Given the vast amount of work a modern server can do in even a few hundred microseconds, delaying sending data for even one RTT isnât clearly a win.&lt;/p&gt;
&lt;p&gt;To make a clearer case, letâs turn back to the justification behind Nagleâs algorithm: amortizing the cost of headers and avoiding that 40x overhead on single-byte packets. But does anybody send single byte packets anymore? Most distributed databases and systems donât. Partially thatâs because they simply have more to say, partially its because of additional overhead of protocols like TLS, and partially its because of encoding and serialization overhead. But mostly, they have more to say.&lt;/p&gt;
&lt;p&gt;The core concern of not sending tiny messages is still a very real one, but weâve very effectively pushed that into the application layer. Sending a byte at a time wrapped in JSON isnât going to be very efficient, no matter what Nagleâs algorithm does.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Is Nagle needed?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;First, the uncontroversial take: if youâre building a latency-sensitive distributed system running on modern datacenter-class hardware, enable &lt;code&gt;TCP_NODELAY&lt;/code&gt; (disable Nagleâs algorithm) without worries. You donât need to feel bad. Itâs not a sin. Itâs OK. Just go ahead.&lt;/p&gt;
&lt;p&gt;More controversially, I suspect that Nagleâs algorithm just isnât needed on modern systems, given the traffic and application mix, and the capabilities of the hardware we have today. In other words, &lt;code&gt;TCP_NODELAY&lt;/code&gt; should be the default. Thatâs going to make some â&lt;code&gt;write&lt;/code&gt; every byteâ code slower than it would otherwise be, but those applications should be fixed anyway if we care about efficiency.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Footnotes&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a&gt;&lt;/a&gt; I wonât got into it here, but RFC896 is also one of the earliest statements I can find of metastable behavior in computer networks. In it, Nagle says: âThis condition is stable. Once the  saturation point has been reached, if the algorithm for selecting packets to be dropped is fair, the network will continue to operate in a degraded condition.â&lt;/li&gt;
&lt;li&gt;&lt;a&gt;&lt;/a&gt; As this has gone around the internet, a number of folks have asked about &lt;code&gt;TCP_QUICKACK&lt;/code&gt;. I donât tend to reach for it for a few reasons, including lack of portability, and weird semantics (seriously, read &lt;a href="https://linux.die.net/man/7/tcp"&gt;the man page&lt;/a&gt;). The bigger problem is that &lt;code&gt;TCP_QUICKACK&lt;/code&gt; doesnât fix the fundamental problem of the kernel hanging on to data longer than my program wants it to. When I say &lt;code&gt;write()&lt;/code&gt;, I mean &lt;code&gt;write()&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;


  « &lt;a href="https://brooker.co.za/blog"&gt;Back to the blog index&lt;/a&gt;&lt;br/&gt;
&lt;br/&gt;
&lt;!-- Similar Posts --&gt;
&lt;h4&gt;Similar Posts&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;21 Oct 2022 » &lt;a href="https://brooker.co.za/blog/2022/10/21/nudge.html"&gt;Give Your Tail a Nudge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;10 May 2014 » &lt;a href="https://brooker.co.za/blog/2014/05/10/lynch-pub.html"&gt;The Essential Nancy Lynch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;20 May 2025 » &lt;a href="https://brooker.co.za/blog/2025/05/20/icpe.html"&gt;Good Performance for Bad Days&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;!-- Dissimilar Posts --&gt;
&lt;h4&gt;Something Completely Different&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;11 Apr 2015 » &lt;a href="https://brooker.co.za/blog/2015/04/11/zero-one.html"&gt;The Zero, One, Infinity Disease&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;
        Marc Brooker&lt;br&gt;
        The opinions on this site are my own. They do not necessarily represent those of my employer.&lt;br&gt;
        marcbrooker@gmail.com
      &lt;/br&gt;&lt;/br&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href="https://brooker.co.za/blog/rss.xml"&gt;&lt;img src="https://brooker.co.za/blog/images/feed-icon-14x14.png"/&gt; RSS&lt;/a&gt;
&lt;a href="https://brooker.co.za/blog/atom.xml"&gt;&lt;img src="https://brooker.co.za/blog/images/feed-icon-14x14.png"/&gt; Atom&lt;/a&gt;
&lt;/p&gt;


&lt;!-- &lt;a rel="license" href="http://creativecommons.org/licenses/by/4.0/"&gt;&lt;img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by/4.0/88x31.png" /&gt;&lt;/a&gt;&lt;br /&gt; --&gt;
      This work is licensed under a &lt;a href="http://creativecommons.org/licenses/by/4.0/"&gt;Creative Commons Attribution 4.0 International License&lt;/a&gt;.
    


&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://brooker.co.za/blog/2024/05/09/nagle.html</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 21:09:59 +0000</pubDate>
    </item>
    <item>
      <title>Ultrasound Cancer Treatment: Sound Waves Fight Tumors</title>
      <link>https://spectrum.ieee.org/ultrasound-cancer-treatment</link>
      <description>HistoSonics turns its tumor-liquifying tech against pancreatic cancer</description>
      <content:encoded>&lt;article class="clearfix image-article sm-mb-1 quality-HD post-2674366292" data-category="Biomedical" data-frozen-sections="[]" elid="2674366292"&gt;&lt;a href="https://spectrum.ieee.org/topic/biomedical/"&gt;Biomedical&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/magazine/"&gt;Magazine&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/type/feature/"&gt;Feature&lt;/a&gt;&lt;h1&gt;
        Ultrasound Treatment Takes on Cancer’s Toughest Tumors
    &lt;/h1&gt;&lt;h2&gt;&lt;p&gt;HistoSonics turns its tumor-liquifying tech against pancreatic cancer&lt;/p&gt;&lt;/h2&gt;&lt;a href="https://spectrum.ieee.org/u/greg-uyeno"&gt;Greg Uyeno&lt;/a&gt;22 Dec 20253 min read&lt;!-- EMAIL --&gt;&lt;a href="mailto:?subject=Ultrasound%20Treatment%20Takes%20on%20Cancer%E2%80%99s%20Toughest%20Tumors&amp;amp;body=https://spectrum.ieee.org/ultrasound-cancer-treatment"&gt;&lt;/a&gt;&lt;!-- COPY LINK --&gt;&lt;!-- TWITTER --&gt;&lt;!-- FACEBOOK --&gt;&lt;!-- LINKEDIN --&gt;&lt;img alt="Illustration of the HistoSonics device over a patient’s abdomen, sending ultrasound through a water-filled membrane into the body. Three insets show a tumor as bubbles form, expand, and break the tumor apart into liquefied tissue." src="https://spectrum.ieee.org/media-library/illustration-of-the-histosonics-device-over-a-patients-abdomen-sending-ultrasound-through-a-water-filled-membrane-into-the-bod.png?id=62599195&amp;amp;width=1199&amp;amp;height=1280"/&gt;&lt;p&gt;HistoSonics’ Edison system uses a water-filled membrane to transmit focused ultrasound into the body. The resulting bubbles expand and collapse within the tumor, producing mechanical stress that destroys cancer cells and liquefies the tumor.&lt;/p&gt;Gyginfographics.com&lt;p&gt;&lt;strong&gt;For many years,&lt;/strong&gt; doctors and technicians who performed medical &lt;a href="https://spectrum.ieee.org/focused-ultrasound-stimulation-inflammation-diabetes"&gt;ultrasound&lt;/a&gt; procedures viewed bubbles with wary concern. The phenomenon of cavitation—the formation and collapse of tiny gas bubbles due to changes in pressure—was considered an undesirable and largely uncontrollable side effect. But in 2001, researchers at the University of Michigan began exploring ways to harness the phenomenon for the destruction of cancerous tumors and other problematic tissue.&lt;/p&gt;&lt;p&gt;The trouble was, creating and controlling cavitation generated heat, which harmed healthy tissue beyond the target area. &lt;a href="https://bme.umich.edu/people/xu-zhen/"&gt;Zhen Xu&lt;/a&gt;, who was working on a Ph.D. in &lt;a href="https://spectrum.ieee.org/tag/biomedical-engineering"&gt;biomedical engineering&lt;/a&gt; at the time, was bombarding pig heart tissue in a tank of water with &lt;a href="https://spectrum.ieee.org/tag/ultrasound"&gt;ultrasound&lt;/a&gt; when she made a breakthrough.&lt;/p&gt;&lt;p&gt;The key was using extremely powerful ultrasound to produce negative pressure of more than 20 megapascals, delivered in short bursts measured in microseconds—but separated by relatively long gaps, between a millisecond and a full second long. These parameters created bubbles that quickly formed and collapsed, tearing apart nearby cells and turning the tissue into a kind of slurry, while avoiding heat buildup. The result was a form of incisionless &lt;a href="https://spectrum.ieee.org/tag/surgery"&gt;surgery&lt;/a&gt;, a way to wipe out tumors without scalpels, &lt;a href="https://spectrum.ieee.org/tag/radiation"&gt;radiation&lt;/a&gt;, or heat.&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;“The experiments worked,” says Xu, now a professor at Michigan, “but I also destroyed the ultrasound equipment that I used,” which was the most powerful available at the time. In 2009, she cofounded a company, &lt;a href="https://histosonics.com/"&gt;HistoSonics&lt;/a&gt;, to commercialize more powerful ultrasound machines, test treatment of a variety of diseases, and make the procedure, called histotripsy, widely available.&lt;/p&gt;&lt;p&gt;So far, the killer app is fighting &lt;a href="https://spectrum.ieee.org/tag/cancer"&gt;cancer&lt;/a&gt;. In 2023, HistoSonics’ Edison system received &lt;a href="https://spectrum.ieee.org/tag/fda"&gt;FDA&lt;/a&gt; approval for &lt;a href="https://histosonics.com/news/fda-awards-histosonics-clearance-of-its-first-of-a-kind-edison-histotripsy-system-2/"&gt;treatment of liver tumors&lt;/a&gt;. In 2026, clinicians will conclude a &lt;a href="https://histosonics.com/news/worlds-first-kidney-tumor-treated-using-the-histosonics-edison-histotripsy-system/"&gt;pivotal kidney cancer study&lt;/a&gt; and apply for regulatory approval. They’ll also launch a large-scale pivotal trial for pancreatic &lt;a href="https://spectrum.ieee.org/tag/cancer"&gt;cancer&lt;/a&gt;, considered one of the deadliest forms of the disease with a five-year survival rate of just &lt;a href="https://pancan.org/press-releases/pancreatic-cancer-diagnoses-and-mortality-rates-climb-five-year-survival-rate-for-pancreatic-cancer-stalls-at-13/"&gt;13 percent&lt;/a&gt;. An effective treatment for pancreatic cancer would represent a major advance against one of the most lethal malignancies.&lt;/p&gt;&lt;h2&gt;Histotripsy’s Benefits for Cancer Treatment&lt;/h2&gt;&lt;p&gt;HistoSonics is not the only developer of histotripsy devices or techniques, but it is first to market with a purpose-built device. “What HistoSonics has developed is a symphony of technologies, which combines physics, biology, and biomedical engineering,” says &lt;a href="https://www.cc.nih.gov/meet-our-doctors/bwood"&gt;Bradford Wood&lt;/a&gt;, an interventional radiologist at the National Institutes of Health, who is not affiliated with the company. Its engineering effort has spanned multiple disciplines to produce robotic, computer-guided systems that turn physical forces into therapeutic effects.&lt;/p&gt;&lt;p&gt;Over the past decade, research has confirmed or found other benefits of histotripsy. With precise calibration, fibrous tissue—such as blood vessels—can be spared from damage even in the target zone. And while other noninvasive techniques may leave scar tissue, the liquefied debris created by histotripsy is cleared away by the body’s natural processes.&lt;/p&gt;&lt;p&gt;In HistoSonics’ early trials for pancreatic cancer, doctors used &lt;a href="https://spectrum.ieee.org/tag/focused-ultrasound"&gt;focused ultrasound&lt;/a&gt; pulses to ablate, or destroy, tumors deep within the pancreas. “It’s a great achievement for the entire field to show that it is possible to ablate pancreatic tumors and that it’s well tolerated,” says &lt;a href="https://gastro.uw.edu/people/faculty/khokhlova-t"&gt;Tatiana Khokhlova&lt;/a&gt;, a medical ultrasound researcher at the University of Washington, in Seattle, who has worked on alternative histotripsy techniques.&lt;/p&gt;&lt;p&gt;Khokhlova says the key to harnessing histotripsy’s benefits “will be combining ablation of the primary tumor in the pancreas with some other therapy.” Combination treatment could fight recurrent cancer and tiny tumors that ultrasound might miss, while also tapping into a surprising benefit.&lt;/p&gt;&lt;p&gt;Histotripsy generally seems to &lt;a href="https://pubmed.ncbi.nlm.nih.gov/31940590/"&gt;stimulate an immune response&lt;/a&gt;, helping the body attack cancer cells that weren’t targeted directly by ultrasound. The mechanical destruction of tumors likely leaves behind recognizable traces of cancer proteins that help the immune system learn to identify and destroy similar cells elsewhere in the body, explains Wood. Researchers are now exploring ways to pair histotripsy with immunotherapy to amplify that effect.&lt;/p&gt;&lt;p&gt;The company’s capacity to explore the treatment‘s potential for different conditions will only improve with time, says HistoSonics CEO &lt;a href="https://www.linkedin.com/in/mike-blue-860b9522/"&gt;Mike Blue&lt;/a&gt;. The company has fresh resources to accelerate R&amp;amp;D: A new ownership group, which includes billionaire &lt;a href="https://spectrum.ieee.org/tag/jeff-bezos"&gt;Jeff Bezos&lt;/a&gt;, &lt;a href="https://www.businesswire.com/news/home/20250807749442/en/HistoSonics-Announces-%242.25B-Acquisition-by-Consortium-of-Top-Tier-Investors"&gt;acquired&lt;/a&gt; HistoSonics in August 2025 at a valuation of US $2.25 billion. &lt;/p&gt;&lt;p&gt;Engineers are already testing a new guidance system that uses a form of &lt;a href="https://spectrum.ieee.org/tag/x-rays"&gt;X-rays&lt;/a&gt; rather than &lt;a href="https://spectrum.ieee.org/tag/ultrasound-imaging"&gt;ultrasound imaging&lt;/a&gt;, which should expand use cases. The R&amp;amp;D team is also developing a feedback system that analyzes echoes from the therapeutic ultrasound to detect tissue destruction and integrates that information into the live display, says Blue.&lt;/p&gt;&lt;p&gt;If those advances pan out, histotripsy could move well beyond the liver, kidney, and pancreas in the fight against cancer. What started as a curiosity about bubbles might soon become a new pillar of noninvasive medicine—a future in which surgeons wield not scalpels, but sound waves.&lt;/p&gt;From Your Site Articles&lt;ul&gt;&lt;li&gt;&lt;a href="https://spectrum.ieee.org/focused-ultrasound-stimulation-inflammation-diabetes"&gt;Doctors Could Hack the Nervous System With Ultrasound ›&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://spectrum.ieee.org/cancer-ultrasound-blood-brain-barrier"&gt;Ultrasound Opens New Front Against Lethal Brain Cancer in Kids ›&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;Related Articles Around the Web&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.uchicagomedicine.org/cancer/types-treatments/histotripsy"&gt;Histotripsy - Liver Cancer Ultrasound - UChicago Medicine ›&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://news.umich.edu/tumor-destroying-sound-waves-receive-fda-approval-for-liver-treatment-in-humans/"&gt;Tumor-destroying sound waves receive FDA approval for liver ... ›&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;a href="https://spectrum.ieee.org/tag/cancer"&gt;cancer&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/tag/cancer-therapy"&gt;cancer therapy&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/tag/focused-ultrasound"&gt;focused ultrasound&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/tag/immune-system"&gt;immune system&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/tag/pancreas"&gt;pancreas&lt;/a&gt;&lt;a href="https://spectrum.ieee.org/tag/ultrasound"&gt;ultrasound&lt;/a&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://spectrum.ieee.org/ultrasound-cancer-treatment</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 19:37:34 +0000</pubDate>
    </item>
    <item>
      <title>The Illustrated Transformer</title>
      <link>https://jalammar.github.io/illustrated-transformer/</link>
      <description>Discussions: Hacker News (65 points, 4 comments) , Reddit r/MachineLearning (29 points, 3 comments) Translations: Arabic , Chinese (Simplified) 1 , Chinese (Simplified) 2 , French 1 , French 2 , Italian , Japanese , Korean , Persian , Russian , Spanish 1 , Spanish 2 , Vietnamese Watch: MIT’s Deep Learning State of the Art lecture referencing this post Featured in courses at Stanford , Harvard , MIT , Princeton , CMU and others</description>
      <content:encoded>&lt;article class="post"&gt;
&lt;h1&gt;The Illustrated Transformer&lt;/h1&gt;

&lt;p&gt;Discussions:
&lt;a href="https://news.ycombinator.com/item?id=18351674"&gt;Hacker News (65 points, 4 comments)&lt;/a&gt;, &lt;a href="https://www.reddit.com/r/MachineLearning/comments/8uh2yz/p_the_illustrated_transformer_a_visual_look_at/"&gt;Reddit r/MachineLearning (29 points, 3 comments)&lt;/a&gt;

&lt;br/&gt;
Translations: &lt;a href="https://www.mundhor.site/post/post14"&gt;Arabic&lt;/a&gt;, &lt;a href="https://blog.csdn.net/yujianmin1990/article/details/85221271"&gt;Chinese (Simplified) 1&lt;/a&gt;, &lt;a href="https://blog.csdn.net/qq_36667170/article/details/124359818"&gt;Chinese (Simplified) 2&lt;/a&gt;, &lt;a href="https://a-coles.github.io/2020/11/15/transformer-illustre.html"&gt;French 1&lt;/a&gt;, &lt;a href="https://lbourdois.github.io/blog/nlp/Transformer/"&gt;French 2&lt;/a&gt;, &lt;a href="https://medium.com/@val.mannucci/il-transformer-illustrato-it-37a78e3e2348"&gt;Italian&lt;/a&gt;, &lt;a href="https://tips-memo.com/translation-jayalmmar-transformer"&gt;Japanese&lt;/a&gt;, &lt;a href="https://nlpinkorean.github.io/illustrated-transformer/"&gt;Korean&lt;/a&gt;, &lt;a href="http://dml.qom.ac.ir/2022/05/17/illustrated-transformer/"&gt;Persian&lt;/a&gt;, &lt;a href="https://habr.com/ru/post/486358/"&gt;Russian&lt;/a&gt;, &lt;a href="https://www.ibidemgroup.com/edu/transformer-ilustrado-jay-alammar/"&gt;Spanish 1&lt;/a&gt;, &lt;a href="https://hackernoon.com/el-transformador-ilustrado-una-traduccion-al-espanol-0y73wwp"&gt;Spanish 2&lt;/a&gt;, &lt;a href="https://trituenhantao.io/tin-tuc/minh-hoa-transformer/"&gt;Vietnamese&lt;/a&gt;
&lt;br/&gt;
Watch: MIT’s &lt;a href="https://youtu.be/53YvP6gdD7U?t=432"&gt;Deep Learning State of the Art&lt;/a&gt; lecture referencing this post
&lt;br/&gt;
Featured in courses at &lt;a href="https://web.stanford.edu/class/cs224n/"&gt;Stanford&lt;/a&gt;, &lt;a href="https://scholar.harvard.edu/binxuw/classes/machine-learning-scratch/materials/transformers"&gt;Harvard&lt;/a&gt;, &lt;a href="https://ocw.mit.edu/courses/6-s897-machine-learning-for-healthcare-spring-2019/d39a6eed387ee90b1f72a01949c35c7b_MIT6_S897S19_lec8.pdf"&gt;MIT&lt;/a&gt;, &lt;a href="https://www.cs.princeton.edu/courses/archive/fall22/cos597G/"&gt;Princeton&lt;/a&gt;, &lt;a href="https://www.cs.cmu.edu/~leili/course/mldl22w/14-Transformer.pdf"&gt;CMU&lt;/a&gt; and others&lt;/p&gt;



&lt;a href="https://www.llm-book.com"&gt;&lt;img src="https://github.com/user-attachments/assets/a471dfff-00cc-4cb4-8df5-123e195bcc71"/&gt;&lt;/a&gt;

Update: This post has now become a book! Check out &lt;a href="https://llm-book.com"&gt;LLM-book.com&lt;/a&gt; which contains (Chapter 3) an updated and expanded version of this post speaking about the latest Transformer models and how they've evolved in the seven years since the original Transformer (like Multi-Query Attention and RoPE Positional embeddings).
  


&lt;p&gt;In the &lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/"&gt;previous post, we looked at Attention&lt;/a&gt; – a ubiquitous method in modern deep learning models. Attention is a concept that helped improve the performance of neural machine translation applications. In this post, we will look at &lt;strong&gt;The Transformer&lt;/strong&gt; – a model that uses attention to boost the speed with which these models can be trained. The Transformer outperforms the Google Neural Machine Translation model in specific tasks. The biggest benefit, however, comes from how The Transformer lends itself to parallelization. It is in fact Google Cloud’s recommendation to use The Transformer as a reference model to use their &lt;a href="https://cloud.google.com/tpu/"&gt;Cloud TPU&lt;/a&gt; offering. So let’s try to break the model apart and look at how it functions.&lt;/p&gt;
&lt;p&gt;The Transformer was proposed in the paper &lt;a href="https://arxiv.org/abs/1706.03762"&gt;Attention is All You Need&lt;/a&gt;. A TensorFlow implementation of it is available as a part of the &lt;a href="https://github.com/tensorflow/tensor2tensor"&gt;Tensor2Tensor&lt;/a&gt; package. Harvard’s NLP group created a &lt;a href="http://nlp.seas.harvard.edu/2018/04/03/attention.html"&gt;guide annotating the paper with PyTorch implementation&lt;/a&gt;. In this post, we will attempt to oversimplify things a bit and introduce the concepts one by one to hopefully make it easier to understand to people without in-depth knowledge of the subject matter.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2025 Update&lt;/strong&gt;: We’ve built a &lt;a href="https://bit.ly/4aRnn7Z"&gt;free short course&lt;/a&gt; that brings the contents of this post up-to-date with animations:&lt;/p&gt;



&lt;h2&gt;A High-Level Look&lt;/h2&gt;
&lt;p&gt;Let’s begin by looking at the model as a single black box. In a machine translation application, it would take a sentence in one language, and output its translation in another.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/the_transformer_3.png"/&gt;

&lt;!--more--&gt;
&lt;p&gt;Popping open that Optimus Prime goodness, we see an encoding component, a decoding component, and connections between them.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png"/&gt;

&lt;p&gt;The encoding component is a stack of encoders (the paper stacks six of them on top of each other – there’s nothing magical about the number six, one can definitely experiment with other arrangements). The decoding component is a stack of decoders of the same number.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png"/&gt;

&lt;p&gt;The encoders are all identical in structure (yet they do not share weights). Each one is broken down into two sub-layers:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/Transformer_encoder.png"/&gt;

&lt;p&gt;The encoder’s inputs first flow through a self-attention layer – a layer that helps the encoder look at other words in the input sentence as it encodes a specific word. We’ll look closer at self-attention later in the post.&lt;/p&gt;
&lt;p&gt;The outputs of the self-attention layer are fed to a feed-forward neural network. The exact same feed-forward network is independently applied to each position.&lt;/p&gt;
&lt;p&gt;The decoder has both those layers, but between them is an attention layer that helps the decoder focus on relevant parts of the input sentence (similar what attention does in &lt;a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/"&gt;seq2seq models&lt;/a&gt;).&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/Transformer_decoder.png"/&gt;

&lt;h2&gt;Bringing The Tensors Into The Picture&lt;/h2&gt;
&lt;p&gt;Now that we’ve seen the major components of the model, let’s start to look at the various vectors/tensors and how they flow between these components to turn the input of a trained model into an output.&lt;/p&gt;
&lt;p&gt;As is the case in NLP applications in general, we begin by turning each input word into a vector using an &lt;a href="https://medium.com/deeper-learning/glossary-of-deep-learning-word-embedding-f90c3cec34ca"&gt;embedding algorithm&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/embeddings.png"/&gt;
&lt;br/&gt;
  Each word is embedded into a vector of size 512. We'll represent those vectors with these simple boxes.

&lt;p&gt;The embedding only happens in the bottom-most encoder. The abstraction that is common to all the encoders is that they receive a list of vectors each of the size 512 – In the bottom encoder that would be the word embeddings, but in other encoders, it would be the output of the encoder that’s directly below. The size of this list is hyperparameter we can set – basically it would be the length of the longest sentence in our training dataset.&lt;/p&gt;
&lt;p&gt;After embedding the words in our input sequence, each of them flows through each of the two layers of the encoder.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors.png"/&gt;
&lt;br/&gt;

&lt;p&gt;Here we begin to see one key property of the Transformer, which is that the word in each position flows through its own path in the encoder. There are dependencies between these paths in the self-attention layer. The feed-forward layer does not have those dependencies, however, and thus the various paths can be executed in parallel while flowing through the feed-forward layer.&lt;/p&gt;
&lt;p&gt;Next, we’ll switch up the example to a shorter sentence and we’ll look at what happens in each sub-layer of the encoder.&lt;/p&gt;
&lt;h2&gt;Now We’re Encoding!&lt;/h2&gt;
&lt;p&gt;As we’ve mentioned already, an encoder receives a list of vectors as input. It processes this list by passing these vectors into a ‘self-attention’ layer, then into a feed-forward neural network, then sends out the output upwards to the next encoder.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/encoder_with_tensors_2.png"/&gt;
&lt;br/&gt;
  The word at each position passes through a self-attention process. Then, they each pass through a feed-forward neural network -- the exact same network with each vector flowing through it separately.

&lt;h2&gt;Self-Attention at a High Level&lt;/h2&gt;
&lt;p&gt;Don’t be fooled by me throwing around the word “self-attention” like it’s a concept everyone should be familiar with. I had personally never came across the concept until reading the Attention is All You Need paper. Let us distill how it works.&lt;/p&gt;
&lt;p&gt;Say the following sentence is an input sentence we want to translate:&lt;/p&gt;
&lt;p&gt;”&lt;code&gt;The animal didn't cross the street because it was too tired&lt;/code&gt;”&lt;/p&gt;
&lt;p&gt;What does “it” in this sentence refer to? Is it referring to the street or to the animal? It’s a simple question to a human, but not as simple to an algorithm.&lt;/p&gt;
&lt;p&gt;When the model is processing the word “it”, self-attention allows it to associate “it” with “animal”.&lt;/p&gt;
&lt;p&gt;As the model processes each word (each position in the input sequence), self attention allows it to look at other positions in the input sequence for clues that can help lead to a better encoding for this word.&lt;/p&gt;
&lt;p&gt;If you’re familiar with RNNs, think of how maintaining a hidden state allows an RNN to incorporate its representation of previous words/vectors it has processed with the current one it’s processing. Self-attention is the method the Transformer uses to bake the “understanding” of other relevant words into the one we’re currently processing.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization.png"/&gt;
&lt;br/&gt;
  As we are encoding the word "it" in encoder #5 (the top encoder in the stack), part of the attention mechanism was focusing on "The Animal", and baked a part of its representation into the encoding of "it".

&lt;p&gt;Be sure to check out the &lt;a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb"&gt;Tensor2Tensor notebook&lt;/a&gt; where you can load a Transformer model, and examine it using this interactive visualization.&lt;/p&gt;
&lt;h2&gt;Self-Attention in Detail&lt;/h2&gt;
&lt;p&gt;Let’s first look at how to calculate self-attention using vectors, then proceed to look at how it’s actually implemented – using matrices.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;first step&lt;/strong&gt; in calculating self-attention is to create three vectors from each of the encoder’s input vectors (in this case, the embedding of each word). So for each word, we create a Query vector, a Key vector, and a Value vector. These vectors are created by multiplying the embedding by three matrices that we trained during the training process.&lt;/p&gt;
&lt;p&gt;Notice that these new vectors are smaller in dimension than the embedding vector. Their dimensionality is 64, while the embedding and encoder input/output vectors have dimensionality of 512. They don’t HAVE to be smaller, this is an architecture choice to make the computation of multiheaded attention (mostly) constant.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_self_attention_vectors.png"/&gt;
&lt;br/&gt;
  Multiplying x1 by the WQ weight matrix produces q1, the "query" vector associated with that word. We end up creating a "query", a "key", and a "value" projection of each word in the input sentence.

&lt;p&gt;&lt;br/&gt;
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;What are the “query”, “key”, and “value” vectors?
&lt;br/&gt;
&lt;br/&gt;
They’re abstractions that are useful for calculating and thinking about attention. Once you proceed with reading how attention is calculated below, you’ll know pretty much all you need to know about the role each of these vectors plays.&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;second step&lt;/strong&gt; in calculating self-attention is to calculate a score. Say we’re calculating the self-attention for the first word in this example, “Thinking”. We need to score each word of the input sentence against this word. The score determines how much focus to place on other parts of the input sentence as we encode a word at a certain position.&lt;/p&gt;
&lt;p&gt;The score is calculated by taking the dot product of the query vector with the key vector of the respective word we’re scoring. So if we’re processing the self-attention for the word in position #1, the first score would be the dot product of q1 and k1. The second score would be the dot product of q1 and k2.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_self_attention_score.png"/&gt;
&lt;br/&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;third and fourth steps&lt;/strong&gt; are to divide the scores by 8 (the square root of the dimension of the key vectors used in the paper – 64. This leads to having more stable gradients. There could be other possible values here, but this is the default), then pass the result through a softmax operation. Softmax normalizes the scores so they’re all positive and add up to 1.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/self-attention_softmax.png"/&gt;
&lt;br/&gt;

&lt;p&gt;This softmax score determines how much each word will be expressed at this position. Clearly the word at this position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;fifth step&lt;/strong&gt; is to multiply each value vector by the softmax score (in preparation to sum them up). The intuition here is to keep intact the values of the word(s) we want to focus on, and drown-out irrelevant words (by multiplying them by tiny numbers like 0.001, for example).&lt;/p&gt;
&lt;p&gt;The &lt;strong&gt;sixth step&lt;/strong&gt; is to sum up the weighted value vectors. This produces the output of the self-attention layer at this position (for the first word).&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/self-attention-output.png"/&gt;
&lt;br/&gt;

&lt;p&gt;That concludes the self-attention calculation. The resulting vector is one we can send along to the feed-forward neural network. In the actual implementation, however, this calculation is done in matrix form for faster processing. So let’s look at that now that we’ve seen the intuition of the calculation on the word level.&lt;/p&gt;
&lt;h2&gt;Matrix Calculation of Self-Attention&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;The first step&lt;/strong&gt; is to calculate the Query, Key, and Value matrices. We do that by packing our embeddings into a matrix X, and multiplying it by the weight matrices we’ve trained (WQ, WK, WV).&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation.png"/&gt;
&lt;br/&gt;
  Every row in the X matrix corresponds to a word in the input sentence. We again see the difference in size of the embedding vector (512, or 4 boxes in the figure), and the q/k/v vectors (64, or 3 boxes in the figure)

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Finally&lt;/strong&gt;, since we’re dealing with matrices, we can condense steps two through six in one formula to calculate the outputs of the self-attention layer.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/self-attention-matrix-calculation-2.png"/&gt;
&lt;br/&gt;
  The self-attention calculation in matrix form

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;The Beast With Many Heads&lt;/h2&gt;
&lt;p&gt;The paper further refined the self-attention layer by adding a mechanism called “multi-headed” attention. This improves the performance of the attention layer in two ways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;It expands the model’s ability to focus on different positions. Yes, in the example above, z1 contains a little bit of every other encoding, but it could be dominated by the actual word itself. If we’re translating a sentence like “The animal didn’t cross the street because it was too tired”, it would be useful to know which word “it” refers to.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;It gives the attention layer multiple “representation subspaces”. As we’ll see next, with multi-headed attention we have not only one, but multiple sets of Query/Key/Value weight matrices (the Transformer uses eight attention heads, so we end up with eight sets for each encoder/decoder). Each of these sets is randomly initialized. Then, after training, each set is used to project the input embeddings (or vectors from lower encoders/decoders) into a different representation subspace.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_qkv.png"/&gt;
&lt;br/&gt;
   With multi-headed attention, we maintain separate Q/K/V weight matrices for each head resulting in different Q/K/V matrices. As we did before, we multiply X by the WQ/WK/WV matrices to produce Q/K/V matrices.
 
&lt;p&gt;&lt;br/&gt;
If we do the same self-attention calculation we outlined above, just eight different times with different weight matrices, we end up with eight different Z matrices&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_z.png"/&gt;
&lt;br/&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;This leaves us with a bit of a challenge. The feed-forward layer is not expecting eight matrices – it’s expecting a single matrix (a vector for each word). So we need a way to condense these eight down into a single matrix.&lt;/p&gt;
&lt;p&gt;How do we do that? We concat the matrices then multiply them by an additional weights matrix WO.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_attention_heads_weight_matrix_o.png"/&gt;
&lt;br/&gt;

&lt;p&gt;That’s pretty much all there is to multi-headed self-attention. It’s quite a handful of matrices, I realize. Let me try to put them all in one visual so we can look at them in one place&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png"/&gt;
&lt;br/&gt;

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;Now that we have touched upon attention heads, let’s revisit our example from before to see where the different attention heads are focusing as we encode the word “it” in our example sentence:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_2.png"/&gt;
&lt;br/&gt;
  As we encode the word "it", one attention head is focusing most on "the animal", while another is focusing on "tired" -- in a sense, the model's representation of the word "it" bakes in some of the representation of both "animal" and "tired".

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;If we add all the attention heads to the picture, however, things can be harder to interpret:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_self-attention_visualization_3.png"/&gt;
&lt;br/&gt;

&lt;h2&gt;Representing The Order of The Sequence Using Positional Encoding&lt;/h2&gt;
&lt;p&gt;One thing that’s missing from the model as we have described it so far is a way to account for the order of the words in the input sequence.&lt;/p&gt;
&lt;p&gt;To address this, the transformer adds a vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word, or the distance between different words in the sequence. The intuition here is that adding these values to the embeddings provides meaningful distances between the embedding vectors once they’re projected into Q/K/V vectors and during dot-product attention.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_vectors.png"/&gt;
&lt;br/&gt;
  To give the model a sense of the order of the words, we add positional encoding vectors -- the values of which follow a specific pattern.

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;If we assumed the embedding has a dimensionality of 4, the actual positional encodings would look like this:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_example.png"/&gt;
&lt;br/&gt;
  A real example of positional encoding with a toy embedding size of 4

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;What might this pattern look like?&lt;/p&gt;
&lt;p&gt;In the following figure, each row corresponds to a positional encoding of a vector. So the first row would be the vector we’d add to the embedding of the first word in an input sequence. Each row contains 512 values – each with a value between 1 and -1. We’ve color-coded them so the pattern is visible.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_positional_encoding_large_example.png"/&gt;
&lt;br/&gt;
  A real example of positional encoding for 20 words (rows) with an embedding size of 512 (columns). You can see that it appears split in half down the center. That's because the values of the left half are generated by one function (which uses sine), and the right half is generated by another function (which uses cosine). They're then concatenated to form each of the positional encoding vectors.

&lt;p&gt;The formula for positional encoding is described in the paper (section 3.5). You can see the code for generating positional encodings in &lt;a href="https://github.com/tensorflow/tensor2tensor/blob/23bd23b9830059fbc349381b70d9429b5c40a139/tensor2tensor/layers/common_attention.py"&gt;&lt;code&gt;get_timing_signal_1d()&lt;/code&gt;&lt;/a&gt;. This is not the only possible method for positional encoding. It, however, gives the advantage of being able to scale to unseen lengths of sequences (e.g. if our trained model is asked to translate a sentence longer than any of those in our training set).&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;July 2020 Update:&lt;/strong&gt; 
The positional encoding shown above is from the Tensor2Tensor implementation of the Transformer. The method shown in the paper is slightly different in that it doesn’t directly concatenate, but interweaves the two signals. The following figure shows what that looks like. &lt;a href="https://github.com/jalammar/jalammar.github.io/blob/master/notebookes/transformer/transformer_positional_encoding_graph.ipynb"&gt;Here’s the code to generate it&lt;/a&gt;:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/attention-is-all-you-need-positional-encoding.png"/&gt;
&lt;br/&gt;

&lt;h2&gt;The Residuals&lt;/h2&gt;
&lt;p&gt;One detail in the architecture of the encoder that we need to mention before moving on, is that each sub-layer (self-attention, ffnn) in each encoder has a residual connection around it, and is followed by a &lt;a href="https://arxiv.org/abs/1607.06450"&gt;layer-normalization&lt;/a&gt; step.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm.png"/&gt;
&lt;br/&gt;

&lt;p&gt;If we’re to visualize the vectors and the layer-norm operation associated with self attention, it would look like this:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_2.png"/&gt;
&lt;br/&gt;

&lt;p&gt;This goes for the sub-layers of the decoder as well. If we’re to think of a Transformer of 2 stacked encoders and decoders, it would look something like this:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_resideual_layer_norm_3.png"/&gt;
&lt;br/&gt;

&lt;h2&gt;The Decoder Side&lt;/h2&gt;
&lt;p&gt;Now that we’ve covered most of the concepts on the encoder side, we basically know how the components of decoders work as well. But let’s take a look at how they work together.&lt;/p&gt;
&lt;p&gt;The encoder start by processing the input sequence. The output of the top encoder is then transformed into a set of attention vectors K and V. These are to be used by each decoder in its “encoder-decoder attention” layer which helps the decoder focus on appropriate places in the input sequence:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_1.gif"/&gt;
&lt;br/&gt;
  After finishing the encoding phase, we begin the decoding phase. Each step in the decoding phase outputs an element from the output sequence (the English translation sentence in this case).

&lt;p&gt;The following steps repeat the process until a special  symbol is reached indicating the transformer decoder has completed its output. The output of each step is fed to the bottom decoder in the next time step, and the decoders bubble up their decoding results just like the encoders did. And just like we did with the encoder inputs, we embed and add positional encoding to those decoder inputs to indicate the position of each word.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_decoding_2.gif"/&gt;
&lt;br/&gt;

&lt;p&gt;The self attention layers in the decoder operate in a slightly different way than the one in the encoder:&lt;/p&gt;
&lt;p&gt;In the decoder, the self-attention layer is only allowed to attend to earlier positions in the output sequence. This is done by masking future positions (setting them to &lt;code&gt;-inf&lt;/code&gt;) before the softmax step in the self-attention calculation.&lt;/p&gt;
&lt;p&gt;The “Encoder-Decoder Attention” layer works just like multiheaded self-attention, except it creates its Queries matrix from the layer below it, and takes the Keys and Values matrix from the output of the encoder stack.&lt;/p&gt;
&lt;h2&gt;The Final Linear and Softmax Layer&lt;/h2&gt;
&lt;p&gt;The decoder stack outputs a vector of floats. How do we turn that into a word? That’s the job of the final Linear layer which is followed by a Softmax Layer.&lt;/p&gt;
&lt;p&gt;The Linear layer is a simple fully connected neural network that projects the vector produced by the stack of decoders, into a much, much larger vector called a logits vector.&lt;/p&gt;
&lt;p&gt;Let’s assume that our model knows 10,000 unique English words (our model’s “output vocabulary”) that it’s learned from its training dataset. This would make the logits vector 10,000 cells wide – each cell corresponding to the score of a unique word. That is how we interpret the output of the model followed by the Linear layer.&lt;/p&gt;
&lt;p&gt;The softmax layer then turns those scores into probabilities (all positive, all add up to 1.0). The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_decoder_output_softmax.png"/&gt;
&lt;br/&gt;
  This figure starts from the bottom with the vector produced as the output of the decoder stack. It is then turned into an output word.

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;h2&gt;Recap Of Training&lt;/h2&gt;
&lt;p&gt;Now that we’ve covered the entire forward-pass process through a trained Transformer, it would be useful to glance at the intuition of training the model.&lt;/p&gt;
&lt;p&gt;During training, an untrained model would go through the exact same forward pass. But since we are training it on a labeled training dataset, we can compare its output with the actual correct output.&lt;/p&gt;
&lt;p&gt;To visualize this, let’s assume our output vocabulary only contains six words(“a”, “am”, “i”, “thanks”, “student”, and “&amp;lt;eos&amp;gt;” (short for ‘end of sentence’)).&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/vocabulary.png"/&gt;
&lt;br/&gt;
   The output vocabulary of our model is created in the preprocessing phase before we even begin training.
 
&lt;p&gt;Once we define our output vocabulary, we can use a vector of the same width to indicate each word in our vocabulary. This also known as one-hot encoding. So for example, we can indicate the word “am” using the following vector:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/one-hot-vocabulary-example.png"/&gt;
&lt;br/&gt;
  Example: one-hot encoding of our output vocabulary

&lt;p&gt;Following this recap, let’s discuss the model’s loss function – the metric we are optimizing during the training phase to lead up to a trained and hopefully amazingly accurate model.&lt;/p&gt;
&lt;h2&gt;The Loss Function&lt;/h2&gt;
&lt;p&gt;Say we are training our model. Say it’s our first step in the training phase, and we’re training it on a simple example – translating “merci” into “thanks”.&lt;/p&gt;
&lt;p&gt;What this means, is that we want the output to be a probability distribution indicating the word “thanks”. But since this model is not yet trained, that’s unlikely to happen just yet.&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/transformer_logits_output_and_label.png"/&gt;
&lt;br/&gt;
  Since the model's parameters (weights) are all initialized randomly, the (untrained) model produces a probability distribution with arbitrary values for each cell/word. We can compare it with the actual output, then tweak all the model's weights using backpropagation to make the output closer to the desired output.

&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;How do you compare two probability distributions? We simply subtract one from the other. For more details, look at  &lt;a href="https://colah.github.io/posts/2015-09-Visual-Information/"&gt;cross-entropy&lt;/a&gt; and &lt;a href="https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained"&gt;Kullback–Leibler divergence&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But note that this is an oversimplified example. More realistically, we’ll use a sentence longer than one word. For example – input: “je suis étudiant” and expected output: “i am a student”. What this really means, is that we want our model to successively output probability distributions where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Each probability distribution is represented by a vector of width vocab_size (6 in our toy example, but more realistically a number like 30,000 or 50,000)&lt;/li&gt;
&lt;li&gt;The first probability distribution has the highest probability at the cell associated with the word “i”&lt;/li&gt;
&lt;li&gt;The second probability distribution has the highest probability at the cell associated with the word “am”&lt;/li&gt;
&lt;li&gt;And so on, until the fifth output distribution indicates ‘&lt;code&gt;&amp;lt;end of sentence&amp;gt;&lt;/code&gt;’ symbol, which also has a cell associated with it from the 10,000 element vocabulary.&lt;/li&gt;
&lt;/ul&gt;

&lt;img src="https://jalammar.github.io/images/t/output_target_probability_distributions.png"/&gt;
&lt;br/&gt;
   The targeted probability distributions we'll train our model against in the training example for one sample sentence.
 
&lt;p&gt;&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;After training the model for enough time on a large enough dataset, we would hope the produced probability distributions would look like this:&lt;/p&gt;

&lt;img src="https://jalammar.github.io/images/t/output_trained_model_probability_distributions.png"/&gt;
&lt;br/&gt;
    Hopefully upon training, the model would output the right translation we expect. Of course it's no real indication if this phrase was part of the training dataset (see: &lt;a href="https://www.youtube.com/watch?v=TIgfjmp-4BA"&gt;cross validation&lt;/a&gt;). Notice that every position gets a little bit of probability even if it's unlikely to be the output of that time step -- that's a very useful property of softmax which helps the training process.

&lt;p&gt;Now, because the model produces the outputs one at a time, we can assume that the model is selecting the word with the highest probability from that probability distribution and throwing away the rest. That’s one way to do it (called greedy decoding). Another way to do it would be to hold on to, say, the top two words (say, ‘I’ and ‘a’ for example), then in the next step, run the model twice: once assuming the first output position was the word ‘I’, and another time assuming the first output position was the word ‘a’, and whichever version produced less error considering both positions #1 and #2 is kept. We repeat this for positions #2 and #3…etc. This method is called “beam search”, where in our example, beam_size was two (meaning that at all times, two partial hypotheses (unfinished translations) are kept in memory), and top_beams is also two (meaning we’ll return two translations). These are both hyperparameters that you can experiment with.&lt;/p&gt;
&lt;h2&gt;Go Forth And Transform&lt;/h2&gt;
&lt;p&gt;I hope you’ve found this a useful place to start to break the ice with the major concepts of the Transformer. If you want to go deeper, I’d suggest these next steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Read the &lt;a href="https://arxiv.org/abs/1706.03762"&gt;Attention Is All You Need&lt;/a&gt; paper, the Transformer blog post (&lt;a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html"&gt;Transformer: A Novel Neural Network Architecture for Language Understanding&lt;/a&gt;), and the &lt;a href="https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html"&gt;Tensor2Tensor announcement&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Watch &lt;a href="https://www.youtube.com/watch?v=rBCqOTEfxvg"&gt;Łukasz Kaiser’s talk&lt;/a&gt; walking through the model and its details&lt;/li&gt;
&lt;li&gt;Play with the &lt;a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb"&gt;Jupyter Notebook provided as part of the Tensor2Tensor repo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Explore the &lt;a href="https://github.com/tensorflow/tensor2tensor"&gt;Tensor2Tensor repo&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Follow-up works:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1706.03059"&gt;Depthwise Separable Convolutions for Neural Machine Translation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1706.05137"&gt;One Model To Learn Them All&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1801.09797"&gt;Discrete Autoencoders for Sequence Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1801.10198"&gt;Generating Wikipedia by Summarizing Long Sequences&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1802.05751"&gt;Image Transformer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1804.00247"&gt;Training Tips for the Transformer Model&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1803.02155"&gt;Self-Attention with Relative Position Representations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1803.03382"&gt;Fast Decoding in Sequence Models using Discrete Latent Variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://arxiv.org/abs/1804.04235"&gt;Adafactor: Adaptive Learning Rates with Sublinear Memory Cost&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Thanks to &lt;a href="https://twitter.com/ilblackdragon"&gt;Illia Polosukhin&lt;/a&gt;, &lt;a href="http://jakob.uszkoreit.net/"&gt;Jakob Uszkoreit&lt;/a&gt;, &lt;a href="https://www.linkedin.com/in/llion-jones-9ab3064b"&gt;Llion Jones &lt;/a&gt;, &lt;a href="https://ai.google/research/people/LukaszKaiser"&gt;Lukasz Kaiser&lt;/a&gt;, &lt;a href="https://twitter.com/nikiparmar09"&gt;Niki Parmar&lt;/a&gt;, and &lt;a href="https://dblp.org/pers/hd/s/Shazeer:Noam"&gt;Noam Shazeer&lt;/a&gt; for providing feedback on earlier versions of this post.&lt;/p&gt;
&lt;p&gt;Please hit me up on &lt;a href="https://twitter.com/JayAlammar"&gt;Twitter&lt;/a&gt; for any corrections or feedback.&lt;/p&gt;


    Written on June 27, 2018
  
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://jalammar.github.io/illustrated-transformer/</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 19:15:56 +0000</pubDate>
    </item>
    <item>
      <title>GLM-4.7: Advancing the Coding Capability</title>
      <link>https://z.ai/blog/glm-4.7</link>
      <description>GLM-4.7: Advancing the Coding Capability</description>
      <content:encoded>&lt;div class="example-content"&gt;Live StyleCyber DomainArtistic PortfolioPromptbuild a html website, High-contrast dark mode + bold condensed headings + animated ticker + chunky category chips + magnetic CTA.&lt;!-- --&gt; &lt;a href="https://chat.z.ai/s/23c15468-405d-4993-9110-cffa99f79acb"&gt;View full trajectory at Z.ai&lt;img src="https://z-cdn.chatglm.cn/z-blog/z-icon.svg"/&gt;&lt;/a&gt;GLM-4.7GLM-4.6Scroll down to see more&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://z.ai/blog/glm-4.7</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 18:46:32 +0000</pubDate>
    </item>
    <item>
      <title>Toad is a unified experience for AI in the terminal</title>
      <link>https://willmcgugan.github.io/toad-released/</link>
      <description>Will McGugan  ·  December 18, 2025</description>
      <content:encoded>&lt;article class="post detailed"&gt;
&lt;h1&gt;Toad is a unified experience for AI in the terminal&lt;/h1&gt;

&lt;p&gt;Will McGugan  ·  December 18, 2025&lt;/p&gt;

&lt;a href="https://willmcgugan.github.io/categories/#text"&gt;text&lt;/a&gt;
         
      
        &lt;a href="https://willmcgugan.github.io/categories/#toad"&gt;toad&lt;/a&gt;
         
      
        &lt;a href="https://willmcgugan.github.io/categories/#ai"&gt;ai&lt;/a&gt;



&lt;p&gt;My startup for terminals wrapped up mid-2025 when the funding ran dry.
So I don’t have money, but what I do have are a very particular set of skills.
Skills I have acquired over a very long career convincing terminals they are actually GUIs.&lt;/p&gt;
&lt;p&gt;Skills which I have used to create a terminal app that offers a more pleasant experience for agentic coding.
Toad (a play on &lt;em&gt;Textual Code&lt;/em&gt;) is a front-end for AI tools such as &lt;a href="https://openhands.dev/"&gt;OpenHands&lt;/a&gt;, &lt;a href="https://www.claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt;, &lt;a href="https://geminicli.com/"&gt;Gemini CLI&lt;/a&gt;, and many more. 
All of which run seamlessly under a single terminal UI, thanks to the &lt;a href="https://agentclientprotocol.com/protocol/initialization"&gt;ACP&lt;/a&gt; protocol.&lt;/p&gt;
&lt;p&gt;At the time of writing, Toad supports 12 agent CLIs, and I expect many more to come online soon.&lt;/p&gt;
&lt;p&gt;Here’s a screenshot:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Toad UI" src="https://willmcgugan.github.io/images/toad-released/toad-1.png"/&gt;&lt;/p&gt;
&lt;p&gt;So what does Toad offer over the CLI apps from big tech?&lt;/p&gt;
&lt;p&gt;It has most of the UI interactions users have come to expect from agentic coding, but hopefully more refined.
For instance the “@” character to bring in files into the context. Here’s Toad’s implementation:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Toad fuzzy files" src="https://willmcgugan.github.io/images/toad-released/fuzzy-file.gif"/&gt;&lt;/p&gt;
&lt;p&gt;A snappy &lt;em&gt;fuzzy&lt;/em&gt; search which filters patterns from the project’s &lt;code&gt;.gitignore&lt;/code&gt; (if there is one).&lt;/p&gt;
&lt;p&gt;The prompt editor offers an experience which you might be surprised to find in a terminal.
You can navigate and select with the keyboard and mouse, select, cut, copy, paste, etc.
The prompt will highlight Markdown as you type (even syntax highlighting code fences &lt;em&gt;before&lt;/em&gt; you close them).&lt;/p&gt;
&lt;p&gt;&lt;img alt="Toad prompt" src="https://willmcgugan.github.io/images/toad-released/prompt.gif"/&gt;&lt;/p&gt;
&lt;p&gt;Toad has really nice Markdown streaming, based on the techniques I described &lt;a href="https://willmcgugan.github.io/streaming-markdown/"&gt;here&lt;/a&gt;.
It remains fast with large documents, and renders everything from tables to syntax highlighted code fences.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Toad Markdown streaming" src="https://willmcgugan.github.io/images/toad-released/stream.gif"/&gt;&lt;/p&gt;
&lt;p&gt;Many other tools either don’t bother to render the Markdown, or they do a fairly half-hearted job.&lt;/p&gt;
&lt;p&gt;Another goal I had for Toad was to integrate a shell.
I wanted the conversation with AI to feel like a natural extension of a traditional terminal based workflow.&lt;/p&gt;
&lt;p&gt;Most tools stop at displaying monochrome output from commands.
Some will break if you run something interactive, like a TUI.
Toad doesn’t have this limitation, and will let you run all your CLI apps with full color, interactivity, and mouse support.&lt;/p&gt;
&lt;p&gt;At the time of writing the only terminal based agentic coding tool I know of that runs dynamic commands inline is Gemini.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Toad running htop" src="https://willmcgugan.github.io/images/toad-released/htop.gif"/&gt;&lt;/p&gt;
&lt;p&gt;Toad adopts the convention of using a &lt;code&gt;!&lt;/code&gt; character to introduce a shell command.
There is also a list of commands in settings which will automatically trigger shell mode.
In practice, this means that you rarely need to explicitly introduce shell commands—just type what’s on your mind.&lt;/p&gt;
&lt;p&gt;Toad borrows tab completion from the shell.
You’ll appreciate this if you have worked in the terminal long enough to commit this interaction to muscle memory.
Hit tab to complete the command or path.
If there is more than one possibility you can hit tab again to cycle through them, and enter to accept.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Toad tab complete" src="https://willmcgugan.github.io/images/toad-released/tabcomplete.gif"/&gt;&lt;/p&gt;
&lt;p&gt;In addition to the shell, Toad implements a few concepts from Jupyter notebooks.
You can cursor through previous conversation, moving a logical block at a time, and interact with it again.
At the moment that feature is used as a convenience to copy content to the clipboard or prompt, and a few other niceties like exporting a SVG.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Cursor block" src="https://willmcgugan.github.io/images/toad-released/cursor-block.png"/&gt;&lt;/p&gt;
&lt;p&gt;Toad will lean more heavily in to this kind of interaction in the future.&lt;/p&gt;
&lt;h2&gt;Friends of Toad&lt;/h2&gt;
&lt;p&gt;I was very fortunate to collaborate with &lt;a href="https://openhands.dev/"&gt;OpenHands&lt;/a&gt;, who are doing some amazing work in this space. Check out their &lt;a href="https://www.openhands.dev/blog/20251218-openhands-toad-collaboration"&gt;blog post&lt;/a&gt; on Toad!&lt;/p&gt;
&lt;p&gt;I also collaborated with &lt;a href="https://huggingface.co"&gt;Hugging Face&lt;/a&gt; on this release. Check out their blog post on their &lt;a href="https://huggingface.co/toad-hf-inference-explorers"&gt;inference explorers&lt;/a&gt;!&lt;/p&gt;
&lt;h2&gt;Try Toad&lt;/h2&gt;
&lt;p&gt;When this post is live you will be able to install Toad yourself.&lt;/p&gt;
&lt;p&gt;The work is ongoing: a few missing features and interface improvements to be done, but Toad is solid enough to use as your daily driver for AI.
I used it to create &lt;a href="https://www.batrachian.ai"&gt;batrachian.ai&lt;/a&gt;, where you will find install instructions.&lt;/p&gt;
&lt;p&gt;For more details, see the &lt;a href="https://github.com/batrachianai/toad"&gt;Toad&lt;/a&gt; repository.&lt;/p&gt;
&lt;p&gt;I need a break (sabbaticals are tiring), but I’ll be picking things up in 2026.
I’m hoping that by the time my year off ends, Toad could become my full-time gig.
If you want to help make that happen, consider &lt;a href="https://github.com/sponsors/willmcgugan"&gt;sponsoring my work&lt;/a&gt;.&lt;/p&gt;


&lt;p&gt;Share: &lt;a href="http://twitter.com/share?text=Toad is a unified experience for AI in the terminal&amp;amp;url=http://willmcgugan.github.io/toad-released/"&gt;Twitter&lt;/a&gt;, &lt;a href="https://www.facebook.com/sharer.php?u=http://willmcgugan.github.io/toad-released/"&gt;Facebook&lt;/a&gt;&lt;/p&gt;

&lt;!--&lt;div class="date"&gt;
    Written on December 18, 2025
  &lt;/div&gt;--&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://willmcgugan.github.io/toad-released/</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 15:12:40 +0000</pubDate>
    </item>
    <item>
      <title>Lua 5.5</title>
      <link>https://lua.org/versions.html#5.5</link>
      <description>Here is a chronology of the versions of Lua. The evolution of Lua is documented in a paper presented at HOPL III,
the Third ACM SIGPLAN History of Programming Languages Conference ,
in 2007.
See also its continuation published in 2025 in a journal .
The source code and documentation for all releases of Lua are available in the download area . Numbering scheme The releases of Lua are numbered x.y.z ,
where x is the series, x.y is the version, and z is the release. Different releases of the same version correspond to bug fixes .
Different releases of the same version have the same reference manual ,
the same virtual machine, and are binary compatible (ABI compatible). Different versions are really different.
The API is likely to be a little different
(but with compatibility switches),
and there is no ABI compatibility:
applications that embed Lua and C libraries for Lua must be recompiled.
The virtual machine is also very likely to be different in a new version:
Lua programs that have been precompiled for one version will not load in a different version. Lua 5.5 Lua 5.5.0 was released on 22 Dec 2025.
Its main new features are
declarations for global variables,
more compact arrays,
new generational mode for garbage collection,
and
major garbage collections done incrementally. Lua 5.4 Lua 5.4
was released on 29 Jun 2020.
Its main new features are
a new generational mode for garbage collection and
const and to-be-closed variables. The current release is Lua 5.4.8 ,
released on 4 Jun 2025. Lua 5.3 Lua 5.3
was released on 12 Jan 2015.
Its main new features were
integers,
bitwise operators,
a basic utf-8 library,
and support for both 64-bit and 32-bit platforms. The last release was Lua 5.3.6 ,
released on 25 Sep 2020.
There will be no further releases of Lua 5.3. Lua 5.2 Lua 5.2
was released on 16 Dec 2011.
Its main new features were
yieldable pcall and metamethods,
new lexical scheme for globals,
ephemeron tables,
new library for bitwise operations,
light C functions,
emergency garbage collector,
goto statement,
and
finalizers for tables. The last release was Lua 5.2.4 ,
released on 7 Mar 2015.
There will be no further releases of Lua 5.2. Lua 5.1 Lua 5.1
was released on 21 Feb 2006.
Its main new features were
a new module system,
incremental garbage collection,
new mechanism for varargs,
new syntax for long strings and comments,
mod and length operators,
metatables for all types,
new configuration scheme via luaconf.h,
and a
fully reentrant parser. The last release was Lua 5.1.5 ,
released on 17 Feb 2012.
There will be no further releases of Lua 5.1. Lua 5.0 Lua 5.0
was released on 11 Apr 2003. Its main new features were
collaborative multithreading via Lua coroutines,
full lexical scoping instead of upvalues,
and
metatables instead of tags and tag methods.
Lua 5.0 also introduced
booleans,
proper tail calls,
and weak tables.
Other features were
better support for packages,
new API for loading Lua chunks,
new error handling protocol,
better error messages,
and much more.
Lua 5.0 was the first version to be released under the new license . The last release was Lua 5.0.3 ,
released on 26 Jun 2006.
There will be no further releases of Lua 5.0. Lua 4.0 Lua 4.0
was released on 6 Nov 2000.
Its main new features were
multiples states,
a new API,
"for" statements,
and full speed execution with full debug information.
Also,
Lua 4.0 no longer had built-in functions:
all functions in the standard library are written using the official API. The last release was Lua 4.0.1 ,
released on 4 Jul 2002.
There will be no further releases of Lua 4.0. Lua 3.2 Lua 3.2
was released on 8 Jul 1999.
Its main new features were
a debug library
and
new table functions. The last release was Lua 3.2.2 ,
released on 22 Feb 2000.
There will be no further releases of Lua 3.2. Lua 3.1 Lua 3.1 was released on 11 Jul 1998.
Its main new features were
anonymous functions and
function closures via "upvalues".
( Lua 5.0 brought full lexical scoping and dropped upvalues.)
This brought a flavor of functional programming to Lua.
There was also support for multiple global contexts;
however, the API was not fully reentrant
(this had to wait until Lua 4.0 ).
Lua 3.1 also saw a
major code re-organization and clean-up,
with much reduced module interdependencies.
Lua 3.1 also adopted double precision for the internal representation of numbers. Lua 3.0 Lua 3.0 was released on 1 Jul 1997.
Its main new feature was
tag methods as a powerful replacement for fallbacks.
Lua 3.0 also introduced auxlib,
a library for helping writing Lua libraries in C,
and support for conditional compilation
(dropped in Lua 4.0 ). Lua 2.5 Lua 2.5 was released on 19 Nov 1996.
Its main new features were
pattern matching and vararg functions. Lua 2.4 Lua 2.4 was released on 14 May 1996.
Its main new features were
the external compiler luac ,
an extended debug interface with hooks,
and the "getglobal" fallback. Lua 2.3 Lua 2.3 was never released publicly; it only existed as a beta version. Lua 2.2 Lua 2.2 was released on 28 Nov 1995.
Its main new features were
long strings,
the debug interface,
better stack tracebacks,
extended syntax for function definition,
garbage collection of functions,
and support for pipes. Lua 2.1 Lua 2.1 was released on 7 Feb 1995.
Its main new features were
extensible semantics via fallbacks
and support for object-oriented programming.
It was described in a journal paper which was awarded the
II Compaq Award for Research and Development in Computer Science in 1997.
Starting with Lua 2.1,
Lua became freely available for all purposes,
including commercial uses. Lua 1.1 Lua 1.1 was released on 8 Jul 1994.
It was the first public release of Lua and was described in a conference paper .
Lua 1.1 already featured
powerful data description constructs,
simple syntax,
and a bytecode virtual machine.
Lua 1.1 was freely available for academic purposes;
commercial uses had to be negotiated, but none ever were. Lua 1.0 Lua 1.0 was never released publicly.
It was up and running on 28 Jul 1993 and most probably a couple of months before that. Last update:
Mon Dec 22 14:21:22 UTC 2025</description>
      <content:encoded>&lt;body&gt;
&lt;h1&gt;
&lt;a href="https://lua.org/home.html"&gt;&lt;img alt="Lua" src="https://lua.org/images/logo.png"/&gt;&lt;/a&gt;
Version history
&lt;/h1&gt;

&lt;a href="#5.5"&gt;5.5&lt;/a&gt;
·
&lt;a href="#5.4"&gt;5.4&lt;/a&gt;
·
&lt;a href="#5.3"&gt;5.3&lt;/a&gt;
·
&lt;a href="#5.2"&gt;5.2&lt;/a&gt;
·
&lt;a href="#5.1"&gt;5.1&lt;/a&gt;
·
&lt;a href="#5.0"&gt;5.0&lt;/a&gt;
·
&lt;a href="#4.0"&gt;4.0&lt;/a&gt;
·
&lt;a href="#3.2"&gt;3.2&lt;/a&gt;
·
&lt;a href="#3.1"&gt;3.1&lt;/a&gt;
·
&lt;a href="#3.0"&gt;3.0&lt;/a&gt;
·
&lt;a href="#2.5"&gt;2.5&lt;/a&gt;
·
&lt;a href="#2.4"&gt;2.4&lt;/a&gt;
·
&lt;a href="#2.2"&gt;2.2&lt;/a&gt;
·
&lt;a href="#2.1"&gt;2.1&lt;/a&gt;
·
&lt;a href="#1.1"&gt;1.1&lt;/a&gt;
·
&lt;a href="#1.0"&gt;1.0&lt;/a&gt;

&lt;p&gt;
Here is a chronology of the versions of Lua.
&lt;a href="https://lua.org/doc/hopl.pdf"&gt;The evolution of Lua&lt;/a&gt;
is documented in a
&lt;a href="https://lua.org/docs.html#papers"&gt;paper&lt;/a&gt;
presented at
&lt;a href="https://en.wikipedia.org/wiki/History_of_Programming_Languages#HOPL_III"&gt;HOPL III,
the Third ACM SIGPLAN History of Programming Languages Conference&lt;/a&gt;,
in 2007.
See also its
&lt;a href="https://lua.org/doc/cola.pdf"&gt;continuation&lt;/a&gt; published in 2025 in a
&lt;a href="https://doi.org/10.1016/j.cola.2025.101326"&gt;journal&lt;/a&gt;.
The source code and documentation for all releases of Lua are available in the
&lt;a href="https://lua.org/ftp/"&gt;download area&lt;/a&gt;.


&lt;img src="https://lua.org/images/timeline.png"/&gt;

&lt;h2&gt;&lt;a&gt;Numbering scheme&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
The releases of Lua are numbered &lt;em&gt;x.y.z&lt;/em&gt;,
where
&lt;em&gt;x&lt;/em&gt; is the series, &lt;em&gt;x.y&lt;/em&gt; is the version, and &lt;em&gt;z&lt;/em&gt; is the release.

&lt;p&gt;
Different releases of the same version correspond to
&lt;a href="https://lua.org/bugs.html"&gt;bug fixes&lt;/a&gt;.
Different releases of the same version have the same
&lt;a href="https://lua.org/manual/"&gt;reference manual&lt;/a&gt;,
the same virtual machine, and are binary compatible (ABI compatible).

&lt;p&gt;
Different versions are really different.
The API is likely to be a little different
(but with compatibility switches),
and there is no ABI compatibility:
applications that embed Lua and C libraries for Lua must be recompiled.
The virtual machine is also very likely to be different in a new version:
Lua programs that have been precompiled for one version will not load in a different version.

&lt;!--
We are getting ready to release
&lt;A HREF="work/"&gt;Lua 5.5&lt;/A&gt;,
the next version of Lua.
Try the
&lt;A HREF="work/"&gt;latest release candidate&lt;/A&gt;.
--&gt;
&lt;h2&gt;&lt;a&gt;Lua 5.5&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
Lua 5.5.0 was released on 22 Dec 2025.
Its
&lt;a href="https://lua.org/manual/5.5/readme.html#changes"&gt;main new features&lt;/a&gt;
are
declarations for global variables,
more compact arrays,
new generational mode for garbage collection,
and
major garbage collections done incrementally.

&lt;h2&gt;&lt;a&gt;Lua 5.4&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
Lua 5.4
was released on 29 Jun 2020.
Its
&lt;a href="https://lua.org/manual/5.4/readme.html#changes"&gt;main new features&lt;/a&gt;
are
a new generational mode for garbage collection and
const and to-be-closed variables.

&lt;p&gt;
The current release is
&lt;a href="https://lua.org/ftp/lua-5.4.8.tar.gz"&gt;Lua 5.4.8&lt;/a&gt;,
released on 4 Jun 2025.

&lt;!--
We are getting ready to release
&lt;A HREF="work/"&gt;Lua 5.4.8&lt;/A&gt;.
--&gt;
&lt;h2&gt;&lt;a&gt;Lua 5.3&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
Lua 5.3
was released on 12 Jan 2015.
Its
&lt;a href="https://lua.org/manual/5.3/readme.html#changes"&gt;main new features&lt;/a&gt;
were
integers,
bitwise operators,
a basic utf-8 library,
and support for both 64-bit and 32-bit platforms.

&lt;p&gt;
The last release was
&lt;a href="https://lua.org/ftp/lua-5.3.6.tar.gz"&gt;Lua 5.3.6&lt;/a&gt;,
released on 25 Sep 2020.
There will be no further releases of Lua 5.3.

&lt;h2&gt;&lt;a&gt;Lua 5.2&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
Lua 5.2
was released on 16 Dec 2011.
Its
&lt;a href="https://lua.org/manual/5.2/readme.html#changes"&gt;main new features&lt;/a&gt;
were
yieldable pcall and metamethods,
new lexical scheme for globals,
ephemeron tables,
new library for bitwise operations,
light C functions,
emergency garbage collector,
goto statement,
and
finalizers for tables.

&lt;p&gt;
The last release was
&lt;a href="https://lua.org/ftp/lua-5.2.4.tar.gz"&gt;Lua 5.2.4&lt;/a&gt;,
released on 7 Mar 2015.
There will be no further releases of Lua 5.2.

&lt;h2&gt;&lt;a&gt;Lua 5.1&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
Lua 5.1
was released on 21 Feb 2006.
Its main new features were
a new module system,
incremental garbage collection,
new mechanism for varargs,
new syntax for long strings and comments,
mod and length operators,
metatables for all types,
new configuration scheme via luaconf.h,
and a
fully reentrant parser.

&lt;p&gt;
The last release was
&lt;a href="https://lua.org/ftp/lua-5.1.5.tar.gz"&gt;Lua 5.1.5&lt;/a&gt;,
released on 17 Feb 2012.
There will be no further releases of Lua 5.1.

&lt;h2&gt;&lt;a&gt;Lua 5.0&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
Lua 5.0
was released on 11 Apr 2003.
&lt;!--
&lt;A HREF="http://compilers.iecc.com/comparch/article/03-04-041"&gt;More...&lt;/A&gt;
--&gt;
Its main new features were
collaborative multithreading via Lua coroutines,
full lexical scoping instead of upvalues,
and
metatables instead of tags and tag methods.
Lua 5.0 also introduced
booleans,
proper tail calls,
and weak tables.
Other features were
better support for packages,
new API for loading Lua chunks,
new error handling protocol,
better error messages,
and much more.
Lua 5.0 was the first version to be released under the
&lt;a href="https://lua.org/license.html"&gt;new license&lt;/a&gt;.

&lt;p&gt;
The last release was
&lt;a href="https://lua.org/ftp/lua-5.0.3.tar.gz"&gt;Lua 5.0.3&lt;/a&gt;,
released on 26 Jun 2006.
There will be no further releases of Lua 5.0.

&lt;h2&gt;&lt;a&gt;Lua 4.0&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
Lua 4.0
was released on 6 Nov 2000.
Its main new features were
multiples states,
a new API,
"for" statements,
and full speed execution with full debug information.
Also,
Lua 4.0 no longer had built-in functions:
all functions in the standard library are written using the official API.

&lt;p&gt;
The last release was
&lt;a href="https://lua.org/ftp/lua-4.0.1.tar.gz"&gt;Lua 4.0.1&lt;/a&gt;,
released on 4 Jul 2002.
There will be no further releases of Lua 4.0.
&lt;!--
&lt;A HREF="http://compilers.iecc.com/comparch/article/00-11-147"&gt;More...&lt;/A&gt;
--&gt;
&lt;h2&gt;&lt;a&gt;Lua 3.2&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
Lua 3.2
was released on 8 Jul 1999.
Its main new features were
a debug library
and
new table functions.

&lt;p&gt;
The last release was
&lt;a href="https://lua.org/ftp/lua-3.2.2.tar.gz"&gt;Lua 3.2.2&lt;/a&gt;,
released on 22 Feb 2000.
There will be no further releases of Lua 3.2.
&lt;!--
&lt;A HREF="http://compilers.iecc.com/comparch/article/99-07-033"&gt;More...&lt;/A&gt;
--&gt;
&lt;h2&gt;&lt;a&gt;Lua 3.1&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
&lt;a href="https://lua.org/ftp/lua-3.1.tar.gz"&gt;Lua 3.1&lt;/a&gt;
was released on 11 Jul 1998.
Its main new features were
anonymous functions and
function closures via "upvalues".
(&lt;a href="#5.0"&gt;Lua 5.0&lt;/a&gt; brought full lexical scoping and dropped upvalues.)
This brought a flavor of functional programming to Lua.
There was also support for multiple global contexts;
however, the API was not fully reentrant
(this had to wait until &lt;a href="#4.0"&gt;Lua 4.0&lt;/a&gt;).
Lua 3.1 also saw a
major code re-organization and clean-up,
with much reduced module interdependencies.
Lua 3.1 also adopted double precision for the internal representation of numbers.
&lt;!--
&lt;A HREF="http://compilers.iecc.com/comparch/article/98-07-106"&gt;More...&lt;/A&gt;
--&gt;
&lt;h2&gt;&lt;a&gt;Lua 3.0&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
&lt;a href="https://lua.org/ftp/lua-3.0.tar.gz"&gt;Lua 3.0&lt;/a&gt;
was released on 1 Jul 1997.
Its main new feature was
tag methods as a powerful replacement for fallbacks.
Lua 3.0 also introduced auxlib,
a library for helping writing Lua libraries in C,
and support for conditional compilation
(dropped in &lt;a href="#4.0"&gt;Lua 4.0&lt;/a&gt;).
&lt;!--
&lt;A HREF="http://compilers.iecc.com/comparch/article/97-07-021"&gt;More...&lt;/A&gt;
--&gt;
&lt;h2&gt;&lt;a&gt;Lua 2.5&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
&lt;a href="https://lua.org/ftp/lua-2.5.tar.gz"&gt;Lua 2.5&lt;/a&gt;
was released on 19 Nov 1996.
Its main new features were
pattern matching and vararg functions.
&lt;!--
&lt;A HREF="http://compilers.iecc.com/comparch/article/96-11-120"&gt;More...&lt;/A&gt;
--&gt;
&lt;h2&gt;&lt;a&gt;Lua 2.4&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
&lt;a href="https://lua.org/ftp/lua-2.4.tar.gz"&gt;Lua 2.4&lt;/a&gt;
was released on 14 May 1996.
Its main new features were
the external compiler &lt;em&gt;luac&lt;/em&gt;,
an extended debug interface with hooks,
and the "getglobal" fallback.
&lt;!--
&lt;A HREF="http://compilers.iecc.com/comparch/article/96-05-101"&gt;More...&lt;/A&gt;
--&gt;
&lt;h2&gt;&lt;a&gt;Lua 2.3&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
Lua 2.3 was never released publicly; it only existed as a beta version.

&lt;h2&gt;&lt;a&gt;Lua 2.2&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
&lt;a href="https://lua.org/ftp/lua-2.2.tar.gz"&gt;Lua 2.2&lt;/a&gt;
was released on 28 Nov 1995.
Its main new features were
long strings,
the debug interface,
better stack tracebacks,
extended syntax for function definition,
garbage collection of functions,
and support for pipes.

&lt;h2&gt;&lt;a&gt;Lua 2.1&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
&lt;a href="https://lua.org/ftp/lua-2.1.tar.gz"&gt;Lua 2.1&lt;/a&gt;
was released on 7 Feb 1995.
Its main new features were
extensible semantics via fallbacks
and support for object-oriented programming.
It was described in a
&lt;a href="https://lua.org/spe.html"&gt;journal paper&lt;/a&gt;
which was awarded the
II Compaq Award for Research and Development in Computer Science in 1997.
Starting with Lua 2.1,
Lua became freely available for all purposes,
including commercial uses.
&lt;!--
&lt;A HREF="http://compilers.iecc.com/comparch/article/95-02-083"&gt;More...&lt;/A&gt;
--&gt;
&lt;h2&gt;&lt;a&gt;Lua 1.1&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
&lt;a href="https://lua.org/ftp/lua-1.1.tar.gz"&gt;Lua 1.1&lt;/a&gt;
was released on 8 Jul 1994.
It was the
&lt;a href="https://compilers.iecc.com/comparch/article/94-07-051"&gt;first public release of Lua&lt;/a&gt; and was described in a
&lt;a href="https://lua.org/semish94.html"&gt;conference paper&lt;/a&gt;.
Lua 1.1 already featured
powerful data description constructs,
simple syntax,
and a bytecode virtual machine.
Lua 1.1 was freely available for academic purposes;
commercial uses had to be negotiated, but none ever were.

&lt;h2&gt;&lt;a&gt;Lua 1.0&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;
&lt;a href="https://lua.org/ftp/lua-1.0.tar.gz"&gt;Lua 1.0&lt;/a&gt;
was never released publicly.
It was up and running on
&lt;a href="http://lua-users.org/lists/lua-l/2023-07/msg00130.html"&gt;28 Jul 1993&lt;/a&gt;
and most probably a couple of months before that.

&lt;p&gt;
Last update:
Mon Dec 22 14:21:22 UTC 2025
&lt;/p&gt;
&lt;!--
Last change: Lua 5.5.0 released
--&gt;
&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/p&gt;&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://lua.org/versions.html#5.5</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 15:06:13 +0000</pubDate>
    </item>
    <item>
      <title>Show HN: Yapi – FOSS terminal API client for power users</title>
      <link>https://yapi.run/blog/what-is-yapi</link>
      <description>Yapi is Postman, Insomnia or Bruno for the power user.</description>
      <content:encoded>&lt;article class="max-w-3xl w-full"&gt;&lt;a href="https://yapi.run/blog"&gt;Back to Blog&lt;/a&gt;&lt;blockquote&gt;
&lt;p&gt;Yapi is Postman, Insomnia or Bruno for the power user.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Yapi is an OSS command line tool that makes it easy to test APIs from your
terminal. Yapi speaks HTTP, gRPC, TCP, GraphQL (and more coming soon).&lt;/p&gt;
&lt;p&gt;&lt;img alt="yapi in action" src="https://github.com/jamierpond/madea.blog/blob/main/yapi/yapi-example.gif?raw=true"/&gt;&lt;/p&gt;
&lt;h3&gt;Heads up! &lt;em&gt;Yapi is early, early alpha software&lt;/em&gt;&lt;/h3&gt;
&lt;p&gt;I use yapi daily in my development workflow. However, yapi is a &lt;em&gt;SUPER&lt;/em&gt;
young project and will have bugs, missing features and rough edges.&lt;/p&gt;
&lt;p&gt;If you &lt;a href="https://github.com/jamierpond/yapi"&gt;download yapi&lt;/a&gt;, I would &lt;em&gt;LOVE&lt;/em&gt; your feedback on how to make it better. Please &lt;a href="https://github.com/jamierpond/yapi/issues"&gt;open an issue&lt;/a&gt;
if you have any suggestions or find any bugs!&lt;/p&gt;
&lt;h3&gt;Show me some examples!&lt;/h3&gt;
&lt;h4&gt;POST&lt;/h4&gt;
&lt;p&gt;This request:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# create-issue.yapi.yml
yapi: v1 # specify yapi version
method: POST # or GET, PUT, DELETE, PATCH, etc.
url: https://api.github.com/repos/jamierpond/yapi/issues

headers:
  Accept: application/vnd.github+json
  Authorization: Bearer ${GITHUB_PAT} # supports environment variables

body: # defaults to JSON body, converted automatically
  title: Help! yapi made me too productive.
  body: Now I can't stop YAPPIN' about yapi!

expect: # supports expected response tests
  status: 201
  assert: # assert using jq syntax
    - .body == "Now I can't stop YAPPIN' about yapi!"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Gives you this response:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yapi run create-issue.yapi.yml
{
  "active_lock_reason": null,
  "assignee": null,
  "assignees": [],
  "author_association": "OWNER",
  "body": "Now I can't stop YAPPIN' about yapi!\n",
  // ...blah blah blah
}

URL: https://api.github.com/repos/jamierpond/yapi/issues
Time: 579.408625ms
Size: 2.3 kB (1 lines, 2288 chars)

[PASS] status check
[PASS] .body == "Now I can't stop YAPPIN' about yapi!"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;(Only the JSON goes to stdout, the rest goes to stderr, so is pipeable!)&lt;/em&gt;&lt;/p&gt;
&lt;h3&gt;Yapi supports chaining requests between protocols&lt;/h3&gt;
&lt;h4&gt;Multi-protocol chaining&lt;/h4&gt;
&lt;p&gt;Yapi makes it easy to chain requests and share data between them, even if they are different protocols.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# multi-protocol-chain.yapi.yml
yapi: v1
chain:
  - name: get_todo # HTTP request
    url: https://jsonplaceholder.typicode.com/todos/1
    method: GET

  - name: grpc_hello # gRPC request
    url: grpc://grpcb.in:9000
    service: hello.HelloService
    rpc: SayHello # Supports reflection if server has it enabled
    plaintext: true

    body:
      greeting: $get_todo.title # use data from previous request

    expect:
      assert:
        - .reply == "hello delectus aut autem" # assert on gRPC response
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://yapi.run/c/Df.8OgAzqUG-ZpArHJoiQovBOB1XLQM8BNSbz655jxnoC_d1kKWwWp3qeqyLUO_M73lKIwrUWJ6prOLMl5R2.qS8r1QzMvktH~6BGCJjH3E6CO6.iI_fuN4z.kAT3W70t~of01maCruwdBfYgS_nxmtesmpiqKbjalxSWIKMGIRbdL_u8WwRc89gKXPB0kW5wy_CGDmIF0Kef.vuRpV7Hm3BjZie2~yI6DHtvb-RgOqEzldl0W~Y.m4RTNw_Oy.OlksIrAkhwiIy6gdyVqPk0tgTzOePDzuo.trOigUj1AtfBNDpowrEdIU3MmT53pjaobcZV73FYwwpjWOfdNCEJqKTTUVrCc8ZgVB5riViWnJxqo5yz759FWyiBFbi~_2nLHnu67V7RLQPUYnFknAovF2SegQYEmmI~vrbJjjmdNShJNaVW"&gt;Run this example in the yapi playground&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Integration Testing with yapi&lt;/h3&gt;
&lt;p&gt;Yapi has built-in support for writing integration tests with expectations and assertions.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yapi: v1
method: GET
url: https://api.github.com/repos/jamierpond/yapi/issues/5
headers:
    Accept: application/vnd.github+json
expect:
    status: 200
    assert:
      - .state == "closed"
      - .closed_by.login == "jamierpond"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href="https://yapi.run/c/TccVrmpVtt_daI~NZovhqJO6LNVxr-qTEAL9aQp.nAvs9GoUK8PdGgJ6o34wC-THPf64WS.-iAWCfXohQ8~eo~7iOhp6Wop-a_lwPT.Y624K-1S97CVJgXwMRxtwUzZz6on7xftwVegIkX~6hO81OIvTsA6ASUgWdnf8va0QlaGHLI5w1d3LZ5WQ4xzYDg8~5lqPB5s3FE~~EL8aBeCKk-FtOPJ1AIPDMNH4X55A8QLYUF3NWY"&gt;Run this example in the yapi playground&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Yapi has an LSP Server for IDE Integration&lt;/h3&gt;
&lt;p&gt;Yapi comes with a Language Server Protocol (LSP) server that provides
syntax highlighting, autocompletion and validation for yapi request files in
editors that support LSP (Neovim, etc), you can also use the &lt;a href="https://github.com/jamierpond/yapi/blob/main/lua/yapi_nvim/init.lua"&gt;yapi Neovim plugin&lt;/a&gt; (still early days).&lt;/p&gt;
&lt;p&gt;At some point I'll write the VSCode extension too, please make an issue if you think this is important!&lt;/p&gt;
&lt;h3&gt;GitHub Actions Support&lt;/h3&gt;
&lt;p&gt;I use yapi's GitHub Action to run &lt;a href="https://github.com/jamierpond/yapi/actions/runs/20426239184/job/58687025263"&gt;integraion tests on the CI for this blog&lt;/a&gt;!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name: Integration Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm ci

      - name: Build Application
        run: npm build

      - name: Run Yapi Integration Tests
        uses: jamierpond/yapi/action@0.X.X
        with:
          start: npm run start
          wait-on: http://localhost:3000/health
          command: yapi test ./tests -a
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, here is the output of yapi running integration tests in GitHub Actions:
&lt;img alt="yapi in GitHub Actions" src="https://github.com/jamierpond/madea.blog/blob/main/yapi/ci.png?raw=true"/&gt;&lt;/p&gt;
&lt;h3&gt;Supports for Multiple Environments&lt;/h3&gt;
&lt;p&gt;Yapi make it easy to manage multiple environments (dev, staging, prod, etc).
Define your environments in a &lt;code&gt;yapi.config.yml&lt;/code&gt; file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yapi: v1

default_environment: local

environments:
  local:
    url: http://localhost:3000
    env_file: .env.local
    vars:
      some_param: default_value

  prod:
    url: https://yapi.run
    env_file: .env.prod
    vars:
      some_param: some_value
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then run yapi with the desired environment:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yapi run my-request.yapi.yml --env prod
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This also cleans up your request files a little, now you can use &lt;code&gt;path&lt;/code&gt;s instead of full URLs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;yapi: v1
method: GET
path: /api/v1/status # base URL comes from the selected environment
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Getting Started with Yapi&lt;/h3&gt;
&lt;p&gt;To get started with yapi, simply install it using the instructions on the
&lt;a href="https://github.com/jamierpond/yapi"&gt;yapi GitHub repository&lt;/a&gt; and start creating your
first request files!&lt;/p&gt;
&lt;h3&gt;Contributing to Yapi&lt;/h3&gt;
&lt;p&gt;Yapi is an open-source project maintained by just me, &lt;a href="https://pond.audio"&gt;Jamie&lt;/a&gt;.
If you find bugs or have feature requests, please open an issue on the
&lt;a href="https://github.com/jamierpond/yapi"&gt;yapi GitHub repository&lt;/a&gt;. Pull requests are very welcome too!&lt;/p&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://yapi.run/blog/what-is-yapi</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 08:49:47 +0000</pubDate>
    </item>
    <item>
      <title>Dancing around the rhythm space with Euclid</title>
      <link>https://pv.wtf/posts/euclidean-rhythms</link>
      <description>2025-12-22</description>
      <content:encoded>&lt;article&gt;
&lt;h1&gt;Dancing around the rhythm space with Euclid&lt;/h1&gt;
&lt;p&gt;2025-12-22&lt;/p&gt;
&lt;p&gt;I've been playing with sequencers and getting out of Euclidean rhythms (kind of) and into Non-Euclidean ones, and at the end of the whole story managed to build a little one of my own. If those words mean nothing to you yet, enjoy the ride.&lt;/p&gt;
&lt;p&gt;There's a little music corner at home, and in it I've got the classic Synth hipster combo of an Elektron Digitone and a Digitakt. Both are really fun to play with, especially the Digitone. I really like the immediacy, and often it's with me on vacation. A powerbank going in and a pair of headphones coming out. The Elektron sequencer workflow makes it easy to get started, and it pairs it with a great FM-synthesis sound engine, which normally has a reputation for being hard to understand.&lt;/p&gt;
&lt;p&gt;And yes, even with the playful Digitone this reputation is still well earned, which has led me to experiment more. Synthesizers are normally fixed in their architecture, oscillator goes into filter and if you are lucky, there's a mysterious mod-matrix to re-jigger parts via cryptic button combinations. I love my hardware, but… Sometimes it's just not the best for learning.&lt;/p&gt;
&lt;p&gt;Modular synthesizers exist as well, but my synth corner needs to stay just a corner. This brings us to VCV Rack, it's a software modular synthesis environment with a lot of overlap with the Eurorack hardware format. You can have a lot of fun following &lt;a href="https://www.youtube.com/channel/UCuWKHSHTHMV_nVSeNH4gYAg"&gt;Omri Cohen&lt;/a&gt;'s videos, cables and modulation going everywhere to end up with something &lt;em&gt;Very Nice&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Of course, when you get a cool sound going, it needs to keep playing while you somehow make it worse and worse. This is where a Sequencer usually helps, and there is a wealth of different ones to play with in VCV Rack. Connect them with semi-random modulation sources and all the little bleeps, thonks and thwangs can keep evolving with what the neighbors will add as wall-based percussion track for hours.&lt;/p&gt;
&lt;p&gt;When I play on the Digitone/takt, it's a bit different. What I do is create a set of patterns that evolve in some small way as you move from one to the next. On top of this I tweak and twiddle parameters, filters and effects to help create transitions over time. I keep to my little corner at home, but I'm romanticizing about the idea of a thrilling live performance, especially with live improvisation.&lt;/p&gt;
&lt;p&gt;The tricky thing is that live improvisation requires tools and a thought out workflow, and the way I've been using my devices requires a lot of preparation up-front. On one end maybe more randomization can help, but pure random usually doesn't sound good either, so I need some way to increase my lucky accidents.&lt;/p&gt;
&lt;p&gt;Now, of course, the real solution is really quite simple, you might already be thinking it: I should practice more with the gear that I already have. Yes, so of course I'm doing something entirely different.&lt;/p&gt;
&lt;p&gt;Among the many sequencers in VCV Rack I found some based on Euclidean rhythms, and it turns out that they might be just what I needed. What are they? Hit play and take it away!&lt;/p&gt;

&lt;p&gt;The Euclidean algorithm tries to position a number of hits as evenly as possible across a pattern. There's a lot of material online that explains it from many angles, &lt;a href="https://www.youtube.com/results?search_query=euclidean+rhythms"&gt;YouTube Videos&lt;/a&gt; and &lt;a href="https://cgm.cs.mcgill.ca/~godfried/publications/banff-extended.pdf"&gt;the original paper&lt;/a&gt; written by Godfried Toussaint is also short and clear.&lt;/p&gt;
&lt;p&gt;It turns out that by varying the hits and length of a pattern, you get a fair number of world music rhythms that you will most likely recognize. We'll use &lt;code&gt;E(N,L)&lt;/code&gt; notation with &lt;code&gt;N=Number of hits&lt;/code&gt; and &lt;code&gt;L=Length of pattern&lt;/code&gt; to describe them.&lt;/p&gt;
&lt;p&gt;Take the &lt;code&gt;E(3,8)&lt;/code&gt; rhythm, it's all over the place. In Elvis's Hound Dog, and 50s rockabilly. In Cuba it's the &lt;em&gt;Tresillo&lt;/em&gt; and you can find it in West African drum rhythms. We've also got &lt;code&gt;E(5,8)&lt;/code&gt; which again is present all over the world. The really interesting part is that certain rhythms have made their home more in certain parts of the world than others. The paper goes into more detail so just read it, and maybe use the widget above for playback.&lt;/p&gt;
&lt;p&gt;Back to where we were. The Euclidean algorithm gives us a fair amount of different rhythms. As you probably paused the widget above at some point, you noticed that it can get quite repetitive. Prime number divisions tend to be interesting but some rhythms like &lt;code&gt;E(4,8)&lt;/code&gt; is just a simple four-on-the floor groove. Many Euclidian sequencers allow you to rotate the pattern to create more variation, but you'd need to keep changing it to prevent it from becoming monotonous over time. On the other hand, this might even be desired for something percussive, a funky bassline or the ticking of hi-hats.&lt;/p&gt;
&lt;p&gt;Then modulate the tension by increasing or decreasing the number of hits in the pattern. Get wild, wire a 4-step sequencer that moves every bar, to the density of hits in a Euclidian pattern so that every bar the feeling changes and creates a much more interesting evolution over time. To me, that bridges the gap between a tool for short percussive rhythms, into something that might even be a melody when given a nice big heap of pitch changes.&lt;/p&gt;
&lt;p&gt;There is a more fundamental drawback to Euclidean Rhythms though, which is also their definition: Evenness.&lt;/p&gt;
&lt;p&gt;Or not really a drawback, but a lot of interesting rhythms have uneven rhythm placement. We can use them to explore the rhythm space, but have to keep on the roads. Another approach is to store a lot of interesting patterns and interpolate between them, Mutable Instruments Grids is an example of such a Eurorack module. But I feel like that gives less control and ability to insert intent into the shape of the rhythms.&lt;/p&gt;
&lt;p&gt;There are people experimenting in another direction. Shakmat Knight's gallop is a Eurorack module with a normal Euclidean mode, but also an Anti-Euclidean one. As far as I can tell from the manual, it makes an attempt to position hits as uneven as possible. Both the Knight's Gallop and another one called the lx-euclid with modes that cluster hits in the beginning or end. This gives us some more room in the rhythm space do dance around in.&lt;/p&gt;

&lt;p&gt;Change the interpolation control above to one of the extremes and what you get was one attempt to create something like an Anti-Euclidian rhythm by creating uneven spacing, but I wasn't really happy with the original outcome. There's some interesting grooves in there at lower densities and lengths, but at higher ones it just became too clumped together.&lt;/p&gt;
&lt;p&gt;In his writing, Toussaint discusses how different metrics can be used to describe the distance between two rhythms. That led me to try interpolating between the Euclidean and the Anti-Euclidean rhythm we just played with. It took a bit of tweaking, the key was to constrain the interpolation so that it only moved one hit at a time. This actually felt like exploring the rhythm space in a much more interesting way. The Anti-Euclidean algorithm tended to cluster hits in the beginning, so it made sense to add a mirror version of it as well.&lt;/p&gt;
&lt;p&gt;Nice. That's just one possible take on "optimize for uneven" and there might be more interesting parts of the rhythm space now that we're off-roading it. Another interesting experiment was clumping the hits, and then attempting to do something similar to Wavefolding where as peaks start to form we push them back in on itself, creating holes in the clusters that turn into new peaks.&lt;/p&gt;

&lt;p&gt;I don't know about you, but to me this version also has a couple of good grooves in its repertoire. A drawback is that as you increase the intensity you also get repeats of the same rhythms you've had before, lessening the feeling that you are exploring the rhythm space.&lt;/p&gt;
&lt;p&gt;Though again, setting one of these as the interpolation target and exploring what you find on the way is quite fun still, so I really liked that.&lt;/p&gt;
&lt;p&gt;I continued to play around with more ideas, thinking of different places in the rhythm space we could visit. Trying things like alternating clusters, but they didn't really result in more interesting rhythms. We could also do something like Euclidean subdivisions, treat the pattern as one of a subdivided length and use that to place the hits in clusters instead.&lt;/p&gt;
&lt;p&gt;The widget below collects a few of those experiments, it's less of a curated tour and more of a notebook of different attempts at this point, select an algorithm in the dropdown and make sure to play with interpolation slider.&lt;/p&gt;

&lt;p&gt;My main takeaway from the experimentation was that Euclidean rhythms are good (no surprise there), and to add some spice you don't need to stray too far away from them to get interesting syncopation. A rhythm that looks beautiful on a circle might still not sound so interesting, as I tried to take higher-order polynomial curves and map them to the hits. In the end, interpolating between a clustered version and the Euclidean was one of the best ways to explore.&lt;/p&gt;
&lt;p&gt;With that in mind, I wanted to try moving these experiments a bit further towards a sequencer that could support longer patterns, and combine it with some of the ideas I mentioned earlier, like changing density over time. The interpolation feature is key, and modulating hit density over time. The closest standalone sequencers I know would be either the Torso T1 or the Oxi one, but I don't think either really support do that outside of manually changing controls.&lt;/p&gt;
&lt;p&gt;I started expanding the widgets above into this, and it grew and grew until I split it out into a separate page. Firstly because then I don't need to scroll to the ends of the earth every time I refreshed the page. It also makes it easier for myself to bookmark for the future.&lt;/p&gt;
&lt;p&gt;Obligatory side-note: I'm writing this in the very tail end of 2025, a time where everything circles around AI in some way. If I had been writing a year or two back, all of the interactive widgets would probably have been images instead. They are not that hard to build, but involve a lot of micro-decisions that take time and energy. I do my faffing about in the mornings before work, so time and energy are not that abundant.&lt;/p&gt;
&lt;p&gt;This was an opportunity to experimenting with the latest batch of AI models while building as well. Claude Opus 4.5 seems like a clear step up from Sonnet 4.5 (but more annoying usage limits), and the new Gemini 3 Flash is also a strong contender. They struggled with some parts though. Neither had an easy time understanding how to make the Shift Register work well in the sequencer context, and I had to rewrite the core rhythm generation a couple of times to make it work the way I needed it to before handing it back.&lt;/p&gt;
&lt;p&gt;With that out of the way, follow the link below.&lt;/p&gt;

&lt;a href="https://pv.wtf/playground/euclidean-sequencer"&gt;Open Really Cool Sequencer&lt;/a&gt;

&lt;p&gt;Back? It might need a little bit of explanation.&lt;/p&gt;
&lt;p&gt;There are four different parts to a pattern, with either a global length or individual part lengths. And for each part we can control the density as an offset from the main one, so it's easy to perform by only tweaking the main one. For each we can also control the distance from the euclidean pattern.&lt;/p&gt;
&lt;p&gt;Now this I feel like has the seed of something that can be used beyond simple-ish percussion loops. Lets you get going quickly but also has enough control to shape what's happening, add intent.&lt;/p&gt;
&lt;p&gt;I added controls for rotation, inverting the rhythm, and manual overrides for forcing a hit or a rest. Having the same pitch for each hit started to get a bit tedious, so I added a Shift Register (also known as Turing Machine) inspired generator for pitch information as well.&lt;/p&gt;
&lt;p&gt;The thing that's really cool (alternatively: really confusing) is the Boolean mode. Normally each part plays in sequence, one after another. But in boolean mode they act as different layers that combine into one output. You can choose which one to listen too, and see what the effect of playing Part 1 OR Part 2 is. And since we already have a Shift Register for pitch, why not reuse it for beats as well?&lt;/p&gt;
&lt;p&gt;There are a couple of more features as well, they are hopefully either easy to understand or fun to click around on anyway so I'm pretty satisfied with this version. What comes next?&lt;/p&gt;
&lt;p&gt;I haven't written a VCV Rack plugin, but it might be fun to try as a next step. Or maybe add WebMIDI to the sequencer, either way would let me see how it plays with the Digitone. End result being that I spend some more time in my synth corner with tiny blinking lights rather than big laptop screens.&lt;/p&gt;
&lt;p&gt;That's it for this dance, see you next time!&lt;/p&gt;


&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://pv.wtf/posts/euclidean-rhythms</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 08:08:46 +0000</pubDate>
    </item>
    <item>
      <title>CSRF protection without tokens or hidden form fields</title>
      <link>https://blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields</link>
      <description>A couple of months ago, I received a request from a random Internet user to add CSRF protection to my little web framework Microdot , and I thought it was a fantastic idea.</description>
      <content:encoded>&lt;div class="post"&gt;

&lt;h1&gt;&lt;a href="https://blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields"&gt;CSRF Protection without Tokens or Hidden Form Fields&lt;/a&gt;&lt;/h1&gt;
&lt;h2&gt;
    Posted by
    
    on
    2025-12-21T15:54:28Z
    under
    
      

&lt;/h2&gt;

&lt;p&gt;A couple of months ago, I received a &lt;a href="https://github.com/miguelgrinberg/microdot/issues/321"&gt;request&lt;/a&gt; from a random Internet user to add &lt;a href="https://en.wikipedia.org/wiki/Cross-site_request_forgery"&gt;CSRF&lt;/a&gt; protection to my little web framework &lt;a href="https://github.com/miguelgrinberg/microdot"&gt;Microdot&lt;/a&gt;, and I thought it was a fantastic idea.&lt;/p&gt;
&lt;p&gt;When I set off to do this work in early November I expected I was going to have to deal with anti-CSRF tokens, double-submit cookies and hidden form fields, pretty much the traditional elements that we have used to build a defense against CSRF for years. And I did start along this tedious route. But then I bumped into a new way some people are dealing with CSRF attacks that is way simpler, which I describe below.&lt;/p&gt;
&lt;h2&gt;Implementing a security feature&lt;/h2&gt;
&lt;p&gt;An often shared piece of advice is that you should never implement security features yourself. Instead, you should look for well established solutions built by people who think about security day in and day out.&lt;/p&gt;
&lt;p&gt;Unfortunately, as the lead (and only) maintainer of Microdot, I do not have an ecosystem of existing solutions available to me. Even though I gladly accept external contributions, most of the framework has been built by myself out of nothing. So in this case, like many other times before, I felt I had no choice but to go against the standard advice and write CSRF protection code by myself, because if I didn't do it then the feature would not be built.&lt;/p&gt;
&lt;p&gt;What is the first step when you need to build a security feature? Check out what &lt;a href="https://owasp.org/"&gt;OWASP&lt;/a&gt; has to say about the matter.&lt;/p&gt;
&lt;p&gt;So, in early November, I opened OWASP's &lt;a href="https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html"&gt;CSRF Prevention Cheat Sheet&lt;/a&gt; page to see what was new and interesting in the world of CSRF protection. And I found that nothing of significance had changed.&lt;/p&gt;
&lt;p&gt;According to OWASP, the best CSRF protection you could get (at the time I checked) was still built around the idea of using anti-CSRF tokens. So I set off to implement this for Microdot.&lt;/p&gt;
&lt;h2&gt;A disturbance in the (CSRF) force&lt;/h2&gt;
&lt;p&gt;I was happily making progress on my CSRF implementation, and then in early December, another random Internet user dropped &lt;a href="https://github.com/pallets/flask/issues/5863"&gt;an issue&lt;/a&gt; on the Flask repository, proposing that Flask adds support for "modern" CSRF protection. Modern? How could there be a new way to protect against CSRF that isn't mentioned by OWASP?&lt;/p&gt;
&lt;p&gt;This led me down a rabbit hole of blog posts and discussions spanning the Go and Ruby communities, plus a &lt;a href="https://github.com/OWASP/CheatSheetSeries/issues/1803"&gt;long discussion&lt;/a&gt; about this method on the OWASP GitHub repository itself, resulting in a &lt;a href="https://github.com/OWASP/CheatSheetSeries/pull/1875"&gt;pull request&lt;/a&gt; that added a &lt;a href="https://cheatsheetseries.owasp.org/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.html#fetch-metadata-headers"&gt;mention&lt;/a&gt; of this method to the CSRF Cheat Sheet, only a couple of weeks after I went to this page looking for guidance for my own implementation.&lt;/p&gt;
&lt;h2&gt;Modern CSRF Protection&lt;/h2&gt;
&lt;p&gt;The so called "modern" method to protect against CSRF attacks is based on the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Sec-Fetch-Site"&gt;Sec-Fetch-Site&lt;/a&gt; header, which all modern desktop and mobile browsers include in the requests they send to servers. According to Mozilla, all browsers released since March 2023 have support for this header.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header can have one of four values:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;same-origin&lt;/code&gt;, when the request comes from the same origin as the target server&lt;/li&gt;
&lt;li&gt;&lt;code&gt;same-site&lt;/code&gt;, when the request comes from the same site, but not exactly the same origin (e.g. a different subdomain) as the target server&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cross-site&lt;/code&gt;, when the request comes from an origin that does not match the target server&lt;/li&gt;
&lt;li&gt;&lt;code&gt;none&lt;/code&gt;, when the request is originated by the user&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The value of this header cannot be set via JavaScript, so the server can assume that a) if this header is present, then the client is a web browser, and b) the value of the header can be trusted. So basically, the server can reject requests that come with this header set to &lt;code&gt;cross-site&lt;/code&gt;, and in essence that is all you need to do to protect against CSRF!&lt;/p&gt;
&lt;p&gt;After seeing this, I paused my work on the token-based CSRF implementation and spent a few hours to implement this modern approach. As always, the devil is in the details, so let's see what else I needed to do to build a complete solution.&lt;/p&gt;
&lt;p&gt;First of all, in some cases subdomains sharing the same registered domain may operate independently, and as such, it is not out of the question that one subdomain may attempt to attack another through CSRF. Depending on the level of trust an application has for other subdomains, a server may want to block requests that come with the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header set to &lt;code&gt;same-site&lt;/code&gt;. In Microdot, I have added an argument &lt;code&gt;allow_subdomains&lt;/code&gt; to cover this case. I decided to err on the side of security, so the default is &lt;code&gt;False&lt;/code&gt;, meaning that requests from subdomains are also blocked.&lt;/p&gt;
&lt;p&gt;The other big problem is that not everyone is using a recent browser that implements this header. Looking at the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Sec-Fetch-Site#browser_compatibility"&gt;browser compatibility&lt;/a&gt; for the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header, you can see that most browsers implemented this feature long ago, between 2019 and 2021, with one notable exception: Safari. Apple added this header to its browser in 2023, so it is reasonable to assume that there are still users out there running older browsers that do not support it.&lt;/p&gt;
&lt;p&gt;One option is to reject all requests that do not have the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header. This keeps everyone secure, but of course, there's going to be some unhappy users of old devices that will not be able to use your application. Plus, this would also reject HTTP clients that are not browsers. If this is not a problem for your use case, then great, but it isn't a good solution overall.&lt;/p&gt;
&lt;p&gt;From what I gathered from looking at other implementations of this method, an accepted solution is to use the &lt;code&gt;Origin&lt;/code&gt; header as fallback when &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; is not implemented, since this header has been around for &lt;a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Headers/Origin#browser_compatibility"&gt;much longer&lt;/a&gt;. The last of the major browsers to add it were Firefox desktop in 2019 and Edge and Firefox mobile in 2020. Like &lt;code&gt;Sec-Fetch-Site&lt;/code&gt;, the &lt;code&gt;Origin&lt;/code&gt; header is also a restricted header that is set by the browser, so it can also be used to determine from where a request is coming from.&lt;/p&gt;
&lt;p&gt;The problem with using the &lt;code&gt;Origin&lt;/code&gt; header is that it isn't always easy to know what is the correct origin that applies to a web application. The standard option is to compare the value of the &lt;code&gt;Origin&lt;/code&gt; header against the value of the &lt;code&gt;Host&lt;/code&gt; header, but &lt;code&gt;Host&lt;/code&gt; only includes the hostname and port, while &lt;code&gt;Origin&lt;/code&gt; also includes the scheme. Also, the &lt;code&gt;Host&lt;/code&gt; header is overwritten as it passes through reverse proxies. So comparing these two headers is actually not easy.&lt;/p&gt;
&lt;p&gt;Another, more direct option is to ask the user to configure the expected origin name explicitly. To keep things simple, in Microdot I opted for the explicit configuration, for which I linked to the existing Cross-Origin Request Sharing (CORS) support. The CORS feature already maintains a list of allowed origins, so my CSRF logic automatically trusts these. I decided to not complicate myself adding support for &lt;code&gt;Host&lt;/code&gt; header checks at this time, but maybe I'll add this in the future.&lt;/p&gt;
&lt;p&gt;Filippo Valsorda, a security developer active in the Go ecosystem (and author of the popular &lt;a href="https://github.com/FiloSottile/mkcert"&gt;mkcert&lt;/a&gt; tool) wrote a &lt;a href="https://words.filippo.io/csrf/"&gt;blog post&lt;/a&gt; about this method that you may want to check out if you want to learn more details about it. He seems to be the first to propose this method and has implemented it for the Go standard library.&lt;/p&gt;
&lt;p&gt;Also if you are interested, feel free to review my implementation of CSRF protection in Microdot. Have a look at the &lt;a href="https://microdot.readthedocs.io/en/latest/extensions/csrf.html"&gt;documentation&lt;/a&gt;, the &lt;a href="https://github.com/miguelgrinberg/microdot/blob/main/src/microdot/csrf.py"&gt;code&lt;/a&gt; and an &lt;a href="https://github.com/miguelgrinberg/microdot/tree/main/examples/csrf"&gt;example&lt;/a&gt;, and let me know if you have any improvements or fixes to suggest.&lt;/p&gt;
&lt;h2&gt;Let's revisit OWASP&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Note: this section is now out of date. As of December 24th 2025 the OWASP CSRF Cheat Sheet page lists the Fetch Metadata method as a complete solution that can be used as an alternative to token-based approaches.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;As I mentioned above, the CSRF Prevention Cheat Sheet page from OWASP was updated in early December to include the use of the &lt;code&gt;Sec-Fetch-Site&lt;/code&gt; header in the list of prevention methods. But this method is currently listed as a &lt;a href="https://en.wikipedia.org/wiki/Defence_in_depth"&gt;defense in depth&lt;/a&gt; mechanism, and not a complete solution, which I thought was odd.&lt;/p&gt;
&lt;p&gt;I referenced the &lt;a href="https://github.com/OWASP/CheatSheetSeries/issues/1803"&gt;discussion&lt;/a&gt; in the OWASP GitHub repository that resulted in the recent changes made to the Cheat Sheet page. Several participants in that discussion have suggested that this method should be upgraded to a complete alternative to the standard token-based approaches. The OWASP maintainer was initially skeptical, but towards the end of the thread they have agreed. The &lt;a href="https://github.com/OWASP/CheatSheetSeries/pull/1875"&gt;pull request&lt;/a&gt; that closed the discussion added this solution as an alternative to the token-based approaches, but then a later change made significant updates, including the downgrade to defense in depth. My hope is that this is just a misunderstanding, and that the OWASP folks will restore the content as it was agreed by all the parties involved.&lt;/p&gt;
&lt;p&gt;In any case, I consider that in Microdot, going from no CSRF support at all to this is a great step forward that is also consistent with the minimalist ethos of the project. I will be keeping an eye on the OWASP CSRF Cheat Sheet page to see what is their final word on this new protection method, and if they end up keeping it as defense in depth, I still have a mostly complete implementation of double-submit anti-CSRF tokens that I can bring into my project.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;What I like the most about working in open source is that all the work happens in the open, so it is a permanent record that can be searched and reviewed. My CSRF protection journey started as a somewhat tedious exercise in the use of cryptography and cookies, but then thanks to an unexpected lead it turned into a fun and exciting learning opportunity for me.&lt;/p&gt;
&lt;h2&gt;Buy me a coffee?&lt;/h2&gt;
&lt;p&gt;Thank you for visiting my blog! If you enjoyed this article, please consider supporting my work and keeping me caffeinated with a small one-time donation through &lt;a href="https://www.buymeacoffee.com/miguelgrinberg"&gt;Buy me a coffee&lt;/a&gt;. Thanks!&lt;/p&gt;
&lt;a href="https://www.buymeacoffee.com/miguelgrinberg"&gt;&lt;img alt="Buy Me A Coffee" src="https://blog.miguelgrinberg.com/static/buymeacoffee-yellow.png"/&gt;&lt;/a&gt;
&lt;h2&gt;Share this post&lt;/h2&gt;
&lt;!-- Sharingbutton Hacker News --&gt;
&lt;a href="https://news.ycombinator.com/submitlink?u=https%3A//blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields&amp;amp;t=CSRF%20Protection%20without%20Tokens%20or%20Hidden%20Form%20Fields"&gt;

Hacker News
&lt;/a&gt;
&lt;!-- Sharingbutton Reddit --&gt;
&lt;a href="https://reddit.com/submit/?url=https%3A//blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields&amp;amp;resubmit=true&amp;amp;title=CSRF Protection without Tokens or Hidden Form Fields"&gt;

Reddit
&lt;/a&gt;
&lt;!-- Sharingbutton Twitter --&gt;
&lt;a href="https://twitter.com/intent/tweet/?text=CSRF%20Protection%20without%20Tokens%20or%20Hidden%20Form%20Fields&amp;amp;url=https%3A//blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields"&gt;

Twitter
&lt;/a&gt;
&lt;!-- Sharingbutton LinkedIn --&gt;
&lt;a href="https://www.linkedin.com/shareArticle?mini=true&amp;amp;url=https%3A//blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields&amp;amp;title=CSRF%20Protection%20without%20Tokens%20or%20Hidden%20Form%20Fields&amp;amp;summary=CSRF%20Protection%20without%20Tokens%20or%20Hidden%20Form%20Fields&amp;amp;source=https%3A//blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields"&gt;

LinkedIn
&lt;/a&gt;
&lt;!-- Sharingbutton Facebook --&gt;
&lt;a href="https://facebook.com/sharer/sharer.php?u=https%3A//blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields"&gt;

Facebook
&lt;/a&gt;
&lt;!-- Sharingbutton E-Mail --&gt;
&lt;a href="mailto:?subject=CSRF%20Protection%20without%20Tokens%20or%20Hidden%20Form%20Fields&amp;amp;body=https%3A//blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields"&gt;

E-Mail
&lt;/a&gt;

&lt;a href="https://blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields#comments"&gt;No comments yet&lt;/a&gt;


&lt;h3&gt;Leave a Comment&lt;/h3&gt;


&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://blog.miguelgrinberg.com/post/csrf-protection-without-tokens-or-hidden-form-fields</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 05:38:33 +0000</pubDate>
    </item>
    <item>
      <title>Your inbox is a bandit problem</title>
      <link>https://parentheticallyspeaking.org/articles/bandit-inbox/</link>
      <description>1 The Bandit</description>
      <content:encoded>&lt;div class="maincolumn"&gt;&lt;h2&gt;&lt;a&gt;&lt;/a&gt;Your Inbox is a Bandit&lt;a href="#(part._bandit-inbox)"&gt;🔗&lt;/a&gt; &lt;/h2&gt;&lt;p&gt;    &lt;a href="#%28part._.The_.Bandit%29"&gt;1 The Bandit&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;    &lt;a href="#%28part._.Combatting_the_.Bandit%29"&gt;2 Combatting the Bandit&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;    &lt;a href="#%28part._.My_.Context%29"&gt;3 My Context&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;    &lt;a href="#%28part._.Hit_.Snooze_%29"&gt;4 Hit Snooze?&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;    &lt;a href="#%28part._.My_.Solution%29"&gt;5 My Solution&lt;/a&gt;&lt;/p&gt;&lt;p&gt;      &lt;a href="#%28part._.Populating_the_.Folder%29"&gt;5.1 Populating the Folder&lt;/a&gt;&lt;/p&gt;&lt;p&gt;      &lt;a href="#%28part._.Processing_the_.Folder%29"&gt;5.2 Processing the Folder&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;    &lt;a href="#%28part._.What_.About_.Things_.That_.Aren_t_.Email_%29"&gt;6 What About Things That Aren’t Email?&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;    &lt;a href="#%28part._.Conclusion%29"&gt;7 Conclusion&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;1 &lt;a&gt;&lt;/a&gt;The Bandit&lt;a href="#(part._.The_.Bandit)"&gt;🔗&lt;/a&gt; &lt;/h3&gt;&lt;p&gt;In probability and machine learning, there’s a notion of
&lt;a href="https://en.wikipedia.org/wiki/Multi-armed_bandit"&gt;multi-arm
bandit&lt;/a&gt; problems.  Your mental image should of you sitting in front of a row of
slot machines (known as a one-armed bandit: the “arm” being the lever,
“bandit” because it takes your money), each of which may produce a payoff at
any moment. Which one do you play next? Facing a machine, you have a choice
between exploitation—pulling its lever—or
exploration—choosing another machine. The literature is always cast in
terms of maximizing your reward, though in the case of slot machines, and the
situation we’ll discuss here, it’s more about minimizing your loss.&lt;/p&gt;&lt;p&gt;Many real-world problems can be cast as bandit problems. How do you allocate
money to portfolios? Which restaurant do you go to? What ad do you show? And so
on.&lt;/p&gt;&lt;p&gt;Very loosely speaking, your email inbox is a bandit. You’re given a bunch of
message threads, and you have to decide whether to “exploit” a particular
one—read it, respond to it, deal with replies in the thread, and so on—or
“explore” another thread. And much like a slot machine, this bandit also
leaves you broke: if not for money, then certainly for time and energy. Having
to make choices is cognitively taxing, and having to constantly make decisions
from a large number of options becomes numbing. We end up picking either
sub-optimal strategies (like always choosing the top thread), clicking at
random, or just rooted in indecision. Nobody enjoys this.&lt;/p&gt;&lt;h3&gt;2 &lt;a&gt;&lt;/a&gt;Combatting the Bandit&lt;a href="#(part._.Combatting_the_.Bandit)"&gt;🔗&lt;/a&gt; &lt;/h3&gt;&lt;p&gt;Many people have suggested strategies for dealing with this. One popular
technique is Inbox Zero. The jokes about it suggests virtually nobody attains
it, but I’m not even convinced it’s a virtue. I have many correspondents—such
as my collaborators—who write detailed, thoughtful messages, and deserve
detailed, thoughtful answers. (And if I don’t provide those, they’ll stop
writing me, which will be to my detriment.) Mindlessly dashing off replies to
get them out of my inbox is neither an option nor desirable.&lt;/p&gt;&lt;p&gt;Other have suggested strategies like Getting Things Done. These always strike
me as heavyweight and solving problems I don’t have.&lt;/p&gt;&lt;p&gt;This article instead describes a strategy I’ve been trying to avoid this
problem, and it’ll evolve as my strategies evolve.&lt;/p&gt;&lt;h3&gt;3 &lt;a&gt;&lt;/a&gt;My Context&lt;a href="#(part._.My_.Context)"&gt;🔗&lt;/a&gt; &lt;/h3&gt;&lt;p&gt;Let me first tell you how I work. My situation may not apply to you at all.&lt;/p&gt;&lt;p&gt;First of all, I try to have only one inbox, which is my email account. I have
not have open Direct Messaging on Twitter; I try to avoid Facebook Messenger
(and wish I could turn it off); I don’t use Slack; I use Zulip only with my
course staff; most people know not to text me. So just about everything gets
routed through my inbox.&lt;/p&gt;&lt;p&gt;Some of my inbox entries are big tasks that require a lot of thinking: e.g.,
correspondence with research colleagues on code, experiments, results, and
papers. They take time and require me to engage deeply. They often interleave
email, calls, and shared documents. These are not what cause me grief. They’re
actually the most enjoyable part of my work.&lt;/p&gt;&lt;p&gt;But I get several messages that are small and, for technical reasons (not having
to do with their sender), ones that I don’t want to deal with right away. For instance:
&lt;ul&gt;&lt;li&gt;&lt;p&gt;I need to check something on an official work site. This requires going
through a multi-step authentication process with multiple redirections.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I need to look up a departmental policy. This requires searches, finding
the right page, scrolling to the right spot, reading the text carefully, and
formulating a response.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I need to approve some procedural matter, such as certifying effort on
past payments.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;I have to add an entry to a calendar, with supporting documentation.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;and so on. None of these takes more than five minutes in terms of wall-clock
time, often much less. But they completely destroy my concentration, and it
takes me a long time to recover my flow.&lt;/p&gt;&lt;p&gt;These are the “death by a thousand cuts” emails.Judging from the
&lt;a href="https://twitter.com/ShriramKMurthi/status/1386521260323184641"&gt;social
media response&lt;/a&gt;, a lot of people resonate with this diagnosis. There are often
several a week. They stare at me accusingly from my inbox, taunting me to make
explore/exploit decisions. These are the messages that destroy my
concentration, peace of mind, and joy. These are the bandits. These are what I
need to address.&lt;/p&gt;&lt;p&gt;But there’s another category of email that causes a different kind of pain:
personal email. It comes from friends and acquaintances. I’d like to write a
long, personal reply, but really not in the middle of the workday. So I either
write too short a reply, or put it off and take too long to reply, or feel the
usual pain of breaking away from my flow.&lt;/p&gt;&lt;p&gt;For both categories of messages, traditionally, there have been only two things
I can do (often both!). One is to leave them in there, staring at me
accusingly, distracting me, and making me feel guilty. The other is to deal
with them now, breaking concentration, and often leaving me feeling like I’ve
“gotten nothing done all day” (with maybe shorter personal email replies than
I would wish).&lt;/p&gt;&lt;p&gt;Here is one more observation that is true of most of these: they don’t need to
be dealt with right away. It’s very rare that they can’t wait a few days for
when you’re in a better state to deal with them. You might think this provides
flexibility, but in fact it makes the situation worse: you’re constantly
wondering when to deal with them. This is the classic multi-arm bandit
situation. Your inbox is a bandit who robs you of concentration, peace of mind,
and joy.&lt;/p&gt;&lt;h3&gt;4 &lt;a&gt;&lt;/a&gt;Hit Snooze?&lt;a href="#(part._.Hit_.Snooze_)"&gt;🔗&lt;/a&gt; &lt;/h3&gt;&lt;p&gt;They don’t need to be dealt with right away, right? Problem solved: use Gmail
Snooze or the equivalent!  Figure out when you want to do them, snooze until
then, they come up at that point, deal with them when they come up. Voilà!&lt;/p&gt;&lt;p&gt;But that has not worked at all, for three reasons.&lt;/p&gt;&lt;p&gt;First: I was constantly having to think about when to snooze to. Which
often led to increasingly complicated over-thinking (“Tue PM? Wed night? Oh
wait…”), checking my calendar multiple times, and so on. My concentration was
destroyed just in deciding when to snooze to.&lt;/p&gt;&lt;p&gt;Second: When it showed up, I wasn’t necessarily ready. Something else may have
come up (e.g., a colleague wanting urgent feedback). So now the emails are back
in my inbox staring accusingly at me. Now with extra Gmail chroming saying
the bandits are back. Which reminds me I’ve already put these off once. If I put
them off again, I know I’ll put them off again and again, and they may never
get done. So much more stress!&lt;/p&gt;&lt;p&gt;Third: They’re in there with lots of other email. Those others messages are
distracting me. And as I’m dealing with these, new ones are coming. It’s all a
big mess that is an even bigger source of stress. No better than before; heck,
maybe even worse. Snooze was failing badly.&lt;/p&gt;&lt;h3&gt;5 &lt;a&gt;&lt;/a&gt;My Solution&lt;a href="#(part._.My_.Solution)"&gt;🔗&lt;/a&gt; &lt;/h3&gt;&lt;p&gt;Hopefully I have laid it out clearly enough that the answer is obvious to you,
even though up front it wasn’t to me. Here is my solution: a new Gmail
label that I have always showing, even when empty. For now, I’m calling it&lt;/p&gt;&lt;p&gt;DBTC&lt;/p&gt;&lt;p&gt;That’s short for “Death By a Thousand Cuts”.&lt;/p&gt;&lt;h4&gt;5.1 &lt;a&gt;&lt;/a&gt;Populating the Folder&lt;a href="#(part._.Populating_the_.Folder)"&gt;🔗&lt;/a&gt; &lt;/h4&gt;&lt;p&gt;All little tasks that come up during the week are candidates for this
folder. During the week, I’m ruthless. My rule is,
&lt;ul&gt;&lt;li&gt;&lt;p&gt;if this message is not urgent, and&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;if dealing with it now will distract me, and&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;if it’s either not long, or if it’s personal&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;it goes straight into the folder. It’s out of my inbox; it’s out of my
sight. It’s a slot machine I don’t have to worry about playing.&lt;/p&gt;&lt;p&gt;Most of the time, I don’t have to even glance at the message to know it fits
this category. The sender, subject line, and short email preview will all
suffice.&lt;/p&gt;&lt;p&gt;This has the benefit of Snooze, in that it’s taken the message out of my
current field of vision. Unlike Snooze, I didn’t have to think about when to
move it to: the label already says when.One weakness: unlike Snooze,
which automatically awakens messages, this does not. You may need to use a
calendar for that. The critical thing is that it takes me almost no time to do
it. I don’t have to stop thinking about whatever I’m thinking about. I don’t
have to process any new information. I barely have to make a decision. I just
have to move it out of the way.&lt;/p&gt;&lt;p&gt;Note that this now leaves Snooze to do what it does well: sleep messages until
specific dates/times. Let’s say I’m expecting a reply from X on Y. I can Snooze
the thread until the time I want to be reminded about it. Alarm clocks ≠
folders; Snooze is an alarm clock, not a folder.&lt;/p&gt;&lt;p&gt;Sometimes, I get duplicate messages on a topic. For instance, when writing the
first version of this article, our final grades were due; we received multiple
reminders about it.  I was pretty sure I already had older messages about that
in the folder. Still, when I got new messages about it, I didn’t stop and
think, and I didn’t check: I didn’t want the distraction. It was more important
to not miss the matter than to worry about the duplicates. If when I processed
it I found  duplicates, no matter: it would just mean I had fewer things to
do.Reader: there were several duplicates. Score.&lt;/p&gt;&lt;p&gt;Note that if I leave things unread before putting them in the folder, the
folder count shows me how many things are in there. That gives me some sense of
the task list length.&lt;/p&gt;&lt;h4&gt;5.2 &lt;a&gt;&lt;/a&gt;Processing the Folder&lt;a href="#(part._.Processing_the_.Folder)"&gt;🔗&lt;/a&gt; &lt;/h4&gt;&lt;p&gt;The critical thing is to set aside time to process this folder: let’s
call it DBTC-time. I happen to do it on the weekend (because I’ve “remixed”
my week so I much more freely interleave work and personal time); you might
want to do it at some other time. You may even want to have two folders, one of
work DBTC and the other personal, and process them at different times. The
critical thing is to block that time, put it on your calendar, create a
reminder, and do whatever else you need to be disciplined about processing it.&lt;/p&gt;&lt;p&gt;Here’s the beauty of this system. When DBTC-time comes, I go to that folder. As
a result, I see only what is in that folder. Nothing else. No other
emails interleaving. No weird snooze color chroming. No new messages getting in
the way. That folder is exactly the stuff I have to get through.&lt;/p&gt;&lt;p&gt;Think of how you might process paper mail. You don’t check every letter as soon
as it’s delivered. In the evening, you pick up the mail and sort it. You might
even accumulate it to the weekend. You then set aside time for it. Same deal
here. The only exception is if there’s a letter or package you were urgently
awaiting; those you process right away. For me, that’s my interesting
mail.&lt;/p&gt;&lt;p&gt;My one goal is, “DBTC Zero” by the end of the DBTC period. It’s all got to get
cleaned out. I’m allowed to move it somewhere else, add things to todo-lists,
make issues on code repositories, or whatever else. But it’s got to be clear by
the end.&lt;/p&gt;&lt;p&gt;When I open the folder, I put myself in a “boring” state of mind. I know there
will be lots of annoying little logins and clicks and pedantry. I might have a
sports match in the background, or music, or a snack, or something. But what
I’ve found is:&lt;/p&gt;&lt;p&gt;Those tasks are not remotely as annoying or distracting when I do them in their
assigned “down” time as when they interrupt my flow.&lt;/p&gt;&lt;p&gt;Flow state is so hard to get, details are so hard to hold in my head, they
really hurt. During DBTC-time, they barely register: they’re more like a
low-order numbness than like a high-order pain. And I feel good that this
enabled me to have a better past week, and by doing this, I’ll have a better
next week. I can actually feel the virtue!&lt;/p&gt;&lt;h3&gt;6 &lt;a&gt;&lt;/a&gt;What About Things That Aren’t Email?&lt;a href="#(part._.What_.About_.Things_.That_.Aren_t_.Email_)"&gt;🔗&lt;/a&gt; &lt;/h3&gt;&lt;p&gt;Indeed! I now create DBTC channels in multiple media. For instance, my
task manager has a DBTC list as well. When I think of a task that
needs to be done, but meets the criteria above, it goes into the DBTC
list instead of my main todo list. When my DBTC-time arrives, I switch
my task manager to the DBTC list, just like my inbox. Same principle.&lt;/p&gt;&lt;p&gt;Another thing I’ve found useful is to treat entire apps as DBTC
items. For instance, I am effectively forced to use Discord, WhatsApp,
Apple Messages, etc. But I very rarely need to read these frequently,
and doing so would only create more distractions. Therefore, unless I
posted something and need a quick answer, I only read these during
DBTC-time. If you’ve been on any of these systems with me, you may
have noticed I typically only respond once a week, on the
weekend. This has the added benefit of slowing down conversations,
which on instant-messaging-style media is often a virtue (the
exception, naturally, being when you actually need instant
messaging).&lt;/p&gt;&lt;h3&gt;7 &lt;a&gt;&lt;/a&gt;Conclusion&lt;a href="#(part._.Conclusion)"&gt;🔗&lt;/a&gt; &lt;/h3&gt;&lt;p&gt;Hopefully you can see that all the issues raised earlier are addressed
by this process. I’ve been doing this since March 2021, and it
continues to work well for me. I hope it works for you too!&lt;/p&gt;&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://parentheticallyspeaking.org/articles/bandit-inbox/</guid>
      <category>Hacker News</category>
      <pubDate>Mon, 22 Dec 2025 04:04:04 +0000</pubDate>
    </item>
    <item>
      <title>Why did we use leaded petrol for so long? (2017)</title>
      <link>https://www.bbc.com/news/business-40593353</link>
      <description>Leaded petrol was safe. Its inventor was sure of it.</description>
      <content:encoded>&lt;article&gt;&lt;h1&gt;Why did we use leaded petrol for so long?&lt;/h1&gt;27 August 2017ShareSaveTim HarfordBBC World Service, 50 Things That Made the Modern EconomyShareSave&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="Science Photo Library Chemist Thomas Midgley" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/10479/production/_97018666_9761100thomas_midgley_us_chemist-spl.jpg.webp"/&gt;Science Photo LibraryChemist Thomas Midgley insisted that tetraethyl lead was safe&lt;p&gt;Leaded petrol was safe. Its inventor was sure of it. &lt;/p&gt;&lt;p&gt;Facing sceptical reporters at a press conference in October 1924, Thomas Midgley dramatically produced a container of tetraethyl lead - the additive in question - and washed his hands in it. &lt;/p&gt;&lt;p&gt;"I'm not taking any chance whatever," Midgley declared. "Nor would I... doing that every day."&lt;/p&gt;&lt;p&gt;Midgley was - perhaps - being a little disingenuous. He had recently spent several months in Florida, recuperating from lead poisoning.&lt;/p&gt;&lt;p&gt;Some of those who'd made Midgley's invention hadn't been so lucky, which is why reporters were interested.&lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="line" src="https://ichef.bbci.co.uk/news/624/mcs/media/images/76020000/jpg/_76020974_line976.jpg"/&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="Programme image for 50 Things That Made the Modern Economy" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/711C/production/_92965982_50things_promo_image_24new_1920x1080.jpg.webp"/&gt;&lt;p&gt;&lt;a href="http://www.bbc.co.uk/programmes/p04b1g3c"&gt;50 Things That Made the Modern Economy&lt;/a&gt; highlights the inventions, ideas and innovations which have helped create the economic world in which we live.&lt;/p&gt;&lt;p&gt;It is broadcast on the BBC World Service. You can find &lt;a href="http://www.bbc.co.uk/programmes/p057fvwf"&gt;more information about the programme's sources&lt;/a&gt; and &lt;a href="http://www.bbc.co.uk/programmes/p057fvwf"&gt;listen online&lt;/a&gt; or &lt;a href="http://www.bbc.co.uk/programmes/p04b1g3c/episodes/downloads"&gt;subscribe to the programme podcast.&lt;/a&gt;&lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="line" src="https://ichef.bbci.co.uk/news/624/mcs/media/images/76020000/jpg/_76020974_line976.jpg"/&gt;&lt;p&gt;On the Thursday of the week before Midgley's press conference, at a Standard Oil plant in New Jersey, a worker named Ernest Oelgert started hallucinating. By Friday, he was running around the laboratory, screaming in terror. &lt;/p&gt;&lt;p&gt;On Saturday, with Oelgert dangerously unhinged, his sister called the police. He was taken to hospital and forcibly restrained. By Sunday, he was dead. Within the week, so were four of his colleagues - and 35 more were in hospital.&lt;/p&gt;&lt;p&gt;Only 49 people worked there. &lt;/p&gt;&lt;h2&gt;'The loony gas building'&lt;/h2&gt;&lt;p&gt;None of this surprised workers elsewhere in Standard Oil's facility. They knew there was a problem with tetraethyl lead. &lt;/p&gt;&lt;p&gt;As Gerald Markowitz and David Rosner note in their book Deceit and Denial: The Deadly Politics of Industrial Pollution, the lab where it was developed was known as "the loony gas building".  &lt;/p&gt;&lt;p&gt;Nor should it have shocked Standard Oil, General Motors or the DuPont Corporation, the three companies involved with adding tetraethyl lead to gasoline. &lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="Science Photo Library An aerial photograph of DuPont's Deepwater factory site, where tetraethyl lead (TEL) was developed" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/DD69/production/_97018665_976475dupont_deepwater_factory_site_1935-spl.jpg.webp"/&gt;Science Photo LibraryAn aerial photograph of DuPont's Deepwater factory site, where tetraethyl lead was developed&lt;p&gt;The first production line in Ohio had already been shut down after two deaths. A third plant elsewhere in New Jersey had also seen fatalities. Workers kept hallucinating insects - the lab was known as "the house of butterflies". &lt;/p&gt;&lt;p&gt;Better working practices could make tetraethyl lead safe to produce. But was it really sensible to add it to petrol, when the fumes would be belched out on to city streets?&lt;/p&gt;&lt;p&gt;About a century ago, when General Motors had first proposed adding lead to petrol - in order to improve performance - scientists were alarmed. They urged the government to investigate the public health implications. &lt;/p&gt;&lt;p&gt;Midgley breezily assured the surgeon general that "the average street will probably be so free from lead that it will be impossible to detect it or its absorption", although he conceded that "no actual experimental data has been taken". &lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="Science Photo Library Chemist Thomas Midgley with the Delco laboratory test engine" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/12B89/production/_97018667_9761200thomas_midgley-spl.jpg.webp"/&gt;Science Photo LibraryChemist Thomas Midgley with the Delco laboratory test engine&lt;p&gt;General Motors funded a government bureau to conduct some research, adding a clause saying it had to approve the findings. &lt;/p&gt;&lt;h2&gt;Risky, but useful?&lt;/h2&gt;&lt;p&gt;The bureau's report was published amid the media frenzy over Oelgert's poisoned workmates. It gave tetraethyl lead a clean bill of health and was met with some scepticism. &lt;/p&gt;&lt;p&gt;Under pressure, the government organised a conference in Washington DC in May 1925. The debate there exemplified the two extremes of approach to any new idea that looks risky, but useful. &lt;/p&gt;&lt;p&gt;In one corner: Frank Howard, vice-president of the Ethyl Corporation - a joint venture between General Motors and Standard Oil. He called leaded petrol a "gift of God", arguing that "continued development of motor fuels is essential in our civilization". &lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="Alamy Dr Alice Hamilton" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/6F32/production/_97266482_9751200cwb8tr.jpg.webp"/&gt;AlamyDr Alice Hamilton argued the benefits of adding lead to petrol were outweighed by the risks&lt;p&gt;In the other corner: Dr Alice Hamilton, the country's foremost authority on lead. &lt;/p&gt;&lt;p&gt;She argued leaded petrol was a chance not worth taking. "Where there is lead," she said, "some case of lead poisoning sooner or later develops, even under the strictest supervision."&lt;/p&gt;&lt;p&gt;Hamilton knew that lead had been poisoning people for thousands of years. In 1678, workers who made lead white - a pigment for paint - were described as suffering ailments including "dizziness in the head, with continuous great pain in the brows, blindness, stupidity".  &lt;/p&gt;&lt;p&gt;The Romans used lead in water pipes. Lead miners often ended up mad or dead - and some correctly intuited that low-level, long-term exposure was also unwise.&lt;/p&gt;&lt;p&gt;"Water conducted through earthen pipes is more wholesome than that through lead," wrote the civil engineer Vitruvius, 2,000 years ago. "This may be verified by observing the workers in lead, who are of a pallid colour." &lt;/p&gt;&lt;h2&gt;Pollution v progress&lt;/h2&gt;&lt;p&gt;Many societies still grapple with the general question on which Howard and Hamilton disagreed: how much pollution is a price worth paying for progress? &lt;/p&gt;&lt;p&gt;There's some evidence that as countries get richer, they tend initially to get dirtier and later clean up. &lt;/p&gt;&lt;p&gt;Economists call this the "environmental Kuznets curve", and it makes intuitive sense. If you're poor, you prioritise material gains. As your income grows, you may choose to spend some of it on a nicer, safer environment. &lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="Alamy Vitruvius" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/155AA/production/_97266478_9761300d8bc46.jpg.webp"/&gt;AlamyThe Roman civil engineer Vitruvius warned against the dangers of lead 2,000 years ago&lt;p&gt;But was lead-free petrol really such an expensive luxury? True, the lead additive solved a problem: it enabled engines to use higher compression ratios, which made cars more powerful. &lt;/p&gt;&lt;p&gt;However, it was not the only way to solve the problem. &lt;/p&gt;&lt;p&gt;Ethyl alcohol had much the same effect and wouldn't mess with your head, unless you drank it. Midgley knew this, having combined petrol with practically every imaginable substance, from iodine to camphor to melted butter. &lt;/p&gt;&lt;p&gt;Why did the petrol companies push tetraethyl lead instead of ethyl alcohol? Researchers who have studied the decision remain puzzled. Cynics might point out that any old farmer could distil ethyl alcohol from grain. It couldn't be patented, or its distribution profitably controlled. Tetraethyl lead could. &lt;/p&gt;&lt;h2&gt;The crime connection&lt;/h2&gt;&lt;p&gt;The US didn't tax lead in petrol until the 1970s, then finally banned it as part of clean air legislation, as the country moved down the far side of the environmental Kuznets curve. &lt;/p&gt;&lt;p&gt;Two decades later, in the 1990s, rates of violent crime started to go down. There are many reasons why this might have happened, but the economist Jessica Reyes had an intriguing thought. &lt;/p&gt;&lt;p&gt;Children's brains are especially susceptible to chronic lead poisoning. Is it possible that kids who didn't breathe leaded petrol fumes grew up to commit less violent crime?&lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt='Alamy Old petrol pump sign saying "For use as a motor fuel only. Contains Lead (Tetraethyl)' src="https://ichef.bbci.co.uk/news/480/cpsprodpb/2112/production/_97266480_976549b3y3e7.jpg.webp"/&gt;Alamy&lt;p&gt;Reyes could test her hypothesis: different US states phased out leaded petrol at different times. &lt;/p&gt;&lt;p&gt;By comparing the dates of clean air legislation with subsequent crime data, &lt;a href="http://www.nber.org/papers/w13097"&gt;she concluded that more than half the drop - 56% - was because of cars switching to unleaded petrol.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;Other researchers have found &lt;a href="http://scholar.harvard.edu/files/jfeigenbaum/files/feigenbaum_muller_lead_crime.pdf"&gt;similar links between lead water pipes and urban homicide.&lt;/a&gt;&lt;/p&gt;&lt;h2&gt;Disputed science and delayed regulation&lt;/h2&gt;&lt;p&gt;You can put a dollar figure on the value of crime reduction, Reyes found. It's about 20 times higher than the cost of de-leading petrol - and that's before you count other downsides of children breathing lead, like worse performance in school. &lt;/p&gt;&lt;p&gt;How did the US get this so wrong for so long? &lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="A Periam Photography / Alamy Stock Photo A sign warning of the dangers of asbestos" src="https://ichef.bbci.co.uk/news/480/cpsprodpb/12EC3/production/_97270577_976650f4g31j.jpg.webp"/&gt;A Periam Photography / Alamy Stock PhotoAsbestos continued to be widely used in construction despite the emerging evidence of its dangers&lt;p&gt;It's a tale of disputed science and delayed regulation, much like you could tell about asbestos, or tobacco, or other products we now know slowly kill us. &lt;/p&gt;&lt;p&gt;The problem is that people who want to ban things aren't always disinterested visionaries like Hamilton. Sometimes they're obstructive cranks. The only way to tell the difference is by conducting studies. &lt;/p&gt;&lt;p&gt;And, as Gerald Markowitz and David Rosner point out, "For the next four decades, all studies of the use of tetraethyl lead were conducted by laboratories and scientists funded by the Ethyl Corporation and General Motors".&lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="line" src="https://ichef.bbci.co.uk/news/624/mcs/media/images/76020000/jpg/_76020974_line976.jpg"/&gt;&lt;h2&gt;More from Tim Harford:&lt;/h2&gt;&lt;p&gt;&lt;a href="http://www.bbc.co.uk/news/business-38302874"&gt;How Diesel's engine changed the world&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://www.bbc.co.uk/news/business-39420729"&gt;Battery bonanza: From frogs' legs to mobiles and electric cars&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://www.bbc.co.uk/news/business-38650976"&gt;Why the falling cost of light matters&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="http://www.bbc.co.uk/news/business-39132802"&gt;How a razor revolutionised the way we pay for stuff&lt;/a&gt;&lt;/p&gt;&lt;img src="https://static.files.bbci.co.uk/bbcdotcom/web/20251210-151139-37baf2dfdd-web-2.36.1-1/grey-placeholder.png"/&gt;&lt;img alt="line" src="https://ichef.bbci.co.uk/news/624/mcs/media/images/76020000/jpg/_76020974_line976.jpg"/&gt;&lt;p&gt;And what of the scientist who first put lead in petrol? &lt;/p&gt;&lt;p&gt;By all accounts, Midgley was a genial man who may even have believed his own spin about the safety of a daily tetraethyl lead handwash.&lt;/p&gt;&lt;p&gt;But, as an inventor, his inspirations seem to have been cursed. His second major contribution to civilisation was the chlorofluorocarbon, or CFC, which improved refrigerators, but destroyed the ozone layer. &lt;/p&gt;&lt;p&gt;In middle age, afflicted by polio, Midgley applied his inventor's mind to lifting his weakened body out of bed. He devised an ingenious system of pulleys and strings. They tangled around his neck, and killed him. &lt;/p&gt;&lt;p&gt;Tim Harford writes the Financial Times's Undercover Economist column. &lt;a href="http://www.bbc.co.uk/programmes/p04b1g3c"&gt;50 Things That Made the Modern Economy&lt;/a&gt; is broadcast on the BBC World Service. You can &lt;a href="http://www.bbc.co.uk/programmes/p057fvwf"&gt;find more information about the programme's sources&lt;/a&gt; and &lt;a href="http://www.bbc.co.uk/programmes/p057fvwf"&gt;listen online&lt;/a&gt; or &lt;a href="http://www.bbc.co.uk/programmes/p04b1g3c/episodes/downloads"&gt;subscribe to the programme podcast.&lt;/a&gt;&lt;/p&gt;&lt;a href="https://www.bbc.com/news/magazine-29568505"&gt;&lt;h2&gt;The fatal attraction of lead&lt;/h2&gt;&lt;/a&gt;&lt;a href="https://www.bbc.com/news/magazine-27067615"&gt;&lt;h2&gt;Did removing lead from petrol spark a decline in crime?&lt;/h2&gt;&lt;/a&gt;&lt;a href="https://www.bbc.com/news/health-20961241"&gt;&lt;h2&gt;Does lead poisoning make you violent?&lt;/h2&gt;&lt;/a&gt;&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.bbc.com/news/business-40593353</guid>
      <category>Hacker News</category>
      <pubDate>Sun, 21 Dec 2025 20:40:00 +0000</pubDate>
    </item>
    <item>
      <title>How GNU Guile is 10x better (2021)</title>
      <link>https://www.draketo.de/software/guile-10x</link>
      <description>In Rust at Facebook by Fitzhardinge of the Mercurial team , Jeremy says
that a new language must be 10x better at something than one of the
(other) incumbent languages.</description>
      <content:encoded>&lt;div class="content" id="content"&gt;



&lt;a href="https://www.draketo.de/wissen.html"&gt;Wissen&lt;/a&gt;
&lt;a href="https://www.draketo.de/software.html"&gt;Software&lt;/a&gt;
&lt;a href="https://www.draketo.de/politik.html"&gt;Politik&lt;/a&gt;
&lt;a href="https://www.draketo.de/index.html"&gt;Â &lt;/a&gt;
&lt;a href="https://www.draketo.de/anderes.html"&gt;Anderes&lt;/a&gt;
&lt;a href="https://www.draketo.de/kreatives.html"&gt;Kreatives&lt;/a&gt;
&lt;a href="https://www.draketo.de/rollenspiel.html"&gt;Rollenspiel&lt;/a&gt;



&lt;a&gt;(dark mode)ðï¸&lt;/a&gt;
&lt;p&gt;
In &lt;a href="https://www.youtube.com/watch?v=kylqq8pEgRs&amp;amp;list=PL85XCvVPmGQhDOUIZBe6u388GydeACbTt&amp;amp;index=8"&gt;Rust at Facebook by Fitzhardinge of the Mercurial team&lt;/a&gt;, Jeremy says
that a new language must be 10x better at something than one of the
(other) incumbent languages.
&lt;/p&gt;
&lt;p&gt;
So I asked on IRC: whatâs the 10x advantage of &lt;a href="http://gnu.org/s/guile"&gt;Guile&lt;/a&gt;?
&lt;/p&gt;
&lt;p&gt;
This is not âwhich Scheme to chooseâ (aside from one specific feature). For that question, see the &lt;a href="https://wingolog.org/archives/2013/01/07/an-opinionated-guide-to-scheme-implementations"&gt;opinionated guide to scheme implementations&lt;/a&gt;. For Guile's 10x advantages (some due to being Scheme), read on.
&lt;/p&gt;

&lt;a href="https://www.draketo.de/software/guile-10x.pdf"&gt;&lt;img src="https://www.draketo.de/assets/pdf-thumbnail.png"/&gt;&lt;/a&gt;&lt;br/&gt;
&lt;a href="https://www.draketo.de/software/guile-10x.pdf"&gt;PDF&lt;/a&gt; (drucken)



&lt;h2&gt;1. powerful core&lt;/h2&gt;

&lt;p&gt;
Macros (&lt;code&gt;define-syntax&lt;/code&gt;) and delimited continuations enable creation of
high level concepts like &lt;a href="https://github.com/wingo/fibers"&gt;fibers&lt;/a&gt; without having to change the core.
&lt;/p&gt;
&lt;p&gt;
Thanks to the efficient compiler, there is rarely a need to use macros
for performance instead of for semantics, so your code stays cleaner.
&lt;/p&gt;
&lt;p&gt;
thanks to stis.
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
âDelimited continuations are superior to Python's yield, the macrology
is superior to any language except Scheme, the hackability is better
then essentially all closed sorurce solutions of program languages.&lt;br/&gt;
â¦&lt;br/&gt;
And the efficient inlining of lambdas is perhaps matched by C, but not
many higher languages. The design of Scheme really shines here compared
to e.g. Python.â â stis who is building &lt;a href="https://www.mail-archive.com/guile-devel%40gnu.org/msg15805.html"&gt;Python on Guile&lt;/a&gt;
&lt;/p&gt;
&lt;/blockquote&gt;



&lt;h2&gt;2. runtime introspection and modification&lt;/h2&gt;

&lt;p&gt;
Compared to C and Go, runtime access to running code is very useful.
You can jump into a module and modify anything during runtime.
&lt;/p&gt;
&lt;p&gt;
thanks to str1ngs for this point.
&lt;/p&gt;
&lt;p&gt;
While you even get a subset of this with Java using incremental
compilation and hot reloading of code in IntelliJ, at work weâre always
dancing around changes that change some method arguments or streams,
because those break hot reloading so you have to restart.
&lt;/p&gt;
&lt;p&gt;
And for Javascript we can in theory replace every function, but in
practice at work we transpile everything with babel and webpack and
that breaks hot reloading, so we have to reload after every change.
&lt;/p&gt;
&lt;p&gt;
In Guile you can either start in a REPL, or create a dedicated REPL in
the running program, or create a REPL socket for your development
environment and connect to that to hack on the running server.
&lt;/p&gt;
&lt;p&gt;
Then you can re-define all top-level definitions in all modules.
&lt;/p&gt;
&lt;p&gt;
As example str1ngs usually develops the &lt;a href="http://www.nongnu.org/nomad/"&gt;Nomad web browser&lt;/a&gt; like that.
&lt;/p&gt;
&lt;p&gt;
And if you need a game loop as main thread, you can use it to drive the &lt;a href="https://www.gnu.org/software/guile/docs/docs-2.2/guile-ref/Cooperative-REPL-Servers.html"&gt;cooperative repl server&lt;/a&gt;.
&lt;/p&gt;



&lt;h2&gt;3. s-expressions and homoiconicity&lt;/h2&gt;

&lt;p&gt;
Compared to non-lisp languages, the regularity of s-expressions and
being able to treat code as data and the other way round
(&lt;a href="https://en.wikipedia.org/wiki/Homoiconicity"&gt;homoiconicity&lt;/a&gt;) is a big advantage.
&lt;/p&gt;
&lt;p&gt;
thanks to pinoaffe for this point.
&lt;/p&gt;
&lt;p&gt;
This is an essential elegance &lt;a href="http://www.draketo.de/proj/wisp/why-wisp.html"&gt;I want to conserve in wisp&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
Wikipedia notes as advantage that 
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
extending the language with new concepts typically becomes simpler, as data representing code can be passed between the meta and base layer of the program. â &lt;a href="https://en.wikipedia.org/w/index.php?title=Homoiconicity&amp;amp;oldid=1037434473#Uses_and_advantages"&gt;Homoiconicity: Uses and Advantages&lt;/a&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
and
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
It can be much easier to understand how to manipulate the code since it can be more easily understood as simple data (since the format of the language itself is a data format).  â &lt;a href="https://en.wikipedia.org/w/index.php?title=Homoiconicity&amp;amp;oldid=1037434473#Uses_and_advantages"&gt;Homoiconicity: Uses and Advantages&lt;/a&gt;
&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
For Wisp I use this a lot, because it allows me to do a first simple
pass over the code, add incremental improvements and finally have the
cleaned up code that I can pass to the language spec definition:
&lt;/p&gt;

&lt;pre&gt;define : wisp-scheme-read-chunk port
         . "Read and parse one chunk of wisp-code"
     let : :  lines : wisp-scheme-read-chunk-lines port
          wisp-make-improper
            wisp-replace-empty-eof
              wisp-unescape-underscore-and-colon
                wisp-replace-paren-quotation-repr
                  wisp-propagate-source-properties
                    wisp-scheme-indentation-to-parens lines
&lt;/pre&gt;

&lt;p&gt;
Also this enables me to write a Question-Asking macro for
&lt;a href="https://hg.sr.ht/~arnebab/dryads-wake/"&gt;dryads wake&lt;/a&gt; without going totally insane. Usage:
&lt;/p&gt;

&lt;pre&gt;Choose
    : new game
      ,(first-encounter)
    : load game
      ,(load-game)
    : show prologue
      ,(prologue) ,(welcome-screen)
    : exit
      We hope you enjoyed our game!
&lt;/pre&gt;

&lt;p&gt;
Definition:
&lt;/p&gt;

&lt;pre&gt;define-syntax-rule : Choose . choices
   . "Ask questions, apply consequences"
   begin 
     say-lines : ("") ;; newline before question
     let loop :
       ;; Get the response via the Ask macro 
       ;; to evaluate inline-code incrementally
       define resp : string-&amp;gt;number : Ask choices
       or
         cond
           : equal? resp 1
             Respond1 choices
           : equal? resp 2
             Respond2 choices
           : equal? resp 3
             Respond3 choices
           : equal? resp 4
             Respond4 choices
           : equal? resp 5
             Respond5 choices
           : equal? resp 6
             Respond6 choices
           else
             . #f
         loop

define-syntax Ask
  lambda (x)
    syntax-case x ()
      : _ (choices ...)
        #` begin
           ask (QuoteFirsts (choices ...))


&lt;/pre&gt;

&lt;p&gt;
QuoteFirsts interprets the questions as data but leaves the answers as
code which can e.g. use &lt;code&gt;,(load-game)&lt;/code&gt; to open the load game dialog.
&lt;/p&gt;



&lt;h2&gt;4. interfacing with C and access from C&lt;/h2&gt;

&lt;p&gt;
Most of Guile procedures can be called from C (for example when
embedding Guile) and it is easy to interoperate with C
from Guile Scheme.
&lt;/p&gt;
&lt;p&gt;
thanks to str1ngs for this points, too.
&lt;/p&gt;
&lt;p&gt;
I did not embed Guile in a C-program myself yet, but Guile provides
detailed examples and tutorials for this &lt;a href="https://www.gnu.org/software/guile/learn/"&gt;in its Documentation&lt;/a&gt;, with C
interfaces explicitly documented for most of its procedures.
&lt;/p&gt;
&lt;p&gt;
This is the shocking number 4: Guile is better for writing C-Programs than C itself. Consider yourself shocked :-) â and no, this argumentation is not complete. But if youâre here, the title led you here. &lt;a href="https://www.youtube.com/watch?v=S2xHZPH5Sng"&gt;#legitbait&lt;/a&gt;.
&lt;/p&gt;
&lt;p&gt;
If you want to be seriously shocked, look at &lt;a href="http://sph.mn/computer/guides/c/c-indent.html"&gt;c-indent&lt;/a&gt;. Yes, that is Guile.
&lt;/p&gt;



&lt;h2&gt;5. fibers&lt;/h2&gt;

&lt;p&gt;
Fibers provide lightweight threads in Guile without having to change
anything in the core of Guile. They are reasonably performant and
provide concurrency as with Go-channels.
&lt;/p&gt;
&lt;p&gt;
thanks to stis for this point.
&lt;/p&gt;
&lt;p&gt;
With the name giving &lt;code&gt;fibers&lt;/code&gt; and &lt;code&gt;channels&lt;/code&gt; they provide an efficient
and scalable model for coordinated concurrency. See the &lt;a href="https://github.com/wingo/fibers/wiki/Manual"&gt;manual&lt;/a&gt; for
details.
&lt;/p&gt;
&lt;p&gt;
You can test their raw efficiency using either the &lt;a href="https://github.com/wingo/fibers/tree/master/benchmarks"&gt;webserver-benchmark&lt;/a&gt;
or the &lt;a href="https://github.com/atemerev/skynet/blob/master/guile-fibers/skynet.scm"&gt;guile-fibers entry in the skynet benchmark&lt;/a&gt;.
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
fibers is better than kludges like marking procedures and what
not and it is matched by very few languages. â stis
&lt;/p&gt;
&lt;/blockquote&gt;



&lt;h2&gt;6. embedded natural script writing&lt;/h2&gt;

&lt;p&gt;
For me, one 10x advantage over every other language is that I could
integrate &lt;a href="https://www.draketo.de/software/wisp.html"&gt;wisp&lt;/a&gt; and get an embedded script writing language for &lt;a href="https://hg.sr.ht/~arnebab/dryads-wake/"&gt;dryads wake&lt;/a&gt; 
(as embedded domain specific language: eDSL). Thereâs a talk that compares
this to other approaches (including ones I tried before):
&lt;a href="https://fosdem.org/2017/schedule/event/naturalscriptwritingguile/"&gt;Natural script writing with Guile&lt;/a&gt;. Hereâs a real example:
&lt;/p&gt;

&lt;pre&gt;define : first-encounter
    Enter : Juli Fin :profile juli
            Melter Lark :profile melter
            Rooted Breeze :profile dryad
            Old One

    Print
        Please choose your name
    game-state-init!
    game-state-name-set! : read-line
    game-state-id-set! : name-&amp;gt;id : game-state-name
    game-state-scene-set! first-encounter
    save-state : game-state-id
    Print
        Welcome ,(string-append (game-state-name) "!")

    Juli Fin
        Finally we have our own home!

    Melter Lark
        It took long enough.

    Juli Fin
        And it is moist for sure.

    Melter Lark
        I will dry it out.

    Rooted Breeze :eerie
        My slumber breaks
        my mind awakes
        who are you strangers
        in my home?

    Old One
        How do you answer?
        Juli is ,(score-&amp;gt;description (profile-ability-score (game-state) 'juli 'explain))
            . at explaining
        and ,(score-&amp;gt;description (profile-ability-score (game-state) 'juli 'fast-talk))
            . at fast-talk.
    Choose
        : explain your situation to appease the dryad
          ,(explain-your-home)
        : fast-talk the dryad to get her to leave and risk her anger
          ,(fast-talk-the-dryad)
&lt;/pre&gt;




&lt;h2&gt;7. hackability&lt;/h2&gt;

&lt;p&gt;
The language tower and infrastructure make it enjoyable to hack on and
extend Guile itself.
&lt;/p&gt;
&lt;p&gt;
thanks to stis for this point.
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
language tower and effective syntax extensions (define-syntax, etc.) -
without that, lokke might well not exist (such as it is), at least not
by now. â rlb (&lt;a href="https://github.com/lokke-org/lokke"&gt;lokke&lt;/a&gt; is Clojure on top of Guile)
&lt;/p&gt;
&lt;/blockquote&gt;



&lt;h2&gt;8. complete info-manual&lt;/h2&gt;

&lt;p&gt;
Guile comes with a complete and very readable manual in info-format.
If youâve ever tried to program Python without internet access (or
just without Google), youâll know to deeply appreciate this.
&lt;/p&gt;
&lt;p&gt;
You can find most answers by running
&lt;/p&gt;
&lt;pre&gt;
info guile
&lt;/pre&gt;
&lt;p&gt;
in the shell, or calling
&lt;/p&gt;
&lt;pre&gt;
C-h i m Guile Reference
&lt;/pre&gt;
&lt;p&gt;
in Emacs and starting a full-text search with &lt;code&gt;C-s {search terms} C-s&lt;/code&gt;.
&lt;/p&gt;



&lt;h2&gt;9. prototyping and creativity&lt;/h2&gt;

&lt;p&gt;
Compared to Python and C++ Guile removes barriers to abstraction. This
is also possible with R, but Guile provides good enough performance
for these abstractions to make them practical to use. 
&lt;/p&gt;
&lt;p&gt;
The low startup time helps for this, too.
&lt;/p&gt;
&lt;p&gt;
thanks to vijaymarupudi for this point.
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;
âGuile is particularly great for prototyping and creativity, and its
performance allows for such experiments to be deployed to the world
with minimal changes.
&lt;/p&gt;
&lt;p&gt;
I've been using it a lot lately for data cleaning and modeling, and
it's been greatâ â vijaymarupudi
&lt;/p&gt;
&lt;/blockquote&gt;



&lt;h2&gt;10. lots of fun&lt;/h2&gt;

&lt;p&gt;
Hacking in Guile/Scheme is just lots of fun.
&lt;/p&gt;
&lt;p&gt;
thanks to dsmith for this. Even though this sounds small and gets only a single line in this article, looking at the enthusiasm of people who hack on &lt;a href="http://guix.gnu.org"&gt;Guix&lt;/a&gt; shows that dsmith clearly has a point!
&lt;/p&gt;



&lt;h2&gt;11. More 10x advantages&lt;/h2&gt;

&lt;p&gt;
After I wrote this article, people noted more advantages. I might work them into the article sometime later, but for now they live here:
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;named lets, I could be without map reduce and all that, just let me have a named let construct â stis&lt;/li&gt;
&lt;li&gt;python-on-guile has copyable generators and yield as an actual function that can be passed to other functions â stis writing about &lt;a href="https://www.mail-archive.com/guile-devel%40gnu.org/msg15805.html"&gt;Python on Guile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/ijp/pfds"&gt;Purely Functional Datastructures&lt;/a&gt; and &lt;a href="https://github.com/ijp/fectors"&gt;fectors&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://spritely.institute/hoot/"&gt;Hoot&lt;/a&gt; lets you port your tools &lt;a href="https://spritely.institute/news/building-interactive-web-pages-with-guile-hoot.html"&gt;to the browser&lt;/a&gt; with minimal overhead â &lt;a href="https://spritely.institute/news/make-a-game-with-hoot-for-the-lisp-game-jam.html"&gt;including games&lt;/a&gt; like &lt;a href="https://spritely.institute/news/goblinville-a-spring-lisp-game-jam-2025-retrospective.html"&gt;Goblinville&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;


&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://www.draketo.de/software/guile-10x</guid>
      <category>Hacker News</category>
      <pubDate>Sun, 21 Dec 2025 16:16:49 +0000</pubDate>
    </item>
    <item>
      <title>Jingle Bells (Batman Smells): An incomplete festive folk-rhyme taxonomy</title>
      <link>https://loreandordure.com/2025/12/16/jingle-bells/</link>
      <description>Gather round the fire, everyone, and let me tell you a story. It has everything you could want in a Christmas blockbuster: superheroes and villains, a car crash, children singing, a mystery to solve and even a cameo appearance by Bart Simpson.</description>
      <content:encoded>&lt;article class="post-1568 post type-post status-publish format-standard has-post-thumbnail hentry category-academic-interest category-blog-post category-language category-newsletter-post category-now-and-then category-the-way-we-live tag-batman tag-children tag-christmas tag-folk-music tag-history tag-music tag-taxonomies tag-writing" id="post-1568"&gt;
&lt;!-- .entry-header --&gt; 

&lt;a href="https://loreandordure.com/author/loreordure/"&gt;Kate W.&lt;/a&gt; 

&lt;a href="https://loreandordure.com/category/blog-post/academic-interest/"&gt;Academic Interest&lt;/a&gt;, &lt;a href="https://loreandordure.com/category/blog-post/"&gt;Blog Post&lt;/a&gt;, &lt;a href="https://loreandordure.com/category/themes/language/"&gt;language&lt;/a&gt;, &lt;a href="https://loreandordure.com/category/blog-post/newsletter-post/"&gt;Newsletter Post&lt;/a&gt;, &lt;a href="https://loreandordure.com/category/by-decade/now-and-then/"&gt;Now and Then&lt;/a&gt;, &lt;a href="https://loreandordure.com/category/themes/the-way-we-live/"&gt;The Way We Live&lt;/a&gt; &lt;!-- .cat-links --&gt;

December 16, 2025December 17, 2025 
8 Minutes &lt;!-- .entry-meta --&gt;

&lt;p&gt;Gather round the fire, everyone, and let me tell you a story. It has everything you could want in a Christmas blockbuster: superheroes and villains, a car crash, children singing, a mystery to solve and even a cameo appearance by Bart Simpson. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;On a cold winter’s night, not so very long ago… &lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I asked the good folks of BlueSky which version of the school playground ditty “Jingle Bells (Batman Smells)” they remembered, and whether it bore any relationship to the one I’d had stuck in my head for several hours already that day, much to my abundant irritation, and which, dating from a playground in late 1980s London went: &lt;strong&gt;&lt;em&gt;“Jingle bells, Batman smells, Robin flew away. Father Christmas lost his knickers on the motorway! (Hey!)”&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It would turn out (spoiler alert!) that almost nobody recognised my version—though I did have it attested by a couple of people—but I was overwhelmed by the sheer number and variety of the versions that came like an avalanche into my mentions, so much so that I started noting down some of the variations and then ended up, if I’m perfectly honest, thinking about the whole Batman Smells situation in way too much detail.&lt;/p&gt;
&lt;p&gt;As some of you know, I work in lexicography but came to this work via a science background, and it felt very much like what I was looking at was taxonomy: an evolutionary tree if you will, with certain characteristics conserved between different forms of the rhyme, while mutations cause changes which are selected—or not—by the playground troubadours, and die out or spread, to mutate again. Now, obviously like any random sampling approach there is absolutely no way that the list of versions that I collected is anywhere near comprehensive, and the range of contributors is necessarily composed of the people in my wider network on BlueSky (itself famously the social media retirement home of Xennials and their fellow-travellers). That said, I got a good harvest of lyrics from both the UK and North America, along with a handful of Antipodeans (who reasonably enough should have been fast asleep when I was asking), enough, I think, to make a preliminary analysis and draw out one or two interesting trends.&lt;/p&gt;
&lt;p&gt;First, let me show you the most ridiculous diagram I have ever made: &lt;/p&gt;
&lt;a href="https://loreandordure.com/wp-content/uploads/2025/12/jinglebellsinfograph.png"&gt;&lt;img alt="A taxonomic diagram displaying different lyrics for Jingle Bells (Batman Smells)." src="https://loreandordure.com/wp-content/uploads/2025/12/jinglebellsinfograph.png?w=1024"/&gt;&lt;/a&gt;
&lt;p&gt;Think of it as a semi-quantitative taxonomy: basically the lyrics in larger type are more common in my data than the ones in smaller type, though none of that is remotely to scale. The two coloured lines through the lyrics represent the most common version from the UK (above, in green) and in North America (below, in gold), with the variations from those clustered around them. If I’ve made the chart correctly you should be able to find any variation of the rhyme I was given by following a route through the available lyrics.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Robin laid a &lt;/strong&gt;&lt;strong&gt;&lt;em&gt;WHAT&lt;/em&gt;&lt;/strong&gt;&lt;strong&gt;?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;This is the Great Transatlantic Divide. Almost none of my UK-attested versions involved an egg-laying Robin and essentially all of the North American ones did.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;“Jingle bells, Batman smells, Robin laid an egg. The Batmobile has lost a wheel and the Joker got away.”&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Overwhelmingly my American contributors remembered this version of the rhyme or very minor variations from it. One thing which was really obvious from my data was how heavily clustered the American versions were compared to the UK ones. The vast majority of American contributors in my comments were people replying “Yes, that was mine too!”, whereas the UK versions were much more diverse with most being attested by only one or a small handful of people. If the diagram were to scale the most common North American through-line would be absolutely enormous compared with the rest of the text.&lt;/p&gt;
&lt;p&gt;I will set aside the question of poetics here: I’m told that in a number of (particularly Midwestern) US accents the phonetic agreement between ‘egg’ and ‘away’ is a somewhat-imperfect rhyme rather than the absolute mystery that it seems to my British ear. But the dramatic dominance of a particular version, over such a large and diverse country, and over time, seems curious to me.&lt;/p&gt;
&lt;p&gt;But before we look at this in more detail, we need to make a little detour to Springfield to visit The Simpsons.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The Simpsons? Why?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Because the North American Standard Version appears in the very first episode of the Simpsons, titled “&lt;a href="https://simpsons.fandom.com/wiki/Jingle_Bells"&gt;Simpsons Roasting on an Open, Fire&lt;/a&gt;”, broadcast in the US on Fox in December 1989. Several of my social media reporters specifically mentioned this episode of the Simpsons, and it would appear that, at least among the younger generations of schoolyard crooners, there is a belief that this is where the rhyme actually originated. That much is abundantly false, as I have plenty of reports from the 1970s and 1980s which antedate the Simpsons phenomenon substantially.&lt;/p&gt;
&lt;p&gt;However: is it possible that the appearance of this particular version of the rhyme in a show with such a profound influence on generations of kids (young and old) may have retconned people’s memories, and replaced different versions they originally knew in their memories with this consensus version? Or is it just that the writers knew the same version as (almost) everyone else was already singing and that’s why it ended up in the script?&lt;a href="#53144334-6aa2-4c16-837d-89e536a4144a"&gt;1&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;But, one might reasonably wonder, if this is a case of a highly popular media franchise essentially overwriting previous folk memories, why didn’t Robin’s egg, Batmobile’s wheel and the Joker exiting stage right become prevalent in the UK? After all, the Simpsons was (and remains) a TV phenomenon here, too? I have a theory, and it’s a boring one to do with the broadcast environment here compared with North America. &lt;/p&gt;
&lt;p&gt;The first episode of The Simpsons aired on Sky1 (a satellite broadcast channel) in September of 1990. Satellite broadcasting had only really launched in the UK, and it wouldn’t reach its first million subscribers &lt;a href="https://www.systemtek.co.uk/2024/08/the-history-of-sky-tv-from-its-humble-beginnings-to-a-media-powerhouse/"&gt;until the following year&lt;/a&gt;. It was only in 1996 when the BBC picked up the broadcast rights to The Simpsons that it finally reached a mass audience here. The older series were sporadically repeated but would not have reached a mass audience, and critically not at the time of year when kids would have been singing this in the school yard.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Back up a bit here, how does Batman come into this?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Good question! I’m not a comics historian so I had to look this up. &lt;a href="https://dc.fandom.com/wiki/Batman_Publication_History"&gt;Wikipedia tells me&lt;/a&gt; that Batman first appears as a character in 1939, and the first Batmobile first appears by name in 1941. The emergence of Batman as a playground hero—and the particularly camp Batmobile we all know and love—most likely dates from the &lt;a href="https://en.wikipedia.org/wiki/Batman_(TV_series)"&gt;TV series starring Adam West and Burt Ward&lt;/a&gt; which first screened between 1966 and 1968.&lt;/p&gt;
&lt;p&gt;Looking at the clustering of variations, Americans, generally, seem more faithful to the canon: in addition to almost all the rhymes being Batmobile-related, the other characters that get a mention also come, by and large, from the Batman universe, with appearances not just from the Joker, but from Penguin, the Riddler, and the Commissioner. &lt;/p&gt;
&lt;p&gt;It’s probably not surprising that the Batmobile consistently loses or breaks one or more wheels, the rhyme is a gift, and the mental image is strong: between these two things that lyric is going to be pretty sticky. We observe a rarer but nevertheless persistent variation on the final phrase where the Joker does / takes / learns ballet—and these taken together would be the second most popular N. American version—none of my reporters were able to account for it, but you have to admit that Joker doing a pirouette is a joyful little mental image and a great deal more fun than him simply making good his escape.&lt;/p&gt;
&lt;p&gt;On the other side of the Atlantic, not only is there much more ‘biodiversity’ on display with many different versions jostling for position, but the choice of secondary characters is a lot less canonical. I collected appearances by incidental characters including Father Christmas, Wonder Woman, Uncle Billy&lt;a href="#255f9738-eda2-4339-948e-06dee4a8fc55"&gt;2&lt;/a&gt;, and Kojak in addition to Penguin. These secondary characters and their adventures, where they appear, displace the wonky-wheeled-Batmobile in the third part of the rhyme, though they are often losing important items of their own, often—but not universally—on the motorway (a variation not seen in North America, presumably due to ‘interstate’ being a piss-poor rhyme choice).&lt;/p&gt;
&lt;p&gt;The differences between these and the North American versions start sooner though, as in almost all cases in the UK Robin either flew away (this is most common), ran away, or got away. Despite our enlarged cast of characters, by a relatively small margin, the Batmobile losing a wheel pips other options at the post for the third clause. By a fairly narrow lead the most common UK version appears to be: &lt;strong&gt;&lt;em&gt;“Jingle bells, Batman smells, Robin flew away. The Batmobile lost a wheel on the motorway!”&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Which, being as it’s pretty boring, and self-explanatory, I intend to say no more about. &lt;/p&gt;
&lt;p&gt;Something interesting we see in UK sources is localisation of the rhyme—absent from the North American versions I was given. So when things are occurring ‘on the motorway’, there’s about a 50:50 chance they’re reported happening on a specific motorway, the M1, the M4, M5 and M6 appeared in my attestations, usually the local motorway to where the rhyme was picked up. A Scottish Batmobile lost its wheel and landed in the (river) Tay. &lt;/p&gt;
&lt;p&gt;While I had very few antipodean attestations, Wonder Woman lost both her bosoms and her knickers (apparently on separate occasions) while flying TAA&lt;a href="#91638257-d6c1-4e28-a948-9595c7422459"&gt;3&lt;/a&gt;.   The tendency to lose underwear and body parts is probably best attributed to the fact that bosoms, willies, and knickers are just straightforwardly hilarious when you’re seven. &lt;/p&gt;
&lt;p&gt;There are extra variations which I can only encourage you to scroll around the graph and enjoy, as time presses on.&lt;/p&gt;
&lt;p&gt;The one thing I was pretty sure about when I started was that whatever else happens, everyone agreed that Batman smells. &lt;/p&gt;
&lt;p&gt;But before I finish I just want to mention the tantalising possibility of a living fossil…&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;A living fossil?&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Think of a &lt;a href="https://www.marlin.ac.uk/species/detail/50"&gt;Lamprey&lt;/a&gt;. Sometimes as the evolutionary process carries on a species gets… left behind, doesn’t go extinct, doesn’t change much, just sort of hangs around and occasionally bites chunks out of sharks? Living fossil. &lt;/p&gt;
&lt;p&gt;I had a single report of a Batman-free rhyme (the very first thread that separates from the main versions in the chart): &lt;strong&gt;&lt;em&gt;“Jingle Bells, [kid’s name] smells, twenty miles away. He made a fart behind the cart and blew up the U S A.”&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;While I didn’t find a second attestation for a whole version of this, I picked up a UK-based version where, after Robin flew away, he &lt;em&gt;“Did a fart behind the cart and blew up the IRA” &lt;/em&gt;(Surrey, 1970s) and a further attestation, after the chart was drawn, from the UK for &lt;em&gt;“Jingle Bells, [kid’s name] smells, let’s all ran away”&lt;/em&gt; (Lancashire, 1970s), though the reporter couldn’t remember the rhyme having a second part. There are also sporadic final parts of the rhyme where someone or something ends up in the hay, which makes much more sense in cart-related contexts than anything else.&lt;/p&gt;
&lt;p&gt;The original version of Jingle Bells (then titled &lt;em&gt;“One Horse Open Sleigh”&lt;/em&gt;) was &lt;a href="https://www.songhall.org/profiles/j-s-pierpont"&gt;composed by James Pierpont&lt;/a&gt; and first published some time around 1857. It’s a catchy little ditty, and, if you think about it, it’s quite likely that kids were butchering it (and using it for a bit of casual bullying!) long before Batman got on the scene…&lt;/p&gt;
&lt;p&gt;***&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;strong&gt;Wishing you all a very Merry Christmas and a Happy New Year&lt;/strong&gt;&lt;/em&gt;, please try not to lose any wheels on the motorway, any rolling in the hay should be strictly consensual on all parts, and anything that looks like it might be Robin’s egg should probably be treated with the same suspicion given to yellow snow…&lt;/p&gt;
&lt;p&gt;Thank you for sharing this journey with me. &lt;em&gt;See you in 2026!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Lore and Ordure is a digital busking project –&lt;br/&gt;&lt;a href="https://ko-fi.com/loreandordure"&gt;if you enjoy what I’m doing here, please throw some money in the hat!&lt;/a&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;a href="https://ko-fi.com/loreandordure"&gt;&lt;img src="https://loreandordure.com/wp-content/uploads/2024/02/kofi_button_blue.png"/&gt;&lt;/a&gt;

&lt;p&gt;&lt;em&gt;This blog only exists thanks to the generous support of my readers, so, &lt;strong&gt;thank you&lt;/strong&gt;! &lt;/em&gt;&lt;br/&gt;Your tips and donations support my writing here and contribute towards my PhD expenses.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Please &lt;a href="https://loreandordure.com/subscribe/"&gt;subscribe via email&lt;/a&gt; &amp;amp; share my work with others who might enjoy it.&lt;/em&gt;&lt;br/&gt;&lt;em&gt;You can make both one-off and recurring donations &lt;a href="https://ko-fi.com/loreandordure"&gt;on my Ko-Fi page&lt;/a&gt;&lt;/em&gt;&lt;br/&gt;&lt;em&gt;and buy my letterpress prints in my &lt;a href="https://ko-fi.com/loreandordure/shop"&gt;Ko-Fi shop&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;
&lt;ol&gt;&lt;li&gt;This question, obviously, isn’t one I can answer with the information currently at my disposal, and is therefore left as an exercise for some future scholar to pick up. It’s interesting that the same version makes it into the 1992 episode of Batman: The Animated Series “&lt;a href="https://subslikescript.com/series/Batman_The_Animated_Series-103359/season-1/episode-38-Christmas_with_the_Joker"&gt;Christmas with the Joker&lt;/a&gt;”.  &lt;a href="#53144334-6aa2-4c16-837d-89e536a4144a-link"&gt;↩︎&lt;/a&gt;&lt;/li&gt;&lt;li&gt;The same Uncle Billy, presumably, who had a 10 foot willy? &lt;a href="#255f9738-eda2-4339-948e-06dee4a8fc55-link"&gt;↩︎&lt;/a&gt;&lt;/li&gt;&lt;li&gt;A now defunct Australian regional airline which, we speculate, may have been noted for its careless baggage handling. &lt;a href="#91638257-d6c1-4e28-a948-9595c7422459-link"&gt;↩︎&lt;/a&gt;&lt;/li&gt;&lt;/ol&gt;

&lt;p&gt;&lt;/p&gt;
&lt;h3&gt;Share this:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="mailto:?subject=%5BShared%20Post%5D%20Jingle%20Bells%20%28Batman%20Smells%29%3A%20an%20incomplete%20festive%20folk-rhyme%20taxonomy&amp;amp;body=https%3A%2F%2Floreandordure.com%2F2025%2F12%2F16%2Fjingle-bells%2F&amp;amp;share=email"&gt;
Click to email a link to a friend (Opens in new window)
Email
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/2025/12/16/jingle-bells/?share=bluesky"&gt;
Click to share on Bluesky (Opens in new window)
Bluesky
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/2025/12/16/jingle-bells/?share=mastodon"&gt;
Click to share on Mastodon (Opens in new window)
Mastodon
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/2025/12/16/jingle-bells/?share=facebook"&gt;
Click to share on Facebook (Opens in new window)
Facebook
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/2025/12/16/jingle-bells/?share=threads"&gt;
Click to share on Threads (Opens in new window)
Threads
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="#"&gt;More&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/2025/12/16/jingle-bells/?share=x"&gt;
Click to share on X (Opens in new window)
X
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/2025/12/16/jingle-bells/?share=linkedin"&gt;
Click to share on LinkedIn (Opens in new window)
LinkedIn
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/2025/12/16/jingle-bells/?share=reddit"&gt;
Click to share on Reddit (Opens in new window)
Reddit
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/2025/12/16/jingle-bells/?share=pinterest"&gt;
Click to share on Pinterest (Opens in new window)
Pinterest
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/2025/12/16/jingle-bells/?share=tumblr"&gt;
Click to share on Tumblr (Opens in new window)
Tumblr
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;/ul&gt;Like Loading...&lt;a&gt;&lt;/a&gt;

&lt;h3&gt;&lt;em&gt;Related&lt;/em&gt;&lt;/h3&gt;
 &lt;!-- .entry-content --&gt;

&lt;ul&gt;&lt;li&gt;Tagged&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/tag/batman/"&gt;batman&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/tag/children/"&gt;children&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/tag/christmas/"&gt;Christmas&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/tag/folk-music/"&gt;folk-music&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/tag/history/"&gt;history&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/tag/music/"&gt;music&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/tag/taxonomies/"&gt;taxonomies&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://loreandordure.com/tag/writing/"&gt;writing&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;!-- .post-tags --&gt; &lt;!-- .entry-footer --&gt;


&lt;strong&gt;Published&lt;/strong&gt;
December 16, 2025December 17, 2025 &lt;!-- .site-posted-on --&gt;

&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://loreandordure.com/2025/12/16/jingle-bells/</guid>
      <category>Hacker News</category>
      <pubDate>Sun, 21 Dec 2025 11:38:48 +0000</pubDate>
    </item>
    <item>
      <title>I rebuilt FlashAttention in Triton to understand the performance archaeology</title>
      <link>https://aminediro.com/posts/flash_attn/</link>
      <description>⏲️ Estimated reading time ~45min.</description>
      <content:encoded>&lt;article&gt;


Table of Contents



&lt;blockquote&gt;
&lt;p&gt;⏲️ Estimated reading time ~45min.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1&gt;Flash Attention: From Theory to Implementation&lt;/h1&gt;
&lt;p&gt;Flash Attention has become one of the most impactful optimizations in modern deep learning. Since the original paper was published in 2022, we’ve seen four major versions—each squeezing more performance out of increasingly powerful hardware. But here’s the thing: reading papers is one thing, understanding &lt;em&gt;why&lt;/em&gt; these optimizations were made is another entirely.&lt;/p&gt;
&lt;p&gt;My goal here is simple: start from first principles, implement FlashAttention v1 exactly as described in the paper, profile it, find the bottlenecks, and see how far we can push it. We’ll build intuition by iterating on the algorithm, discovering through profiling exactly why v2, v3, and v4 were necessary. Think of this as archaeology—digging through the performance layers to understand what each version was really solving.&lt;/p&gt;
&lt;p&gt;So let’s put ourselves in the shoes of that mythical Stanford grad student. You’ve finally finished configuring your neovim and archlinux setup (a multi-year endeavor, naturally). You open up a fresh LLaMA model to peek under the hood. Text goes in, gets tokenized, embedded, then flows through a stack of transformer blocks. Standard stuff. But then you look closer at the attention mechanism—three projections and then… there it is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;scores = torch.matmul(q, k.transpose(3, 2)) / math.sqrt(self.head_dim)
scores = F.softmax(scores, dim=-1)
output = torch.matmul(scores, v)  # (B, N_h, T, D_h)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This monstrosity of a code is staring you right in the face. For those who don’t immediately see the problem with these 4 lines, let me add some annotations on how this would normally execute in PyTorch (without compilation).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# 1. We load q `(B, N_h, S, D_h)` and k `(B, N_h, S, D_h)`
# 2. We compute Q.Kt and write it back to HBM. Note score is `(B, N_h, S, S)`.
scores = torch.matmul(q, k.transpose(3, 2)) / math.sqrt(self.head_dim)
# 3. Reload the scores tensor to compute the softmax and write it back to HBM
scores = F.softmax(scores, dim=-1)
# 4. Load v `(B, N_h, S, D_h)`, load the scores from HBM
# 5. Compute scores@v and write it back to HBM.
output = torch.matmul(scores, v)  # `(B, N_h, T, D_h)`
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Do you see it now? Well, we have three tensors &lt;code&gt;q&lt;/code&gt;, &lt;code&gt;k&lt;/code&gt;, &lt;code&gt;v&lt;/code&gt; each of dimension &lt;code&gt;(B, N_h, T, D_h)&lt;/code&gt;&lt;a href="#fn:1"&gt;1&lt;/a&gt;. The output tensor of the attention mechanism is &lt;code&gt;(B, N_h, T, D_h)&lt;/code&gt;, and somehow in the middle we had to materialize a &lt;code&gt;(B, N_h, S, S)&lt;/code&gt; tensor for funsies. The attention mechanism has a critical bottleneck: &lt;strong&gt;quadratic memory complexity&lt;/strong&gt;. Let’s take a standard training sequence length &lt;code&gt;S=8192&lt;/code&gt;. Computing attention naively requires &lt;code&gt;O(S²)&lt;/code&gt; memory to store the full attention matrix, which means consuming several gigabytes of GPU memory. Crucially, in modern transformers, &lt;code&gt;S &amp;gt;&amp;gt; D_h&lt;/code&gt; (sequence length is much larger than head dimension) - we typically have &lt;code&gt;S=8192&lt;/code&gt; or more while &lt;code&gt;D_h=64&lt;/code&gt; or &lt;code&gt;128&lt;/code&gt;. This massive asymmetry is what makes Flash Attention algorithm possible. The second big issue here is the back and forth to HBM. Modern GPUs have compute throughput vastly exceeding memory bandwidth. Repeatedly reading Q, K, V, and scores from slow High Bandwidth Memory (HBM) is going to greatly impact performance (more on this later).&lt;/p&gt;
&lt;p&gt;The whole idea of Flash Attention is to bypass these intermediate steps—i.e., go from tensors q, k, v to the output tensor directly and compute the attention in one go, with minimal memory footprint (materializing only the tensors we need) and minimal back and forth to HBM, and hopefully getting to &lt;code&gt;O(S)&lt;/code&gt; memory complexity.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;The Plan&lt;/strong&gt;: Start with FlashAttention v1 from the original paper. Implement it faithfully in Triton, profile with NVIDIA’s tooling, identify the bottlenecks, then iterate. Each optimization will teach us something about the GPU memory hierarchy and why the subsequent versions (v2, v3, v4) introduced the changes they did. Four versions represents an enormous amount of engineering work—let’s see how much of that journey we can reconstruct by just following the profiler’s breadcrumbs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Setup and Hardware&lt;/h2&gt;
&lt;p&gt;First things first, I’ll use &lt;code&gt;triton&lt;/code&gt; to implement the attention kernels. I wanted to implement them in CUDA but I thought this was a good opportunity to learn &lt;code&gt;triton&lt;/code&gt;. I’m always skeptical about DSLs and abstractions that promise “write once, run fast everywhere,” but like my very wise friend &lt;a href="https://fleetwood.dev/"&gt;Chris Fleetwood&lt;/a&gt; said, you can’t go wrong learning something shipped inside PyTorch. Running &lt;code&gt;triton&lt;/code&gt; is also extremely straightforward and reduces the mess of boilerplate and C++ code that you have to write when implementing CUDA kernels, especially if you want to call them from Python. I actually went back and reimplemented Flash Attention in CUDA to have a bit more control, but that will come later (a little teasing).&lt;/p&gt;
&lt;p&gt;I’ll compare these kernels directly with a reference PyTorch implementation, first to make sure the kernel is doing what it’s supposed to, and second to profile the kernel against the baseline.&lt;/p&gt;
&lt;h3&gt;Why Triton? Block-level Programming Without Thread Hell&lt;/h3&gt;
&lt;p&gt;Triton is a Python-based DSL for writing GPU kernels. The pitch is simple: write Python-like code at the block level, and the compiler handles individual thread management, memory coalescing, and other low-level optimizations. What makes Triton fundamentally different from CUDA is the abstraction level - in CUDA, you explicitly program individual threads of a block. In Triton, you write your kernel thinking about blocks/tiles of data a little bit how you’d write torch code, and the compiler figures out how to map that to threads. It handles threads data access pattern, synchronization barriers and work splitting. My skepticism comes from the fact that I don’t really trust these “magic” compilers for running parallel code. Usually, the promised performance falls apart quickly. But Triton has a few things going for it:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;It’s maintained by OpenAI and ships with PyTorch 2.0+&lt;/li&gt;
&lt;li&gt;The generated PTX is easily inspectable, so you can see what it’s actually doing&lt;/li&gt;
&lt;li&gt;It handles the tedious bits (pointer arithmetic, bounds checking) while still giving you control over the algorithm. You write your kernel at block level and the compilers issues the correct code to load your tensors in.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Setup&lt;/h3&gt;
&lt;p&gt;I’m running this on my personal machine:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;OS&lt;/strong&gt;: Arch Linux (btw)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;GPU&lt;/strong&gt;: NVIDIA GeForce RTX 2070 (8 GB VRAM)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Driver&lt;/strong&gt;: 580.95.05&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;CUDA&lt;/strong&gt;: 13.0&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Triton&lt;/strong&gt;: 3.5&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here are the GPU specs from &lt;code&gt;cudaGetDeviceProperties&lt;/code&gt;. These numbers will be useful once we start profiling our kernel to detect performance issues:&lt;/p&gt;









&lt;strong&gt;Name&lt;/strong&gt;
NVIDIA GeForce RTX 2070


&lt;strong&gt;Compute Capability&lt;/strong&gt;
7.5


&lt;strong&gt;Total Memory&lt;/strong&gt;
8 GB


&lt;strong&gt;MultiProcessor Count (SM_count)&lt;/strong&gt;
36


&lt;strong&gt;Max Threads per MultiProcessor&lt;/strong&gt;
1024


&lt;strong&gt;Warp Size&lt;/strong&gt;
32


&lt;strong&gt;L2 Cache Size&lt;/strong&gt;
4 MB


&lt;strong&gt;Shared Memory per Block&lt;/strong&gt;
48 KB


&lt;strong&gt;Shared Memory per MultiProcessor&lt;/strong&gt;
64 KB


&lt;strong&gt;Registers per MultiProcessor&lt;/strong&gt;
65536



&lt;h3&gt;Profiling Tools&lt;/h3&gt;
&lt;p&gt;For profiling, I use three tools at different granularities:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;&lt;code&gt;torch.profiler&lt;/code&gt;&lt;/strong&gt;: Quick and dirty. Good for seeing wall-clock time and basic GPU utilization. I use this for initial sanity checks.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NVIDIA Nsight Systems (&lt;code&gt;nsys&lt;/code&gt;)&lt;/strong&gt;: System-wide profiler. Shows CPU/GPU timeline, kernel launches, memory transfers. Great for spotting gaps where the GPU is idle.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;NVIDIA Nsight Compute (&lt;code&gt;ncu&lt;/code&gt;)&lt;/strong&gt;: The heavy hitter. Gives you everything: occupancy, memory throughput, warp stalls, instruction mix, bank conflicts. This is what I’ll use for deep-diving into kernel performance. You can run it with:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;sudo ncu --set full --kernel-name "attn_kernel" -o profile_output -f python script.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Then open the &lt;code&gt;.ncu-rep&lt;/code&gt; file with &lt;code&gt;ncu-ui&lt;/code&gt; for the full analysis.&lt;/p&gt;
&lt;h2&gt;The Flash Attention Algorithm&lt;/h2&gt;
&lt;p&gt;For modern GPUs, compute throughput vastly exceeds memory bandwidth - an A100 can do ~300 TFLOPs but only has ~2 TB/s of memory bandwidth. This massive compute-to-memory ratio means that naive algorithms spending most of their time waiting for memory, not computing. Flash Attention restructures the computation to maximize arithmetic intensity (FLOPs per byte transferred).&lt;/p&gt;
&lt;p&gt;Let’s build the intuition behind the core ideas from walking back from the solution.
The goal is to one shot (single kernel) build the output tensor.&lt;/p&gt;
&lt;p&gt;We are in GPU programming land. If you want to minimize transfers to main memory—like any good GPU engineer who has read &lt;a href="https://siboehm.com/articles/22/CUDA-MMM"&gt;Simon’s matmul blog post&lt;/a&gt; (stop reading this post and go read it. I am serious. It’s the best matmul writeup on the internet.)—you’d immediately think about computing blocks of output in parallel and writing each block to memory.&lt;/p&gt;
&lt;p&gt;This is commonly known as &lt;strong&gt;tiling&lt;/strong&gt;, and every GPU kernel out there uses this trick. The idea is simple but powerful: instead of streaming data directly from slow global memory for each operation, you load a tile (a small block of data) into fast shared memory once, reuse it across multiple computations within a thread block, and only write the final results back. This dramatically reduces memory bandwidth bottlenecks by exploiting data locality and the GPU’s memory hierarchy—exactly what you need when global memory access is orders of magnitude slower than compute.&lt;/p&gt;
&lt;p&gt;Let’s first look at how the output tensor is computed based on the attention formula. Let’s focus on a single batch and head &lt;code&gt;(B, N_h)&lt;/code&gt; to clearly see the shapes of the matmuls and the elements. Also, we’ll omit the causal masking here (although it’s not really complicated to add it to the attention score before softmax).&lt;/p&gt;


&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/flashattn_output.png"/&gt;
&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/dark_flashattn_output.png"/&gt;

&lt;p&gt;If you have been following along, you’re probably scratching your head wondering why we are sharding the &lt;code&gt;V&lt;/code&gt; tensor &lt;strong&gt;row-wise&lt;/strong&gt;. Sorry for pulling a quick one here, but this formulation of the output (using the rows of V instead of the columns) will actually help us build the flash attention algorithm. For each row $O_i$ of the output:&lt;/p&gt;
&lt;p&gt;$$
O_i = \frac{\sum_j e^{S_{ij}} V_j}{\sum_j e^{S_{ij}}} \quad\text{where}\quad S_{ij} = Q_i \cdot K_j^{\top}
$$&lt;/p&gt;
&lt;p&gt;Still, why split $V_j$ row-wise and &lt;strong&gt;not column-wise&lt;/strong&gt;? First of all, sharding on the &lt;code&gt;D&lt;/code&gt; dim makes less. Like I pointed out earlier, &lt;code&gt;D&lt;/code&gt; is usually 64 or 128 whereas &lt;code&gt;S&lt;/code&gt; sequence length could be 8192 or more depending on the context window. If we tried to split $V$ column-wise (along &lt;code&gt;D&lt;/code&gt;), the math would look like this:&lt;/p&gt;
&lt;p&gt;$$
\begin{bmatrix}
\dots &amp;amp; P_{ij} &amp;amp; \dots
\end{bmatrix}
\times
\begin{bmatrix}
V_{\text{left}} &amp;amp; V_{\text{right}}
\end{bmatrix}
=
\begin{bmatrix}
P \cdot V_{\text{left}} &amp;amp; P \cdot V_{\text{right}}
\end{bmatrix}
$$&lt;/p&gt;
&lt;p&gt;This would force us to load the entire score matrix $P=softmax(Q.K^t)$ just to compute the left half of the output. But we can’t store the entire $P$ matrix—that’s the exact problem FlashAttention solves! By splitting row-wise:&lt;/p&gt;

$$
\left[ \begin{array}{c|c} P_{i0} &amp;amp; P_{i1} \end{array} \right] \times \begin{bmatrix} V_0 \\ \hline V_1 \end{bmatrix} = (P_{i0} \cdot V_0) + (P_{i1} \cdot V_1)
$$

&lt;blockquote&gt;
&lt;p&gt;Now, the genius piece of flash attention is this: if we found a way to build $O_i$ iteratively for a given $i$, we could calculate a small chunk $P_{ij}$, multiply by $V_j$, add it to the sum, and discard $P_{ij}$. This means we are only allocating a small block of memory!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;But why does this matter anyway? Isn’t it still mathematically equivalent if we compute the whole &lt;code&gt;P_i&lt;/code&gt; row? Well, if you live in some mythical mathematical idea world, yes. But this code runs on hardware, and when and how we access memory does matter a LOT!&lt;/p&gt;
&lt;h3&gt;Quick Detour into GPU Memory Land&lt;/h3&gt;
&lt;p&gt;Understanding GPU memory is crucial, especially because GPUs are &lt;a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_threads"&gt;&lt;strong&gt;SIMT&lt;/strong&gt; (Single Instruction, Multiple Thread)&lt;/a&gt; machines. If you’re familiar with SIMD programming on the CPU side, you usually need to use explicit vector instructions to pack and align vectors before executing instructions. SIMT, on the other hand, lets you write scalar thread code that the GPU transparently executes as a lockstep vector, coalescing loads automatically when memory is well-aligned.&lt;/p&gt;
&lt;p&gt;GPUs execute thousands of lightweight threads in lockstep (called warps). Multiple warps form a block, and blocks are scheduled into SMs. Looking back at the &lt;a href="#setup"&gt;Setup section&lt;/a&gt;, we can see that my RTX 2070 has 36 SMs (streaming multiprocessors), and each SM can handle 1024 threads (32 warps) concurrently.&lt;/p&gt;
&lt;p&gt;GPU cores are simple and rely on this massive parallelism to &lt;strong&gt;hide latency&lt;/strong&gt;—whenever one warp stalls waiting on memory, the scheduler swaps in another warp that already has its data “in flight.” This only works if kernels expose enough parallelism and if memory accesses are structured to take advantage of locality&lt;a href="#fn:2"&gt;2&lt;/a&gt;. A core part of the CUDA programming model is that it exposes the &lt;a href="https://modal.com/gpu-glossary/device-software/memory-hierarchy"&gt;memory hierarchy directly&lt;/a&gt;, forcing the programmer (or compiler) to reason explicitly about where data lives and how far it is from the compute units. Memory proximity matters enormously:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;DRAM/HBM (High Bandwidth Memory)&lt;/strong&gt;: I don’t have HBM on my RTX 2070, but even on high-end cards like the A100 with large capacity (~80GB), this memory is relatively far from the SMs. Despite impressive raw bandwidth (~1–2 TB/s), latency is high, so naive repeated reads kill performance.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;L2 Cache:&lt;/strong&gt; A chip-wide cache that helps buffer global memory traffic. Still far slower than on-SM memories. L2 cache behavior is typically leveraged implicitly through access patterns rather than explicit optimization.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;L1 / Shared Memory (SRAM)&lt;/strong&gt;: On-SM, extremely fast, and explicitly managed in CUDA. This is where SRAM truly shines compared to HBM. First, the physics: SRAM sits directly on the SM, mere micrometers from the compute units (vs millimeters for HBM - that’s 1000x closer!). It uses 6-transistor flip-flop circuits that hold state without refresh cycles, unlike HBM’s capacitor-based cells. This means SRAM access takes only ~20-30 cycles vs ~200-600 for HBM.&lt;/p&gt;
&lt;p&gt;The bandwidth story is even more compelling: each SM gets its own ~164KB of SRAM (48 Kb for my poor RTX 2070) with ~1-2 TB/s bandwidth. With 108 SMs on an A100, that’s theoretically ~100+ TB/s aggregate SRAM bandwidth across the chip, compared to “only” ~2 TB/s to HBM. But here’s the real beauty - SRAM is explicitly programmer-controlled! Unlike HBM which goes through L2 cache, L1 cache, and complex replacement policies you can’t control, with SRAM you orchestrate the exact choreography of data movement with computation. No cache thrashing, no surprise evictions, just &lt;strong&gt;deterministic high-speed access&lt;/strong&gt; exactly when you need it.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Registers&lt;/strong&gt;: The closest memory to the compute units. Tiny (~256KB per SM) but insanely fast (100+ TB/s effective). The compiler allocates these, and register pressure directly impacts occupancy (how many warps can run concurrently, which in turn affects latency hiding).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Look at this diagram of &lt;strong&gt;memory hierarchy with bandwidth and memory size&lt;/strong&gt; taken from Flash Attention v1 very closely, and try to internalize it. It is extremely important to take I/O into account when designing highly performant algorithms.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img alt="Memory hierarchy and bandwidth" src="https://aminediro.com/posts/flash_attn/images/ta.png"/&gt;&lt;/p&gt;

&lt;p&gt;If you’re still following along with me, the main insight is to restructure attention so that all intermediate activations fit within these fast memories—registers and shared memory—minimizing slow HBM traffic and maximizing warp-level parallelism. This is why building the output block by block using the same size $P_{ij}$ is a core pillar of fast attention. But it is still unclear at this stage how we could build the output incrementally.&lt;/p&gt;
&lt;h3&gt;Online Softmax Mathematics&lt;/h3&gt;
&lt;p&gt;Before we go deeper into how we could build these blocks, we need one last quick detour into something I omitted until now for simplification reasons. The last lego block we need in our toolbox before building flash attention is &lt;strong&gt;softmax numerical stability&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Numerically stable softmax&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Until now I wrote the softmax function for a vector $z = (z_1, \dots, z_n)$ as:&lt;/p&gt;
&lt;p&gt;$$
\operatorname{softmax}(z_i) = \frac{e^{z_i}}{\sum_{j=1}^{n} e^{z_j}}
$$&lt;/p&gt;
&lt;p&gt;But what happens if input values $z$ are large (e.g., $z_i = 1000$)? Computing $e^{1000}$ will exceed the maximum value a floating-point number can hold, resulting in &lt;code&gt;inf&lt;/code&gt; (infinity) or &lt;code&gt;NaN&lt;/code&gt; (Not a Number) errors. Conversely, underflow can happen if values are very negative—the denominator might vanish to zero, leading to division by zero errors. The trick is to &lt;em&gt;numerically stabilize&lt;/em&gt; by subtracting the maximum logit.&lt;/p&gt;
&lt;p&gt;The key property is that &lt;strong&gt;Softmax is invariant to adding or subtracting a constant ( c )&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$$
\operatorname{softmax}(z_i + c) = \operatorname{softmax}(z_i)
$$&lt;/p&gt;
&lt;p&gt;For numerical stability, we usually subtract the maximum value ($m = \max_j z_j$). Setting ( c = -m ) ensures that the exponentials are at most 1, preventing overflow :&lt;/p&gt;
&lt;p&gt;$$
\operatorname{softmax}(z_i) = \frac{e^{z_i - m}}{\sum_{j=1}^{n} e^{z_j - m}}
$$&lt;/p&gt;
&lt;p&gt;So let’s go back to incrementally computing a row of the output $O_i$. Let’s start slow to build the intuition. We take row &lt;code&gt;i=0&lt;/code&gt; and &lt;code&gt;j=0&lt;/code&gt;. This means we are focusing on the first block of $P_{00}=Q_0@K_0^t$ and the first row of the value tensor $V_0$.&lt;/p&gt;

&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/flashattn_row_0.png"/&gt;
&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/dark_flashattn_row_0.png"/&gt;

&lt;p&gt;If you already see an issue with the current softmax, bear with me a minute. Remember that each element of the score matrix is computed as $ P_{ij} = \frac{e^{Q_i \cdot K_j^T - m_i}}{\sum_j e^{Q_i \cdot K_j^T- m_i}} $. So the denominator is clearly broken (we need to compute the whole row to compute this sum).&lt;/p&gt;
&lt;p&gt;For now we only have $Q_0\cdot K_0^t$ in the row, so the first value we computed is clearly broken. Similarly, $m_i=m_0$ here represents the maximum value of the row. For now we’ve only computed one value, so the max is also broken. Let’s continue to the second value of the output row and see how we can fix what is broken:&lt;/p&gt;

&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/flashattn_row_1.png"/&gt;
&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/dark_flashattn_row_1.png"/&gt;

&lt;p&gt;When we see a new block, we can’t just throw away our previous work. Instead, we need to &lt;strong&gt;rescale&lt;/strong&gt; what we’ve already computed. How though? If we simplify the problem to only having two values in this row (&lt;code&gt;D=2&lt;/code&gt;) and we have computed the first one, the correct output value should be :&lt;/p&gt;
&lt;p&gt;$$
O_1 = \frac{e^{Q_1 \cdot K_1^T - m_1} \cdot V_1 + e^{Q_1 \cdot K_2^T - m_1} \cdot V_2}{e^{Q_1 \cdot K_1^T - m_1} + e^{Q_1 \cdot K_2^T - m_1}} \quad \text{where} \quad m_1 = \max(Q_1 \cdot K_1^T, Q_1 \cdot K_2^T)
$$&lt;/p&gt;
&lt;p&gt;Thanks to the exponential multiplicative property we can easily build these from the previous work and currently computed block. This is done using &lt;strong&gt;running correction factors&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;$$
\begin{gathered}
m_1 = Q_1 \cdot K_1^T, \quad m_2 = Q_1 \cdot K_2^T, \quad m_{\text{new}} = \max(m_1, m_2) \quad
\alpha = e^{m_1 - m_{\text{new}}}, \quad \beta = e^{m_2 - m_{\text{new}}}
\end{gathered}
$$&lt;/p&gt;
&lt;p&gt;These $\alpha$ and $\beta$ factors let us rescale our previous exponentials to the new maximum. Think of it as “adjusting the baseline” - when we find a new maximum or a new sum, we scale down the previous values accordingly.&lt;/p&gt;
&lt;p&gt;$$
l_{\text{new}} = \alpha l_1 + \beta l_2 = e^{m_1 - m_{\text{new}}} l_1 + e^{m_2 - m_{\text{new}}} l_2
$$&lt;/p&gt;
&lt;p&gt;$$
\boxed{l_{\text{new}} = e^{Q_1 \cdot K_1^T - m_{\text{new}}} + e^{Q_1 \cdot K_2^T - m_{\text{new}}}}
$$&lt;/p&gt;
&lt;p&gt;Now here’s where the magic happens. We also need to update our output $O_1$. Remember, we had computed $O_1^{\text{prev}}$ using only the first block, but now we need to incorporate the second block. The update formula rescales the old output and adds the contribution from the new block:&lt;/p&gt;
&lt;p&gt;$$
O_1^{\text{new}} = \frac{\alpha \cdot l_1 \times O_1^{\text{prev}} + \beta \cdot e^{Q_1 \cdot K_2^T - m_2} \cdot V_2}{l_{\text{new}}}
$$&lt;/p&gt;
&lt;p&gt;Let’s expand this to see what’s really happening. The old output was $O_1^{\text{prev}} = \frac{e^{Q_1 K_1^T - m_1}}{l_1} \cdot V_1$, so:&lt;/p&gt;
&lt;p&gt;$$
= \frac{1}{l_{\text{new}}} \left( e^{m_1 - m_{\text{new}}} \cdot \cancel{l_1} \cdot \frac{e^{Q_1 K_1^T - m_1}}{\cancel{l_1}} \cdot V_1 + e^{m_2 - m_{\text{new}}} \cdot e^{Q_1 \cdot K_2^T - m_2} \cdot V_2 \right)
$$&lt;/p&gt;
&lt;p&gt;Simplifying by combining the exponentials:&lt;/p&gt;
&lt;p&gt;$$
= \frac{1}{l_{\text{new}}} \left( e^{Q_1 \cdot K_1^T - m_{\text{new}}} \cdot V_1 + e^{Q_1 K_2^T - m_{\text{new}}} \cdot V_2 \right)
$$&lt;/p&gt;
&lt;p&gt;And voilà! We get exactly what we’d expect - the proper softmax formula:&lt;/p&gt;
&lt;p&gt;$$
= \frac{\sum_{j=1}^{2} e^{Q_1 \cdot K_j^T - m_{\text{new}}} V_j}{\sum_{j=1}^{2} e^{Q_1 \cdot K_j^T - m_{\text{new}}}}
$$&lt;/p&gt;
&lt;p&gt;The beauty of this approach is that we never had to store the full attention matrix. We just kept updating our running statistics ($m$ and $l$) and our output incrementally!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is the core insight of Flash Attention’s &lt;strong&gt;online softmax&lt;/strong&gt; - we can compute exact attention without materializing the entire attention matrix in memory.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Core Idea: Tiling and Online Softmax&lt;/h3&gt;
&lt;p&gt;TLDR, Flash Attention solves the memory problem through &lt;strong&gt;two key insights&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Block-wise Computation&lt;/strong&gt;: Instead of computing the full attention matrix, process Q, K, V in small blocks that fit in fast on-chip SRAM. We have been working with a single row of the output matrix, but we could easily generalize to computing a chunk of &lt;code&gt;n&lt;/code&gt; rows of the matrix. For a single chunk &lt;code&gt;n&lt;/code&gt; of the output, we would need &lt;code&gt;n&lt;/code&gt; rows of the query matrix &lt;code&gt;Q&lt;/code&gt; and all &lt;code&gt;j&lt;/code&gt; rows of &lt;code&gt;K&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt;. More concretely, the algorithm divides the sequence into blocks of size &lt;code&gt;Bc&lt;/code&gt; and processes them iteratively.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online Softmax&lt;/strong&gt;: Compute softmax incrementally without materializing the full attention matrix. This is usually the unintuitive part of the flash attention algorithm. Hopefully, if you have been following along, you can see the core idea behind the online softmax. The key is keeping track of running statistics (max value &lt;code&gt;m&lt;/code&gt; and sum &lt;code&gt;l&lt;/code&gt;) to compute the correct softmax normalization.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s roll up our sleeves and implement the algorithm!&lt;/p&gt;

&lt;h2&gt;Implementing Flash Attention v1&lt;/h2&gt;
&lt;p&gt;Here is the triton implementation of the FA1 algorithm&lt;a href="#fn:3"&gt;3&lt;/a&gt; straight out of the paper. I tried to follow the algorithm as closely as possible to have a good baseline that we can work from:&lt;/p&gt;

$$
\small
\begin{array}{l}
\hline
\textbf{Algorithm 1 } \text{FlashAttention} \\
\hline
\\
\textbf{Require: } \text{Matrices } Q, K, V \in \mathbb{R}^{N \times d} \text{ in HBM, on-chip SRAM of size } M. \\
\\
1. \quad \text{Set block sizes } B_c = \lceil \frac{M}{4d} \rceil, \ B_r = \min(\lceil \frac{M}{4d} \rceil, d). \\
2. \quad \text{Initialize } O = \mathbf{0}_{N \times d}, \ \ell = \mathbf{0}_N, \ m = (-\infty)_N. \\
3. \quad \text{Divide } Q \text{ into } T_r \text{ blocks } Q_i, \text{ and } K, V \text{ into } T_c \text{ blocks } K_j, V_j. \\
4. \quad \text{Divide } O, \ell, m \text{ into blocks } O_i, \ell_i, m_i. \\
5. \quad \textbf{for } 1 \le j \le T_c \textbf{ do} \\
6. \qquad \text{Load } K_j, V_j \text{ from HBM to SRAM.} \\
7. \qquad \textbf{for } 1 \le i \le T_r \textbf{ do} \\
8. \qquad \quad \text{Load } Q_i, O_i, \ell_i, m_i \text{ from HBM to SRAM.} \\
9. \qquad \quad \text{Compute } S_{ij} = Q_i K_j^\top \in \mathbb{R}^{B_r \times B_c}. \\
10.\qquad \quad \tilde{m}_{ij} = \mathrm{rowmax}(S_{ij}), \ \tilde{P}_{ij} = \exp(S_{ij} - \tilde{m}_{ij}), \ \tilde{\ell}_{ij} = \mathrm{rowsum}(\tilde{P}_{ij}). \\
11.\qquad \quad m_i^{\text{new}} = \max(m_i, \tilde{m}_{ij}), \ \ell_i^{\text{new}} = e^{m_i - m_i^{\text{new}}} \ell_i + e^{\tilde{m}_{ij} - m_i^{\text{new}}} \tilde{\ell}_{ij}. \\
12.\qquad \quad O_i \leftarrow \mathrm{diag}(\ell_i^{\text{new}})^{-1} \left( \mathrm{diag}(\ell_i) e^{m_i - m_i^{\text{new}}} O_i + e^{\tilde{m}_{ij} - m_i^{\text{new}}} \tilde{P}_{ij} V_j \right). \\
13.\qquad \quad \ell_i \leftarrow \ell_i^{\text{new}}, \ m_i \leftarrow m_i^{\text{new}}. \\
14.\qquad \textbf{end for} \\
15.\quad \textbf{end for} \\
16.\quad \textbf{return } O. \\
\hline
\end{array}
$$

&lt;p&gt;We recognize the usual suspects from the math we derived earlier. I will only focus on the forward pass without causal masking to keep focus on the core algorithm. Let’s start with the simple reference implementation in pytorch:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# q,k,v are of shape: `(B, N_h, S, D_h)`
# B: batch_size
# N_h: num heads
# S: sequence length
# D_h: head dim
def simple_attn(q, k, v):
    att = q @ k.transpose(-2, -1) * (1.0 / math.sqrt(k.size(-1)))
    att = F.softmax(att, dim=-1)
    y = att @ v
    return y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;My first implementation &lt;a href="https://github.com/AmineDiro/nano-llama-flash/blob/0d2b59e74574b32d03c25dca43c1c34c2735433e/kernels/triton_flash_att.py"&gt;&lt;code&gt;kernels/triton_flash_att.py&lt;/code&gt;&lt;/a&gt; follows the original Flash Attention paper very closely:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;@triton.jit
def attn_kernel(Q, K, V, O, S, D, Tc, Tr, Bc, Br, softmax_scale, l, m):
    # ... [SETUP offsets here]
    # Outer loop over K, V blocks
    for j in range(0, Tc):
        # Load K_j, V_j from HBM to SRAM
        kj = tl.load(k_ptr + offset_j)  # (Bc, D)
        vj = tl.load(v_ptr + offset_j)  # (Bc, D)

        # Inner loop over Q blocks
        for i in range(0, Tr):
            # Load Q_i and previous O_i, l_i, m_i
            qi = tl.load(q_ptr + offset_i)  # `(Bc, D)`
            prev_oi = tl.load(o_ptr + offset_i)
            prev_li = tl.load(l_ptr + S_i_offset)
            prev_mi = tl.load(m_ptr + S_i_offset)

            # Compute attention scores for this block
            Sij = tl.dot(qi, tl.trans(kj)) * softmax_scale  # (Bc, Bc)

            # Online softmax update
            mij = tl.max(Sij, 1)  # Row-wise max
            pij = tl.exp(Sij - mij[:, None])
            lij = tl.sum(pij, 1)  # Row-wise sum

            # Update running statistics
            mi_new = tl.maximum(prev_mi, mij)
            alpha = tl.exp(prev_mi - mi_new)
            beta = tl.exp(mij - mi_new)
            li_new = prev_li * alpha + lij * beta

            # Update output
            oi_new = (alpha[:, None] * prev_li[:, None] * prev_oi
                      + beta[:, None] * tl.dot(pij, vj)) / li_new[:, None]

            # Write back to HBM
            tl.store(o_ptr + offset_i, oi_new)
            tl.store(m_ptr + S_i_offset, mi_new)
            tl.store(l_ptr + S_i_offset, li_new)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Some notes about this implementation :&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Double loop&lt;/strong&gt;: Outer loop over K/V blocks, inner loop over Q blocks. Notice we are reloading block &lt;code&gt;qi = tl.load(q_ptr + offset_i)  # (Bc, D)&lt;/code&gt; in the inner loop which is &lt;em&gt;pretty&lt;/em&gt; inefficient.&lt;/li&gt;
&lt;li&gt;We dispatch this kernel on a grid of &lt;code&gt;B x N_h&lt;/code&gt; blocks. This means that each block has to find the correct matrix offset in &lt;code&gt;Q&lt;/code&gt;,&lt;code&gt;K&lt;/code&gt;,&lt;code&gt;V&lt;/code&gt; and compute a full of the output &lt;code&gt;O&lt;/code&gt; for the batch and attention head. I immediately thought that we are wasting compute here as each row &lt;code&gt;O&lt;/code&gt; can be computed separately from each other. But don’t worry I’ll come back to this in our V2.&lt;/li&gt;
&lt;li&gt;Another wasteful thing I threw in is allocating &lt;code&gt;l&lt;/code&gt; and &lt;code&gt;m&lt;/code&gt; as &lt;code&gt;l = torch.zeros(B, N_h, S).cuda() ; m = torch.full((B, N_h, S), float("-inf")).cuda()&lt;/code&gt;. If you recall the memory access bit earlier, we are effectively loading rows using &lt;code&gt;S_i_offset&lt;/code&gt; from HBM which isn’t great. What we would want is for each block to allocate these accumulators locally in SRAM and avoid allocating them entirely on HBM.&lt;/li&gt;
&lt;li&gt;Notice also that I threw in another simplification &lt;code&gt;Br = Bc = 32&lt;/code&gt;. This means that we are splitting &lt;code&gt;Q&lt;/code&gt; and &lt;code&gt;K&lt;/code&gt; and &lt;code&gt;V&lt;/code&gt; into same size chunks. This isn’t the greatest idea because we might need to have different values for optimization reason. It is just another simplification I threw in for the implementation to be straightforward.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Before looking at the profiling of this v1 naive implementation let’s first look at another requirement I brushed over quickly but that is really important: &lt;strong&gt;SRAM limit&lt;/strong&gt;. Because we are living in the real world we can’t have infinite SRAM on GPUs (sigh! ..), we need to have a ballpark estimation of how much SRAM we need to allocate and if this fits into my device SRAM.&lt;/p&gt;
&lt;p&gt;Quick back-of-the-enveloppe calculation, the kernel at minimum needs to store in SRAM simultaneously:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Query block Q_i: &lt;code&gt;Bc × D&lt;/code&gt; floats&lt;/li&gt;
&lt;li&gt;Key block K_j: &lt;code&gt;Bc × D&lt;/code&gt; floats&lt;/li&gt;
&lt;li&gt;Value block V_j: &lt;code&gt;Bc × D&lt;/code&gt; floats&lt;/li&gt;
&lt;li&gt;Attention scores S_ij: &lt;code&gt;Bc × Bc&lt;/code&gt; floats&lt;/li&gt;
&lt;li&gt;Running maximum and running sum: &lt;code&gt;2 × Bc&lt;/code&gt; floats&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For &lt;code&gt;B=10; Bc = 32; N_h = 64; S = 64; D_h = 32&lt;/code&gt;, Total SRAM: &lt;code&gt;2 × Bc + 3 × Bc × D + Bc²&lt;/code&gt; floats = &lt;code&gt;2 × 32 + 3 × 32 × 64 + 32² = 7,232&lt;/code&gt; floats = &lt;code&gt;7,232 × 4 bytes ≈ 28KB&lt;/code&gt;. This fits comfortably in the ~48KB of shared memory available per thread block. It does mean, though, that we are &lt;strong&gt;limited to ~2 blocks per SM&lt;/strong&gt;. If you’re confused about this limit, don’t worry, I’ll explain this promptly once we get into profiling.&lt;/p&gt;
&lt;h3&gt;Profiling the v1 Implementation&lt;/h3&gt;
&lt;p&gt;As I mentioned in the &lt;a href="#setup"&gt;Setup and hardware&lt;/a&gt; section, I’ll be using the Nsight Compute &lt;code&gt;ncu&lt;/code&gt; tool from the start. It’s one of those tools that comes with a LOT of information, and it can be pretty overwhelming. I recommend watching this &lt;a href="https://www.youtube.com/watch?v=F_BazucyCMw&amp;amp;t=6910s"&gt;lecture&lt;/a&gt; to get a global overview of all the &lt;code&gt;ncu-ui&lt;/code&gt; sections. I also highly recommend reading &lt;a href="https://modal.com/gpu-glossary/perf"&gt;Modal’s GPU glossary performance section&lt;/a&gt; front to back to at least familiarize yourself with the key terms you need to understand GPU program performance, as well as gain a general understanding of how GPUs execute code. If you don’t know what a &lt;code&gt;warp scheduler&lt;/code&gt; is, please go read that resource before continuing to the next section.&lt;/p&gt;
&lt;p&gt;I ran the &lt;code&gt;ncu&lt;/code&gt; profiler using this command to get the full set of timer and metrics:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash

sudo CUDA_HOME=/opt/cuda /usr/local/NVIDIA-Nsight-Compute/ncu \
    --set full \
    --kernel-name "attn_kernel" \
    --import-source yes \
    -o profile_flash_attn_v1 \
    -f .venv/bin/python3 kernels/triton_flash_att.py
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Once the profiling is done, we can open it using &lt;code&gt;ncu-ui&lt;/code&gt;, here is an annotated view of the profile once we open it:&lt;/p&gt;

&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/ncu_description.png"/&gt;
&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/dark_ncu_description.png"/&gt;

&lt;p&gt;Great, let’s drill down on the key metrics. First, we can see that our kernel took &lt;code&gt;166.47ms&lt;/code&gt; to execute. Our kernel used a grid size of (10, 64, 1) matchs our triton grid of &lt;code&gt;(B, N_h)&lt;/code&gt;. Each block has a size of &lt;code&gt;(128, 1, 1)&lt;/code&gt;. Because we are using triton to write our kernel, there is no way to specify the block size directly (although there is a &lt;code&gt;num_warps&lt;/code&gt; param that we could use). This means that triton chose to use &lt;strong&gt;4 warps&lt;/strong&gt; per block to run the kernel.&lt;/p&gt;
&lt;p&gt;Next, the profiler actually picked up of a very interesting problem that we identified earlier:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;The 2.00 theoretical warps per scheduler this kernel can issue according to its occupancy are below the hardware maximum of 8. This kernel’s theoretical occupancy (25.0%) is limited by the required amount of shared memory.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To understand this occupancy problem a little bit more, &lt;code&gt;ncu&lt;/code&gt; provides a quite handy occupancy calculator tool. Let’s look at what the tool says :&lt;/p&gt;
&lt;p&gt;&lt;img alt="occupancy v1" src="https://aminediro.com/posts/flash_attn/images/occupancy_v1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Because our shared memory requirement per block is quite high, we can only have 2 active blocks at a time per SM!
Low occupancy really hurts performance when there aren’t enough warps to hide the latency. But once occupancy is sufficient for latency hiding, increasing it further can degrade performance. Higher occupancy reduces resources per thread, potentially bottlenecking the kernel on registers or reducing the arithmetic intensity.&lt;/p&gt;
&lt;p&gt;To fix this we need to change our SRAM requirement: SRAM only depends on &lt;code&gt;Bc&lt;/code&gt; and &lt;code&gt;D_h&lt;/code&gt;. So we can either have smaller chunks (although this could impact memory bandwidth), or have more attention heads to reduce each &lt;code&gt;D&lt;/code&gt; (if we control model architecture). Either way, we can go back to tweaking this later. Let’s look at the detail section of the profile report to see what other surprises await us!&lt;/p&gt;
&lt;p&gt;&lt;img alt="memory_v1" src="https://aminediro.com/posts/flash_attn/images/memory_v1.png"/&gt;&lt;/p&gt;
&lt;p&gt;The whole idea behind Flash Attention is to avoid going to main memory (HBM) for intermediate steps. The &lt;code&gt;11.58 GB&lt;/code&gt; reads and &lt;code&gt;5.54 GB&lt;/code&gt; writes confirm a bottleneck. Quick math: In this naive implementation, we iterate over columns (&lt;code&gt;K&lt;/code&gt;, &lt;code&gt;V&lt;/code&gt;) in the outer loop and rows (&lt;code&gt;Q&lt;/code&gt;, &lt;code&gt;O&lt;/code&gt;) in the inner loop. This loop order forces us to reload the Accumulator ($O$) and Query ($Q$) from HBM for every single chunk of keys. With $S/Bc = 64$ chunks, we are reading and writing the entire output matrix 64 times! &lt;strong&gt;Math&lt;/strong&gt;: Size of $O \approx 83 \text{ MB}$. Reads $\approx 64 \times (Q + O) \approx 10.6 \text{ GB}$. Writes $\approx 64 \times O \approx 5.3 \text{ GB}$.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
  for j in range(0, Tc):
      # Load K_j, V_j from HBM
      # ....
      for i in range(0, Tr):
          # ....
          # -&amp;gt; Reading previous O_i (Bc,D)
          prev_oi = tl.load(o_ptr + offset_i)
          # -&amp;gt; Writing previous O_i (Bc,D)
          tl.store(o_ptr + offset_i, oi_new)
&lt;/code&gt;&lt;/pre&gt;&lt;blockquote&gt;
&lt;p&gt;We are treating HBM like a register, which explains the massive bandwidth usage!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The last thing to look at before starting to look at the potential solutions we can implement is the &lt;strong&gt;source&lt;/strong&gt; from the profiler.&lt;/p&gt;
&lt;p&gt;&lt;img alt="source_v1" src="https://aminediro.com/posts/flash_attn/images/source_v1_division.png"/&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;ncu&lt;/code&gt; marks problematic kernel code lines with a warning emoji ⚠️, which is quite helpful! The &lt;code&gt;div&lt;/code&gt; operation is usually costly on CPUs, and it’s basically the same story for GPUs. CUDA implements floating-point division on GPUs via reciprocal + multiply ops: using &lt;code&gt;MUFU&lt;/code&gt; (Multi-Function Unit) followed by one or two &lt;code&gt;FFMA&lt;/code&gt; or &lt;code&gt;FMUL&lt;/code&gt; instructions to refine precision. If we look at the &lt;code&gt;SASS&lt;/code&gt; disassembly for this line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;     MUFU.RCP R8, R8
     ...
@P5  FMUL R29, R29, 0.25
@P5  FMUL R15, R15, 0.25
@!P4 FMUL R10, R10, 16777216
@!P6 FMUL R29, R29, 16777216
@!P4 FMUL R23, R23, 16777216
@!P6 FMUL R15, R15, 16777216
     FMUL R10, R9, R10
     FMUL R29, R8, R29
     FMUL R9, R9, R23
     FMUL R8, R8, R15
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Because we are doing the division inside the hot loop we are doing a lot more work here and we can start thinking about how we can avoid this division all together.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  oi_new = (
      alpha[:, None] * prev_li[:, None] * prev_oi
      + beta[:, None] * tl.dot(pij, vj)
  ) / li_new[:, None]
&lt;/code&gt;&lt;/pre&gt;&lt;h3&gt;Next Implementation Plan&lt;/h3&gt;
&lt;p&gt;Based on the ncu profiling data and our analysis of the memory traffic, we have identified three critical bottlenecks to address in the next iteration (V2).&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Invert the Loop Order&lt;/strong&gt;: The massive 11.58 GB of main memory reads and 5.54 GB of writes is our biggest performance killer. It stems from treating HBM as a temporary register for our output accumulator. Current loop forces us to repeatedly read/write the accumulator $O$ and reload $Q$ for every block of $K$. We must invert the loops: Parallelize the kernel over Queries (rows) so that each thread block handles a tile of $Q$:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stationary Data:&lt;/strong&gt; Rows of $O$ and $Q$ remain in SRAM/registers for the entire kernel.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Streaming Data:&lt;/strong&gt; $K$ and $V$ stream from HBM. Since all blocks share the same $K/V$, the L2 cache will absorb most of the traffic (coalesced access).&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Defer Normalization&lt;/strong&gt;: Before describing the fix, let’s recall the true attention output: $O_i = \frac{\sum_j e^{S_{ij}} V_j}{\sum_j e^{S_{ij}}}$. Inside the kernel, we currently divide during every iteration of the loop: $O_{\text{new}} = \frac{\dots}{l_{\text{new}}}$. This normalization step does not need to happen each time. We will store the unnormalized accumulated numerator and denominator in registers throughout the loop. We will perform the normalization &lt;strong&gt;once&lt;/strong&gt;, at the end of the kernel, just before writing the result to HBM.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Tuning Block Sizes&lt;/strong&gt;: Theoretical occupancy is capped at 25% due to shared-memory pressure. Smaller &lt;code&gt;B_c&lt;/code&gt; may reduce register/SRAM pressure and increase the number of active warps. But too small a tile can fragment memory access and reduce bandwidth efficiency. I’ll leave tweaking this value for later.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;(My) Flash Attention v2&lt;/h2&gt;
&lt;p&gt;The v2 implementation (&lt;a href="https://github.com/AmineDiro/nano-llama-flash/blob/main/kernels/triton_flash_att_v2.py"&gt;&lt;code&gt;kernels/triton_flash_att_v2.py&lt;/code&gt;&lt;/a&gt;) makes critical changes for better performance:&lt;/p&gt;
&lt;h3&gt;Reorganized Loop Structure&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;@triton.jit
def attn_kernel(
    Q, K, V, O,
    S, stride_H, softmax_scale,
    D: tl.constexpr, Tc: tl.constexpr, Bc: tl.constexpr
  ):
    # ... offset setup
    # Load query block ONCE at the start !!
    qi = tl.load(
        q_ptr + offset_i, mask=mask[:, None], other=0.0
    )  # shape (Bc,D)

    # Block accumulator and running max in SRAM  !!
    prev_li = tl.zeros([Bc], dtype=tl.float32)
    prev_mi = tl.zeros([Bc], dtype=tl.float32) - float("inf")
    acc = tl.zeros([Bc, D], dtype=tl.float32)

    for j in range(0, Tc):
        # .. setup offset for K and V
        # Load K_j, V_j from HBM to SRAM
        kj = tl.load(k_ptr + offset_j)  # shape(Bc,D)
        vj = tl.load(v_ptr + offset_j)  # shape(Bc,D)

        # Compute Sij on SRAM : Q_i * K_j.T / sqrt(D)
        Sij = tl.dot(qi, tl.trans(kj)) * softmax_scale  # (Bc,Bc)


        # accumulators
        mij = tl.max(Sij, 1) # Rowmax(Sij): (Bc,)
        pij = tl.exp(Sij - mij[:, None])  # (Bc,Bc)
        lij = tl.sum(pij, 1)  # (Bc,)

        # Running maximum
        mi_new = tl.maximum(prev_mi, mij)

        # Compute scaling factors using previous_max
        alpha = tl.exp(prev_mi - mi_new)
        beta = tl.exp(mij - mi_new)

        # Update running sum
        li_new = prev_li * alpha + lij * beta

        # Update the output block
        acc = alpha[:, None] * acc + beta[:, None] * tl.dot(pij, vj)

        prev_li = li_new
        prev_mi = mi_new

    # Divide by the  last accumulated sum !
    acc = acc / prev_li[:, None]
    # Update in HBM
    tl.store(o_ptr + offset_i, acc)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;I also adjusted the grid configuration:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;grid = lambda META: (triton.cdiv(S, META["Bc"]), B * N_h)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Where &lt;strong&gt;Dimension 0&lt;/strong&gt;: Number of Q blocks = &lt;code&gt;S / Bc&lt;/code&gt; and &lt;strong&gt;Dimension 1&lt;/strong&gt;: Batch × Heads = &lt;code&gt;B × N_h&lt;/code&gt;. To reiterate the main changes compared to v1:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Single loop&lt;/strong&gt;: Each thread block processes one Q block, iterating over all K/V blocks. Each thread block is independent, allowing parallelism. With &lt;code&gt;B=10&lt;/code&gt;, &lt;code&gt;N_h=64&lt;/code&gt;, &lt;code&gt;S=1024&lt;/code&gt;, &lt;code&gt;D_h=32&lt;/code&gt; &lt;code&gt;Bc=32&lt;/code&gt;, we launch &lt;code&gt;32 × 640 = 20,480&lt;/code&gt; independent thread blocks.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Load Q once&lt;/strong&gt;: Query block is loaded once and reused across all iterations&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Register accumulation&lt;/strong&gt;: Output accumulator &lt;code&gt;acc&lt;/code&gt; stays in fast registers, no main memory writes until the end&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No intermediate main memory traffic&lt;/strong&gt;: Notice that $l$ and $m$ are kept in registers, only final output written to main memory.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Profiling the v2 Implementation&lt;/h3&gt;
&lt;p&gt;Great, let’s profile our newly crafted kernel and see what &lt;code&gt;ncu&lt;/code&gt; tells us!&lt;/p&gt;
&lt;p&gt;&lt;img alt="compare_v2_v1" src="https://aminediro.com/posts/flash_attn/images/compare_v2_v1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Well, it is faster that the v1 but only &lt;strong&gt;6%&lt;/strong&gt; faster. Let’s first look at the memory chart that was the biggest&lt;/p&gt;
&lt;p&gt;&lt;img alt="memory_v2_v1" src="https://aminediro.com/posts/flash_attn/images/memory_v2_v1.png"/&gt;&lt;/p&gt;
&lt;p&gt;Great! Rewriting reduced main memory reads to &lt;strong&gt;412.18 MB (-92.98%)&lt;/strong&gt;. We are also writing &lt;code&gt;80MB&lt;/code&gt; corresponding exactly to the $O$ matrix size. But there is still a clear problem somewhere—we would expect a lot more speedup as we are now parallelizing 32x more. Let’s look at the occupancy; maybe it is somehow worse than v1 (sanity check here)?&lt;/p&gt;
&lt;p&gt;&lt;img alt="occupancy_v2" src="https://aminediro.com/posts/flash_attn/images/occupancy_v2.png"/&gt;&lt;/p&gt;
&lt;p&gt;We are at &lt;strong&gt;63%&lt;/strong&gt; occupancy and are limited by shared memory with &lt;strong&gt;~12KB&lt;/strong&gt; per block. So that’s clearly not the culprit. Let’s go back to the summary page of the profile; &lt;code&gt;ncu&lt;/code&gt; picks up on these issues:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Shared Load Bank Conflicts Est. Speedup: 63.57%&lt;/strong&gt;: The memory access pattern for shared loads might not be optimal and causes on average a &lt;strong&gt;6.3 - way bank conflict&lt;/strong&gt; across all 293601280 shared load requests. This results in 1174579308 bank conflicts, which represent 63.64% of the overall 1845667948 wavefronts for shared loads. Check the  Source Counters section for uncoalesced shared loads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Uncoalesced Shared Accesses Est. Speedup: 61.46%&lt;/strong&gt;: This kernel has uncoalesced shared accesses resulting in a total of 1174405120 excessive wavefronts (62% of the total 1909063680 wavefronts). Check the L1 Wavefronts Shared Excessive table for the primary source locations.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MIO Throttle Stalls Est. Speedup: 50.06%:&lt;/strong&gt; On average, each warp of this workload spends 18.4 cycles being stalled waiting for the MIO (memory input/output) instruction queue to be not full. This stall reason is high in cases of extreme utilization of the MIO pipelines, which include special math instructions, dynamic branches, as well as shared memory instructions. When caused by shared memory accesses, trying to use fewer but wider loads can reduce pipeline pressure. This stall type represents about 50.7% of the total average of 36.2 cycles between issuing two instructions.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;It seems to be a problem with how we access shared memory in our kernel. A lot of terms are thrown around here, so let’s first understand what &lt;strong&gt;bank conflicts, uncoalesced shared access, and L1 wavefronts shared load&lt;/strong&gt; mean.&lt;/p&gt;
&lt;h3&gt;Understanding the Shared Memory Bottleneck&lt;/h3&gt;
&lt;p&gt;The profiler is screaming at us about bank conflicts and wavefronts. Before we can fix anything, we need to understand what’s actually happening at the hardware level. Let’s build intuition from the ground up.&lt;/p&gt;
&lt;p&gt;Remember from the &lt;a href="#quick-detour-into-gpu-memory-land"&gt;memory hierarchy section&lt;/a&gt; that shared memory (SRAM) lives on-chip, right next to the compute units. It’s blazingly fast (~10-20 TB/s) but there’s a catch: shared memory isn’t a single monolithic block. It’s physically divided into &lt;strong&gt;32 memory banks&lt;/strong&gt; that can be accessed simultaneously (remember how each warp has 32 threads).&lt;/p&gt;
&lt;p&gt;Think of these banks like checkout lanes at a grocery store. If 32 customers each go to a different lane, everyone gets served in one “cycle.” But if multiple customers try to use the same lane, they have to wait in line - that’s a &lt;strong&gt;bank conflict&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The mapping from memory address to bank is straightforward:&lt;/p&gt;
&lt;p&gt;$$
\text{Bank number} = \left\lfloor \frac{\text{byte address}}{4} \right\rfloor \mod 32
$$&lt;/p&gt;
&lt;p&gt;For a &lt;code&gt;float32&lt;/code&gt; array in shared memory, consecutive elements land in consecutive banks:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;data[0]  → byte 0   → bank 0
data[1]  → byte 4   → bank 1
...
data[31] → byte 124 → bank 31
data[32] → byte 128 → bank 0   ← wraps around!
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This is intentional! It means that when threads in a warp access consecutive array elements (a very common pattern), each thread hits a different bank.
Perfect parallelism !&lt;/p&gt;
&lt;h4&gt;What Goes Wrong: The Strided Access Pattern&lt;/h4&gt;
&lt;p&gt;Now here’s where things get spicy. Let’s look at which lines in our kernels this access get’s spicy. Thankfully &lt;code&gt;ncu&lt;/code&gt; again show us the exact problematic line :&lt;/p&gt;
&lt;p&gt;&lt;img alt="tranpose_v2" src="https://aminediro.com/posts/flash_attn/images/transpose_v2.png"/&gt;&lt;/p&gt;
&lt;p&gt;So it turns out, that this line is the culprit :&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Sij = tl.dot(qi, tl.trans(kj)) * softmax_scale
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;But why though ? To understand why we are hitting shared memory bank conflict we’ll need to go a little bit deeper. How deep you ask? Well to the end of the world… But first, let’s continue understanding the remaining &lt;code&gt;ncu&lt;/code&gt; reported issues.&lt;/p&gt;
&lt;h4&gt;Wavefronts: The Unit of Memory Work&lt;/h4&gt;
&lt;p&gt;The profiler keeps mentioning “wavefronts” - what are those? A &lt;strong&gt;wavefront&lt;/strong&gt; (sometimes called a memory transaction) is a single memory operation that the hardware executes atomically. In the &lt;strong&gt;ideal case&lt;/strong&gt;: 32 threads request shared memory, all hit different banks → &lt;strong&gt;1 wavefront&lt;/strong&gt; → 1 cycle&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;N-way bank conflict&lt;/strong&gt;: N threads want the same bank → &lt;strong&gt;N wavefronts&lt;/strong&gt; → N cycles&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now the profiler numbers start making sense:&lt;/p&gt;



Metric
Value
Meaning




Shared load requests
293,601,280
Times our kernel asked for shared memory


Bank conflicts
1,174,579,308
Extra transactions due to serialization


Total wavefronts
1,845,667,948
Actual memory operations executed


&lt;strong&gt;Conflict rate&lt;/strong&gt;
&lt;strong&gt;63.64%&lt;/strong&gt;
Almost 2/3 of bandwidth wasted!



&lt;p&gt;The &lt;strong&gt;6.3-way average conflict&lt;/strong&gt; means that on average, 6.3 threads are fighting for the same bank.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The profiler is telling us we’re doing 6x more memory transactions than necessary. No wonder we only got only 6% speedup despite reducing main memory traffic by 93%!&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4&gt;Uncoalesced Accesses: Same but different, but same&lt;/h4&gt;
&lt;p&gt;The profiler also complains about **uncoalesced shared accesses" with **62% excessive wavefronts**. This is essentially the same problem viewed from a different angle: &lt;strong&gt;Threads access scattered addresses&lt;/strong&gt;. Our column reads are stride-&lt;code&gt;D&lt;/code&gt; accesses, which the hardware cannot combine efficiently. The “excessive wavefronts” metric is counting how many extra transactions we’re issuing beyond the theoretical minimum.&lt;/p&gt;
&lt;h4&gt;MIO Throttle: The Pipeline Backs Up&lt;/h4&gt;
&lt;p&gt;The third warning - &lt;strong&gt;MIO Throttle Stalls (50.06%)&lt;/strong&gt; - is a consequence of the first two. MIO (Memory Input/Output) is the pipeline that handles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Shared memory operations&lt;/li&gt;
&lt;li&gt;Special math instructions (like &lt;code&gt;exp&lt;/code&gt;, &lt;code&gt;log&lt;/code&gt;) (remember this for later)&lt;/li&gt;
&lt;li&gt;Dynamic branches (this is the devil, avoid branches at all cost)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When we’re issuing 6x more shared memory transactions than necessary, the MIO pipeline gets clogged. Warps have to stall waiting for the pipeline to clear, which is what the 50% stall rate is measuring.&lt;/p&gt;
&lt;h4&gt;PTX and fun&lt;/h4&gt;
&lt;p&gt;OK, let’s go back and drill down on this single line:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Sij = tl.dot(qi, tl.trans(kj)) * softmax_scale
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Well, we can’t just look at it, so let’s see what the Triton compiler generated for it. Triton compiles kernels down to PTX, and you can very easily map back the PTX code to Python line code:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;TRITON_CACHE_DIR="./triton_dump" python kernels/triton_flash_att_v2.py

awk '/\.loc.* 83 /{p=1; print; next} /\.loc/{p=0} p' triton_dump/[ID]/attn_kernel.ptx &amp;gt; attn_kernel_v2.ptx
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Great! Let’s look at the assembly for the line &lt;code&gt;triton_flash_att_v2.py:83&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;.loc	1 83 34                         // triton_flash_att_v2.py:83:34
bar.sync 	0;
// We are storing stuff in shared memory `st.`
st.shared.v4.b32 	[%r4], {%r100, %r101, %r102, %r103};
st.shared.v4.b32 	[%r4+2048], {%r104, %r105, %r106, %r107};
st.shared.v4.b32 	[%r4+4096], {%r108, %r109, %r110, %r111};
st.shared.v4.b32 	[%r4+6144], {%r112, %r113, %r114, %r115};


// Here we are loading something from shared memory `ld.`
.loc	1 83 34                         // triton_flash_att_v2.py:83:34
ld.shared.v4.b32 	{%r388, %r389, %r390, %r391}, [%r8];
ld.shared.v4.b32 	{%r392, %r393, %r394, %r395}, [%r8+256];
ld.shared.v4.b32 	{%r396, %r397, %r398, %r399}, [%r8+16];
ld.shared.v4.b32 	{%r400, %r401, %r402, %r403}, [%r8+272];
ld.shared.v4.b32 	{%r404, %r405, %r406, %r407}, [%r8+32];
// ... A lot more ld.shared.v4.b32 instruction

// Then finally we do the acual matmul `tl.dot`
.loc	1 83 25                         // triton_flash_att_v2.py:83:25
fma.rn.f32 	%r516, %r132, %r388, 0f00000000;
fma.rn.f32 	%r517, %r133, %r389, %r516;
fma.rn.f32 	%r518, %r134, %r390, %r517;

// And this mul is the `.softmax_scale` we can ignore it
.loc	1 83 41                         // triton_flash_att_v2.py:83:41
mul.f32 	%r1028, %r25, %r579;
mul.f32 	%r1029, %r25, %r643;
mul.f32 	%r1030, %r25, %r707;
mul.f32 	%r1031, %r25, %r771;
mul.f32 	%r1032, %r25, %r835;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The storing PTX part is pretty straightforward: we are storing &lt;code&gt;K&lt;/code&gt; from registers to shared memory in parallel with each of the 128 threads in the warp executing these instructions in parallel. &lt;code&gt;st.shared.v4.b32&lt;/code&gt; is a vectorized instruction, meaning we store &lt;code&gt;4 * 4bytes = 64bytes&lt;/code&gt; in one shot. Remember that we have $K_j$ of size &lt;code&gt;(Bc, D)&lt;/code&gt;, meaning each chunk is &lt;code&gt;32 x 64 = 8192 bytes&lt;/code&gt;. We are issuing 4 stores of 64 bytes per thread, and with 128 threads this amounts to exactly &lt;code&gt;8192 bytes&lt;/code&gt;. Important detail: we are storing &lt;code&gt;K&lt;/code&gt; in row-major order in shared memory, with a &lt;strong&gt;row stride of &lt;code&gt;256 bytes&lt;/code&gt;.&lt;/strong&gt; Here is how K is stored in shared memory with (a base offset of 0 to simplify):&lt;/p&gt;

&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/light_k_banks.png"/&gt;
&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/dark_k_banks.png"/&gt;

&lt;p&gt;Now, the next set of instructions are very interesting. &lt;code&gt;ld.shared.v4.b32&lt;/code&gt; is a vectorized load of &lt;code&gt;4x 4bytes&lt;/code&gt; wide from shared memory. Remember again, these instructions are executed in parallel by all threads in the warp, so to understand where the conflict happens, we need to look at what adresses each thread is loading from shared memory.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ld.shared.v4.b32 	{%r388, %r389, %r390, %r391}, [%r8];
ld.shared.v4.b32 	{%r392, %r393, %r394, %r395}, [%r8+256];
ld.shared.v4.b32 	{%r396, %r397, %r398, %r399}, [%r8+16];
ld.shared.v4.b32 	{%r400, %r401, %r402, %r403}, [%r8+272];
ld.shared.v4.b32 	{%r404, %r405, %r406, %r407}, [%r8+32];
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Looking at the pattern, it seems that we are doing multiple loads with an offset from a base register &lt;code&gt;%r8&lt;/code&gt;, so to know from which memory address we are effectively loading, we need to figure out what this register holds for each thread. A quick &lt;code&gt;grep&lt;/code&gt; across the PTX codebase and we find this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mov.u32   %r1, %tid.x;              // Thread ID (0-127)
and.b32   %r77, %r1, 15;            // tid &amp;amp; 0xF (0-15)
shl.b32   %r93, %r77, 9;            // shift left by 9
add.s32   %r8, %r91, %r93;          // %r8 = smem_base + lane_group * 512
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Nice! I thought it would be way more tedious. But let’s break down what these instructions are doing. Thankfully, we are in 2025 and LLMs exist to explain PTX; one prompt to Gemini later:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;%r1 = %tid.x&lt;/code&gt;: Set &lt;code&gt;%r1&lt;/code&gt; register to thread ID within the block (0 to 127)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%r77 = tid &amp;amp; 15&lt;/code&gt;: Extract low 4 bits (values 0-15, repeats for lanes 16-31)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%r93 = %r77 &amp;lt;&amp;lt; 9&lt;/code&gt;: Multiply by 512 (= 2^9)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;%r8 = smem_base + lane_group*512 = base + %r93&lt;/code&gt;: Final shared memory address&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This means that for each thread in the warp we have:&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{c|c|l}
\text{Lane} &amp;amp; \text{tid} \land 15 &amp;amp; \text{r8 = base + offset} \\
\hline
0  &amp;amp; 0  &amp;amp; \text{base} + 0 \\
1  &amp;amp; 1  &amp;amp; \text{base} + 512 \\
2  &amp;amp; 2  &amp;amp; \text{base} + 1024 \\
3  &amp;amp; 3  &amp;amp; \text{base} + 1536 \\
\cdots  &amp;amp; \cdots  &amp;amp; \cdots \\
14 &amp;amp; 14 &amp;amp; \text{base} + 7168 \\
15 &amp;amp; 15 &amp;amp; \text{base} + 7680 \\
\hline
\textbf{16} &amp;amp; \textbf{0} &amp;amp; \textbf{base + 0} \leftarrow \text{duplicate!} \\
17 &amp;amp; 1  &amp;amp; \text{base} + 512 \\
\cdots  &amp;amp; \cdots  &amp;amp; \cdots \\
31 &amp;amp; 15 &amp;amp; \text{base} + 7680 \\
\end{array}
$$&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Key insight&lt;/strong&gt;: Due to masking &lt;code&gt;tid &amp;amp; 15&lt;/code&gt;, only &lt;strong&gt;16 unique base addresses&lt;/strong&gt; exist. Lanes 16-31 duplicate lanes 0-15.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So within a single warp of 32 threads, threads &lt;code&gt;0-15&lt;/code&gt; get unique base addresses (0×512, 1×512, … 15×512) and threads &lt;code&gt;16-31&lt;/code&gt; get duplicate addresses (same as lanes 0-15)! But bear in mind, we are not doing 2x the loading. When two lanes access the same address, the &lt;strong&gt;hardware broadcasts—it&lt;/strong&gt;, fetches once and delivers to both. No conflict here. Let’s dig deeper to see where the conflict occurs.&lt;/p&gt;
&lt;p&gt;Now that we have the base pointer address, let’s see what each thread loads. The PTX shows that we executed &lt;strong&gt;32 loads&lt;/strong&gt; per thread to get data for the matrix multiply:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ld.shared.v4.b32  [%r8];        // 4 floats at base + 0
ld.shared.v4.b32  [%r8+256];    // 4 floats at base + 256 (next row)
ld.shared.v4.b32  [%r8+16];     // 4 floats at base + 16 (next 4 cols)
ld.shared.v4.b32  [%r8+272];    // 4 floats at base + 272 (next row, next 4 cols)
ld.shared.v4.b32  [%r8+32];     // 4 floats at base + 32
ld.shared.v4.b32  [%r8+288];    // 4 floats at base + 288
ld.shared.v4.b32  [%r8+48];     // ...
ld.shared.v4.b32  [%r8+304];
ld.shared.v4.b32  [%r8+64];
ld.shared.v4.b32  [%r8+320];
ld.shared.v4.b32  [%r8+80];
ld.shared.v4.b32  [%r8+336];
ld.shared.v4.b32  [%r8+96];
ld.shared.v4.b32  [%r8+352];
ld.shared.v4.b32  [%r8+112];
ld.shared.v4.b32  [%r8+368];
... (32 total loads)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;The offsets follow an &lt;strong&gt;interleaved pattern&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Column 1: 0, 16, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240&lt;/li&gt;
&lt;li&gt;Column 2: 256, 272, 288, 304, 320, 336, 352, 368, 384, 400, 416, 432, 448, 464, 480, 496&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let’s draw over our previous shared memory schema to see which addresses of K are loaded by which threads and to clearly visualize this interleaved access pattern:&lt;/p&gt;

&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/conflict_shmem.png"/&gt;
&lt;img alt="output tensor" src="https://aminediro.com/posts/flash_attn/images/dark_conflict_shmem.png"/&gt;

&lt;p&gt;And there is the bank conflict right there!&lt;/p&gt;
&lt;p&gt;$$
\begin{array}{c|l|cccc|l}
\text{Lane} &amp;amp; \text{Address} &amp;amp; \text{Bank 0} &amp;amp; \text{Bank 1} &amp;amp; \text{Bank 2} &amp;amp; \text{Bank 3} &amp;amp; \\
\hline
0  &amp;amp; \text{base} + 0      &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \\
1  &amp;amp; \text{base} + 512    &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
2  &amp;amp; \text{base} + 1024   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
3  &amp;amp; \text{base} + 1536   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
4  &amp;amp; \text{base} + 2048   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
5  &amp;amp; \text{base} + 2560   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
6  &amp;amp; \text{base} + 3072   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
7  &amp;amp; \text{base} + 3584   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
8  &amp;amp; \text{base} + 4096   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
9  &amp;amp; \text{base} + 4608   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
10 &amp;amp; \text{base} + 5120   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
11 &amp;amp; \text{base} + 5632   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
12 &amp;amp; \text{base} + 6144   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
13 &amp;amp; \text{base} + 6656   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
14 &amp;amp; \text{base} + 7168   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
15 &amp;amp; \text{base} + 7680   &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \bullet &amp;amp; \leftarrow \text{conflict} \\
\hline
16-31 &amp;amp; \text{broadcast from lanes 0-15} &amp;amp; &amp;amp; &amp;amp; &amp;amp; &amp;amp; \\
\end{array}
$$&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Result&lt;/strong&gt;: 16 requests to banks 0,1,2,3. Hardware serializes these into 16 phases. This means we have a theorical efficiency in this section of: 1/16 = 6.25% Waste: 15/16 = &lt;strong&gt;93.75%&lt;/strong&gt; !!&lt;/p&gt;
&lt;p&gt;One thing we could do is set &lt;code&gt;D = D+1&lt;/code&gt; and see what would happen. Theoretically, the off-by-one stride would spread accesses across all banks (This is the idea behind &lt;strong&gt;padding&lt;/strong&gt; - adding a dummy column to break the stride alignment).&lt;/p&gt;
&lt;p&gt;Unfortunately, you can’t set &lt;code&gt;D&lt;/code&gt; to non power of 2. So we end up doubling the dim. The padding breaks bank conflict but it ends up doing a lot more loads and being way slower than the version.
The implementation is &lt;a href="https://github.com/AmineDiro/nano-llama-flash/blob/main/kernels/triton_flash_att_v2_padded.py"&gt;&lt;code&gt;kernels/triton_flash_att_v2_padded.py&lt;/code&gt;&lt;/a&gt; is very close to v2 with the addition to a function that computes the padded head_dim&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
def compute_padded_headdim(D_h):
    """
    Compute padded head dimension to avoid bank conflicts.

    The doubling provides extra padding that naturally breaks stride-based conflicts.
    With stride=64 instead of 32, threads access different bank groups.
    """
    # Find next power of 2
    if D_h &amp;lt;= 0:
        return 1
    # Check if already power of 2
    if (D_h &amp;amp; (D_h - 1)) == 0:
        # Already power of 2, double it
        return D_h * 2
    else:
        # Round up to next power of 2
        return 1 &amp;lt;&amp;lt; (D_h - 1).bit_length()
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;We can see that bank conflicts got down to &lt;strong&gt;3.4 - way bank conflict across all 21135360 shared store requests&lt;/strong&gt;. So I guess this worked 😂..&lt;/p&gt;
&lt;p&gt;Back to the drawing board, Now that we understand the problem, we have several options:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Padding&lt;/strong&gt;: Allocate K as &lt;code&gt;(Bc, D+1)&lt;/code&gt; in shared memory but only use &lt;code&gt;D&lt;/code&gt; columns - breaks the stride alignment -&amp;gt; works, but additional work makes it slower.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Pre-transpose K&lt;/strong&gt;: Store K in column-major order before the kernel runs, so “column” reads become row reads&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Larger D&lt;/strong&gt;: If we increase head dimension to something not divisible by 32, conflicts naturally reduce (but this changes the model architecture)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Swizzling&lt;/strong&gt;: Use a permuted memory layout that distributes bank accesses (this is what CUTLASS and newer Flash Attention versions do)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In the next section, I’ll implement the &lt;strong&gt;transpose option&lt;/strong&gt; and see how much performance we can claw back.&lt;/p&gt;
&lt;h2&gt;(My) Flash Attention v2 Transpose&lt;/h2&gt;
&lt;p&gt;The v2 transpose kernel &lt;a href="https://github.com/AmineDiro/nano-llama-flash/blob/main/kernels/triton_flash_att_v2_transpose.py"&gt;&lt;code&gt;kernels/triton_flash_att_v2_transpose.py&lt;/code&gt;&lt;/a&gt; seems a little bit like cheating—we transpose the $K$ matrix beforehand. A small but important detail is to make sure that the transpose isn’t just a view and force it to be contiguous in memory:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  k_trans = k.transpose(-1, -2).contiguous() # IMPORTANT!
  attn_kernel[grid](
    q, k_trans, v, o,
    S,
    q.stride(1), stride_k_d, stride_k_s,
    1 / math.sqrt(D_h),
    D_h, Tc, Bc,
  )
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Now the only thing that changes is making sure we load the correct columns in the kernel. Note that I hoisted the softmax_scaling from the inside loop to save mul ops&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;
@triton.jit
def attn_kernel(
    Q, K, V, O,
    S,
    stride_H,
    stride_k_d,
    stride_k_s,
    softmax_scale,
    D: tl.constexpr,
    Tc: tl.constexpr,
    Bc: tl.constexpr,
):
    #  ...

    # Pre-scale Q to save muls inside loop
    qi = qi * softmax_scale

    for j in range(0, Tc):
        # Pointer Math: (Row_Idx * Stride_Row) + (Col_Idx * Stride_Col)
        # Row_Idx is offs_d (0..D)
        # Col_Idx is current_cols (S dimension)
        offset_j_k = (offs_d[:, None] * stride_k_d) + (current_cols[None, :] * stride_k_s)

        # Load K (D, Bc) directly!
        kj = tl.load(k_ptr + offset_j_k)

        # ...
        Sij = tl.dot(qi, kj) # no transpose needed for kj !

    # ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Let’s profile it and look at the result in comparison to the previous two kernels:&lt;/p&gt;
&lt;p&gt;&lt;img alt="compare_v2_transpose" src="https://aminediro.com/posts/flash_attn/images/compare_v2_transpose.png"/&gt;&lt;/p&gt;
&lt;p&gt;Another key metric to track (we haven’t until now because we needed to fix obvious stuff), is to look at the GPU speed of light throughput. This is also known as &lt;a href="https://modal.com/gpu-glossary/perf/roofline-model"&gt;&lt;strong&gt;roofline analysis&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="roofline_v2_trans" src="https://aminediro.com/posts/flash_attn/images/roofline_v2_transpose.png"/&gt;&lt;/p&gt;
&lt;p&gt;Our v2 transpose kernel has way higher arithmetic intensity thanks to removing shared memory access conflicts. This can also be corroborated by looking at the warp scheduler statistics. We can see +153% more eligible warps per cycle as they aren’t stalled by serial shared memory access.&lt;/p&gt;
&lt;p&gt;Great! Kernel ran in &lt;strong&gt;34ms&lt;/strong&gt; which is +145% improvement compared to the v1! Looking at &lt;code&gt;ncu&lt;/code&gt; performance opportunities we can see that the next big blocker is :&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Mio Throttle Stalls Est. Speedup: 43.97%&lt;/strong&gt;: On average, each warp of this workload spends 6.7 cycles being stalled waiting for the MIO (memory input/output) instruction queue to be not full. This stall reason is high in cases of extreme utilization of the MIO pipelines, which include special math instructions, dynamic branches, as well as shared memory instructions. When caused by shared memory accesses, trying to use fewer but wider loads can reduce pipeline pressure. This stall type represents about 44.0% of the total average of 15.3 cycles between issuing two instructions.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Still Having an MIO Bottleneck&lt;/h3&gt;
&lt;p&gt;So we fixed bank conflicts and got a nice 145% speedup. What’s left? The MIO (Memory Input/Output) pipeline is now our bottleneck. Despite the name, this isn’t about main memory - MIO handles two things:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Shared memory access&lt;/strong&gt;: Reading/writing our &lt;code&gt;qi&lt;/code&gt;, &lt;code&gt;kj&lt;/code&gt;, &lt;code&gt;vj&lt;/code&gt; tiles&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Special math instructions&lt;/strong&gt;: Transcendental functions like &lt;code&gt;tl.exp&lt;/code&gt;, &lt;code&gt;tl.max&lt;/code&gt;, &lt;code&gt;tl.log&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Every iteration of our inner loop calls &lt;code&gt;tl.exp&lt;/code&gt; for the softmax and &lt;code&gt;tl.max&lt;/code&gt; for numerical stability. These operations go through the SFU (Special Function Unit), which is much slower than the main FMA units. With &lt;code&gt;Bc=32&lt;/code&gt;, we’re doing these expensive operations very frequently relative to the actual matmul work.&lt;/p&gt;
&lt;p&gt;I tried a few things to reduce MIO pressure:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;FP16&lt;/strong&gt;: Wrote an &lt;a href="https://github.com/AmineDiro/nano-llama-flash/blob/main/kernels/triton_flash_att_v2_transpose_fp16.py"&gt;FP16 kernel&lt;/a&gt; hoping for a speedup by lowering shared memory requirements and increasing &lt;code&gt;D_h&lt;/code&gt; and &lt;code&gt;Bc&lt;/code&gt;. Ended up &lt;em&gt;slower&lt;/em&gt; than FP32 because I kept fighting the compiler—it kept inserting extra shared memory accesses for type conversions, and I didn’t get any SRAM savings because FP16 precision sucks for accumulators and I needed to keep all the on-chip accumulators in FP32 anyway.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Larger block sizes&lt;/strong&gt;: Increasing &lt;code&gt;Bc&lt;/code&gt; means fewer loop iterations, so fewer &lt;code&gt;exp&lt;/code&gt;/&lt;code&gt;max&lt;/code&gt; calls per output element. But my RTX 2070 doesn’t have enough shared memory to go much higher without killing occupancy.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Anyway, the main take here is to try to reduce MIO stalls by having larger block reads and reducing all special function math instructions.&lt;/p&gt;
&lt;h3&gt;The core Tensor Core problem&lt;/h3&gt;
&lt;p&gt;Looking at the instruction stats, something else jumped out:&lt;/p&gt;
&lt;p&gt;&lt;img alt="inst_stats" src="https://aminediro.com/posts/flash_attn/images/instruction_stats.png"/&gt;&lt;/p&gt;
&lt;p&gt;The kernel is dominated by &lt;code&gt;FFMA&lt;/code&gt; (Fused Floating-point Multiply-Add) instructions. These are &lt;strong&gt;regular CUDA core operations, not tensor core operations&lt;/strong&gt;. Tensor cores can do 4x4 matrix multiplies in a single cycle—&lt;strong&gt;they’re the whole reason modern GPUs are so fast at deep learning&lt;/strong&gt;. But my &lt;code&gt;tl.dot&lt;/code&gt; calls aren’t using them for some reason!&lt;/p&gt;
&lt;p&gt;I fought with this for a while. Tried different memory layouts, alignment hints, different block sizes… Nothing worked. Turns out, on SM 7.5 (Turing architecture), Triton struggles to generate tensor core code. The compiler just falls back to regular &lt;code&gt;FMA&lt;/code&gt; instructions which run on regular old CUDA cores, clogging up the pipe.&lt;/p&gt;
&lt;p&gt;I guess I need to stop being poor and buy a newer GPU. More realistically, I’ll rent an H100 and see if the same code magically starts using tensor cores on SM 9.0…&lt;/p&gt;
&lt;h2&gt;Comparison with the Real Flash Attention v2&lt;/h2&gt;
&lt;p&gt;At this point I’ve hit the limits of what I can optimize on my hardware.&lt;/p&gt;
&lt;p&gt;Let’s open up the actual Flash Attention v2 paper&lt;a href="#fn:4"&gt;4&lt;/a&gt; and see what we got right and what we missed:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. Reducing Non-Matmul FLOPs&lt;/strong&gt; ✅ (partially)&lt;/p&gt;
&lt;p&gt;We did defer the final division to the end of the kernel. But FA2 goes further - it restructures the entire online softmax to minimize &lt;code&gt;exp&lt;/code&gt; and &lt;code&gt;max&lt;/code&gt; operations. GPUs have separate units for matmul (Tensor Cores, ~300 TFLOPs on A100) vs generic math (CUDA cores, ~20 TFLOPs). Every non-matmul operation is 15x slower, so minimizing them matters a lot.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. Parallelism Over Sequence Length&lt;/strong&gt; ✅&lt;/p&gt;
&lt;p&gt;We nailed this one. Our v2 kernel parallelizes over &lt;code&gt;(S/Bc, B*N_h)&lt;/code&gt; instead of just &lt;code&gt;(B, N_h)&lt;/code&gt;. This is exactly what FA2 does - split the query sequence into chunks and assign them to different thread blocks.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;3. Warp-Level Work Partitioning&lt;/strong&gt; ⛔&lt;/p&gt;
&lt;p&gt;This is where Triton abstracts too much away. FA2 carefully controls how warps within a block divide work: instead of “Split-K” (warps split the K/V dimension and sync to combine results), they use “Split-Q” (warps split the Q dimension and work independently). This removes expensive synchronization barriers.&lt;/p&gt;
&lt;p&gt;In Triton, we don’t control warp-level scheduling - the compiler decides. We could inspect the generated PTX to see what it’s doing, but we can’t easily change it.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;4. Larger Head Dimensions&lt;/strong&gt; 🤷&lt;/p&gt;
&lt;p&gt;FA2 supports &lt;code&gt;D_h&lt;/code&gt; up to 256 efficiently. Our kernel works with any head dimension, but we haven’t optimized the tiling specifically for larger values. With &lt;code&gt;D_h=128&lt;/code&gt; or &lt;code&gt;256&lt;/code&gt;, you’d want different block sizes and potentially different memory layouts. For implementation simplicity reasons, I kept &lt;code&gt;Bc==Br&lt;/code&gt;, so we haven’t gotten to play with tweaking these parameters.&lt;/p&gt;
&lt;!-- ## Performance Comparison --&gt;
&lt;!-- --&gt;
&lt;!-- From my profiling notes, here are the key findings: --&gt;
&lt;!-- --&gt;
&lt;!-- When Flash Attention Wins --&gt;
&lt;!-- --&gt;
&lt;!-- - **Long sequences (S &gt; 4096)**: Standard PyTorch attention OOMs, Flash Attention continues working --&gt;
&lt;!-- - **Memory-constrained scenarios**: Enables training with batch sizes impossible with standard attention --&gt;
&lt;!-- - **Very long sequences (S &gt; 16K)**: Flash Attention becomes faster due to memory bandwidth bottleneck --&gt;
&lt;!-- --&gt;
&lt;!-- When cuBLAS/PyTorch Wins --&gt;
&lt;!-- --&gt;
&lt;!-- - **Short sequences (S &lt; 2048)**: The overhead of tiling and online softmax isn't worth it --&gt;
&lt;!-- - **S = 8192 with Bc = 32**: cuBLAS highly optimized matmul is faster for medium-sized problems --&gt;
&lt;!-- --&gt;
&lt;!-- The Crossover Point --&gt;
&lt;!-- --&gt;
&lt;!-- The break-even point depends on: --&gt;
&lt;!-- --&gt;
&lt;!-- - GPU architecture (memory bandwidth vs compute ratio) --&gt;
&lt;!-- - Head dimension `D_h` --&gt;
&lt;!-- - Block size `Bc` --&gt;
&lt;!-- - Sequence length `S` --&gt;
&lt;!-- --&gt;
&lt;!-- On my RTX 2070 Super, the crossover is around S=4096-8192. --&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Don’t get it twisted—Flash Attention is a brilliant example of algorithm-hardware co-design. My goal here wasn’t to diminish the work of Tri Dao, but to walk through the reasoning myself. Every brilliant solution seems kind of obvious once you have it in front of you, but having the insight and technical chops to come up with it in the first place is a whole other thing.&lt;/p&gt;
&lt;p&gt;I tried my best to demystify the core ideas behind Flash Attention, and show how understanding the GPU memory hierarchy lets you optimize iteratively: profile, rewrite, tweak, rinse and repeat.&lt;/p&gt;
&lt;p&gt;If you’ve fallen asleep three times reading this and just woke up, here are the key takeaways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Tiling&lt;/strong&gt;: Process attention in blocks that fit in fast SRAM&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Online softmax&lt;/strong&gt;: Compute softmax incrementally without materializing the full attention matrix&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Minimize HBM traffic&lt;/strong&gt;: Load data once, keep accumulators in registers/SRAM, write only the final result&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;There’s more to explore - FA3 brings asynchronous memory copies and FP8 support, FA4 pushes things even further with Blackwell-specific optimizations. But that’s for another post (and another GPU).&lt;/p&gt;
&lt;p&gt;The full implementation is available in this &lt;a href="https://github.com/AmineDiro/nano-llama-flash/tree/main/kernels"&gt;repository&lt;/a&gt;, including the Triton kernels and profiling scripts.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;


&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;I simplified dimensions for Q and K, V. Transformer forward pass is actually split into two phases: prefill and decode. Usually decode Q is &lt;code&gt;(B, N_h, 1, D_h)&lt;/code&gt; and K, V are &lt;code&gt;(B, N_h, cache_len + 1, D_h)&lt;/code&gt; where &lt;code&gt;cache_len&lt;/code&gt; is the size loaded from the KV cache. &lt;a href="#fnref:1"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Anyone interested in GPU programming should read &lt;a href="https://siboehm.com/articles/22/CUDA-MMM"&gt;Simon’s Matmul Kernel writeup&lt;/a&gt;. It really details how to implement a high-performance matmul with exact optimizations. &lt;a href="#fnref:2"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dao, Tri, et al. “FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.” arXiv preprint arXiv:2205.14135v2 (2022). &lt;a href="https://doi.org/10.48550/arXiv.2205.14135"&gt;https://doi.org/10.48550/arXiv.2205.14135&lt;/a&gt; &lt;a href="#fnref:3"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Dao, “FlashAttention-2: Faster Attention with Better Parallelism and Work Partitioning” (2023) &lt;a href="#fnref:4"&gt;↩︎&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://aminediro.com/posts/flash_attn/</guid>
      <category>Hacker News</category>
      <pubDate>Sun, 21 Dec 2025 10:49:52 +0000</pubDate>
    </item>
    <item>
      <title>Comptime – C# meta-programming with compile-time code generation and evaluation</title>
      <link>https://github.com/sebastienros/comptime</link>
      <description>A .NET source generator that executes methods at compile time and serializes their results to C# code. Comptime brings meta-programming capabilities to C#, enabling compile-time code generation and evaluation.</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;h1&gt;Comptime&lt;/h1&gt;&lt;a href="#comptime"&gt;&lt;/a&gt;
&lt;p&gt;A .NET source generator that executes methods at compile time and serializes their results to C# code. Comptime brings meta-programming capabilities to C#, enabling compile-time code generation and evaluation.&lt;/p&gt;
&lt;h2&gt;Overview&lt;/h2&gt;&lt;a href="#overview"&gt;&lt;/a&gt;
&lt;p&gt;Comptime allows you to mark methods with the &lt;code&gt;[Comptime]&lt;/code&gt; attribute to have them executed during compilation. The return values are serialized into C# source code and used at runtime, eliminating the need for runtime computation of values that can be determined at build time.&lt;/p&gt;
&lt;p&gt;This meta-programming approach enables developers to shift expensive computations from runtime to compile time, resulting in faster application startup and execution.&lt;/p&gt;
&lt;h2&gt;Features&lt;/h2&gt;&lt;a href="#features"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Compile-time execution&lt;/strong&gt;: Methods marked with &lt;code&gt;[Comptime]&lt;/code&gt; are executed during compilation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Method parameters&lt;/strong&gt;: Methods can accept parameters with compile-time constant expressions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;C# serialization&lt;/strong&gt;: Results are serialized to valid C# code&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supported return types&lt;/strong&gt;:
&lt;ul&gt;
&lt;li&gt;Primitive types: &lt;code&gt;int&lt;/code&gt;, &lt;code&gt;long&lt;/code&gt;, &lt;code&gt;short&lt;/code&gt;, &lt;code&gt;byte&lt;/code&gt;, &lt;code&gt;sbyte&lt;/code&gt;, &lt;code&gt;uint&lt;/code&gt;, &lt;code&gt;ulong&lt;/code&gt;, &lt;code&gt;ushort&lt;/code&gt;, &lt;code&gt;float&lt;/code&gt;, &lt;code&gt;double&lt;/code&gt;, &lt;code&gt;decimal&lt;/code&gt;, &lt;code&gt;bool&lt;/code&gt;, &lt;code&gt;char&lt;/code&gt;, &lt;code&gt;string&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Collections: &lt;code&gt;IReadOnlyList&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;IReadOnlyDictionary&amp;lt;TKey, TValue&amp;gt;&lt;/code&gt;, &lt;code&gt;List&amp;lt;T&amp;gt;&lt;/code&gt;, &lt;code&gt;Dictionary&amp;lt;TKey, TValue&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Note: Arrays are &lt;strong&gt;not&lt;/strong&gt; allowed as return types because they are mutable. Use &lt;code&gt;IReadOnlyList&amp;lt;T&amp;gt;&lt;/code&gt; instead.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Supported argument types&lt;/strong&gt;: Any expression that doesn't contain variables, including:
&lt;ul&gt;
&lt;li&gt;Literals: &lt;code&gt;42&lt;/code&gt;, &lt;code&gt;"hello"&lt;/code&gt;, &lt;code&gt;true&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Collection initializers: &lt;code&gt;new List&amp;lt;int&amp;gt; { 1, 2, 3 }&lt;/code&gt;, &lt;code&gt;new[] { "a", "b", "c" }&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Expressions: &lt;code&gt;1 + 2&lt;/code&gt;, &lt;code&gt;Math.PI * 2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Const values and enum members&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interceptor-based&lt;/strong&gt;: Uses C# interceptors to replace method calls with pre-computed values&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Usage&lt;/h2&gt;&lt;a href="#usage"&gt;&lt;/a&gt;
&lt;h3&gt;Basic Usage (Parameterless Methods)&lt;/h3&gt;&lt;a href="#basic-usage-parameterless-methods"&gt;&lt;/a&gt;
&lt;pre&gt;using Comptime;

public static partial class Constants
{
    [Comptime]
    public static IReadOnlyList&amp;lt;int&amp;gt; GetPrimeNumbers()
    {
        // Complex computation that runs at compile time
        var primes = new List&amp;lt;int&amp;gt;();
        for (int i = 2; i &amp;lt;= 100; i++)
        {
            if (IsPrime(i))
                primes.Add(i);
        }
        return primes;
    }
    
    private static bool IsPrime(int n) { /* ... */ }
}

// At runtime, calling GetPrimeNumbers() returns the pre-computed list
var primes = Constants.GetPrimeNumbers(); // Returns [2, 3, 5, 7, 11, ...]&lt;/pre&gt;
&lt;h3&gt;Methods with Parameters&lt;/h3&gt;&lt;a href="#methods-with-parameters"&gt;&lt;/a&gt;
&lt;pre&gt;using Comptime;

public static partial class Math
{
    [Comptime]
    public static long Factorial(int n)
    {
        if (n &amp;lt;= 1) return 1;
        long result = 1;
        for (int i = 2; i &amp;lt;= n; i++)
            result *= i;
        return result;
    }

    [Comptime]
    public static int SumList(IReadOnlyList&amp;lt;int&amp;gt; numbers)
    {
        return numbers.Sum();
    }
}

// Each unique argument combination is computed at compile time
var fact5 = Math.Factorial(5);   // Pre-computed: 120
var fact10 = Math.Factorial(10); // Pre-computed: 3628800

// Collection initializers work too!
var sum = Math.SumList(new List&amp;lt;int&amp;gt; { 1, 2, 3, 4, 5 }); // Pre-computed: 15
var sum2 = Math.SumList(new[] { 10, 20, 30 });           // Pre-computed: 60&lt;/pre&gt;
&lt;h3&gt;Generic Methods&lt;/h3&gt;&lt;a href="#generic-methods"&gt;&lt;/a&gt;
&lt;pre&gt;using Comptime;

public static partial class Utils
{
    [Comptime]
    public static int CountItems&amp;lt;T&amp;gt;(IReadOnlyList&amp;lt;T&amp;gt; items)
    {
        return items.Count;
    }

    [Comptime]
    public static string JoinStrings(IReadOnlyList&amp;lt;string&amp;gt; strings, string separator)
    {
        return string.Join(separator, strings);
    }
}

var count = Utils.CountItems(new[] { "a", "b", "c" }); // Pre-computed: 3
var joined = Utils.JoinStrings(new[] { "hello", "world" }, " "); // Pre-computed: "hello world"&lt;/pre&gt;
&lt;h2&gt;Requirements&lt;/h2&gt;&lt;a href="#requirements"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;.NET 8.0 or later&lt;/li&gt;
&lt;li&gt;C# 12 or later (for interceptors support)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Installation&lt;/h2&gt;&lt;a href="#installation"&gt;&lt;/a&gt;
&lt;pre&gt;&amp;lt;PackageReference Include="Comptime" Version="1.0.0" /&amp;gt;&lt;/pre&gt;
&lt;h2&gt;How It Works&lt;/h2&gt;&lt;a href="#how-it-works"&gt;&lt;/a&gt;
&lt;ol&gt;
&lt;li&gt;The source generator finds methods marked with &lt;code&gt;[Comptime]&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;It identifies all call sites and their arguments&lt;/li&gt;
&lt;li&gt;For each unique argument combination, it executes the method at compile time&lt;/li&gt;
&lt;li&gt;The return values are serialized to C# literals/expressions&lt;/li&gt;
&lt;li&gt;Interceptor methods are generated that return the pre-computed values&lt;/li&gt;
&lt;li&gt;At runtime, calls to the original methods are intercepted and return the cached values&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Diagnostics&lt;/h2&gt;&lt;a href="#diagnostics"&gt;&lt;/a&gt;



Code
Description




COMPTIME001
Class must be partial


COMPTIME002
Method must be static


COMPTIME004
Unsupported return type


COMPTIME005
Compilation emit failed


COMPTIME006
Method execution failed


COMPTIME007
Serialization failed


COMPTIME011
Array return type not allowed (use IReadOnlyList)


COMPTIME012
Argument must be a constant (no variables allowed)



&lt;h2&gt;Limitations&lt;/h2&gt;&lt;a href="#limitations"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Methods must be &lt;code&gt;static&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The containing class must be &lt;code&gt;partial&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Return types must be immutable (arrays are not allowed, use &lt;code&gt;IReadOnlyList&amp;lt;T&amp;gt;&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;Method arguments must be compile-time constant expressions (no variables, only literals and expressions of literals)&lt;/li&gt;
&lt;li&gt;Methods cannot have side effects that depend on runtime state&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;License&lt;/h2&gt;&lt;a href="#license"&gt;&lt;/a&gt;
&lt;p&gt;MIT License&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/sebastienros/comptime</guid>
      <category>Hacker News</category>
      <pubDate>Sat, 20 Dec 2025 20:49:52 +0000</pubDate>
    </item>
    <item>
      <title>The dawn of a world simulator</title>
      <link>https://odyssey.ml/the-dawn-of-a-world-simulator</link>
      <description>A causal, multimodal system that learns to predict the world.</description>
      <content:encoded>&lt;main class="page_main__aPXlY"&gt;&lt;a href="https://odyssey.ml/"&gt;&lt;/a&gt;&lt;h1&gt;The dawn of a world simulator&lt;/h1&gt;&lt;p&gt;A causal, multimodal system that learns to predict the world.&lt;/p&gt;&amp;gt; &lt;!-- --&gt;December 20, 2025&lt;img alt="We’re an AI lab focused on general-purpose world models" src="https://odyssey.ml/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fddi2qhl64wkk%2F5Iv2nAklVW0c3lp3mZbHEf%2F2f5ea3bfe9581e93c03bfd18306a1c85%2FDawn.jpg&amp;amp;w=3840&amp;amp;q=75"/&gt;We’re an AI lab focused on general-purpose world models&lt;h1&gt;A new form of audio-visual intelligence&lt;/h1&gt;&lt;p&gt;Over the last few years, we’ve learned that simple, causal prediction objectives can give rise to surprisingly general intelligence. In language, predicting the next token forces models to internalize syntax, semantics, and long-range structure.&lt;/p&gt;&lt;p&gt;We’re now beginning to see this approach extend beyond language to world models, resulting in nascent world simulators. An early world simulator—like &lt;a href="https://odyssey.ml/introducing-odyssey-2"&gt;Odyssey-2&lt;/a&gt;—is a model trained to predict how the world evolves over time, frame-by-frame, using large amounts of video and interaction data. Rather than relying on hand-crafted rules, it learns latent state, dynamics, and cause-and-effect directly from observations.&lt;/p&gt;Odyssey-2 Pro, a nascent world simulator&lt;h1&gt;Learning the world through observation&lt;/h1&gt;&lt;p&gt;Why do we care about next-frame prediction or next-token prediction as pretraining tasks? Because they are simple objectives that require models with very little built-in knowledge to learn how the world works directly from data. Pretraining reduces uncertainty about what comes next in a sequence—whether that’s a frame or a word. As that uncertainty drops, intelligent capabilities begin to emerge.&lt;/p&gt;&lt;p&gt;This is easy to see with language. Given only “=”, next-token prediction is ill-posed. Given “2+3=”, the next token is nearly deterministic. Train a language model on enough of these sequences and the predictions become low-entropy. Some capabilities emerge from scale alone, but others only appear once training sequences are long enough to include the information needed to resolve uncertainty.&lt;/p&gt;&lt;h2&gt;Learning not just video, but the actions that shape it&lt;/h2&gt;&lt;p&gt;The same logic applies to world models. To predict the next observation, a world model has to infer the underlying state of the world and how that state evolves over time. In practice, the best source for this is large-scale, general video. This pushes the model to learn structure about physics, causality, and persistence.&lt;/p&gt;&lt;h2&gt;Learning long horizons and hidden state&lt;/h2&gt;&lt;p&gt;This becomes especially clear in long-horizon settings. Imagine someone starts running a bath, leaves the room for several minutes, and then comes back. While the bath is out of view, the water level continues to rise, the temperature changes, and the tub may eventually overflow. To make a sensible prediction when the person returns, the model has to maintain an internal state of the world and reason about how that state evolved while it was unobserved.&lt;/p&gt;&lt;p&gt;There are a few ways we believe to get this behavior. One is to build in explicit mechanisms for memory or state tracking. The other is to train on sequences long enough that remembering and updating hidden state is required to reduce predictive uncertainty. Short sequences don’t force this: if forgetting carries no cost, long-term structure won’t be learned.&lt;/p&gt;&lt;p&gt;If we want world models that learn the world observation-by-observation—and remain coherent over tens of minutes or hours—we need training data and training procedures that span those horizons. We’ve already seen how this plays out in language: extending context length and improving sequence modeling unlocked capabilities that were not apparent at shorter horizons. World models are earlier on the same trajectory. As data, architectures, and training algorithms are pushed to longer temporal scales, we should expect similar step-changes in their ability to represent persistent state, causality, and long-horizon dynamics. This is incredibly exciting.&lt;/p&gt;&lt;h1&gt;From narrow simulation to general simulation&lt;/h1&gt;&lt;h2&gt;The limits of hand-crafted simulators&lt;/h2&gt;&lt;p&gt;Simulation is about predicting how a system’s state evolves over time, using models, data, or both. In the limit, one could imagine simulating the world from first principles, down to elementary particle interactions. In practice, this is only feasible for very small systems today.&lt;/p&gt;&lt;p&gt;Most real-world simulations today narrow the problem considerably. Specialized, hand-crafted models capture just enough structure to reproduce a particular behavior, while irrelevant detail is ignored or averaged away. This makes simulation tractable, but also constrains each simulator to a specific domain and a fixed set of assumptions. For example, a rigid-body physics engine is not useful for simulating weather.&lt;/p&gt;&lt;p&gt;As systems become more complex, these limitations become more pronounced. Many real-world phenomena are impractical to simulate accurately from explicit rules alone, and building reliable simulators demands significant human effort.&lt;/p&gt;&lt;h2&gt;Learning to simulate the world from video&lt;/h2&gt;&lt;p&gt;World models approach simulation from a new perspective. Rather than designing a simulator for each domain, we train general-purpose, causal models on large amounts of video and interaction data, and task them with predicting what happens next. Because the data reflects how the world evolves over time, frame-by-frame, the learning problem is inherently causal. Through next-frame prediction, the model learns internal representations of state, dynamics, and interactions without those structures needing to be specified in advance.&lt;/p&gt;&lt;img alt="The architecture of a world model" src="https://images.ctfassets.net/ddi2qhl64wkk/B2bJFP6NbS4gR0KWrBuDa/626cd4b9e8181b139ae04a17b30542fc/World_Model_Architecture.jpg"/&gt;The architecture of a world model&lt;p&gt;This changes how simulation scales. Traditional simulators fix their level of detail up front and incur increasing cost as fidelity rises. World models operate under a fixed computational budget and learn how to allocate capacity dynamically, focusing on the latent structure that most reduces predictive uncertainty. Over time, this allows a single model to cover a broader range of phenomena with far less manual intervention. &lt;a href="https://odyssey.ml/introducing-odyssey-2"&gt;Odyssey-2&lt;/a&gt; is an early example of this.&lt;/p&gt;Odyssey-2 Pro, a nascent world simulator&lt;p&gt;A general world simulator, although nascent today, will enable us to test cause and effect in complex systems without writing a simulator for each one. If a model can predict how the world changes when you intervene—turn a knob, take an action, change an initial condition—it becomes a practical tool for reasoning, not solely prediction. Over time, this kind of simulator replaces many narrow, hand-built models, and becomes shared infrastructure for building and studying intelligent systems.&lt;/p&gt;&lt;h1&gt;Interacting with simulations in natural ways&lt;/h1&gt;&lt;p&gt;Today, simulations are mostly used as validation tools. They run offline, answer narrowly defined questions, and produce outputs that are inspected after the fact. Interaction is indirect, and the simulator itself is rarely something a user engages with continuously.&lt;/p&gt;&lt;p&gt;World models change this by turning simulation into an ongoing process. When a model generates a stream of video in real time—conditioned on past observations and user actions—the simulation becomes inherently interactive. The system evolves step by step, responding immediately to interventions, without needing to be restarted or reconfigured.&lt;/p&gt;&lt;img alt="Imagined by AI in real-time" src="https://odyssey.ml/imagined.gif"/&gt;&lt;img alt="Imagined by AI in real-time" src="https://odyssey.ml/imagined.gif"/&gt;&lt;img alt="Imagined by AI in real-time" src="https://odyssey.ml/imagined.gif"/&gt;&lt;img alt="Imagined by AI in real-time" src="https://odyssey.ml/imagined.gif"/&gt;&lt;p&gt;This makes a different kind of interaction possible. Instead of issuing commands and waiting for results, a user can engage continuously with a simulation that maintains state over time. If the model is trained on sufficiently long-horizon data, it can preserve context—what has already happened, what was said, and what is likely to happen next—across extended interactions.&lt;/p&gt;&lt;p&gt;A simple example is a tutor. Imagine a simulated instructor who explains a concept visually, responds to spoken questions, pauses when interrupted, and adapts based on your facial expression. For this to work, the model must learn jointly from long-horizon video, language, and interaction data: how explanations unfold over time, how dialogue and action relate, and how context is maintained across minutes or hours.&lt;/p&gt;&lt;p&gt;The broader implication is that simulations no longer need to be static tools or narrow. When learned from large amounts of multimodal data, world models can produce interactive systems that feel continuous and stateful, supporting richer forms of interaction than traditional simulators. Audio, language, and action become natural ways to interact.&lt;/p&gt;&lt;img alt="Multimodal inputs and outputs" src="https://images.ctfassets.net/ddi2qhl64wkk/6yAzeZ7x4GTHSSG2WZbH9L/36058bbbb345983b52bd4389c3e275ab/Inputs.jpg"/&gt;Multimodal inputs and outputs&lt;h1&gt;Build the world simulator with us&lt;/h1&gt;&lt;p&gt;If this direction resonates, we’re building it at &lt;a href="https://odyssey.ml/"&gt;Odyssey&lt;/a&gt;. We’re an AI lab focused on general-purpose world models: causal, multimodal systems that learn to predict and interact with the world over long horizons. If you’re a researcher interested in pushing beyond narrow models toward learned world simulators—and want to work on problems that won’t fit cleanly into existing paradigms—&lt;a href="https://odyssey.ml/build-something-magical"&gt;we’d love to talk&lt;/a&gt;. This is still extremely early, and the hardest problems remain open.&lt;/p&gt;&lt;img alt="The incredible Odyssey team" src="https://images.ctfassets.net/ddi2qhl64wkk/7Izcnms6isTlftsY1eFvXD/31034c679bc255b3e7553462bdcffd17/Team.jpg"/&gt;The incredible Odyssey team&lt;p&gt;&lt;/p&gt;Email Us&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://odyssey.ml/the-dawn-of-a-world-simulator</guid>
      <category>Hacker News</category>
      <pubDate>Sat, 20 Dec 2025 19:40:02 +0000</pubDate>
    </item>
    <item>
      <title>Proving Bounds for the Randomized MaxCut Approximation Algorithm in Lean4</title>
      <link>https://abhamra.com/blog/randomized-maxcut/</link>
      <description>For a given graph G = (V, E) , a cut C is a set of edges such that there is a partition V = (A, B) where all edges e ∈ C have one vertex in A and the other in B .</description>
      <content:encoded>&lt;main&gt;
&lt;a href="https://abhamra.com/blog/"&gt;..&lt;/a&gt;/randomized-maxcut
Published on: 2025-12-19
&lt;h1&gt;Proving bounds for the Randomized MaxCut Approximation algorithm in Lean4&lt;/h1&gt;
&lt;p&gt;For a given graph &lt;code&gt;G = (V, E)&lt;/code&gt;, a cut &lt;code&gt;C&lt;/code&gt; is a set of edges such that there is a partition &lt;code&gt;V = (A, B)&lt;/code&gt; where all edges &lt;code&gt;e ∈ C&lt;/code&gt; have one vertex in &lt;code&gt;A&lt;/code&gt; and the other in &lt;code&gt;B&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;MaxCut is a very famous combinatorial optimization problem wherein we want to find the largest such cut. This is useful in scheduling, partitioning, financial portfolio optimization, and more! While the problem itself is NP-Complete, there exist a host of approximation algorithms that allow us to do “pretty good” in practice. To see a careful treatment of deterministic MaxCut algorithms, check out these &lt;a href="https://pages.cs.wisc.edu/~jyc/02-810notes/lecture19.pdf"&gt;two&lt;/a&gt; &lt;a href="https://courses.cs.cornell.edu/cs4820/2019sp/handouts/max-cut.pdf"&gt;lecture&lt;/a&gt; notes.&lt;/p&gt;
&lt;p&gt;Some quick nomenclature: an α-approximation for a (maximization/minimization) problem is when we:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;(max) Do as good as 1/α * OPT&lt;/li&gt;
&lt;li&gt;(min) Do as good as α * OPT&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For our purposes, lets say we don’t even care about doing good right now, just that we care about doing good in expectation. That is, while there exists a 1/2-approximation for MaxCut, we want to create an algorithm such that the expected size of our output cut satisfies the 1/2 approximation ratio.&lt;/p&gt;
&lt;h3&gt;Our simple algorithm&lt;/h3&gt;
&lt;p&gt;For every vertex &lt;code&gt;v ∈ V = (A, B)&lt;/code&gt;, choose with 50% probability whether it is in &lt;code&gt;A&lt;/code&gt; or &lt;code&gt;B&lt;/code&gt;. That’s it, that creates the cut.&lt;/p&gt;
&lt;p&gt;Good job! Take a well-deserved break now.&lt;/p&gt;

&lt;h3&gt;Proving it informally&lt;/h3&gt;
&lt;p&gt;Now that you’re back from break, let’s get to proving this with words!&lt;/p&gt;
&lt;p&gt;For any edge &lt;code&gt;e = (u, v) ∈ E&lt;/code&gt;, we have &lt;code&gt;Pr[(u, v) ∈ C] = 1/2&lt;/code&gt;. For each edge &lt;code&gt;e&lt;/code&gt;, create a random variable &lt;code&gt;Xₑ&lt;/code&gt; such that &lt;code&gt;Xₑ = 1 if e ∈ C else 0&lt;/code&gt;. Notice now that the size of the cut, &lt;code&gt;|C| = ∑ Xₑ&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The overall proof is then &lt;code&gt;E[|C|] = ∑ E[Xₑ] = ∑ Pr[e ∈ C] = |E|/2 ≥ |C*|/2&lt;/code&gt;, for some optimal cut &lt;code&gt;C*&lt;/code&gt;. Just throw linearity of expectation and use our previous facts - this, plus the fact that the size of the largest possible cut is bounded by the number of edges (that is, &lt;code&gt;|E| ≥ |C*|&lt;/code&gt;), and we get the result we want. &lt;code&gt;|E| = |C*|&lt;/code&gt; only when the graph &lt;code&gt;G&lt;/code&gt; is bipartite; this follows basically by definition.&lt;/p&gt;
&lt;h2&gt;Proving it with Lean&lt;/h2&gt;
&lt;p&gt;Having encountered this simple and elegant algorithm + proof in my algorithms course, I wanted to see if I could formalize it in Lean. I’ve been getting more interested in formal verification, so this seemed like a fun challenge, especially w.r.t the randomization aspect of it! For the uninitiated, Lean is a programming language and proof assistant similar to Rocq. There has been a big movement in recent times to formalize mathematics and CS concepts within the Lean MathLib and CSLib, and I’m eager to see where it goes :)&lt;/p&gt;
&lt;h3&gt;Structures&lt;/h3&gt;
&lt;p&gt;The first step is always representing our key structures. Lean already has a &lt;code&gt;SimpleGraph&lt;/code&gt;, so all we need to do is design a structure to store our &lt;code&gt;Cut&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-- Given some graph G = (V, E)
-- a cut is defined as a set of edges C ⊆ E such that for each edge c = (u, v) ∈ C,
-- we have that u ∈ V₁ and v ∈ V₂, for V₁ ⊕ V₂ (disjoint union) = V
structure Cut (V : Type*) (G : SimpleGraph V) [DecidableEq V] [Fintype V] where
  A : Finset V
  B : Finset V
  -- below are proof obligations
  -- propositions are types, proofs are values of those types!
  partition : A ∪ B = Finset.univ
  disjoint  : Disjoint A B
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We also create some helper functions, namely for:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Creating cuts from an assignment, a mapping from vertices to booleans (true in A, false in B)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;size&lt;/code&gt; of the cut&lt;/li&gt;
&lt;li&gt;Whether a given edge is in the cut at all.&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;-- determine whether an edge is in the cut
def edgeInCut {V : Type*} [DecidableEq V] [Fintype V] {G : SimpleGraph V}
  (C : Cut V G) (e : Sym2 V) : Bool :=
  e.lift ⟨fun u v =&amp;gt; (u ∈ C.A ∧ v ∈ C.B) ∨ (u ∈ C.B ∧ v ∈ C.A), by simp [or_comm, and_comm]⟩

def size {V : Type*} [DecidableEq V] [Fintype V] {G : SimpleGraph V}
  [DecidableRel G.Adj] (C : Cut V G) : ℕ := 
  (G.edgeFinset.filter (fun e =&amp;gt; C.edgeInCut e)).card

-- given some characteristic function, use char func to determine A, B
def ofAssignment {V : Type*} [DecidableEq V] [Fintype V] {G : SimpleGraph V}
  (f : V -&amp;gt; Bool) : Cut V G where
    A := Finset.univ.filter (fun e =&amp;gt; f e)
    B := Finset.univ.filter (fun v =&amp;gt; !f v)
    partition := by grind
    disjoint  := by
      simp only [Finset.disjoint_iff_inter_eq_empty, Bool.not_eq_eq_eq_not, Bool.not_true]
      ext v
      simp
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Some notable things&lt;/strong&gt;:
The backbone of our &lt;code&gt;Cut&lt;/code&gt; is the &lt;code&gt;Finset&lt;/code&gt;, which is a type representing a finite set of elements of some type α. Since graphs are finite structures, we get a lot of free convenient properties from leveraging &lt;code&gt;Finset&lt;/code&gt; here. We also use typeclass declarations for &lt;code&gt;Fintype&lt;/code&gt; and &lt;code&gt;DecidableEq&lt;/code&gt;. &lt;code&gt;Fintype α&lt;/code&gt; lets our function know that α is finite, and &lt;code&gt;DecidableEq&lt;/code&gt; knows that propositional equality is decidable for all elements of type α.&lt;/p&gt;
&lt;p&gt;Generally, we also use the idea of an assignment function quite a bit, i.e. some mapping from &lt;code&gt;V -&amp;gt; Bool&lt;/code&gt; that defines our cut.&lt;/p&gt;

&lt;p&gt;From here on out, I’ll skimp on some of the proof details and go over more of the overarching approaches for some of my lemmas, since that seems like a more economical use of time and article space.&lt;/p&gt;
&lt;p&gt;First, we finalize our randomized cut instances and the edge containment indicator function, which basically represents our random variable &lt;code&gt;Χₑ&lt;/code&gt; from the proof.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def randomizedMaxCut {V : Type*} [DecidableEq V] [Fintype V]
    {G : SimpleGraph V} : (V → Bool) → Cut V G :=
  fun assignment =&amp;gt; Cut.ofAssignment (G := G) assignment

-- use edgeInCut to create a characteristic function returning in {0, 1}
def edgeIndicator {V : Type*} [DecidableEq V] [Fintype V] {G : SimpleGraph V}
  (C : Cut V G) (e : Sym2 V) : ℕ :=
  if Cut.edgeInCut C e then 1 else 0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Proofs&lt;/h3&gt;
&lt;p&gt;Finally, in the order I proved them, here are the lemmas and theorems!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;cut_size_eq_sum_indicators&lt;/code&gt;: &lt;code&gt;|C| = ∑ χₑ ∀ e ∈ E&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;lemma cut_size_eq_sum_indicators {V : Type*} [DecidableEq V] [Fintype V] (G : SimpleGraph V)
  [DecidableRel G.Adj] (assignment : V -&amp;gt; Bool) :
    (Cut.ofAssignment (G := G) assignment).size =
    ∑ e ∈ G.edgeFinset, edgeIndicator (Cut.ofAssignment (G := G) assignment) e := by ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here, we first unfold our relevant definitions. Then, we convert to using summation for both sides, and finally we simplify and show that our sets are equal; if the sets are equal, their cardinalities must be equal as well!&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;count_diff_assignments&lt;/code&gt;: half of the 2^N possible assignments have &lt;code&gt;f u ≠ f v&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;lemma count_diff_assignments {V : Type*} [Fintype V] [DecidableEq V]
  (u v : V) (huv : u ≠ v) : 2 * (Finset.univ.filter (fun f : V -&amp;gt; Bool =&amp;gt; f u ≠ f v)).card =
    Fintype.card (V -&amp;gt; Bool) := by ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This proof is a behemoth of sorts, unexpectedly. The key thread here is to codify the fact that &lt;code&gt;f u ≠ f v&lt;/code&gt; is half the space by creating a bijection and showing it is an involution (its own inverse). Then, if we know that the sets &lt;code&gt;f u ≠ f v&lt;/code&gt; and &lt;code&gt;f u = f v&lt;/code&gt; have the same cardinality, and that they equal &lt;code&gt;2^|V|&lt;/code&gt;, we get our result.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;prob_edge_in_cut&lt;/code&gt;: &lt;code&gt;Pr[e ∈ C] = 1/2&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;lemma prob_edge_in_cut {V : Type*} [DecidableEq V] [Fintype V] (G : SimpleGraph V)
  (e : Sym2 V) (h : ¬e.IsDiag) :
  (∑ assignment : V -&amp;gt; Bool, (edgeIndicator (G := G) (randomizedMaxCut assignment) e : ℝ)) / 
  (Fintype.card (V -&amp;gt; Bool)) = 1/2 := by ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For this proof we use induction on the edges to extract the vertices, then claim that the sum of the indicators when &lt;code&gt;u ≠ v&lt;/code&gt; is equal to the cardinality of the &lt;code&gt;Finset&lt;/code&gt; when &lt;code&gt;f u ≠ f v&lt;/code&gt; (the count of “good” assignments, when not in same vertex set of partition). This, plus our result from the &lt;code&gt;count_diff_assignments&lt;/code&gt; (counting lemma) plus some tiny polishing steps gives us our result.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;expected_cut_size&lt;/code&gt;: &lt;code&gt;E[|C|] = |E|/2&lt;/code&gt; (the important one!)&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;theorem expected_cut_size {V : Type*} [DecidableEq V] [Fintype V] (G : SimpleGraph V)
  [DecidableRel G.Adj] :
    (∑ assignment : V -&amp;gt; Bool,
    ((randomizedMaxCut (G := G) assignment).size : ℝ)) / (Fintype.card (V -&amp;gt; Bool)) =
      (G.edgeFinset.card : ℝ) / 2 := by ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This proof begins with our original expectation statement and chains together our previous proofs to give us our major result. First, we leverage &lt;code&gt;cut_size_eq_sum_indicators&lt;/code&gt; to get our size in terms of the indicators. Next, we simulate our linearity of expectation via &lt;code&gt;Finset.sum_comm&lt;/code&gt; and &lt;code&gt;Finset.sum_div&lt;/code&gt; to move things around. Finally, we use the &lt;code&gt;calc&lt;/code&gt; tactic to sequentially show equivalences with the &lt;code&gt;prob_edge_in_cut&lt;/code&gt; lemma and summation results to give us our answer!&lt;/p&gt;

&lt;h4&gt;A brief interlude: finding &lt;em&gt;the&lt;/em&gt; Max Cut&lt;/h4&gt;
&lt;p&gt;In order to wrap this up and prove things with respect to the actual maximum cut, we need to find a way to represent this. Today I learned about the &lt;code&gt;Finset.univ.sup&lt;/code&gt;, meaning “supremum”. A supremum is the smallest quantity greater than or equal to each element of a given (sub)set. In effect, we iterate over all &lt;code&gt;Finset&lt;/code&gt;s, create &lt;code&gt;Cut&lt;/code&gt;s based off of each possible assignment, and pick the best/max one!&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def maxCutValue {V : Type*} [DecidableEq V] [Fintype V] (G : SimpleGraph V)
  [DecidableRel G.Adj] : ℕ :=
  Finset.univ.sup (fun f : V -&amp;gt; Bool =&amp;gt; (Cut.ofAssignment (G := G) f).size)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Back to the proofs.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;maxCut_le_edges&lt;/code&gt;: Maximum cut is at most &lt;code&gt;|E|&lt;/code&gt;. This proof is short enough to include in its entirety:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;lemma maxCut_le_edges {V : Type*} [Fintype V] [DecidableEq V]
    (G : SimpleGraph V) [DecidableRel G.Adj] :
    maxCutValue G ≤ G.edgeFinset.card := by
  -- notice that finset S's max size is |E|
  -- a Cut can contain at most |E| edges anyway
  unfold maxCutValue
  -- sup cut sizes &amp;lt;= num edges
  apply Finset.sup_le
  intro S _
  -- unfold to get finset and card
  unfold Cut.ofAssignment Cut.size
  -- filtered subset of edges, so cardinality must be less
  exact Finset.card_filter_le _ _
&lt;/code&gt;&lt;/pre&gt;
&lt;ol&gt;
&lt;li&gt;&lt;code&gt;rand_approx_guarantee&lt;/code&gt;: &lt;code&gt;E[|C|] &amp;gt;= |maxCut|/2&lt;/code&gt;. This proof is also short, because it stands tall on the backs of giants (the others).&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code&gt;theorem rand_approx_guarantee {V : Type*} [DecidableEq V] [Fintype V]
  (G : SimpleGraph V) [DecidableRel G.Adj] :
    (∑ assignment : V -&amp;gt; Bool,
    ((randomizedMaxCut (G := G) assignment).size : ℝ)) / (Fintype.card (V -&amp;gt; Bool)) &amp;gt;=
    (maxCutValue G : ℝ) / 2 := by
      rw [expected_cut_size]
      field_simp
      norm_cast
      exact maxCut_le_edges (G := G)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We basically just use the &lt;code&gt;expected_cut_size&lt;/code&gt; and then simplify the division by two on either side, then use our inequality. Note that the expression &lt;code&gt;(∑ assignment : V -&amp;gt; Bool, ((randomizedMaxCut (G := G) assignment).size : ℝ)) / (Fintype.card (V -&amp;gt; Bool))&lt;/code&gt; accurately represents &lt;code&gt;E[|C|]&lt;/code&gt;, because it is the cut size divided by the total number of possible assignments.&lt;/p&gt;
&lt;h3&gt;Learnings&lt;/h3&gt;
&lt;p&gt;Lean is hard. Also, I have to learn to better speak the language; it was pretty challenging to learn how some tactics worked even with the reference (quite mathematically heavy, as is to be expected) and AI tools (more hand-wavy, imprecise at times), but this was a great learning experience and I’m happy I took the time to prove this! My original goal was to try proving something similar about randomized Quicksort, but that felt like too hard a challenge for a Lean novice.&lt;/p&gt;
&lt;p&gt;The rest of my code (i.e. the full proofs and my silly comments) can be found at this Github repo: &lt;a href="https://github.com/abhamra/verif-randomized-maxcut"&gt;verif-randomized-maxcut&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Thank you for reading!&lt;/p&gt;
&lt;p&gt;
&lt;a href="https://abhamra.com/tags/lean"&gt;/lean/&lt;/a&gt;
&lt;a href="https://abhamra.com/tags/algorithms"&gt;/algorithms/&lt;/a&gt;
&lt;/p&gt;
&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://abhamra.com/blog/randomized-maxcut/</guid>
      <category>Hacker News</category>
      <pubDate>Sat, 20 Dec 2025 13:16:21 +0000</pubDate>
    </item>
    <item>
      <title>Qntm's Power Tower Toy</title>
      <link>https://qntm.org/files/knuth/knuth.html</link>
      <description>qntm's power tower toy</description>
      <content:encoded>&lt;body&gt;

&lt;h2&gt;qntm's power tower toy&lt;/h2&gt;


a&lt;br/&gt;



b&lt;br/&gt;



n&lt;br/&gt;





&#13;
        About &lt;a href="https://en.wikipedia.org/wiki/Knuth%27s_up-arrow_notation"&gt;Knuth's up-arrow notation&lt;/a&gt; Â· See also &lt;a href="https://en.wikipedia.org/wiki/Graham%27s_number"&gt;Graham's number&lt;/a&gt;&lt;br/&gt;&#13;
        Back to &lt;a href="https://qntm.org/src"&gt;Things of Interest&lt;/a&gt;&lt;br/&gt;


&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">https://qntm.org/files/knuth/knuth.html</guid>
      <category>Hacker News</category>
      <pubDate>Sat, 20 Dec 2025 11:19:21 +0000</pubDate>
    </item>
    <item>
      <title>The post-GeForce era: What if Nvidia abandons PC gaming?</title>
      <link>https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html</link>
      <description>Imagine it’s the year 2030 and Nvidia has just announced its newest RTX 7000-series graphics cards. But the cheapest of the cards is priced over $2,000 and the top model is nearly double that. The series offer minimal uplift on rendering performance, but they’re incredibly good at accelerated upscaling and frame generation. Plus, memory bandwidth is almost double over the last-gen models.</description>
      <content:encoded>&lt;article class="post-3013044 post type-post status-publish format-standard has-post-thumbnail category-gaming category-components-graphics category-technology-business languages-en publication-pcworld publication-us-default story_types-feature origin-wp" id="post-3013044"&gt;
&lt;!-- .entry-header --&gt;
&lt;!-- &lt;hr class="wp-block-separator" /&gt; --&gt;




&lt;img alt="rtx 5070 ti" src="https://www.pcworld.com/wp-content/uploads/2025/12/rtx-5070-ti-1.jpg?quality=50&amp;amp;strip=all&amp;amp;w=1024"/&gt; 
Image: Adam Patrick Murray / Foundry 
&lt;!-- .post-thumbnail --&gt;


&lt;!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"&gt;


Summary created by Smart Answers AI&lt;h3&gt;In summary:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;PCWorld explores Nvidia’s potential shift away from PC gaming as AI data center revenue reached $51.2 billion versus just $4.3 billion from gaming in Q3 2025.&lt;/li&gt;&lt;li&gt;Rising component costs and memory shortages driven by AI demand may force Nvidia to cut gaming GPU supply, with RTX 7000-series cards expected to start over $2,000.&lt;/li&gt;&lt;li&gt;This transition could push gaming toward cloud services like GeForce Now, fundamentally changing how consumers access high-end graphics performance through subscription models instead of hardware ownership.&lt;/li&gt;&lt;/ul&gt;

&lt;p&gt;Imagine it’s the year 2030 and Nvidia has just announced its newest RTX 7000-series graphics cards. But the cheapest of the cards is priced over $2,000 and the top model is nearly double that. The series offer minimal uplift on rendering performance, but they’re incredibly good at accelerated upscaling and frame generation. Plus, memory bandwidth is almost double over the last-gen models.&lt;/p&gt;
&lt;p&gt;Let’s continue the hypothetical: Nvidia’s new xx60-series cards aren’t expected for months while Nvidia stockpiles enough defective GPUs. But don’t worry if you can’t afford these new cards or don’t want to wait. Why? Because GeForce Now offers the full upgrade &lt;em&gt;right now&lt;/em&gt; for an “affordable” monthly fee, especially with an annual sub locked in.&lt;/p&gt;


&lt;p&gt;I wrote the above as a nightmare scenario, but it’s odd how close it sounds to the launch of the RTX 50-series. It’s a history that seems likely to repeat and accelerate as Nvidia’s gaming division becomes an ever-more-minor side hustle to its AI initiatives.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Nvidia could effectively give up on gaming in the near future,&lt;/strong&gt; and that might be the most financially sensible thing to do if the AI bubble doesn’t burst. But what would happen if they did?&lt;/p&gt;


&lt;!--js block injected --&gt;




&lt;h2&gt;Just follow the money&lt;/h2&gt;
&lt;p&gt;The numbers behind my pessimistic prognosis paint a stark picture. &lt;a href="https://go.skimresources.com?id=111346X1569483&amp;amp;xs=1&amp;amp;url=https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-third-quarter-fiscal-2026&amp;amp;xcust=2-1-3013044-1-0-0-0-0&amp;amp;sref=https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html"&gt;Nvidia’s Q3 2025 revenue&lt;/a&gt; topped $57 billion. Guess how much of that money came from data centers? A whopping $51.2 billion. That’s just shy of 90% of its total revenue and represents a 25% increase over the previous quarter and a 66% increase year on year.&lt;/p&gt;
&lt;p&gt;How much revenue do you think Nvidia pulled in from gaming? A measly $4.3 billion by comparison. That’s down 1% on the previous quarter, and that’s despite having the most powerful graphics cards available &lt;em&gt;and&lt;/em&gt; with stock and prices being far more favorable than they were earlier in the year. &lt;a href="https://go.skimresources.com?id=111346X1569483&amp;amp;xs=1&amp;amp;url=https://nvidianews.nvidia.com/news/nvidia-announces-financial-results-for-third-quarter-fiscal-2025&amp;amp;xcust=2-1-3013044-1-0-0-0-0&amp;amp;sref=https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html"&gt;It’s still up 30% on last year&lt;/a&gt;, but the difference in potential between data centers and gaming is &lt;em&gt;staggering&lt;/em&gt;.&lt;/p&gt;
&lt;img alt="Nvidia sign outside luxurious building" src="https://b2c-contenthub.com/wp-content/uploads/2025/12/Nvidia-sign-outside-luxurious-building.jpg?quality=50&amp;amp;strip=all&amp;amp;w=1200"/&gt;

&lt;p&gt;Nvidia&lt;/p&gt;
&lt;p&gt;Indeed, gaming makes up less than 8% of Nvidia’s total revenue as of now, and although the overall income from gaming continues to increase, it’s miniscule in comparison to its data center take. &lt;a href="https://go.skimresources.com?id=111346X1569483&amp;amp;xs=1&amp;amp;url=https://bullfincher.io/companies/nvidia-corporation/revenue-by-segment&amp;amp;xcust=2-1-3013044-1-0-0-0-0&amp;amp;sref=https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html"&gt;Bullfincher highlights how quickly that’s changed&lt;/a&gt;, too: just a few years ago, gaming represented over 33% of Nvidia’s total revenue.&lt;/p&gt;




&lt;p&gt;Where do you think it’s going to be in another five years? Assuming the AI bubble doesn’t pop as catastrophically as it could, gaming is going to become a tiny footnote on Nvidia’s balance sheet. Will Jensen Huang even bother doing gaming hardware keynotes at that point?&lt;/p&gt;
&lt;img alt="Nvidia Jensen Huang" src="https://b2c-contenthub.com/wp-content/uploads/2025/01/20250107_103508.jpg?quality=50&amp;amp;strip=all&amp;amp;w=1200"/&gt;

&lt;p&gt;Mark Hachman / IDG&lt;/p&gt;
&lt;p&gt;Nvidia might be the biggest megacorp in this space, but its contemporaries show similar gaming red flags on their balance sheets. &lt;a href="https://go.skimresources.com?id=111346X1569483&amp;amp;xs=1&amp;amp;url=https://ir.amd.com/news-events/press-releases/detail/1265/amd-reports-third-quarter-2025-financial-results&amp;amp;xcust=2-1-3013044-1-0-0-0-0&amp;amp;sref=https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html"&gt;AMD made just over $9 billion this past quarter&lt;/a&gt;, but $4.3 billion was from data center sales while only $1.3 billion came from gaming. That’s &lt;a href="https://go.skimresources.com?id=111346X1569483&amp;amp;xs=1&amp;amp;url=https://ir.amd.com/news-events/press-releases/detail/1224/amd-reports-third-quarter-2024-financial-results&amp;amp;xcust=2-1-3013044-1-0-0-0-0&amp;amp;sref=https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html"&gt;much better than last year&lt;/a&gt;—when data centers brought in $3.5 billion and gaming just $462 million—but data centers are still a far bigger portion of AMD’s revenue than gaming.&lt;/p&gt;
&lt;p&gt;These numbers make a compelling case for giving up some interest and investment in gaming hardware development. It doesn’t mean they’re going to stop make gaming GPUs entirely. (Or does it?) But if you’re Jensen Huang facing off against shareholders who are demanding the revenue numbers go up as much as possible as fast as possible, what are you going to sell them on: a new gaming GPU that has historically low margins, or a new generation of data center hardware to feed into the accelerating AI bubble with untold potential?&lt;/p&gt;
&lt;p&gt;You could even argue that Nvidia’s increasing focus over the past few years on DLSS and ray tracing over pure rasterization performance is an early sign of it putting its eggs in the data center basket.&lt;/p&gt;




&lt;h2&gt;A canary in the RAM mines&lt;/h2&gt;
&lt;p&gt;The biggest side effect of all these new data center builds hasn’t been GPU scarcity, surprisingly. (At least, not to the degree we saw during the cryptocurrency craze.) Rather, it’s &lt;a href="https://www.pcworld.com/article/3010391/ram-prices-are-painfully-out-of-control-4-ways-to-avoid-the-gouging.html"&gt;skyrocketing memory prices&lt;/a&gt;. RAM kits have increased in price by over 200 percent in some cases, making large capacity kits more costly than top-tier GPUs. Some modest RAM options are even more expensive than gaming consoles.&lt;/p&gt;
&lt;p&gt;Consumer RAM is shooting up in price because all the major memory manufacturers are &lt;a href="https://www.pcworld.com/article/2998935/ram-is-so-expensive-samsung-wont-even-sell-it-to-samsung.html"&gt;inundated with orders for data center memory&lt;/a&gt;, like HBM and LPDDR. Some have begun pivoting their fabrication lines to these higher-margin memory types, leading to shortages of NAND chips—and, consequently, &lt;a href="https://www.pcworld.com/article/3003682/memory-prices-are-climbing-its-making-these-5-other-products-cost-more.html"&gt;shortages of consumer memory and SSDs&lt;/a&gt;.&lt;/p&gt;
&lt;img alt="Micron Crucial RAM modules sticks DDR memory" src="https://b2c-contenthub.com/wp-content/uploads/2025/12/Micron-Crucial-RAM-modules-sticks-DDR-memory.jpg?quality=50&amp;amp;strip=all&amp;amp;w=1200"/&gt;

&lt;a href="https://go.skimresources.com?id=111346X1569483&amp;amp;xs=1&amp;amp;url=https://www.shutterstock.com/image-photo/bangkok-thailand-april-28-2023-ddr3l-2295520815&amp;amp;xcust=2-1-3013044-1-0-0-0-0&amp;amp;sref=https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html"&gt;Nor Gal / Shutterstock.com&lt;/a&gt;
&lt;p&gt;Those shortages are making RAM and SSDs far more expensive. And yet, despite the increased margins and diminishing supply versus demand, &lt;a href="https://www.pcworld.com/article/2999460/micron-will-end-crucial-consumer-brand-in-another-ai-casualty.html"&gt;Micron just closed its Crucial brand&lt;/a&gt; of consumer RAM and SSDs.&lt;/p&gt;
&lt;p&gt;It was profitable, it was popular, it had a distinct market niche that served consumers and gamers for decades. But even Micron didn’t see the point of keeping it going when it could instead make heaps more cash from selling Micron NAND chips and server memory.&lt;/p&gt;
&lt;p&gt;And &lt;a href="https://www.pcworld.com/article/3001184/i-hope-crucials-death-isnt-a-canary-in-a-pc-memory-coal-mine.html"&gt;if Micron is so willing to pull out&lt;/a&gt; of the consumer space due to AI-driven demand, how much more will Nvidia be tempted to do the same? What’s stopping Nvidia from reaching the same conclusion?&lt;/p&gt;
&lt;p&gt;For further proof of this future, Nvidia is &lt;a href="https://go.skimresources.com?id=111346X1569483&amp;amp;xs=1&amp;amp;url=https://overclock3d.net/news/gpu-displays/nvidia-plans-heavy-cuts-to-gpu-supply-in-early-2026/&amp;amp;xcust=2-1-3013044-1-0-0-0-0&amp;amp;sref=https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html"&gt;rumored to be cutting its gaming GPU supply in 2026&lt;/a&gt; due to memory shortages. It’s especially notable how Nvidia appears to be cutting the more affordable mid-range graphics cards first, leaving ultra-budget and ultra-high-end lines intact for now. Is this just the first step in Nvidia leaving gamers behind?&lt;/p&gt;




&lt;h2&gt;Where things could go from here&lt;/h2&gt;
&lt;p&gt;There are some intriguing comparisons to make between Nvidia and other big businesses that found growth and revenue in avenues that weren’t where they started. IBM went from being &lt;em&gt;the&lt;/em&gt; name in computing hardware to one that largely runs in the background. It sold off its core hardware businesses and became a software and services company that’s still worth tens of billions of dollars. It recently spun off again, creating a separate company to handle IT services while the core business refocused on cloud computing and AI.&lt;/p&gt;
&lt;p&gt;Nvidia could do that: spin or sell off its gaming divisions and license its GPU technology to that spun-or-sold-off subsidiary.&lt;/p&gt;
&lt;img alt="Nvidia GeForce Now Ultimate upgrade 1" src="https://b2c-contenthub.com/wp-content/uploads/2025/08/GeForce_NOW_Blackwell_KV_.jpg?quality=50&amp;amp;strip=all&amp;amp;w=1200"/&gt;

Notice the lack of graphics cards in this Nvidia promo image.&lt;p&gt;Nvidia&lt;/p&gt;
&lt;p&gt;Perhaps Nvidia could even end up like Adobe. In the mid-2010s, the developer of Photoshop launched Creative Cloud and slowly pushed all its once-in-perpetuity software licenses into a subscription model that’s still going on today. Could that apply to &lt;a href="https://www.pcworld.com/article/630335/geforce-now-review.html"&gt;Nvidia’s GeForce Now streaming service&lt;/a&gt;? It had 25 million subscribers as of 2023 and ran on GPUs designed for data center server racks. Nvidia could leave dedicated desktop and laptop GPUs behind entirely and pivot its gaming divisions into software/hardware-as-a-service firms.&lt;/p&gt;
&lt;p&gt;If gaming goes a similar way to TV and movie streaming, it’s possible Nvidia could even pull a Netflix and slowly de-emphasize its DVD-like hardware business in favor of powering it all from the cloud.&lt;/p&gt;




&lt;h2&gt;Gaming won’t die, but it will change&lt;/h2&gt;
&lt;p&gt;As much as this article is heavy on the doom, Nvidia is unlikely to exit gaming &lt;em&gt;entirely&lt;/em&gt;. People want to play games and there’s money to be made there, so &lt;em&gt;someone&lt;/em&gt; will keep tapping that market. But how that revenue is extracted may change—dramatically so.&lt;/p&gt;
&lt;p&gt;Microsoft is already talking about making the &lt;a href="https://www.pcworld.com/article/2953703/did-pcs-win-the-console-war-the-next-xbox-will-run-windows-report-claims.html"&gt;next Xbox more of a PC/console hybrid&lt;/a&gt;. And with the latest Xbox consoles being the third wheel of this generation, it wouldn’t be a surprise to see the future of Xbox focus more on &lt;em&gt;streaming&lt;/em&gt; games than buying/owning them. Xbox Game Pass already has over 37 million subscribers—that’s more than the number of Xbox Series X/S consoles sold this generation.&lt;/p&gt;
&lt;p&gt;Nvidia could do something similar. Or it could spin off. Or it could stop making gaming GPUs entirely. The only thing we know for sure is this: when a gaming company starts making astronomical amounts of money due to AI-driven demand, it’s hard to imagine it wouldn’t be tempted to dive head-first into an AI-first strategy at the expense of gaming.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Further reading:&lt;/strong&gt; &lt;a href="https://www.pcworld.com/article/2542269/pcs-vs-consoles-the-future-of-gaming-looks-blurrier-than-ever.html"&gt;PC vs. consoles? Gaming’s future is blurrier than ever&lt;/a&gt;&lt;/p&gt;




 
&lt;h3&gt;
&lt;a href="https://www.pcworld.com/author/jon-martindale"&gt;
		Author: Jon Martindale&lt;/a&gt;, Contributor, PCWorld		&lt;/h3&gt;



&lt;img src="https://www.pcworld.com/wp-content/uploads/2025/12/author_photo_Jon-Martindale_1728563874-7.jpg?quality=50&amp;amp;strip=all&amp;amp;w=150&amp;amp;h=150&amp;amp;crop=1"/&gt;

&lt;p&gt;Jon Martindale is a voracious writer and technology fanboy who loves nothing more than digging into the specs of the latest graphics cards, processors, and displays. He's passionate about everything PC, but also enjoys experimenting with AIs, and covering new standing desks that can help avoid his worst posture habits.&lt;/p&gt;


&lt;h3&gt; Recent stories by Jon Martindale:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href="https://www.pcworld.com/article/3003682/memory-prices-are-climbing-its-making-these-5-other-products-cost-more.html"&gt;
									RAM costs are skyrocketing—and these 5 other gadgets are paying the price								&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.pcworld.com/article/2975248/i-used-chatgpt-to-turn-my-old-laptop-into-an-alien-rpg-muthur-terminal.html"&gt;
									I used ChatGPT to turn my old laptop into an Alien RPG MUTHUR terminal								&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href="https://www.pcworld.com/article/2945507/the-future-of-laptops-is-already-here-6-trends-making-2025-a-breakout-year.html"&gt;
									The future of laptops is already here: 6 trends making 2025 a breakout year								&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;







 


&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.pcworld.com/article/3013044/the-post-geforce-era-what-if-nvidia-abandons-pc-gaming.html</guid>
      <category>Hacker News</category>
      <pubDate>Sat, 20 Dec 2025 10:25:38 +0000</pubDate>
    </item>
    <item>
      <title>The Polyglot NixOS</title>
      <link>https://x86.lol/generic/2025/12/19/polyglot.html</link>
      <description>Recently a colleague mentioned building
NixOS images that run unchanged on multiple architectures. Given the past
adventures on this blog with systemd-repart and cross-compiling NixOS , I decide to give this a
go.</description>
      <content:encoded>&lt;article class="post h-entry" itemscope="" itemtype="http://schema.org/BlogPosting"&gt;


&lt;p&gt;Recently a &lt;a href="https://github.com/samueldr"&gt;colleague&lt;/a&gt; mentioned building
NixOS images that run unchanged on multiple architectures. Given the past
adventures on this blog with &lt;a href="https://x86.lol/generic/2024/08/28/systemd-sysupdate.html"&gt;systemd-repart&lt;/a&gt; and
&lt;a href="https://x86.lol/generic/2024/09/21/cross-compile-riscv.html"&gt;cross-compiling NixOS&lt;/a&gt;, I decide to give this a
go.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;tl;dr&lt;/strong&gt; You can find a quick’n’dirty implementation
&lt;a href="https://github.com/blitz/polyglot-image"&gt;here&lt;/a&gt;. Check the repo for
details on how to build and run it.&lt;/p&gt;
&lt;p&gt;So do we want to do: We want to build &lt;em&gt;one&lt;/em&gt; disk image that boots on
x86_64, ARM AArch64, and RISC-V 64-bit. We limit ourselves here to
UEFI platforms, which makes this pretty straight forward.&lt;/p&gt;
&lt;p&gt;From a high-level we need to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Have a NixOS configuration.&lt;/li&gt;
&lt;li&gt;Build the system closure for each target.&lt;/li&gt;
&lt;li&gt;Throw everything into one &lt;code&gt;/nix/store&lt;/code&gt; partition.&lt;/li&gt;
&lt;li&gt;Populate the &lt;a href="https://en.wikipedia.org/wiki/EFI_system_partition"&gt;ESP&lt;/a&gt; to
boot the right closure depending on the architecture.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All of this is surprisingly straight-forward. The ESP has
architecture-dependent default filenames for what the firmware should
boot, given no other configuration. This means we can build an
&lt;a href="https://wiki.archlinux.org/title/Unified_kernel_image"&gt;UKI&lt;/a&gt; per
architecture and drop it at the right place in the ESP
(&lt;code&gt;/EFI/BOOT/BOOTX64.EFI&lt;/code&gt; for 64-bit x86) and we are done!&lt;/p&gt;
&lt;p&gt;By linking the system’s UKI in these locations on the ESP, we skip
over having an actual bootloader and thus can’t have multiple
generations, but it makes for a much leaner example!&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://github.com/blitz/polyglot-image"&gt;example repo&lt;/a&gt; puts the
closure for each architecture in a single Nix store partition. I
&lt;em&gt;thought&lt;/em&gt; this would bring some space savings, because files that are
not binary code should be largely the same. This doesn’t really pan
out in this small example and we only save a couple of percent. Maybe
it makes a bigger difference for larger closures.&lt;/p&gt;
&lt;p&gt;If you want to dig into the details, the &lt;a href="https://github.com/blitz/polyglot-image"&gt;example
repo&lt;/a&gt; has the instructions
how to build and boot the image. I’m also eager to see someone
building a more comprehensive version of this that includes a fully
functioning bootloader and multiple generations!&lt;/p&gt;

&lt;a href="https://x86.lol/generic/2025/08/10/change-monitoring.html"&gt;Quick and Dirty Website Change Monitoring 👈&lt;/a&gt;
&lt;a href="https://x86.lol/generic/2025/12/19/polyglot.html"&gt;&lt;/a&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://x86.lol/generic/2025/12/19/polyglot.html</guid>
      <category>Hacker News</category>
      <pubDate>Sat, 20 Dec 2025 07:39:00 +0000</pubDate>
    </item>
    <item>
      <title>Perfect Software – Software for an Audience of One</title>
      <link>https://outofdesk.netlify.app/blog/perfect-software</link>
      <description>Perfect Software - Software for an Audience of One</description>
      <content:encoded>&lt;div class="content col-span-12 text-justify mb-4 md:mb-4"&gt;&lt;h2&gt;&lt;!-- HTML_TAG_START --&gt;Perfect Software - Software for an Audience of One&lt;!-- HTML_TAG_END --&gt;&lt;/h2&gt;&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://outofdesk.netlify.app/blog/perfect-software</guid>
      <category>Hacker News</category>
      <pubDate>Sat, 20 Dec 2025 07:14:53 +0000</pubDate>
    </item>
    <item>
      <title>Here you can find the contents of the Unix v4 tape ready for bootstrapping</title>
      <link>http://squoze.net/UNIX/v4/README</link>
      <description>Here you can find the contents of
the UNIX v4 tape ready for bootstrapping, including a tar file of the filesystem.</description>
      <content:encoded>&lt;body&gt;



&lt;a href="https://github.com/aap/"&gt;github&lt;/a&gt; |
      &lt;a href="https://mastodon.sdf.org/@aap"&gt;mastodon&lt;/a&gt; |
      &lt;a href="http://tx-0.net"&gt;TX-0&lt;/a&gt; |
      &lt;a href="http://pdp-1.net"&gt;PDP-1&lt;/a&gt; |
      &lt;a href="http://pdp-6.net"&gt;PDP-6/10&lt;/a&gt; |
    

Related sites:
      | &lt;a href="http://squoze.net/sitemap"&gt;site map&lt;/a&gt;



&lt;h1&gt;&lt;a href="http://squoze.net/"&gt;squoze.net &lt;/a&gt;&lt;/h1&gt;

&lt;br/&gt;



&lt;ul&gt;
&lt;li&gt;&lt;a href="http://squoze.net/B/"&gt;› B/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/C/"&gt;› C/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/NB/"&gt;› NB/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/"&gt;» UNIX/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/32v/"&gt;› 32v/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/V6_on_rl01"&gt;› V6 on rl01&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/bltj/"&gt;› bltj/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/fs/"&gt;› fs/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/restored/"&gt;› restored/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/sysIII_pdp11/"&gt;› sysIII pdp11/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/sysIII_vax/"&gt;› sysIII vax/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/sysV_pdp11/"&gt;› sysV pdp11/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v1man/"&gt;› v1man/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v2man/"&gt;› v2man/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v3man/"&gt;› v3man/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v4/"&gt;» v4/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v4/README"&gt;» README&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v4man/"&gt;› v4man/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v5/"&gt;› v5/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v5man/"&gt;› v5man/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v6/"&gt;› v6/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v6man/"&gt;› v6man/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v7/"&gt;› v7/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v8/"&gt;› v8/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/ling/"&gt;› ling/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/math/"&gt;› math/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/misc/"&gt;› misc/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/plan_9/"&gt;› plan 9/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;h1&gt;UNIX Fourth Edition&lt;/h1&gt;
&lt;p&gt;Here you can find the contents of
the &lt;a href="https://archive.org/details/utah_unix_v4_raw"&gt;UNIX v4 tape&lt;/a&gt;
ready for bootstrapping, including a tar file of the filesystem.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v4/unix_v4.tap"&gt;unix_v4.tap&lt;/a&gt; is the original tape file in simh format&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v4/bootstrap"&gt;bootstrap&lt;/a&gt; are the first 38400 bytes of the tape&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v4/disk.rk"&gt;disk.rk&lt;/a&gt; is the rest of the tape, an RK05 image&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v4/unix_v4.tar"&gt;unix_v4.tar&lt;/a&gt; is the filesystem extracted&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v4/install.ini"&gt;install.ini&lt;/a&gt; is an ini file for simh to install the system&lt;/li&gt;
&lt;li&gt;&lt;a href="http://squoze.net/UNIX/v4/boot.ini"&gt;boot.ini&lt;/a&gt; is an ini file for simh to boot the system&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At first I extracted the disk image manually from the tape,
which resulted in &lt;code&gt;bootstrap&lt;/code&gt; and &lt;code&gt;disk.rk&lt;/code&gt;.
These are really nothing more than
the first 38400 bytes of the raw tape content and the rest.
Because &lt;code&gt;unix_v4.tap&lt;/code&gt; is block based, one first has to strip it of its block sizes
to get the raw content.&lt;/p&gt;
&lt;p&gt;Actually it's easier to just use the tape as it is and install a new system from it.&lt;/p&gt;
&lt;h1&gt;Installing the system&lt;/h1&gt;
&lt;p&gt;To install the system we just dump an RK05 disk image from tape to disk:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% pdp11 install.ini

[...]
        ; boot from TM0, now in mboot
=list
dldr
dtf
list
mboot
mcopy
rkf
tboot
uboot
=mcopy
'p' for rp; 'k' for rk
k
disk offset
0
tape offset
75
count
4000
=
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Afterwards, we can just load &lt;code&gt;uboot&lt;/code&gt; from tape to start UNIX:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;=uboot
k
unix
mem = 64530

login: root
# ls
bin
dev
etc
lib
mnt
tmp
unix
usr
# sync
# sync
# sync
# ^E        ; end emulation
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Running the system&lt;/h1&gt;
&lt;p&gt;To boot the system we don't need the tape.
Instead, we load &lt;code&gt;uboot&lt;/code&gt; directly from the boot sector.
We specify &lt;code&gt;k&lt;/code&gt; for RK05, then the filename &lt;code&gt;unix&lt;/code&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;% pdp11 boot.ini

[...]
        ; boot from RK0, now in uboot
k
unix
mem = 64530

login: root
#
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Rebuilding the kernel&lt;/h1&gt;
&lt;p&gt;Put the following into &lt;code&gt;/usr/sys/run&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rm -f low.o mch.o conf.o lib1 lib2

chdir ken
cc -c *.c
sh mklib
rm *.o

chdir ../dmr
cc -c *.c
sh mklib
rm *.o

chdir ..
cc -c conf/conf.c
mv conf/conf.o conf.o
as conf/low.s
mv a.out low.o
as conf/mch.s
mv a.out mch.o
ld -x low.o mch.o conf.o lib1 lib2
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;/usr/sys/ken/mklib&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ar r ../lib1 main.o
ar r ../lib1 alloc.o
ar r ../lib1 iget.o
ar r ../lib1 prf.o
ar r ../lib1 rdwri.o
ar r ../lib1 slp.o
ar r ../lib1 subr.o
ar r ../lib1 text.o
ar r ../lib1 trap.o
ar r ../lib1 sig.o
ar r ../lib1 sysent.o
ar r ../lib1 sys1.o
ar r ../lib1 sys2.o
ar r ../lib1 sys3.o
ar r ../lib1 sys4.o
ar r ../lib1 nami.o
ar r ../lib1 fio.o
ar r ../lib1 clock.o
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;/usr/sys/dmr/mklib&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ar r ../lib2 bio.o
ar r ../lib2 tty.o
ar r ../lib2 malloc.o
ar r ../lib2 pipe.o
ar r ../lib2 cat.o
ar r ../lib2 dc.o
ar r ../lib2 dn.o
ar r ../lib2 dc.o
ar r ../lib2 dn.o
ar r ../lib2 dp.o
ar r ../lib2 kl.o
ar r ../lib2 mem.o
ar r ../lib2 pc.o
ar r ../lib2 rf.o
ar r ../lib2 rk.o
ar r ../lib2 tc.o
ar r ../lib2 tm.o
ar r ../lib2 vs.o
ar r ../lib2 vt.o
ar r ../lib2 partab.o
ar r ../lib2 rp.o
ar r ../lib2 lp.o
ar r ../lib2 dhdm.o
ar r ../lib2 dh.o
ar r ../lib2 dhfdm.o
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then in &lt;code&gt;/usr/sys&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# sh run
alloc.c:
clock.c:
fio.c:
iget.c:
main.c:
nami.c:
prf.c:
rdwri.c:
sig.c:
60: Warning: assignment understood
61: Warning: assignment understood
slp.c:
subr.c:
sys1.c:
sys2.c:
sys3.c:
sys4.c:
sysent.c:
text.c:
trap.c:
bio.c:
cat.c:
dc.c:
dh.c:
dhdm.c:
dhfdm.c:
dn.c:
dp.c:
dv.c:
kl.c:
lp.c:
malloc.c:
mem.c:
partab.c:
pc.c:
pipe.c:
rf.c:
rk.c:
rp.c:
tc.c:
tm.c:
tty.c:
vs.c:
vt.c:
#
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now install and boot the new kernel:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mv a.out /nunix
# sync
# sync
# sync
# ^E
Simulation stopped, PC: 002040 (MOV (SP)+,177776)
sim&amp;gt; b rk
k
nunix
mem = 64529

login: root
#
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;TODO&lt;/h1&gt;
&lt;p&gt;There are a bunch of other things I would like to document
(or do in the first place):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;automatic installation (expect)&lt;/li&gt;
&lt;li&gt;configure kernel (/dev/mem missing)&lt;/li&gt;
&lt;li&gt;add device files&lt;/li&gt;
&lt;li&gt;add man pages&lt;/li&gt;
&lt;li&gt;try rp disk&lt;/li&gt;
&lt;li&gt;try rf swap (ps assumes rf0)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Reconstruction:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;get pre-v4 nsys kernel to work (buffer handling seems broken, i suspect synchronization bugs)&lt;/li&gt;
&lt;li&gt;get B restoration to work&lt;/li&gt;
&lt;/ul&gt;


&lt;a href="http://werc.cat-v.org/"&gt;Powered by werc&lt;/a&gt;
&lt;!-- TODO Maybe should add a programatically generated google search box --&gt;
&lt;a href="http://squoze.net/_users/login"&gt;User Login&lt;/a&gt;
&lt;br/&gt;
&lt;br/&gt;

&lt;/body&gt;</content:encoded>
      <guid isPermaLink="false">http://squoze.net/UNIX/v4/README</guid>
      <category>Hacker News</category>
      <pubDate>Sat, 20 Dec 2025 05:17:32 +0000</pubDate>
    </item>
    <item>
      <title>The Coffee Warehouse</title>
      <link>https://www.scopeofwork.net/the-coffee-warehouse/</link>
      <description>I have a bit of a love hate relationship with Starbucks. It feels expensive. The lines are long. And I resent the fact that I give them an interest-free loan every time I use their mobile app . But my go-to Pike and banana nut loaf are delicious, and the baristas at my preferred location are fun. They give me a hard time if I deviate from my usual, which I appreciate. When I’m feeling uncertain about the day, making a Starbucks run is a surprisingly good way to get my head on straight.</description>
      <content:encoded>&lt;article class="post tag-feature content-wrap post-access-paid"&gt;


&lt;p&gt;I have a bit of a love hate relationship with Starbucks. It feels expensive. The lines are long. And I resent the fact that I give them an &lt;a href="https://www.morningstar.com/news/marketwatch/20250430172/starbucks-customers-are-giving-the-company-over-200-million-of-free-money?ref=scopeofwork.net"&gt;interest-free loan every time I use their mobile app&lt;/a&gt;. But my go-to Pike and banana nut loaf are delicious, and the baristas at my preferred location are fun. They give me a hard time if I deviate from my usual, which I appreciate. When I’m feeling uncertain about the day, making a Starbucks run is a surprisingly good way to get my head on straight.&lt;/p&gt;&lt;p&gt;On a recent visit, I arrived at the pickup counter and found my order incomplete. The slice of banana bread had been warmed, bagged, and labeled, but my cup of black coffee had yet to be dispensed into its paper cup. Looking behind the bar, I saw the usual blur of green-aproned baristas moving from task to task. It was frenetic, but organized too, with defined work areas and clear routines. The scene reminded me of my days working at a distribution center. The area where we packed orders had a similar manic choreography, and watching the baristas go about their jobs I found myself trying to understand their order flows and processes. Specifically, I wanted to understand how Starbucks organizes and prioritizes its work.&lt;/p&gt;&lt;h3&gt;Customer Flexibility vs. Operational Complexity.&lt;/h3&gt;&lt;p&gt;Starbucks is in a bit of a slump. Sales in established locations have &lt;a href="https://www.wsj.com/business/hospitality/starbucks-says-its-making-progress-on-quest-to-fulfill-orders-more-quickly-39492de6?st=SHLAvf&amp;amp;reflink=desktopwebshare_permalink&amp;amp;ref=scopeofwork.net"&gt;fallen for 5 consecutive quarters&lt;/a&gt;, contributing to a recent change in leadership. In an attempt to win back customers, the new CEO, Brian Niccol, has made operations a focus and pledged to reduce wait times and improve the customer experience. They are investing heavily in their order sorting algorithms and store processes, with the topic getting conspicuous attention in recent &lt;a href="https://s203.q4cdn.com/326826266/files/doc_financials/2025/q2/SBUX-2Q25-Corrected-Transcript.pdf?utm_source=chatgpt.com"&gt;earnings calls&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Some of the operational challenges stem from &lt;a href="https://www.qsrmagazine.com/story/the-fix-at-starbucks-had-to-start-with-mobile-ordering/?ref=scopeofwork.net"&gt;the increasing importance of their mobile app&lt;/a&gt;. &lt;a href="https://archive.starbucks.com/record/going-mobile?ref=scopeofwork.net"&gt;Since 2015&lt;/a&gt;, Starbucks has allowed customers to place orders remotely, before they arrive at the store. This grants convenience and flexibility, offloads the labor associated with order entry, and as mentioned previously, encourages customers to give them free loans to earn “mobile rewards.” But this convenience and savings come at the cost of operational complexity. There are three sales channels at a typical Starbucks today: walk-ins, drive thru, and mobile. Drinks are processed in the order received, whether placed in person or through the mobile app. This first-in, first-out system creates challenges, particularly at busy times. Operational capacity is often devoted to mobile customers who have yet to arrive, while those already at the store grow impatient. The staging area gets crowded with completed drinks, leading to that awkward seek and find many of us have experienced. &lt;/p&gt;&lt;p&gt;Though mobile orders create challenges, they also represent a kind of operational opportunity. They are different from orders placed through the traditional sales channels, where customers are present at the restaurant and presumably want their coffee as soon as they can get it. With mobile, customers generally place the order before they arrive and don’t care precisely when it is finished, as long as it is complete, and reasonably fresh, when they get there. This arrival delay makes it sensible to consider processing work &lt;em&gt;out of sequence&lt;/em&gt;.&lt;/p&gt;&lt;h3&gt;Warehouse work&lt;/h3&gt;&lt;p&gt;Back in my warehousing days, we thought a lot about how and when we processed work. Through our website, customers could place orders at any time of the day or night, and we committed to getting them their stuff in two days. The parcel carriers needed most of this time to get the shipment to the customer, but we generally had a few hours to fill the order, pack it, and load it onto the truck. We took advantage of this window to operate more efficiently. A few principles guided our thinking:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;strong&gt;Urgent Work First:&lt;/strong&gt; We prioritized packages that had time constraints. If an order’s truck was leaving soon, we’d complete it first — even if there were other orders that had come in before it.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Stay In Sync:&lt;/strong&gt; Many customers ordered more than one thing. Even if the items were stored in areas far from one another, the customer would still expect them to show up in the same box. We would begin processing all components of that order simultaneously and only when we had enough capacity for all the processes involved.  As a result, the components of an order would arrive in the packing area at a similar time, where they would be combined and put on a truck. This reduced the amount of incomplete work floating around the warehouse, which in turn reduced opportunities for error.&lt;br/&gt;&lt;br/&gt;A consequence of the above is that simple orders (with fewer work areas involved) tended to move through the system faster. They didn’t get held up behind large and complex shipments that gobbled up lots of warehouse capacity.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;Batch Work Where Appropriate&lt;/strong&gt;: The longer the work queue, the more likely you are to see collections of similar jobs in the queue. So we designed work areas to take advantage of this phenomenon, batching jobs that used the same skills and materials. &lt;br/&gt;&lt;br/&gt;Imagine a work area where people pack boxes. A packer will complete two identical boxes more quickly and accurately if she does them back to back, as the packages require the same materials (container, tape, infill, and packing surface) and skills. If she needs to shift to some other task in between, say to pack a different type of package, the process will naturally go more slowly. This is pretty much the same principle that makes assembly lines work: Keep people focused on the same task, and they will perform that task more efficiently.&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;Starbucks as a Coffee Distribution Center&lt;/h3&gt;&lt;p&gt;The work queues at Starbucks are measured in minutes of work rather than hours. Still, there are a number of warehousing principles they could easily adopt.&lt;/p&gt;




&lt;p&gt;&lt;em&gt;Scope of Work is supported by members who love these kinds of operational deep dives. Join as a paid subscriber to support thoughtful, original work like this.&lt;/em&gt;&lt;/p&gt;

&lt;a href="http://scopeofwork.net/membership?ref=scopeofwork.net"&gt;
                            Support SOW &amp;amp; Unlock More →
                        &lt;/a&gt;





&lt;h3&gt;Read the full story&lt;/h3&gt;
&lt;p&gt;
      The rest of this post is for paid members only. Sign up now to read the full post — and all of Scope of Work’s other paid posts.
    &lt;/p&gt;
&lt;a href="https://www.scopeofwork.net/signup/"&gt;Sign up now&lt;/a&gt;

Already have an account?
&lt;a href="https://www.scopeofwork.net/signin/"&gt;Sign in&lt;/a&gt;



&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.scopeofwork.net/the-coffee-warehouse/</guid>
      <category>Hacker News</category>
      <pubDate>Fri, 19 Dec 2025 20:16:27 +0000</pubDate>
    </item>
    <item>
      <title>Astrophotography Target Planner: Discover Hidden Nebulas</title>
      <link>https://astroimagery.com/techniques/imaging/astrophotography-target-planner/</link>
      <description>Posted by</description>
      <content:encoded>&lt;main class="wp-block-group alignfull no-margin no-padding is-layout-constrained wp-container-core-group-is-layout-da976f36 wp-block-group-is-layout-constrained" style="padding-top:0px;padding-right:0px;padding-bottom:0px;padding-left:0px"&gt;&lt;a href="https://astroimagery.com/techniques/imaging/"&gt;Astro Imaging&lt;/a&gt;&lt;h1&gt;Astrophotography Target Planner: Discover Hidden Nebulas with My New App&lt;/h1&gt;&lt;p&gt;Posted by&lt;/p&gt;&lt;p&gt;Karl Perera MA&lt;/p&gt;&lt;p&gt;–&lt;/p&gt;December 17, 2025&lt;p&gt;Have you ever gone out on a clear night, fired up &lt;a href="https://stellarium.org/"&gt;Stellarium&lt;/a&gt;, scrolled through endless objects… and still ended up shooting Andromeda for the seventh time?&lt;/p&gt;&lt;p&gt;That was me, over and over. I love M31, but at some point I realised I wasn’t really exploring the sky anymore – I was just defaulting to the same “safe” ten targets. So I ended up building my own astrophotography target planner. The process of finding something new that was visible, well placed, matched my focal length, and wasn’t completely impossible from my Bortle 5 backyard was just too much friction.&lt;/p&gt;&lt;p&gt;So I built a tool to fix that:&lt;/p&gt;&lt;img alt="Astrophotography target planner app" src="https://astroimagery.com/wp-content/uploads/2025/12/Screenshot-2025-11-22-110231.png"/&gt;How my planner app looks on a desktop&lt;p&gt;My Astrophotography Target Planner helped me discover objects like NGC 7822 and the &lt;a href="https://www.constellation-guide.com/question-mark-nebula-ngc-7822/"&gt;Question Mark Nebula&lt;/a&gt; – targets I genuinely didn’t know existed a few months ago. In this article, I’ll break down the main ideas from the video so you can see how it works and whether it might actually help you plan your own sessions.&lt;/p&gt;&lt;p&gt;Watch the full walkthrough of my Astrophotography Target Planner here:&lt;/p&gt;
&lt;h3&gt;What You’ll Learn in This Video&lt;/h3&gt;&lt;p&gt;In the video, I walk through how I’ve gone from “winging it” every clear night to planning genuinely new targets in minutes.&lt;/p&gt;&lt;p&gt;You’ll see:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;How I used to plan targets manually with Stellarium (and why I kept ending up on the same objects).&lt;/li&gt;&lt;li&gt;What the Astro Target app does differently – filtering by location, visibility, &lt;a href="https://astroimagery.com/equipment/how-to-choose-the-best-focal-length-for-deep-sky-objects/"&gt;focal length&lt;/a&gt;, and difficulty.&lt;/li&gt;&lt;li&gt;How “Discovery Mode” surfaces lesser‑known nebulae that are actually well suited to your gear.&lt;/li&gt;&lt;li&gt;Examples of hidden gems like NGC 7822, the Headphone Nebula, and the Question Mark Nebula.&lt;/li&gt;&lt;li&gt;How the app’s timing, RA/Dec, and difficulty notes help you decide if a target is realistic from your sky.&lt;/li&gt;&lt;li&gt;Why this change in workflow helped me go from ~10 repeat targets to over 40 different &lt;a href="https://astroimagery.com/astrophotography/deep-space-astrophotography/brightest-deep-sky-objects/"&gt;deep sky objects&lt;/a&gt; in a year.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Key Takeaways&lt;/h3&gt;&lt;h4&gt;From Manual Hunting to Smart Target Selection&lt;/h4&gt;&lt;p&gt;For years, my target selection routine looked like this:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Open Stellarium.&lt;/li&gt;&lt;li&gt;Scroll through a long list of objects.&lt;/li&gt;&lt;li&gt;Check what’s visible tonight.&lt;/li&gt;&lt;li&gt;Check the moon phase.&lt;/li&gt;&lt;li&gt;Check if it fits my focal length.&lt;/li&gt;&lt;li&gt;Repeat until my patience runs out.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;After 15–20 minutes of that, I’d usually shrug and point the rig back at something familiar. Usually Andromeda. Again.&lt;/p&gt;&lt;p&gt;The problem wasn’t that there’s a lack of interesting objects – it’s the friction. Every step requires you to cross‑check: altitude, timing, framing, difficulty, and sky conditions. None of that is hard, but together it adds up, especially on a work night when you just want to get something in the can.&lt;/p&gt;&lt;p&gt;Astro Target is basically my way of compressing that whole process into a couple of clicks. You put in:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Your sky quality (for me: suburban Bortle 5),&lt;/li&gt;&lt;li&gt;Your focal length (e.g. 650 mm),&lt;/li&gt;&lt;li&gt;Your camera (sensor size is stored automatically),&lt;/li&gt;&lt;li&gt;What types of targets you want (e.g. Nebula only),&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;…and it just returns a short list of objects that are:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Visible from your exact location tonight,&lt;/li&gt;&lt;li&gt;Well framed in your field of view,&lt;/li&gt;&lt;li&gt;Tagged by difficulty (beginner / intermediate / advanced),&lt;/li&gt;&lt;li&gt;And annotated with basic imaging notes.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;How This Astrophotography Target Planner Works&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;Try the Astrophotography Target Planner (beta) here:&lt;/strong&gt;&lt;/p&gt;&lt;a href="https://astrotarget-planner-30718389249.us-west1.run.app/"&gt;AstroTarget Planner&lt;/a&gt;&lt;h4&gt;What “Discovery Mode” Actually Does&lt;/h4&gt;&lt;p&gt;The real game changer for me has been Discovery Mode.&lt;/p&gt;&lt;p&gt;Instead of showing you the usual greatest hits, Discovery Mode prioritises objects that almost nobody photographs – the hidden gems that are still practical for a typical backyard rig.&lt;/p&gt;&lt;p&gt;A few examples that popped up for me:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;NGC 7822&lt;/strong&gt; – a beautiful emission nebula I’d literally never thought about imaging before.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;The Headphone Nebula (Jones–Emberson 1)&lt;/strong&gt; – an object I’d never heard of until the astrophotography target planner for deep sky objects surfaced it.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;The Witch Head Nebula (IC 2118)&lt;/strong&gt; – a large, faint reflection nebula that matches my FOV surprisingly well.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;The Question Mark Nebula&lt;/strong&gt; – another one of those “how did I not know this existed?” moments.&lt;/li&gt;&lt;/ul&gt;&lt;img alt="Results from the astrophotography target planning app" src="https://astroimagery.com/wp-content/uploads/2025/12/Untitled-7-6-1024x576.png"/&gt;A few targets I found on my planning app&lt;p&gt;For each object, this planner for new astrophotography targets gives you:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The optimal imaging time for &lt;em&gt;tonight&lt;/em&gt; (e.g. “Best around 4:00 a.m. when it’s highest in the sky”).&lt;/li&gt;&lt;li&gt;RA/Dec coordinates so you can slew to it easily.&lt;/li&gt;&lt;li&gt;A size estimate and how it frames in your setup.&lt;/li&gt;&lt;li&gt;A difficulty rating and notes like “faint, requires many hours of total exposure from Bortle 5” or “large, challenging to separate from sky glow.”&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;That last bit is important. It’s honest about whether a target is going to be a slog in mediocre skies. You still have to decide if it’s worth the effort, but at least you’re making that decision up front instead of after three wasted hours.&lt;/p&gt;&lt;h4&gt;How This Changed My Imaging Year&lt;/h4&gt;&lt;p&gt;The difference in practice has been big.&lt;/p&gt;&lt;p&gt;When I did things manually, I timed it: about &lt;strong&gt;13 minutes&lt;/strong&gt; just to end up on a target I’d already shot before.&lt;/p&gt;&lt;p&gt;With Discovery Mode, it took about &lt;strong&gt;85 seconds&lt;/strong&gt; to find something entirely new that:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Was visible that night,&lt;/li&gt;&lt;li&gt;Fit my 650 mm FOV,&lt;/li&gt;&lt;li&gt;And wasn’t completely insane to attempt from Bortle 5.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;That’s how I went from essentially cycling through the same 10 comfortable objects… to aiming for &lt;strong&gt;40+ different targets&lt;/strong&gt; in a year.&lt;/p&gt;&lt;p&gt;To put it another way:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;This is my &lt;strong&gt;seventh&lt;/strong&gt; Andromeda image.&lt;/li&gt;&lt;li&gt;This is my &lt;strong&gt;first&lt;/strong&gt; Question Mark Nebula.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Both are valid choices. But one of them feels like genuine exploration again.&lt;/p&gt;&lt;p&gt;And that, more than anything, is what I wanted back – the sense that I’m still discovering things in the night sky, not just perfecting the same photos over and over.&lt;/p&gt;&lt;p&gt;A couple of notes for transparency:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;The target planner app is still &lt;strong&gt;in beta&lt;/strong&gt;. I built it primarily for myself because I was frustrated with the manual workflow.&lt;/li&gt;&lt;li&gt;It currently works &lt;strong&gt;best for northern hemisphere&lt;/strong&gt; targets. I’m actively adding more southern targets.&lt;/li&gt;&lt;li&gt;It’s &lt;strong&gt;free while I’m testing it&lt;/strong&gt;. The link is in the video description (and I’ll add it here too when this goes live).&lt;/li&gt;&lt;li&gt;If you find bugs or have ideas, I genuinely want to hear them – I’m shaping it around what you actually need out there.&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;Gear Used in This Video&lt;/h3&gt;&lt;p&gt;Some of the links I use are affiliate links, which means they help support the channel at no extra cost to you. I only recommend gear I actually use in my own imaging.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Imaging Rig&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Lens: &lt;strong&gt;Samyang 135mm F2.0&lt;/strong&gt; – &lt;a href="https://amzn.to/3KYXUkn"&gt;Check on Amazon&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Mount: &lt;strong&gt;Ioptron CEM26&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;Imaging camera: &lt;strong&gt;ZWO ASI533 MCPRO&lt;/strong&gt;&lt;/li&gt;&lt;li&gt;Guide scope: &lt;strong&gt;SVBony 60mm&lt;/strong&gt; – &lt;a href="https://amzn.to/4j3ESWNhttps://amzn.to/4j3ESWN"&gt;Check same model by Astromania&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Guide camera: &lt;strong&gt;SV305&lt;/strong&gt; – &lt;a href="https://amzn.to/4qlUZS5"&gt;Check on Amazon&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Control &amp;amp; Accessories&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Filter(s) : &lt;strong&gt;Optolong LPro&lt;/strong&gt; – &lt;a href="https://amzn.to/44y5ucq"&gt;Check on Amazon&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Software&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Astro Target app (Discovery Mode) – &lt;a href="https://astrotarget-planner-30718389249.us-west1.run.app/"&gt;AstroTarget Planner&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Stellarium (for comparison / star hopping) – &lt;a href="https://stellarium.org/"&gt;Stellarium Astronomy Software&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Feel free to swap these for your own equivalents – the app doesn’t require this exact setup, it just needs your focal length and sensor size to do its thing.&lt;/p&gt;&lt;h3&gt;What to Watch / Read Next&lt;/h3&gt;&lt;p&gt;If this kind of planning and target discovery is interesting to you, here are some related topics I’d recommend exploring next:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;A beginner‑friendly guide to choosing your &lt;strong&gt;&lt;a href="https://astroimagery.com/astrophotography/deep-space-astrophotography/brightest-deep-sky-objects/"&gt;first five deep sky targets&lt;/a&gt;&lt;/strong&gt; from light‑polluted skies.&lt;/li&gt;&lt;li&gt;A breakdown of &lt;a href="https://astroimagery.com/equipment/telescopes/light-pollution-filter-comparison-for-astrophotography/"&gt;&lt;strong&gt;light pollution vs. narrowband vs. broadband imaging&lt;/strong&gt; &lt;/a&gt;and when each makes sense.&lt;/li&gt;&lt;li&gt;A “real world” comparison of &lt;strong&gt;&lt;a href="https://astroimagery.com/astrophotography/deep-space-astrophotography/nebula-photography-guide/"&gt;different focal lengths for nebulae&lt;/a&gt;&lt;/strong&gt; – what 135 mm, and 650 mm actually look like on the same target.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;I’ll link to the relevant videos and articles once this post is live so you can dive straight in.&lt;/p&gt;&lt;h3&gt;A Small Way to Carry the Night Sky with You&lt;/h3&gt;&lt;p&gt;Most of the time, our astrophotography lives on hard drives, in processing projects, or as big prints that only a few people ever see. That’s great, but I also like having a quieter, everyday reminder of the night sky.&lt;/p&gt;&lt;a href="https://astroimagery.com/astroimagery-shop/"&gt;&lt;img src="https://astroimagery.com/wp-content/uploads/2025/12/Screenshot-2025-12-16-215849-1-152x300.png"/&gt;&lt;/a&gt;&lt;p&gt;That’s why I started turning some of my favourite Astroimagery captures into &lt;strong&gt;phone cases&lt;/strong&gt;. They’re not shouty or over‑branded – just subtle, high‑resolution slices of nebulae and galaxies you can literally carry around in your hand.&lt;/p&gt;&lt;p&gt;If you’d like a small, practical way to keep a bit of the night sky with you during the day, have a look here:&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Browse the Astroimagery phone cases here: &lt;/strong&gt;&lt;a href="https://astroimagery.com/astroimagery-shop/"&gt;Astroimagery Shop&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
  &lt;img src="https://secure.gravatar.com/avatar/b335d8c790c525812a40fe540abf1a93e70e3fdc9cffecabe0b1817804633194?s=48&amp;amp;d=mm&amp;amp;r=g"/&gt;&lt;p&gt;Karl Perera MA&lt;/p&gt;I’m Karl Perera, an experienced astrophotographer, author, and blogger with a master’s degree in teaching. I’m a member of the British Astronomy Association. Welcome!
  &lt;h3&gt;&lt;strong&gt;Follow&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://www.instagram.com/karl_astroimagery/"&gt;karl_astroimagery&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.youtube.com/@Astroimagery"&gt;@Astroimagery&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.linkedin.com/company/astroimagery/"&gt;Astroimagery&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;strong&gt;Recent Posts&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://astroimagery.com/techniques/imaging/astrophotography-target-planner/"&gt;Astrophotography Target Planner: Discover Hidden Nebulas with My New App&lt;/a&gt;December 17, 2025&lt;/li&gt;&lt;li&gt;&lt;a href="https://astroimagery.com/techniques/post-processing/pleiades-two-filters/"&gt;&lt;img alt="Pleiades two filters workflow" src="https://astroimagery.com/wp-content/uploads/2025/12/Untitled-3-22-150x150.png"/&gt;&lt;/a&gt;&lt;a href="https://astroimagery.com/techniques/post-processing/pleiades-two-filters/"&gt;Better Images with Two Filters for the Pleiades (At 135mm)&lt;/a&gt;December 16, 2025&lt;/li&gt;&lt;li&gt;&lt;a href="https://astroimagery.com/techniques/astrophotography-skills-and-techniques/"&gt;&lt;img alt="astrophotography skills and techniques - shooting the Milky Way" src="https://astroimagery.com/wp-content/uploads/2025/11/astrophotography-skills-and-techniques-150x150.jpg"/&gt;&lt;/a&gt;&lt;a href="https://astroimagery.com/techniques/astrophotography-skills-and-techniques/"&gt;Master Astrophotography Skills and Techniques&lt;/a&gt;November 6, 2025&lt;/li&gt;&lt;li&gt;&lt;a href="https://astroimagery.com/astrophotography/deep-space-astrophotography/nebula-photography-guide/"&gt;Nebula Photography the Best Gear, Filters, and Processing&lt;/a&gt;November 1, 2025&lt;/li&gt;&lt;li&gt;&lt;a href="https://astroimagery.com/uncategorized/astrophotography-update/"&gt;Astrophotography Update: New Deep‑Sky Images, Special Offers, and Print Releases | AstroImagery&lt;/a&gt;October 21, 2025&lt;/li&gt;&lt;/ul&gt;&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://astroimagery.com/techniques/imaging/astrophotography-target-planner/</guid>
      <category>Hacker News</category>
      <pubDate>Fri, 19 Dec 2025 19:44:41 +0000</pubDate>
    </item>
    <item>
      <title>What makes you senior</title>
      <link>https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/</link>
      <description>People love to describe senior engineers with a big checklist: architecture, communication, ownership, leadership, etc.</description>
      <content:encoded>&lt;main class="wp-block-group is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;img src="https://terriblesoftware.org/wp-content/uploads/2025/11/cznmcy1wcml2yxrll3jhd3bpegvsx2ltywdlcy93zwjzaxrlx2nvbnrlbnqvbhivzmw0ndc0nji0mtg2mi1pbwfnzs1rewjlahu4ni5qcgc.webp?w=1024"/&gt;
&lt;h2&gt;What Actually Makes You Senior&lt;/h2&gt;

&lt;p&gt;People love to describe senior engineers with a big checklist: architecture, communication, ownership, leadership, etc.&lt;/p&gt;
&lt;p&gt;But if you strip away the title, the salary, and the years of experience, there’s one core skill that separates senior+ engineers from everyone else: &lt;strong&gt;reducing ambiguity&lt;/strong&gt;. Everything else flows from that.&lt;/p&gt;
&lt;p&gt;Here’s what I mean. A mid-level engineer can absolutely crush a well-defined problem. Give them a clear spec, some reasonable constraints, and they’ll deliver solid work. Don’t get me wrong, that &lt;em&gt;is&lt;/em&gt; valuable.&lt;/p&gt;
&lt;p&gt;The moment you hand them something fuzzy, though, like &lt;em&gt;“we need to improve performance”&lt;/em&gt;, &lt;em&gt;“users are complaining about the onboarding flow”&lt;/em&gt; or &lt;em&gt;“we should probably think about scaling”&lt;/em&gt;, that’s when you see the difference. Not because mid-level engineers are bad at their jobs, but because ambiguous problems require something more.&lt;/p&gt;
&lt;p&gt;Senior engineers look at the big, messy, abstract thing and start digging:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;They ask questions nobody else thought to ask.&lt;/li&gt;
&lt;li&gt;They separate what matters from noise.&lt;/li&gt;
&lt;li&gt;They identify what should be done now vs. what to punt.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s one of the reasons why senior engineers are worth their salaries. Not just because they write good code (which they often do!), but because &lt;strong&gt;they derisk projects&lt;/strong&gt;. They turn &lt;em&gt;“I don’t even know what this is”&lt;/em&gt; into &lt;em&gt;“there are two small projects and one thing we should cut.”&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;And you know what’s funny? When senior engineers do this well, it looks easy. Like nothing was even done. The project just… goes smoothly. Fewer surprises, production fires, or emergency meetings. But what actually happened was that someone did a lot of invisible work upfront.&lt;/p&gt;
&lt;p&gt;Just a few questions, as an example, that senior+ engineers ask:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;What problem are we actually trying to solve?&lt;/strong&gt; (Not what solution do we want, but what’s the underlying problem?)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Who’s the user here and what’s painful for them?&lt;/strong&gt; (They try to be specific. “Users” isn’t an answer.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What are we assuming that might be wrong?&lt;/strong&gt; (Every plan has hidden assumptions.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;What happens if we’re wrong and ship this anyway?&lt;/strong&gt; (How bad is the downside?)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In other words, they first make the problem clear. Then, and only then, they go to solve it.&lt;/p&gt;
&lt;p&gt;One frustrating part is that many companies are still terrible at hiring for this. Job descriptions list technologies and years of experience. Interviews focus on LeetCode. None of that really measures your ability to take a vague product requirement and turn it into a shippable plan.&lt;/p&gt;
&lt;p&gt;So we end up with “senior” engineers who can reverse a binary tree on the whiteboard but freeze when the spec is half-baked.&lt;/p&gt;
&lt;p&gt;I’m not saying the other stuff doesn’t matter. Architecture matters. Communication matters. &lt;strong&gt;But those things are way more valuable once you’ve figured out what you’re actually building&lt;/strong&gt;. If you can’t reduce ambiguity, all your other skills are just elegant ways of solving the wrong problem.&lt;/p&gt;
&lt;p&gt;So if you’re wondering whether you’re operating at a senior+ level, here’s one test: What happens when someone hands you something abstract/fuzzy/complex? Do you wait for someone else to clarify it for you? Do you start coding immediately and hope for the best? Or do you spend time up front making it concrete enough that you and your team can actually execute with confidence?&lt;/p&gt;
&lt;p&gt;If it’s the last one, you’re probably already there. If it’s not, the good news is this isn’t talent, but practice: start with the next vague ticket that’s assigned to you.&lt;/p&gt;
&lt;h3&gt;Share this:&lt;/h3&gt;&lt;ul&gt;&lt;li&gt;&lt;a href="https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=facebook"&gt;
Click to share on Facebook (Opens in new window)
Facebook
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=linkedin"&gt;
Click to share on LinkedIn (Opens in new window)
LinkedIn
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=threads"&gt;
Click to share on Threads (Opens in new window)
Threads
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=bluesky"&gt;
Click to share on Bluesky (Opens in new window)
Bluesky
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=mastodon"&gt;
Click to share on Mastodon (Opens in new window)
Mastodon
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/?share=x"&gt;
Click to share on X (Opens in new window)
X
&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;/li&gt;&lt;/ul&gt;Like Loading…&lt;a&gt;&lt;/a&gt;


&lt;a href="https://terriblesoftware.org/category/opinion/"&gt;opinion&lt;/a&gt;
&lt;a href="https://terriblesoftware.org/tag/career/"&gt;career&lt;/a&gt;, &lt;a href="https://terriblesoftware.org/tag/engineering/"&gt;engineering&lt;/a&gt;, &lt;a href="https://terriblesoftware.org/tag/growth/"&gt;growth&lt;/a&gt;, &lt;a href="https://terriblesoftware.org/tag/programming/"&gt;programming&lt;/a&gt;



&lt;h3&gt;Discover more from Terrible Software&lt;/h3&gt;
&lt;p&gt;Subscribe to get the latest posts sent to your email.&lt;/p&gt;
 










&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://terriblesoftware.org/2025/11/25/what-actually-makes-you-senior/</guid>
      <category>Hacker News</category>
      <pubDate>Fri, 19 Dec 2025 16:34:41 +0000</pubDate>
    </item>
    <item>
      <title>Life, Death and Mowing</title>
      <link>https://www.cam.ac.uk/stories/lawnmower-poetry</link>
      <description>Over the last half-century, British poets including Philip Larkin and Andrew Motion have driven a ‘lawnmower poetry microgenre’, using the machine to explore childhood, masculinity, violence, addiction, mortality and much more, new research shows.</description>
      <content:encoded>&lt;article class="Core--rootElement Theme-Story" id="article" role="main"&gt;








&lt;p&gt;&lt;strong&gt;Over the last half-century, British poets including Philip Larkin and Andrew Motion have driven a ‘lawnmower poetry microgenre’, using the machine to explore childhood, masculinity, violence, addiction, mortality and much more, new research shows.&lt;/strong&gt;&lt;/p&gt;







&lt;p&gt;&lt;strong&gt;The study, published in &lt;/strong&gt;&lt;a href="https://onlinelibrary.wiley.com/doi/full/10.1111/criq.12818"&gt;&lt;em&gt;&lt;strong&gt;Critical Quarterly&lt;/strong&gt;&lt;/em&gt;&lt;/a&gt;&lt;strong&gt;, argues that the tradition goes back to the 17&lt;/strong&gt;&lt;strong&gt;th&lt;/strong&gt;&lt;strong&gt;-century poet Andrew Marvell who used mowing – with a scythe – to comment on the violence of the English Civil War.&lt;/strong&gt;&lt;/p&gt;

























&lt;img src="data:image/gif;base64,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"/&gt;







&lt;img/&gt;













&lt;p&gt;“Lawnmower poetry had its highpoint in the late 20th century but now would be a good moment for a revival,” says the study’s author, Francesca Gardner, from Cambridge’s English Faculty and St Catharine’s College.&lt;/p&gt;
&lt;p&gt;“It might seem random to write poetry about mowing but it’s a great vehicle for exploring our relationship with nature and with each other. Andrew Marvell wrote about mowing with scythes after the English Civil War and modern poets continue to use lawnmowers to think about their own ups and downs.&lt;/p&gt;
&lt;p&gt;“In a time of eco-crisis, conflict and societal problems, perhaps another poet will be inspired to write one soon. They might reflect the growing anti-lawn movement or something else entirely.”&lt;/p&gt;
&lt;p&gt;In 1651, Andrew Marvell wrote a poem in which a mower accidentally kills a bird crouched in the grass. In ‘Upon Appleton House’, he wrote that the ‘Edge’ of the scythe was left ‘all bloody from its Breast’. &lt;/p&gt;
&lt;p&gt;Gardner argues that the poem makes us think about ‘the Flesh untimely mow’d’ as a result of powerful undeviating cycles including the seasons and warfare which dominate our lives and determine our actions.&lt;/p&gt;
&lt;p&gt;In 1979, another poet from Hull, Philip Larkin, described killing a hedgehog with his own motorised machine. In &lt;a href="https://www.poetryfoundation.org/poems/48423/the-mower-56d229a740294"&gt;&lt;em&gt;The Mower&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, &lt;/em&gt;Larkin wrote that&lt;em&gt; &lt;/em&gt;his mower had 'stalled, twice' and that he found 'A hedgehog jammed up against the blades, / Killed.’&lt;/p&gt;



&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTIwNCA4MDMiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgd2lkdGg9IjEyMDQiIGhlaWdodD0iODAzIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIj48L3JlY3Q+PC9zdmc+"/&gt;


&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgMTIwNCA4MDMiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgd2lkdGg9IjEyMDQiIGhlaWdodD0iODAzIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIj48L3JlY3Q+PC9zdmc+"/&gt;






&lt;img alt="A baby hedgehog in long grass. Photo by Mike Finn via Flikr" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"/&gt;








&lt;p&gt;Inspired by ‘Upon Appleton House’, Larkin also admired Marvell’s four mower poems, ‘The Mower’s Song’, ‘Damon the Mower’, ‘The Mower Against Gardens’, and ‘The Mower to the Glow-Worms’, describing them as ‘charming and exquisite in the pastoral tradition’, and Gardner points out numerous similarities between the two poets.&lt;/p&gt;
&lt;p&gt;“Larkin had a deep awareness of pastoral and georgic poetry and this makes his poem more unsettling. While he felt terrible about killing the hedgehog, which really happened, his poem is disturbing because it presents an uneasy affinity between the natural and the mechanical.”&lt;/p&gt;
&lt;p&gt;“Every time Larkin cuts the grass, it grows back so he’s forced to use a machine that completes the job efficiently and repeatedly. By mirroring nature’s cruel, relentless forces, mowers like Larkin commit their own acts of cruelty and violence.”&lt;/p&gt;
&lt;p&gt;And yet, Gardner argues, it is often through their violence that the human mowers in these poems discover a capacity to be careful, sensitive and empathetic.&lt;/p&gt;
&lt;p&gt;Larkin’s is one the best-known lawnmower poems from the UK and USA discussed by Gardner but not the only one to tackle traumatic events.&lt;/p&gt;
&lt;p&gt;In 2007, Andrew Motion based a moving elegy for his father on happy memories of him mowing the lawn. By contrast, &lt;a href="https://www.the-tls.co.uk/regular-features/poem-of-the-week/the-lawnmower-michael-laskey-poem-of-the-week-andrew-mcculloch"&gt;Michael Laskey’s 1999 ‘The Lawnmower’&lt;/a&gt; uses the machine to describe fatherly ‘despotism and neglect’, Gardner argues.&lt;/p&gt;
&lt;p&gt;“Mowing a lawn is often viewed as a victory over nature but these poems reflect an increasing sense that this is a pyrrhic or ignoble victory,” Gardner says. “The father in Michael Laskey’s poem is so intent on mowing straight lines that he misses out on the joyful messiness of life with his children.”&lt;/p&gt;
&lt;p&gt;Laskey’s poem ends: ‘We keep back, / do as we’re told, don’t touch. / It must be overgrown now, the grave’.&lt;/p&gt;
&lt;p&gt;Gardner says: “British poets are very interested in the lawn as a nostalgic space so lawnmowers are often associated with childhood memories, especially of fathers working. The lawn is a safe domestic, often suburban, space in which unexpected violence can occur, as when Larkin kills a hedgehog.”&lt;/p&gt;
&lt;p&gt;Gardner’s favourite lawnmower poem is &lt;a href="https://www.poetryfoundation.org/poetrymagazine/poems/118580/i-wish-i-loved-lawnmowers"&gt;Mark Waldron’s 2017 ‘I wish I loved lawnmowers’&lt;/a&gt; which explores alienation, obsession and drug addiction. The speaker tells us that, if he loved lawnmowers, he would take a trip to the British Lawnmower Museum in Southport. But he doesn’t and the poem ends: ‘Now crack cocaine — &lt;em&gt;that&lt;/em&gt; I loved’.&lt;/p&gt;
&lt;p&gt;Most of the poems Gardner studied were written by recognised poets but she also found examples written by lawnmower enthusiasts. In 2013, &lt;em&gt;Grassbox&lt;/em&gt;, the Old Lawnmower Club’s magazine, published Tony Hopwood’s parody of the hymn ‘Morning Has Broken’ which laments: ‘Mower has broken, / Gardener’s in mourning. / Missus has spoken, / Had the last word.’&lt;/p&gt;
&lt;p&gt;“Lawnmowers draw people to poetry as much as poetry draws people to lawnmowers,” Gardner says.&lt;/p&gt;
&lt;p&gt;Gardner points out that to-date most British lawnmower poems have been written by men but has found examples of women poking fun at mower-obsessed men. In 2002, &lt;em&gt;Grassbox&lt;/em&gt; published ‘A Lawnmower Widow’s Lament’, a poem by Peggy Miller, which opens: ‘I once was loved and cherished by a man who was quite handsome / But now I’m second fiddle to a Dennis or Ransomes’.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.caths.cam.ac.uk/harding/profiles/frankie-gardner"&gt;Francesca Gardner, a Harding Distinguished Scholar&lt;/a&gt;, is an expert on early modern pastoral, georgic, and 'nature' writing. She explains that British and American lawnmower poetry is rooted in two forms of ancient nature poetry. &lt;/p&gt;
&lt;p&gt;The pastoral form presents an idyllic form of nature in which shepherds stroll through fields and the land yields things up to them. By contrast, georgic poetry involves people having to work hard and use tools because nature isn’t so generous. &lt;/p&gt;
&lt;p&gt;Gardner points out that Andrew Marvell's ‘Upon Appleton House’ is an unusual mixture of both pastoral and georgic.&lt;/p&gt;
&lt;p&gt;“Poets inspired by Marvell appreciate that clash between idyllic nature and what it takes to maintain the lawn as an ideal space, the georgic conception of work,” Gardner says.&lt;/p&gt;
&lt;p&gt;The final lines of Larkin’s poem were widely quoted during the Covid-19 pandemic: ‘we should be kind / While there is still time.’&lt;/p&gt;
&lt;p&gt;“That remains a useful lesson whether we’re mowing or not,” Gardner says.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://onlinelibrary.wiley.com/doi/full/10.1111/criq.12818"&gt;&lt;em&gt;Francesca Gardner, ‘Lawnmower Poetry and the Poetry of Lawnmowers’,&lt;br/&gt;Critical Quarterly (2025). DOI: 10.1111/criq.12818&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Find out more from Francesca in this short film:&lt;/strong&gt;&lt;/p&gt;











&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDEyNzcuMjU5MzAzMDEyNDA0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4MDAiIGhlaWdodD0iMTI3Ny4yNTkzMDMwMTI0MDQiPjxyZWN0IHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiPjwvcmVjdD48L3N2Zz4="/&gt;


&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDEyNzcuMjU5MzAzMDEyNDA0IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSI4MDAiIGhlaWdodD0iMTI3Ny4yNTkzMDMwMTI0MDQiPjxyZWN0IHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiPjwvcmVjdD48L3N2Zz4="/&gt;







&lt;img/&gt;





&lt;p&gt;Francesca Gardner at St Catharine's College, Cambridge&lt;/p&gt;


&lt;p&gt;Francesca Gardner at St Catharine's College, Cambridge&lt;/p&gt;







&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDk2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iODAwIiBoZWlnaHQ9Ijk2MCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSI+PC9yZWN0Pjwvc3ZnPg=="/&gt;


&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDk2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iODAwIiBoZWlnaHQ9Ijk2MCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSI+PC9yZWN0Pjwvc3ZnPg=="/&gt;









&lt;img/&gt;





&lt;p&gt;Portrait of Andrew Marvell attributed to Godfrey Kneller in the collection of his Marvell's alma mater, Trinity College, Cambridge&lt;/p&gt;


&lt;p&gt;Portrait of Andrew Marvell attributed to Godfrey Kneller in the collection of his Marvell's alma mater, Trinity College, Cambridge&lt;/p&gt;



&lt;a href="https://collections.britishart.yale.edu/catalog/tms:11516"&gt;&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgNzk5Ljk5OTk5OTk5OTk5OTkgODg5LjQ2Nzk2OTU5ODI2MjciIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgd2lkdGg9Ijc5OS45OTk5OTk5OTk5OTk5IiBoZWlnaHQ9Ijg4OS40Njc5Njk1OTgyNjI3Ij48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIj48L3JlY3Q+PC9zdmc+"/&gt;&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDk2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iODAwIiBoZWlnaHQ9Ijk2MCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSI+PC9yZWN0Pjwvc3ZnPg=="/&gt;&lt;img/&gt;&lt;/a&gt;


&lt;p&gt;Francis Place (1647-1728), A mower with a scythe (undated)&lt;/p&gt;


&lt;p&gt;Francis Place (1647-1728), A mower with a scythe (undated)&lt;/p&gt;







&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDk2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iODAwIiBoZWlnaHQ9Ijk2MCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSI+PC9yZWN0Pjwvc3ZnPg=="/&gt;


&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDk2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iODAwIiBoZWlnaHQ9Ijk2MCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSI+PC9yZWN0Pjwvc3ZnPg=="/&gt;









&lt;img/&gt;








&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDk2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iODAwIiBoZWlnaHQ9Ijk2MCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSI+PC9yZWN0Pjwvc3ZnPg=="/&gt;


&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDk2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iODAwIiBoZWlnaHQ9Ijk2MCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSI+PC9yZWN0Pjwvc3ZnPg=="/&gt;









&lt;img/&gt;








&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDk2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iODAwIiBoZWlnaHQ9Ijk2MCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSI+PC9yZWN0Pjwvc3ZnPg=="/&gt;


&lt;img src="data:image/svg+xml;base64,PHN2ZyB2aWV3Qm94PSIwIDAgODAwIDk2MCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB3aWR0aD0iODAwIiBoZWlnaHQ9Ijk2MCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSI+PC9yZWN0Pjwvc3ZnPg=="/&gt;









&lt;img/&gt;





&lt;p&gt;Mowing the meadow at King's College, Cambridge in 2022&lt;/p&gt;


&lt;p&gt;Mowing the meadow at King's College, Cambridge in 2022&lt;/p&gt;




























&lt;p&gt;&lt;strong&gt;Published 17th May 2025&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The text in this work is licensed under a &lt;/strong&gt;&lt;a href="https://creativecommons.org/licenses/by-nc-sa/4.0/"&gt;&lt;strong&gt;Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;










&lt;p&gt;&lt;strong&gt;Image credits&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;University of Cambridge&lt;/strong&gt;: Title image; Francesca Gardner&lt;br/&gt;&lt;strong&gt;Sarah Laval via Flikr&lt;/strong&gt;: mower in motion (banner)&lt;br/&gt;&lt;strong&gt;Trinity College, Cambridge&lt;/strong&gt;: Portrait of Andrew Marvell&lt;br/&gt;&lt;strong&gt;Yale Center for British Art, Paul Mellon Collection&lt;/strong&gt;: Mower with a scythe&lt;br/&gt;&lt;strong&gt;Mike Finn via Flikr&lt;/strong&gt;: Hedgehog&lt;br/&gt;&lt;strong&gt;Dave's Archive via Flikr&lt;/strong&gt;: two archive photographs of men mowing&lt;br/&gt;&lt;strong&gt;Lloyd Mann&lt;/strong&gt;: Meadow mowing at King's College, Cambridge&lt;br/&gt;&lt;/p&gt;














&lt;img/&gt;





&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://www.cam.ac.uk/stories/lawnmower-poetry</guid>
      <category>Hacker News</category>
      <pubDate>Fri, 19 Dec 2025 09:58:23 +0000</pubDate>
    </item>
    <item>
      <title>Research team digitizes more than 100 years of Canadian infectious disease data</title>
      <link>https://news.mcmaster.ca/mcmaster-research-team-digitizes-more-than-100-years-of-canadian-infectious-disease-data/</link>
      <description>The new, publicly accessible database can be used to study the patterns of disease incidence and strengthen public health preparedness.</description>
      <content:encoded>&lt;main class="news-post" id="site-content"&gt;
&lt;!-- News Source  --&gt;





&lt;!-- Categories Section --&gt;

&lt;a href="https://news.mcmaster.ca/research-innovation/health-medicine/"&gt;Health &amp;amp; Medicine&lt;/a&gt; 
&lt;!-- Title --&gt;


&lt;h1&gt;McMaster research team digitizes more than 100 years of Canadian infectious disease data&lt;/h1&gt; 

&lt;!-- Tagline --&gt;

&lt;p&gt;The new, publicly accessible database can be used to study the patterns of disease incidence and strengthen public health preparedness. &lt;/p&gt;

&lt;!-- Author --&gt;

&lt;p&gt;
By Blake Dillon
&lt;!-- Date --&gt;
 
									December 17, 2025								
&lt;/p&gt;

&lt;!-- Share Buttons --&gt;


&lt;a href="https://twitter.com/intent/tweet?url=https://news.mcmaster.ca/mcmaster-research-team-digitizes-more-than-100-years-of-canadian-infectious-disease-data/&amp;amp;text=McMaster research team digitizes more than 100 years of Canadian infectious disease data"&gt;Twitter&lt;/a&gt;
&lt;a href="https://www.facebook.com/sharer.php?u=https://news.mcmaster.ca/mcmaster-research-team-digitizes-more-than-100-years-of-canadian-infectious-disease-data/"&gt;Facebook&lt;/a&gt;
&lt;a href="https://www.linkedin.com/sharing/share-offsite/?url=https://news.mcmaster.ca/mcmaster-research-team-digitizes-more-than-100-years-of-canadian-infectious-disease-data/"&gt;LinkedIn&lt;/a&gt;






&lt;!-- Featured Image --&gt;



&lt;img alt="David Earn stands in front of a bookcase." src="https://news.mcmaster.ca/app/uploads/2025/12/cb-1800-x-1066-15.png"/&gt; 

							David Earn, a member of the Michael G. DeGroote Institute for Infectious Disease Research, hopes that the new dataset — and his team’s herculean efforts to assemble it — will help spur important changes to Canada’s current infectious disease reporting standards. 						



&lt;!-- Horizontal Rule --&gt;













&lt;!-- Experts --&gt;

&lt;h3&gt;
        Expert Featured In This Story
    &lt;/h3&gt;







&lt;img alt="David Earn" src="https://news.mcmaster.ca/app/themes/news/images/icon-person.svg"/&gt;



&lt;h5&gt;David Earn&lt;/h5&gt;
&lt;p&gt;Professor&lt;/p&gt;

&lt;a href="https://experts.mcmaster.ca/people/earn"&gt;See Profile&lt;/a&gt;









&lt;p&gt;Twenty-five years ago, in a neglected storage area at the Ontario Ministry of Health, David Earn happened upon epidemiological gold: two boxes of hand-written documents accounting for 50 years of weekly infectious disease incidence reports, spanning 1939-1989.  &lt;/p&gt;
&lt;p&gt;The buried treasure was exactly the sort of thing that the McMaster University professor hoped to unearth during his visit — historical public health data that could help contextualize current and future infectious disease outbreaks.  &lt;/p&gt;
&lt;p&gt;“Initially, the Ministry said that they couldn’t provide the data — that they didn’t have the time to search through their archives for us,” recalls Earn, a professor in McMaster’s Department of Mathematics and Statistics. “So, I offered to come to Toronto and look through their files myself, if they would let me. I basically begged, insisting on the value of the historical records, and I wouldn’t let it go. Eventually, I guess I became too much of a nuisance and they relented.”   &lt;/p&gt;
&lt;p&gt;&lt;img alt="David Earn works at a computer, with a stack files beside him, one clearly labeled '1903 to 1939 monthly communicable disease incidence, Ontario.'" src="https://news.mcmaster.ca/app/uploads/2025/12/David-Earn-2025-003-scaled.png"/&gt;&lt;/p&gt;
&lt;p&gt;The documents uncovered that day catalyzed a massive retrospective research project that has culminated in a complete, province-by-province inventory of Canadian infectious disease records.    &lt;/p&gt;
&lt;p&gt;The result, published today in &lt;a href="https://journals.plos.org/globalpublichealth/article?id=10.1371/journal.pgph.0005550"&gt;PLOS Global Public Health&lt;/a&gt;, is what Earn describes as a “genuinely beautiful dataset” that strings together more than 100 years of historical epidemiological information.  &lt;/p&gt;
&lt;p&gt;Altogether, the &lt;a href="https://canmod.net/digitization/"&gt;new database&lt;/a&gt; — the Canadian Notifiable Disease Incidence Dataset, or “CANDID” — contains more than a million infectious disease incidence counts that date back as far as 1903.   &lt;/p&gt;
&lt;p&gt;The dataset, which is now publicly accessible, captures weekly, monthly, and quarterly case numbers for diseases like poliomyelitis, hepatitis, tuberculosis, whooping cough, influenza, rubella, mumps, measles, and many others, and tracks their spread in each province and territory across time.   &lt;/p&gt;
&lt;p&gt;&lt;img alt="A collage of historical disease records. " src="https://news.mcmaster.ca/app/uploads/2025/12/Infectious-disease-history.png"/&gt;&lt;/p&gt;
&lt;p&gt;“Data like these reveal the speed and shape of outbreaks and recurrent epidemics of the past, and allow us to test models that predict patterns of spread,” Earn says. “This new dataset can be leveraged to understand the ecology and evolution of infectious disease across Canada’s history, and to help us prepare for emerging and re-emerging diseases in the future.”  &lt;/p&gt;
&lt;p&gt;In fact, Earn’s team has already used the database to better understand the spatial and temporal incidence of polio and whooping cough across several decades of Canadian history.  &lt;/p&gt;
&lt;p&gt;While the new study was 25 years in the making, Earn says it really accelerated in 2021, when a large pandemic-related &lt;a href="https://www.nserc-crsng.gc.ca/index_eng.asp"&gt;NSERC&lt;/a&gt; network grant allowed him to recruit Steven Walker, a former McMaster postdoctoral fellow, to his team.  &lt;/p&gt;
&lt;p&gt;Walker, who re-joined McMaster as a data scientist in Earn’s group, was tasked with curating, cleaning, and harmonizing the troves of data that Earn and his associates had previously unearthed from libraries, public health offices, and provincial and federal agencies based all across Canada.  &lt;/p&gt;
&lt;p&gt;“We would start with scans of handwritten or typewritten documents and manually transcribe them into Microsoft Excel to ensure that we had functional replicas of every original document,” Walker explains. “But the replicas aren’t conducive to data analysis, due to inconsistent formatting, so we’ve also been developing flexible data structures that are more convenient for analysis and discovery.” &lt;/p&gt;
&lt;p&gt;Earn, a member of the &lt;a href="https://iidr.mcmaster.ca/"&gt;Michael G. DeGroote Institute for Infectious Disease Research&lt;/a&gt;, hopes that the new dataset — and the herculean efforts to assemble it — will help spur important changes to Canada’s current infectious disease reporting standards, noting that the public release of infectious disease data is arguably worse now than it was at any point during the 20th century, including the pre-digital era.   &lt;/p&gt;
&lt;p&gt;&lt;img alt="David Earn stands at a table in a living room, looking over multiple papers and files spread on the table. " src="https://news.mcmaster.ca/app/uploads/2025/12/David-Earn-2025-004-scaled.png"/&gt;&lt;/p&gt;
&lt;p&gt;In fact, today, the Public Health Agency of Canada issues only annual, nationally aggregated incidence counts — not weekly or regional information — which limits opportunity for important studies into epidemic patterns, seasonal effects, and geographic variation.  &lt;/p&gt;
&lt;p&gt;Earn says that the reduced resolution in today’s data is due in large part to patient privacy protection — a critically important consideration, but one that Earn believes can be maintained even with increased sharing of useful data.  &lt;/p&gt;
&lt;p&gt;“It is extremely important to protect patient privacy, and our federal, provincial, and territorial agencies have developed protocols for data release that aim to ensure privacy is protected,” he says. “But there is no individual-level information in aggregate counts of infectious disease cases, and no identifying information can be extracted from these data. I think that current data release protocols should be thoughtfully and carefully reconsidered, so that they still prioritize privacy, but also allow for the release of more useful information, which could help us to prepare for future outbreaks — to the benefit of all Canadians.” &lt;/p&gt;
&lt;p&gt;In the meantime, Earn’s group encourages epidemiologists in Canada and elsewhere to use CANDID to study the patterns of disease incidence, to learn from historical surveillance efforts, and to strengthen public health preparedness. &lt;/p&gt;
&lt;!-- CONTENT ELEMENTS BEGIN --&gt;


&lt;!-- Related News Section --&gt;


&lt;h2&gt;Related News&lt;/h2&gt;








&lt;img alt="Brightly coloured spray bottles of cleaning products in front of a tiled wall." src="https://news.mcmaster.ca/app/uploads/2025/12/cleaners-conversation.png"/&gt; 


&lt;a href="https://news.mcmaster.ca/research-innovation/health-medicine/"&gt; &lt;p&gt;Health &amp;amp; Medicine&lt;/p&gt;
&lt;/a&gt; 
&lt;h3&gt;
&lt;a href="https://news.mcmaster.ca/?post_type=post&amp;amp;p=29158"&gt;
                  Analysis: Everyday chemicals, global consequences: How disinfectants contribute to antimicrobial resistance                &lt;/a&gt;
&lt;/h3&gt;

                  Antimicrobial resistance is often seen as a clinical problem caused by antibiotic misuse, but it begins even earlier, in households, wastewater, rivers, lakes and soils, writes Milena Esser.                 


&lt;p&gt;&lt;strong&gt;December 22, 2025&lt;/strong&gt;&lt;/p&gt;















&lt;img alt="An overhead shot of ancient walls and ruins, surrounded by grass." src="https://news.mcmaster.ca/app/uploads/2025/12/Hadrians-Wall.png"/&gt; 


&lt;a href="https://news.mcmaster.ca/research-innovation/health-medicine/"&gt; &lt;p&gt;Health &amp;amp; Medicine&lt;/p&gt;
&lt;/a&gt; 
&lt;h3&gt;
&lt;a href="https://news.mcmaster.ca/?post_type=post&amp;amp;p=29130"&gt;
                  New analysis reveals hidden health risks in ancient Roman fort                &lt;/a&gt;
&lt;/h3&gt;

                  Examining sediment from Vindolanda, near Hadrian's Wall, the study offers fresh insights into health challenges faced on the Roman frontier.                 


&lt;p&gt;&lt;strong&gt;December 19, 2025&lt;/strong&gt;&lt;/p&gt;















&lt;img alt="In a lab, three people in lab coats look at a red container that the woman in the middle is holding up." src="https://news.mcmaster.ca/app/uploads/2025/12/Dorey.png"/&gt; 


&lt;a href="https://news.mcmaster.ca/research-innovation/health-medicine/"&gt; &lt;p&gt;Health &amp;amp; Medicine&lt;/p&gt;
&lt;/a&gt; 
&lt;h3&gt;
&lt;a href="https://news.mcmaster.ca/?post_type=post&amp;amp;p=28907"&gt;
                  Simple tools, big breakthrough: New tissue engineering technique speeds healing                &lt;/a&gt;
&lt;/h3&gt;

                  McMaster researchers have developed a rapid, low-cost method for creating cell sheets that could transform regenerative medicine.                 


&lt;p&gt;&lt;strong&gt;December 10, 2025&lt;/strong&gt;&lt;/p&gt;







 







&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://news.mcmaster.ca/mcmaster-research-team-digitizes-more-than-100-years-of-canadian-infectious-disease-data/</guid>
      <category>Hacker News</category>
      <pubDate>Fri, 19 Dec 2025 06:24:52 +0000</pubDate>
    </item>
    <item>
      <title>A faster path to container images in Bazel</title>
      <link>https://www.tweag.io/blog/2025-12-18-rules_img/</link>
      <description>18 December 2025 — by Malte Poll</description>
      <content:encoded>&lt;main class="css-1vb6nck"&gt;&lt;h2&gt;Announcing rules_img: a faster path to container images in Bazel&lt;/h2&gt;&lt;p&gt;18 December 2025&lt;!-- --&gt; — by&lt;!-- --&gt; Malte Poll&lt;/p&gt;&lt;a href="https://www.tweag.io/tag/tools"&gt;tools&lt;/a&gt;&lt;a href="https://www.tweag.io/tag/build-systems"&gt;build-systems&lt;/a&gt;&lt;a href="https://www.tweag.io/tag/bazel"&gt;bazel&lt;/a&gt;&lt;p&gt;Say you have a Bazel project that builds a web application, and you want to deploy it as a Docker container. The app is already built by Bazel, so you just need to package it into an image with the right base layers and configuration. This should be quick. Bazel is good at this sort of thing. But when you add container image building to your setup, something surprising happens: your builds start downloading gigabytes of base image data, your CI slows down, and pushing images feels slow. This is the story of why that happens and how &lt;a href="https://github.com/bazel-contrib/rules_img"&gt;&lt;code&gt;rules_img&lt;/code&gt;&lt;/a&gt; fixes it.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Prefer watching to reading? &lt;a href="https://www.youtube.com/watch?v=biYXmAv4Ppk"&gt;The content of this post is also available in video form&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;&lt;a href="#the-components"&gt;&lt;/a&gt;The components&lt;/h2&gt;
&lt;p&gt;Before we dive in, we need to establish where data lives and where it moves. There are three main players:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;The registry&lt;/strong&gt; (like Docker Hub or gcr.io): A remote server that stores container images. You download base images from here and push your built images back to it.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Your local machine&lt;/strong&gt;: Where you run &lt;code&gt;bazel build&lt;/code&gt; or &lt;code&gt;bazel run&lt;/code&gt;. This is your laptop or workstation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Remote execution and remote cache&lt;/strong&gt;: A remote caching backend (like Aspect Workflows, BuildBuddy, EngFlow, or Google’s RBE) that runs Bazel actions on remote machines and caches the results. Optional, but common in CI and larger projects.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The core tension is simple: to build a container image that extends a base image, you need information about that base. The question is how much information, and where does it need to be?&lt;/p&gt;
&lt;h2&gt;&lt;a href="#the-scenario"&gt;&lt;/a&gt;The scenario&lt;/h2&gt;
&lt;p&gt;Here’s what building a container image looks like with &lt;code&gt;rules_oci&lt;/code&gt;, the current recommended approach. I’ll show the data flow explicitly:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Pull a base image
# → Downloads manifest + config + all layer blobs from registry to local machine
pull(
    name = "ubuntu",
    image = "index.docker.io/library/ubuntu:24.04",
    digest = "sha256:1e622c5...",
)

# Build your image
# → Creates a directory containing all blobs (base layers + your layer)
# → With remote execution: all blobs are inputs and outputs of this actions
oci_image(
    name = "app_image",
    base = "@ubuntu",  # References the complete local directory
    tars = [":app_layer.tar"],
    entrypoint = ["/app/bin/server"],
)

# Push to registry
# → Downloads all image blobs from remote cache to local machine
# → Uploads missing blobs from local machine to registry
oci_push(
    name = "push",
    image = ":app_image",
    repository = "gcr.io/my-project/app",
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Data flow summary:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Registry → Local machine: full base image (hundreds of MB)&lt;/li&gt;
&lt;li&gt;Local machine → Remote cache: full base image (anything that’s not already cached)&lt;/li&gt;
&lt;li&gt;Remote cache → Remote Executor (creating an image): full image (hundreds of MB)&lt;/li&gt;
&lt;li&gt;Remote cache → Local machine: full image (hundreds of MB)&lt;/li&gt;
&lt;li&gt;Local machine → Registry: missing layers&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here’s the same thing with &lt;code&gt;rules_img&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Pull a base image
# → Downloads only manifest + config JSON from registry to local machine (~10 KB)
# → Layer blobs stay in the registry
pull(
    name = "ubuntu",
    registry = "index.docker.io",
    repository = "library/ubuntu",
    tag = "24.04",
    digest = "sha256:1e622c5...",
)

# Build a layer
# → Writes layer tar + metadata to Bazel's content-addressable storage
# → With remote execution: layer blob stays in remote cache
image_layer(
    name = "app_layer",
    srcs = {
        "/app/bin/server": "//cmd/server",  # Bazel-built binary
        "/app/config": "//configs:prod",
    },
)

# Assemble the image
# → Writes manifest JSON referencing base layers + your layers (by digest)
# → Only metadata is read and written
image_manifest(
    name = "app",
    base = "@ubuntu",  # References only metadata, not blobs
    layers = [":app_layer"],  # References only metadata, not blobs
    entrypoint = ["/app/bin/server"],
)

# Push (at bazel run time, not build time)
# → Checks registry: which blobs are already present?
# → Streams only missing blobs: remote cache → local machine → registry
# → If layers are already in registry: nothing to transfer
image_push(
    name = "push_app",
    image = ":app",
    registry = "ghcr.io",
    repository = "my-project/app",
    tag = "latest",
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Data flow summary:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Registry → Local machine: only manifest + config (~10 KB)&lt;/li&gt;
&lt;li&gt;Local machine → Remote cache: only metadata on base images&lt;/li&gt;
&lt;li&gt;Remote cache → Local machine → Registry: only missing blobs (often just your new layers)&lt;/li&gt;
&lt;li&gt;Base layers (almost) never move through local machine or remote executors&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;&lt;a href="#a-twominute-primer-on-images"&gt;&lt;/a&gt;A two‑minute primer on images&lt;/h2&gt;
&lt;p&gt;An OCI image is a bundle of metadata and bytes. The bytes live in &lt;em&gt;layers&lt;/em&gt;, which are compressed tar archives that encode file additions and deletions. The metadata lives in three JSON objects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;em&gt;config&lt;/em&gt;: what to run, environment variables, user, working directory, and the list of uncompressed layer digests (also called diff IDs)&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;manifest&lt;/em&gt;: pointers to one config and many layer blobs, identified by digest, size, and media type&lt;/li&gt;
&lt;li&gt;The &lt;em&gt;index&lt;/em&gt;: for multi‑architecture images, a list of per‑platform manifests&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Tags in a registry point at a manifest digest. The digests are content-addressed, so the same bytes always mean the same name everywhere.&lt;/p&gt;
&lt;p&gt;
&lt;a href="https://www.tweag.io/static/2c013ad4d476d25db7c0322b0665dd58/2bef9/layers_in_a_trenchcoat.png"&gt;

&lt;img alt="A container image is just some tar files in a trenchcoat" src="https://www.tweag.io/static/2c013ad4d476d25db7c0322b0665dd58/fcda8/layers_in_a_trenchcoat.png"/&gt;
&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How builds usually work.&lt;/strong&gt; &lt;code&gt;docker build&lt;/code&gt; executes a Dockerfile &lt;em&gt;inside&lt;/em&gt; a base image. Each step like &lt;code&gt;RUN&lt;/code&gt;, &lt;code&gt;COPY&lt;/code&gt;, or &lt;code&gt;ADD&lt;/code&gt; runs against a snapshot of the previous root file system and produces a new layer. The final image is the base’s layers plus the layers created by those steps. This is convenient, but it assumes you have the base image bytes locally while you build.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;How Bazel thinks about it.&lt;/strong&gt; Bazel does not need to &lt;em&gt;run inside&lt;/em&gt; the base at all. It builds your program artifacts the same way it always does&lt;a href="#fn-1"&gt;1&lt;/a&gt;, then assembles an image by writing a config and a manifest that reference the base image &lt;em&gt;by digest&lt;/em&gt; alongside the new layers you produced. Bazel needs the base’s identity to compose a correct manifest and, later, to upload or load the image. But it doesn’t have to materialize the base layers during the build itself&lt;a href="#fn-2"&gt;2&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why this matters for performance.&lt;/strong&gt; Assembling an image is easy. It’s mostly JSON with a few checksums. The hard part is &lt;em&gt;data locality&lt;/em&gt;: getting the right bytes to the right place at the right time. Do the executors have to download layers just to write a small manifest? Does a pusher really need to pull all blobs to a workstation before uploading them again? Does a local daemon have to ingest layers it already owns? &lt;code&gt;rules_img&lt;/code&gt; answers those questions by moving metadata first and moving bytes only at the edges.&lt;/p&gt;
&lt;h2&gt;&lt;a href="#the-status-quo-rules_oci"&gt;&lt;/a&gt;The status quo: rules_oci&lt;/h2&gt;
&lt;p&gt;The first major ruleset for building container images in Bazel was &lt;code&gt;rules_docker&lt;/code&gt;, which integrated with every language ecosystem: Python, Node.js, Java, Scala, Groovy, C++, Go, Rust, and D. This approach proved extremely hard to maintain. Any change in a language ruleset could ripple into &lt;code&gt;rules_docker&lt;/code&gt;. Today it is mostly unmaintained and lacks official bzlmod support.&lt;/p&gt;
&lt;p&gt;The current recommendation is &lt;a href="https://github.com/bazel-contrib/rules_oci"&gt;&lt;code&gt;rules_oci&lt;/code&gt;&lt;/a&gt;, which takes the opposite approach: use only off‑the‑shelf tools, maintain a strict complexity budget, and delegate layer creation to language rulesets or end users. This design results in a maintainable project with a narrow scope that’s easy to understand.&lt;/p&gt;

&lt;p&gt;&lt;img alt="Data transfers performed by rules_oci when pulling a base image" src="https://www.tweag.io/ba15c362074a6f3d56c09848d334ea3b/rules_oci_repo_rule.svg"/&gt;&lt;/p&gt;
Data transfers performed by rules_oci when pulling a base image

&lt;p&gt;Under the hood, &lt;code&gt;rules_oci&lt;/code&gt; represents images as complete &lt;a href="https://specs.opencontainers.org/image-spec/image-layout/"&gt;OCI layouts&lt;/a&gt; on disk. When you pull a base image, the repository rule downloads the full image—all blobs, all layers—into a tree artifact. When you build an image with &lt;code&gt;oci_image&lt;/code&gt; or &lt;code&gt;oci_image_index&lt;/code&gt;, the result is again a directory containing every blob of that image. Layers are always tar files, with no separate metadata to describe them, and the ruleset does not use Bazel providers to pass structured information between targets. This approach is simple and works well for local builds, but as we scaled to Remote Execution, we encountered bottlenecks that this design did not address.&lt;/p&gt;
&lt;h2&gt;&lt;a href="#from-bottlenecks-to-breakthroughs-how-rules_img-works"&gt;&lt;/a&gt;From bottlenecks to breakthroughs: how rules_img works&lt;/h2&gt;
&lt;p&gt;I started with a simple goal: build container images in Bazel and let Remote Execution carry the weight. I used &lt;code&gt;rules_oci&lt;/code&gt; in my experiments, the recommended way of building container images in Bazel today&lt;a href="#fn-3"&gt;3&lt;/a&gt;. I was surprised by the inefficiencies I saw. Repository rules that pulled base images ran again and again in CI, even when nothing had changed&lt;a href="#fn-4"&gt;4&lt;/a&gt;. My laptop shoveled data uphill to the remote cache before any real work could begin. Actions that only wrote a few lines of JSON insisted on dragging entire layer blobs along for the ride. When the build finally finished on RBE, Bazel downloaded every layer into a push tool’s runfiles, only to upload them to a registry a moment later. Loading images into Docker added insult to injury by ignoring layers that were already present. None of that felt like Bazel, so I ran experiments until a pattern emerged.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The breakthrough: treat images as metadata first.&lt;/strong&gt; The key was to see the whole build as a metadata pipeline and to move bytes only at the edges. Keep base images shallow until you truly need a blob. Assemble manifests from digests and sizes, not gigabytes. Push and load by streaming from content‑addressable storage straight to the destination, and skip anything that already exists there. Once that clicked, the rest of the design fell into place.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Pulling, without the pain.&lt;/strong&gt; Base pulls were the first time sink. In &lt;code&gt;rules_img&lt;/code&gt;, the repository rule fetches only the manifest and config JSON files at build time. Just enough metadata to know what layers exist and their digests. The actual layer blobs are never downloaded during the build&lt;a href="#fn-5"&gt;5&lt;/a&gt;. They wait until the run phase when you &lt;code&gt;bazel run&lt;/code&gt; a push or load target. CI becomes predictable, and Remote Execution doesn’t spend its morning downloading CUDA for the fourth time this week. Less data moves during builds, and the cache behaves like a cache.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Stop hauling bytes uphill.&lt;/strong&gt; The next fix addressed the torrent of developer-to-remote uploads. We generate metadata-only providers wherever possible. The heavy blobs live in content-addressable storage (CAS) and stream later to whoever needs them, whether that’s a registry or a local daemon. Your workstation stops being a relay, cold starts are faster, and incremental builds are a breeze.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Let manifests stay tiny.&lt;/strong&gt; Manifest assembly had been oddly heavyweight. We reshaped the graph so each layer is built in a single action that computes both the blob and the metadata that describes it&lt;a href="#fn-6"&gt;6&lt;/a&gt;. The layer blob stays in Bazel’s CAS, while only a small JSON descriptor (digest, size, media type) flows through the build graph. Downstream actions consume only this metadata during the build phase, so they schedule quickly, cache well, and avoid pulling gigabytes across executors. The manifests remain correct, and the path to them is light. The actual blob bytes only move later during &lt;code&gt;bazel run&lt;/code&gt; when you push or load.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Push without the round trip.&lt;/strong&gt; Pushing used to mean downloading all layers to a local tool and then sending them back up again. With &lt;code&gt;rules_img&lt;/code&gt;, we defer all blob transfers to the run phase (&lt;code&gt;bazel run //:push&lt;/code&gt;). The build phase only produces a lightweight push specification: a JSON file listing what needs pushing. When you run the pusher, it first asks the registry what blobs it already has, then streams only the missing ones directly from CAS. In environments where your registry speaks the same CAS protocol, the push is close to zero‑copy. For very large monorepos, you can even emit pushes as a side effect of Build Event Service uploads. The principle is simple. Build time produces metadata, run time moves bytes, and nothing passes through your workstation unnecessarily. See the &lt;a href="https://github.com/bazel-contrib/rules_img/blob/main/docs/push-strategies.md"&gt;push strategies documentation&lt;/a&gt; for other configurations including direct CAS-to-registry transfers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Loading should be incremental.&lt;/strong&gt; &lt;code&gt;docker load&lt;/code&gt; treats every import like a blank slate. When containerd is available, &lt;code&gt;rules_img&lt;/code&gt; talks to its content store and streams only what is missing&lt;a href="#fn-7"&gt;7&lt;/a&gt;. It can also load a single platform from a multi‑platform image, which keeps feedback loops tight&lt;a href="#fn-8"&gt;8&lt;/a&gt;. If containerd isn’t available, we fall back to &lt;code&gt;docker load&lt;/code&gt; and tell you what you’re giving up.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Extra touches that add up.&lt;/strong&gt; Performance rarely comes from one trick alone. We use hardlink-based deduplication inside layers so identical files don’t bloat your tars. We support &lt;a href="https://github.com/containerd/stargz-snapshotter/blob/main/docs/estargz.md"&gt;eStargz&lt;/a&gt; to make layers seekable and quick to start with the stargz snapshotter.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Quick start.&lt;/strong&gt; If you want to try it, here is a minimal setup:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# MODULE.bazel
bazel_dep(name = "rules_img", version = "&amp;lt;version&amp;gt;")

pull = use_repo_rule("@rules_img//img:pull.bzl", "pull")

# Pulls manifest+config only (no layer blobs yet)
pull(
    name = "ubuntu",
    registry = "index.docker.io",
    repository = "library/ubuntu",
    tag = "24.04",
    digest = "sha256:1e622c5f073b4f6bfad6632f2616c7f59ef256e96fe78bf6a595d1dc4376ac02",
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# BUILD.bazel
load("@rules_img//img:layer.bzl", "image_layer")
load("@rules_img//img:image.bzl", "image_manifest")

image_layer(
    name = "app_layer",
    srcs = {
        "/app/bin/server": "//cmd/server",
        "/app/config": "//configs:prod",
    },
    compress = "zstd",
)

image_manifest(
    name = "app_image",
    base = "@ubuntu",
    layers = [":app_layer"],
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Optional &lt;code&gt;.bazelrc&lt;/code&gt; speed dials if you like the metadata‑first defaults:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;common --@rules_img//img/settings:compress=zstd
common --@rules_img//img/settings:estargz=enabled
common --@rules_img//img/settings:push_strategy=lazy
# Or: cas_registry / bes (see docs for setup)&lt;/code&gt;&lt;/pre&gt;
&lt;h2&gt;&lt;a href="#conclusion-container-images-that-feel-native-to-bazel"&gt;&lt;/a&gt;Conclusion: container images that feel native to Bazel&lt;/h2&gt;
&lt;p&gt;The performance gains are real. Pulling large base images on fresh machines takes seconds instead of minutes. Loading into Docker takes milliseconds for incremental updates instead of reloading the full image, which could waste 1–5 minutes in the workflows we examined. Manifest assembly actions run dramatically faster, especially on RBE systems that fetch inputs eagerly&lt;a href="#fn-9"&gt;9&lt;/a&gt;. Building push targets no longer destroys the benefits of Build without the Bytes. Where other rulesets might download gigabytes to your machine, &lt;code&gt;rules_img&lt;/code&gt; downloads only a few kilobytes of metadata, saving many gigabytes in transfers and minutes per push. A comprehensive benchmark would warrant its own blog post given the wide matrix of possible configurations, RBE backends, image sizes, and network conditions.&lt;/p&gt;
&lt;p&gt;Our aim with &lt;code&gt;rules_img&lt;/code&gt; is straightforward: make Bazel feel native for container images, with no unnecessary bytes and no unnecessary waits. By treating images as metadata with on-demand bytes, we get faster CI, quieter laptops, and a build graph that scales without drama. Try it, tell us what flies, and tell us what still hurts. There’s more to tune, and we intend to keep tuning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Get started with rules_img: &lt;a href="https://github.com/bazel-contrib/rules_img"&gt;github.com/bazel-contrib/rules_img&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;Bazel actions only access explicitly declared inputs within the execroot, whilst &lt;code&gt;docker build&lt;/code&gt; mounts all base image layers into the build environment. This means Bazel builds layers independently of base layers, though specific toolchains (like C++) can use workarounds such as &lt;code&gt;--sysroot&lt;/code&gt; to simulate filesystem mounting.&lt;a href="#fnref-1"&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Building without mounting base layers risks creating binaries incompatible with the target image, as there’s no way to execute code atop existing layers during the build. The &lt;a href="https://github.com/GoogleContainerTools/container-structure-test"&gt;container-structure-test&lt;/a&gt; tool addresses this by enabling tests on the final image, including running commands in a Docker daemon with assertions.&lt;a href="#fnref-2"&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rules_oci&lt;/code&gt; is a good ruleset for building container images in Bazel, and I am a happy user most of the time. However, I quickly noticed that it is only optimized for local execution. I want to stress that most of the issues I’m describing here only matter for the remote execution case.&lt;a href="#fnref-3"&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Repository rules downloading image blobs are inefficient in stateless CI environments where caches aren’t preserved between runs. Whilst CI can be configured to preserve these directories, &lt;code&gt;rules_img&lt;/code&gt; avoids the problem entirely by fetching only metadata.&lt;a href="#fnref-4"&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;This is configurable. If you really need access to base image layers at build time (for instance, to run a container structure test), you can set the &lt;code&gt;layer_handling&lt;/code&gt; attribute accordingly (&lt;a href="https://github.com/bazel-contrib/rules_img/blob/main/docs/pull.md#pull"&gt;docs&lt;/a&gt;).&lt;a href="#fnref-5"&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;In &lt;code&gt;rules_oci&lt;/code&gt;, manifest assembly receives entire layer tar files as inputs, transferring multi-gigabyte blobs with remote execution. &lt;code&gt;rules_img&lt;/code&gt; instead generates small metadata files (containing digests and diff IDs) when writing layers, passing only this fixed-size metadata to downstream actions. Layer contents enter the build graph once, remain in CAS, while tiny metadata flows through subsequent actions.&lt;a href="#fnref-6"&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;docker load&lt;/code&gt; requires a tar file with all layers, even those previously loaded. Whilst hacks exist to skip lower layers by abusing chain IDs, &lt;code&gt;rules_oci&lt;/code&gt; doesn’t support this. &lt;code&gt;rules_img&lt;/code&gt; interfaces directly with containerd’s content-addressable store to check blob existence and load only missing layers. Docker will soon expose its own content store via the socket (&lt;a href="https://github.com/moby/moby/issues/44369"&gt;moby/moby#44369&lt;/a&gt;), making this approach more widely accessible.&lt;a href="#fnref-7"&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Platform filtering is not yet implemented for the containerd backend (&lt;a href="https://github.com/bazel-contrib/rules_img/issues/107"&gt;rules_img#107&lt;/a&gt;). The &lt;code&gt;docker load&lt;/code&gt; fallback path does support platform filtering.&lt;a href="#fnref-8"&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Some RBE systems can make action inputs available lazily on-demand, while others fetch all declared inputs eagerly before the action runs. For the latter, avoiding multi-gigabyte layer inputs makes a dramatic difference in action scheduling and execution time.&lt;a href="#fnref-9"&gt;↩&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2&gt;Behind the scenes&lt;/h2&gt;Malte Poll&lt;p&gt;Malte is a software engineer with a background in security.
In the process of improving the supply chain security and reproducibility
of security-critical software, he has gained experience with Bazel and Nix.
He is passionate about building secure and reliable systems and enjoys
tinkering with immutable operating systems.
&lt;/p&gt;&lt;p&gt;If you enjoyed this article, you might be interested in &lt;!-- --&gt; &lt;a href="https://www.tweag.io/careers"&gt;joining the Tweag team&lt;/a&gt;.&lt;/p&gt;&lt;img src="data:image/svg+xml;base64,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"&gt;&lt;img src="data:image/svg+xml;base64,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"/&gt;This article is licensed under a&lt;!-- --&gt; &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;Creative Commons Attribution 4.0 International&lt;/a&gt; &lt;!-- --&gt;license.&lt;/img&gt;&lt;/main&gt;</content:encoded>
      <guid isPermaLink="false">https://www.tweag.io/blog/2025-12-18-rules_img/</guid>
      <category>Hacker News</category>
      <pubDate>Thu, 18 Dec 2025 19:50:29 +0000</pubDate>
    </item>
    <item>
      <title>Scaling Go Testing with Contract and Scenario Mocks</title>
      <link>https://funnelstory.ai/blog/engineering/scaling-go-testing-with-contract-and-scenario-mocks</link>
      <description>Scaling Go Testing with Contract and Scenario Mocks</description>
      <content:encoded>&lt;div class="content-container relative overflow-hidden"&gt; &lt;!-- --&gt;Start Free Trial&lt;!-- --&gt;  &lt;!-- --&gt;Start Free Trial&lt;!-- --&gt; &lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://funnelstory.ai/blog/engineering/scaling-go-testing-with-contract-and-scenario-mocks</guid>
      <category>Hacker News</category>
      <pubDate>Thu, 18 Dec 2025 18:09:51 +0000</pubDate>
    </item>
    <item>
      <title>Adobe Photoshop 1.0 Source Code (1990)</title>
      <link>https://computerhistory.org/blog/adobe-photoshop-source-code/</link>
      <description>Adobe Photoshop Source Code - CHM</description>
      <content:encoded>&lt;div class="right-content"&gt;

&lt;a href="https://donate.computerhistory.org"&gt;Donate&lt;/a&gt;
&lt;a href="https://connect.computerhistory.org"&gt;Tickets&lt;/a&gt;


Menu

&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://computerhistory.org/blog/adobe-photoshop-source-code/</guid>
      <category>Hacker News</category>
      <pubDate>Thu, 18 Dec 2025 15:37:18 +0000</pubDate>
    </item>
    <item>
      <title>Executorch: On-device AI across mobile, embedded and edge for PyTorch</title>
      <link>https://github.com/pytorch/executorch</link>
      <description>On-device AI inference powered by PyTorch</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;
&lt;a href="https://github.com/pytorch/executorch/blob/main/docs/source/_static/img/et-logo.png"&gt;&lt;img alt="ExecuTorch logo mark" src="https://github.com/pytorch/executorch/raw/main/docs/source/_static/img/et-logo.png"/&gt;&lt;/a&gt;
&lt;h1&gt;ExecuTorch&lt;/h1&gt;&lt;a href="#executorch"&gt;&lt;/a&gt;
&lt;p&gt;&lt;strong&gt;On-device AI inference powered by PyTorch&lt;/strong&gt;&lt;/p&gt;


&lt;a href="https://pypi.org/project/executorch/"&gt;&lt;img alt="PyPI - Version" src="https://camo.githubusercontent.com/0a655d9cfc2a1d6c3f54fba80bc87ebea4321ade5755afd0e8dada56fe35f159/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f6578656375746f7263683f7374796c653d666f722d7468652d626164676526636f6c6f723d626c7565"/&gt;&lt;/a&gt;
&lt;a href="https://github.com/pytorch/executorch/graphs/contributors"&gt;&lt;img alt="GitHub - Contributors" src="https://camo.githubusercontent.com/629c378cadd0fd62df5cf89107f8bc8b08b3f8d4fc5b939bde95d7acb9049cdb/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6e7472696275746f72732f7079746f7263682f6578656375746f7263683f7374796c653d666f722d7468652d626164676526636f6c6f723d626c7565"/&gt;&lt;/a&gt;
&lt;a href="https://github.com/pytorch/executorch/stargazers"&gt;&lt;img alt="GitHub - Stars" src="https://camo.githubusercontent.com/461ec8564ce148802f8e6dc5bde3bc70997ad25ecc838c4c7b9813efd9533db4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f73746172732f7079746f7263682f6578656375746f7263683f7374796c653d666f722d7468652d626164676526636f6c6f723d626c7565"/&gt;&lt;/a&gt;
&lt;a href="https://discord.gg/Dh43CKSAdc"&gt;&lt;img alt="Discord - Chat with Us" src="https://camo.githubusercontent.com/5665a739b7459f532d6d1bdb198268464b4e52bbfa6f28b2f36bcd159467db62/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446973636f72642d4a6f696e25323055732d626c75653f6c6f676f3d646973636f7264266c6f676f436f6c6f723d7768697465267374796c653d666f722d7468652d6261646765"/&gt;&lt;/a&gt;
&lt;a href="https://docs.pytorch.org/executorch/main/index.html"&gt;&lt;img alt="Documentation" src="https://camo.githubusercontent.com/4ea00c7ce642fa2d5117120b3237ef4e7f310fdb8f96c6a7ed607d215348dcf9/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f446f63756d656e746174696f6e2d626c75653f6c6f676f3d676f6f676c65646f6373266c6f676f436f6c6f723d7768697465267374796c653d666f722d7468652d6261646765"/&gt;&lt;/a&gt;

&lt;p&gt;&lt;strong&gt;ExecuTorch&lt;/strong&gt; is PyTorch's unified solution for deploying AI models on-device—from smartphones to microcontrollers—built for privacy, performance, and portability. It powers Meta's on-device AI across &lt;strong&gt;Instagram, WhatsApp, Quest 3, Ray-Ban Meta Smart Glasses&lt;/strong&gt;, and &lt;a href="https://docs.pytorch.org/executorch/main/success-stories.html"&gt;more&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Deploy &lt;strong&gt;LLMs, vision, speech, and multimodal models&lt;/strong&gt; with the same PyTorch APIs you already know—accelerating research to production with seamless model export, optimization, and deployment. No manual C++ rewrites. No format conversions. No vendor lock-in.&lt;/p&gt;

&lt;strong&gt;📘 Table of Contents&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#why-executorch"&gt;Why ExecuTorch?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#how-it-works"&gt;How It Works&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#quick-start"&gt;Quick Start&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#installation"&gt;Installation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#export-and-deploy-in-3-steps"&gt;Export and Deploy in 3 Steps&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#run-on-device"&gt;Run on Device&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#llm-example-llama"&gt;LLM Example: Llama&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#platform--hardware-support"&gt;Platform &amp;amp; Hardware Support&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#production-deployments"&gt;Production Deployments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#examples--models"&gt;Examples &amp;amp; Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#key-features"&gt;Key Features&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#documentation"&gt;Documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#community--contributing"&gt;Community &amp;amp; Contributing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#license"&gt;License&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Why ExecuTorch?&lt;/h2&gt;&lt;a href="#why-executorch"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;🔒 Native PyTorch Export&lt;/strong&gt; — Direct export from PyTorch. No .onnx, .tflite, or intermediate format conversions. Preserve model semantics.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;⚡ Production-Proven&lt;/strong&gt; — Powers billions of users at &lt;a href="https://engineering.fb.com/2025/07/28/android/executorch-on-device-ml-meta-family-of-apps/"&gt;Meta with real-time on-device inference&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;💾 Tiny Runtime&lt;/strong&gt; — 50KB base footprint. Runs on microcontrollers to high-end smartphones.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;🚀 &lt;a href="https://docs.pytorch.org/executorch/main/backends-overview.html"&gt;12+ Hardware Backends&lt;/a&gt;&lt;/strong&gt; — Open-source acceleration for Apple, Qualcomm, ARM, MediaTek, Vulkan, and more.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;🎯 One Export, Multiple Backends&lt;/strong&gt; — Switch hardware targets with a single line change. Deploy the same model everywhere.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;How It Works&lt;/h2&gt;&lt;a href="#how-it-works"&gt;&lt;/a&gt;
&lt;p&gt;ExecuTorch uses &lt;strong&gt;ahead-of-time (AOT) compilation&lt;/strong&gt; to prepare PyTorch models for edge deployment:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;🧩 Export&lt;/strong&gt; — Capture your PyTorch model graph with &lt;code&gt;torch.export()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;⚙️ Compile&lt;/strong&gt; — Quantize, optimize, and partition to hardware backends → &lt;code&gt;.pte&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;🚀 Execute&lt;/strong&gt; — Load &lt;code&gt;.pte&lt;/code&gt; on-device via lightweight C++ runtime&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Models use a standardized &lt;a href="https://docs.pytorch.org/executorch/main/compiler-ir-advanced.html#intermediate-representation"&gt;Core ATen operator set&lt;/a&gt;. &lt;a href="https://docs.pytorch.org/executorch/main/compiler-delegate-and-partitioner.html"&gt;Partitioners&lt;/a&gt; delegate subgraphs to specialized hardware (NPU/GPU) with CPU fallback.&lt;/p&gt;
&lt;p&gt;Learn more: &lt;a href="https://docs.pytorch.org/executorch/main/intro-how-it-works.html"&gt;How ExecuTorch Works&lt;/a&gt; • &lt;a href="https://docs.pytorch.org/executorch/main/getting-started-architecture.html"&gt;Architecture Guide&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Quick Start&lt;/h2&gt;&lt;a href="#quick-start"&gt;&lt;/a&gt;
&lt;h3&gt;Installation&lt;/h3&gt;&lt;a href="#installation"&gt;&lt;/a&gt;
&lt;pre&gt;pip install executorch&lt;/pre&gt;
&lt;p&gt;For platform-specific setup (Android, iOS, embedded systems), see the &lt;a href="https://docs.pytorch.org/executorch/main/quick-start-section.html"&gt;Quick Start&lt;/a&gt; documentation for additional info.&lt;/p&gt;
&lt;h3&gt;Export and Deploy in 3 Steps&lt;/h3&gt;&lt;a href="#export-and-deploy-in-3-steps"&gt;&lt;/a&gt;
&lt;pre&gt;import torch
from executorch.exir import to_edge_transform_and_lower
from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner

# 1. Export your PyTorch model
model = MyModel().eval()
example_inputs = (torch.randn(1, 3, 224, 224),)
exported_program = torch.export.export(model, example_inputs)

# 2. Optimize for target hardware (switch backends with one line)
program = to_edge_transform_and_lower(
    exported_program,
    partitioner=[XnnpackPartitioner()]  # CPU | CoreMLPartitioner() for iOS | QnnPartitioner() for Qualcomm
).to_executorch()

# 3. Save for deployment
with open("model.pte", "wb") as f:
    f.write(program.buffer)

# Test locally via ExecuTorch runtime's pybind API (optional)
from executorch.runtime import Runtime
runtime = Runtime.get()
method = runtime.load_program("model.pte").load_method("forward")
outputs = method.execute([torch.randn(1, 3, 224, 224)])&lt;/pre&gt;
&lt;h3&gt;Run on Device&lt;/h3&gt;&lt;a href="#run-on-device"&gt;&lt;/a&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.pytorch.org/executorch/main/using-executorch-cpp.html"&gt;C++&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;#include &amp;lt;executorch/extension/module/module.h&amp;gt;
#include &amp;lt;executorch/extension/tensor/tensor.h&amp;gt;

Module module("model.pte");
auto tensor = make_tensor_ptr({2, 2}, {1.0f, 2.0f, 3.0f, 4.0f});
auto outputs = module.forward(tensor);&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.pytorch.org/executorch/main/ios-section.html"&gt;Swift (iOS)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;import ExecuTorch

let module = Module(filePath: "model.pte")
let input = Tensor&amp;lt;Float&amp;gt;([1.0, 2.0, 3.0, 4.0], shape: [2, 2])
let outputs = try module.forward(input)&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.pytorch.org/executorch/main/android-section.html"&gt;Kotlin (Android)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;val module = Module.load("model.pte")
val inputTensor = Tensor.fromBlob(floatArrayOf(1.0f, 2.0f, 3.0f, 4.0f), longArrayOf(2, 2))
val outputs = module.forward(EValue.from(inputTensor))&lt;/pre&gt;
&lt;h3&gt;LLM Example: Llama&lt;/h3&gt;&lt;a href="#llm-example-llama"&gt;&lt;/a&gt;
&lt;p&gt;Export Llama models using the &lt;a href="https://docs.pytorch.org/executorch/main/llm/export-llm.html"&gt;&lt;code&gt;export_llm&lt;/code&gt;&lt;/a&gt; script or &lt;a href="https://github.com/huggingface/optimum-executorch"&gt;Optimum-ExecuTorch&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;# Using export_llm
python -m executorch.extension.llm.export.export_llm --model llama3_2 --output llama.pte

# Using Optimum-ExecuTorch
optimum-cli export executorch \
  --model meta-llama/Llama-3.2-1B \
  --task text-generation \
  --recipe xnnpack \
  --output_dir llama_model&lt;/pre&gt;
&lt;p&gt;Run on-device with the LLM runner API:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.pytorch.org/executorch/main/llm/run-with-c-plus-plus.html"&gt;C++&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;#include &amp;lt;executorch/extension/llm/runner/text_llm_runner.h&amp;gt;

auto runner = create_llama_runner("llama.pte", "tiktoken.bin");
executorch::extension::llm::GenerationConfig config{
    .seq_len = 128, .temperature = 0.8f};
runner-&amp;gt;generate("Hello, how are you?", config);&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://docs.pytorch.org/executorch/main/llm/run-on-ios.html"&gt;Swift (iOS)&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;import ExecuTorchLLM

let runner = TextRunner(modelPath: "llama.pte", tokenizerPath: "tiktoken.bin")
try runner.generate("Hello, how are you?", Config {
    $0.sequenceLength = 128
}) { token in
    print(token, terminator: "")
}&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Kotlin (Android)&lt;/strong&gt; — &lt;a href="https://docs.pytorch.org/executorch/main/javadoc/org/pytorch/executorch/extension/llm/package-summary.html"&gt;API Docs&lt;/a&gt; • &lt;a href="https://github.com/meta-pytorch/executorch-examples/tree/main/llm/android/LlamaDemo"&gt;Demo App&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;val llmModule = LlmModule("llama.pte", "tiktoken.bin", 0.8f)
llmModule.load()
llmModule.generate("Hello, how are you?", 128, object : LlmCallback {
    override fun onResult(result: String) { print(result) }
    override fun onStats(stats: String) { }
})&lt;/pre&gt;
&lt;p&gt;For multimodal models (vision, audio), use the &lt;a href="https://github.com/pytorch/executorch/blob/main/extension/llm/runner"&gt;MultiModal runner API&lt;/a&gt; which extends the LLM runner to handle image and audio inputs alongside text. See &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/llava/README.md"&gt;Llava&lt;/a&gt; and &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/voxtral/README.md"&gt;Voxtral&lt;/a&gt; examples.&lt;/p&gt;
&lt;p&gt;See &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/llama/README.md"&gt;examples/models/llama&lt;/a&gt; for complete workflow including quantization, mobile deployment, and advanced options.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Next Steps:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;📖 &lt;a href="https://docs.pytorch.org/executorch/main/getting-started.html"&gt;Step-by-step tutorial&lt;/a&gt; — Complete walkthrough for your first model&lt;/li&gt;
&lt;li&gt;⚡ &lt;a href="https://colab.research.google.com/drive/1qpxrXC3YdJQzly3mRg-4ayYiOjC6rue3?usp=sharing"&gt;Colab notebook&lt;/a&gt; — Try ExecuTorch instantly in your browser&lt;/li&gt;
&lt;li&gt;🤖 &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/llama/README.md"&gt;Deploy Llama models&lt;/a&gt; — LLM workflow with quantization and mobile demos&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Platform &amp;amp; Hardware Support&lt;/h2&gt;&lt;a href="#platform--hardware-support"&gt;&lt;/a&gt;



&lt;strong&gt;Platform&lt;/strong&gt;
&lt;strong&gt;Supported Backends&lt;/strong&gt;




Android
XNNPACK, Vulkan, Qualcomm, MediaTek, Samsung Exynos


iOS
XNNPACK, MPS, CoreML (Neural Engine)


Linux / Windows
XNNPACK, OpenVINO, CUDA &lt;em&gt;(experimental)&lt;/em&gt;


macOS
XNNPACK, MPS, Metal &lt;em&gt;(experimental)&lt;/em&gt;


Embedded / MCU
XNNPACK, ARM Ethos-U, NXP, Cadence DSP



&lt;p&gt;See &lt;a href="https://docs.pytorch.org/executorch/main/backends-overview.html"&gt;Backend Documentation&lt;/a&gt; for detailed hardware requirements and optimization guides. For desktop/laptop GPU inference with CUDA and Metal, see the &lt;a href="https://github.com/pytorch/executorch/blob/main/desktop/README.md"&gt;Desktop Guide&lt;/a&gt;. For Zephyr RTOS integration, see the &lt;a href="https://github.com/pytorch/executorch/blob/main/zephyr/README.md"&gt;Zephyr Guide&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Production Deployments&lt;/h2&gt;&lt;a href="#production-deployments"&gt;&lt;/a&gt;
&lt;p&gt;ExecuTorch powers on-device AI at scale across Meta's family of apps, VR/AR devices, and partner deployments. &lt;a href="https://docs.pytorch.org/executorch/main/success-stories.html"&gt;View success stories →&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;Examples &amp;amp; Models&lt;/h2&gt;&lt;a href="#examples--models"&gt;&lt;/a&gt;
&lt;p&gt;&lt;strong&gt;LLMs:&lt;/strong&gt; &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/llama/README.md"&gt;Llama 3.2/3.1/3&lt;/a&gt;, &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/qwen3/README.md"&gt;Qwen 3&lt;/a&gt;, &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/phi_4_mini/README.md"&gt;Phi-4-mini&lt;/a&gt;, &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/lfm2/README.md"&gt;LiquidAI LFM2&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Multimodal:&lt;/strong&gt; &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/llava/README.md"&gt;Llava&lt;/a&gt; (vision-language), &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/voxtral/README.md"&gt;Voxtral&lt;/a&gt; (audio-language), &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/gemma3"&gt;Gemma&lt;/a&gt; (vision-language)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Vision/Speech:&lt;/strong&gt; &lt;a href="https://github.com/meta-pytorch/executorch-examples/tree/main/mv2"&gt;MobileNetV2&lt;/a&gt;, &lt;a href="https://github.com/meta-pytorch/executorch-examples/tree/main/dl3"&gt;DeepLabV3&lt;/a&gt;, &lt;a href="https://github.com/pytorch/executorch/blob/main/examples/models/whisper/README.md"&gt;Whisper&lt;/a&gt; &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Resources:&lt;/strong&gt; &lt;a href="https://github.com/pytorch/executorch/blob/main/examples"&gt;&lt;code&gt;examples/&lt;/code&gt;&lt;/a&gt; directory • &lt;a href="https://github.com/meta-pytorch/executorch-examples"&gt;executorch-examples&lt;/a&gt; out-of-tree demos • &lt;a href="https://github.com/huggingface/optimum-executorch"&gt;Optimum-ExecuTorch&lt;/a&gt; for HuggingFace models • &lt;a href="https://docs.unsloth.ai/new/deploy-llms-phone"&gt;Unsloth&lt;/a&gt; for fine-tuned LLM deployment &lt;/p&gt;
&lt;h2&gt;Key Features&lt;/h2&gt;&lt;a href="#key-features"&gt;&lt;/a&gt;
&lt;p&gt;ExecuTorch provides advanced capabilities for production deployment:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Quantization&lt;/strong&gt; — Built-in support via &lt;a href="https://docs.pytorch.org/ao"&gt;torchao&lt;/a&gt; for 8-bit, 4-bit, and dynamic quantization&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory Planning&lt;/strong&gt; — Optimize memory usage with ahead-of-time allocation strategies&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Developer Tools&lt;/strong&gt; — ETDump profiler, ETRecord inspector, and model debugger&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Selective Build&lt;/strong&gt; — Strip unused operators to minimize binary size&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Custom Operators&lt;/strong&gt; — Extend with domain-specific kernels&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dynamic Shapes&lt;/strong&gt; — Support variable input sizes with bounded ranges&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See &lt;a href="https://docs.pytorch.org/executorch/main/advanced-topics-section.html"&gt;Advanced Topics&lt;/a&gt; for quantization techniques, custom backends, and compiler passes.&lt;/p&gt;
&lt;h2&gt;Documentation&lt;/h2&gt;&lt;a href="#documentation"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://docs.pytorch.org/executorch/main/index.html"&gt;&lt;strong&gt;Documentation Home&lt;/strong&gt;&lt;/a&gt; — Complete guides and tutorials&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.pytorch.org/executorch/main/api-section.html"&gt;&lt;strong&gt;API Reference&lt;/strong&gt;&lt;/a&gt; — Python, C++, Java/Kotlin APIs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.pytorch.org/executorch/main/backend-delegates-integration.html"&gt;&lt;strong&gt;Backend Integration&lt;/strong&gt;&lt;/a&gt; — Build custom hardware backends&lt;/li&gt;
&lt;li&gt;&lt;a href="https://docs.pytorch.org/executorch/main/support-section.html"&gt;&lt;strong&gt;Troubleshooting&lt;/strong&gt;&lt;/a&gt; — Common issues and solutions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Community &amp;amp; Contributing&lt;/h2&gt;&lt;a href="#community--contributing"&gt;&lt;/a&gt;
&lt;p&gt;We welcome contributions from the community!&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;💬 &lt;a href="https://github.com/pytorch/executorch/discussions"&gt;&lt;strong&gt;GitHub Discussions&lt;/strong&gt;&lt;/a&gt; — Ask questions and share ideas&lt;/li&gt;
&lt;li&gt;🎮 &lt;a href="https://discord.gg/Dh43CKSAdc"&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/a&gt; — Chat with the team and community&lt;/li&gt;
&lt;li&gt;🐛 &lt;a href="https://github.com/pytorch/executorch/issues"&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/a&gt; — Report bugs or request features&lt;/li&gt;
&lt;li&gt;🤝 &lt;a href="https://github.com/pytorch/executorch/blob/main/CONTRIBUTING.md"&gt;&lt;strong&gt;Contributing Guide&lt;/strong&gt;&lt;/a&gt; — Guidelines and codebase structure&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;License&lt;/h2&gt;&lt;a href="#license"&gt;&lt;/a&gt;
&lt;p&gt;ExecuTorch is BSD licensed, as found in the &lt;a href="https://github.com/pytorch/executorch/blob/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;&lt;/p&gt;


&lt;p&gt;&lt;strong&gt;Part of the PyTorch ecosystem&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;
&lt;a href="https://github.com/pytorch/executorch"&gt;GitHub&lt;/a&gt; •
    &lt;a href="https://docs.pytorch.org/executorch"&gt;Documentation&lt;/a&gt;
&lt;/p&gt;

&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/pytorch/executorch</guid>
      <category>Hacker News</category>
      <pubDate>Thu, 18 Dec 2025 13:51:11 +0000</pubDate>
    </item>
    <item>
      <title>Partial inlining</title>
      <link>https://xania.org/202512/18-partial-inlining</link>
      <description>Written by me, proof-read by an LLM. Details at end.</description>
      <content:encoded>&lt;div class="small-12 columns article"&gt;
&lt;h2&gt;Partial inlining&lt;/h2&gt;
&lt;p&gt;Written by me, proof-read by an LLM.
&lt;br/&gt;Details at end.&lt;/p&gt;
&lt;p&gt;We’ve learned how important inlining is to optimisation, but also that it might sometimes cause code bloat. Inlining doesn’t have to be all-or-nothing!&lt;/p&gt;
&lt;p&gt;Let’s look at a simple function that has a fast path and slow path; and then see how the compiler handles it&lt;a href="#fn:note"&gt;1&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In this example we have some &lt;code&gt;process&lt;/code&gt; function that has a really trivial fast case for numbers in the range 0-100. For other numbers it does something more expensive. Then &lt;code&gt;compute&lt;/code&gt; calls &lt;code&gt;process&lt;/code&gt; twice (making it less appealing to inline all of &lt;code&gt;process&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Looking at the assembly output, we see what’s happened: The compiler has split &lt;code&gt;process&lt;/code&gt; into two functions, a &lt;code&gt;process (part.0)&lt;/code&gt; that does the expensive part only. It then rewrites &lt;code&gt;process&lt;/code&gt; into the quick check for 100, returning double the value if less than 100. If not, it jumps to the &lt;code&gt;(part.0)&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;process(unsigned int):
  cmp edi, 99                           ; less than or equal to 99?
  jbe .L7                               ; skip to fast path if so
  jmp process(unsigned int) (.part.0)   ; else jump to the expensive path
.L7:
  lea eax, [rdi+rdi]                    ; return `value * 2`
  ret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This first step - extracting the cold path into a separate function - is called &lt;strong&gt;function outlining&lt;/strong&gt;. The original &lt;code&gt;process&lt;/code&gt; becomes a thin wrapper handling the hot path, delegating to the outlined &lt;code&gt;process (.part.0)&lt;/code&gt; when needed. This split sets up the real trick: &lt;strong&gt;partial inlining&lt;/strong&gt;. When the compiler later inlines &lt;code&gt;process&lt;/code&gt; into &lt;code&gt;compute&lt;/code&gt;, it inlines just the wrapper whilst keeping calls to the outlined cold path. External callers can still call &lt;code&gt;process&lt;/code&gt; and have it work correctly for all values.&lt;/p&gt;
&lt;p&gt;Let’s see this optimisation in action in the &lt;code&gt;compute&lt;/code&gt; function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;compute(unsigned int, unsigned int):
  cmp edi, 99                   ; is a &amp;lt;= 99?
  jbe .L13                      ; if so, go to the inlined fast path for a
  call process(unsigned int) (.part.0) ; else, call expensive case
  mov r8d, eax                  ; save the result of process(a)
  cmp esi, 99                   ; is b &amp;lt;= 99?
  jbe .L14                      ; if so go to the inlined fast path for b
.L11:
  mov edi, esi                  ; otherwise, call expensive case for b
  call process(unsigned int) (.part.0)
  add eax, r8d                  ; add the two slow cases together
  ret                           ; return

.L13:                           ; case where a is fast case
  lea r8d, [rdi+rdi]            ; process(a) is just a + a
  cmp esi, 99                   ; is b &amp;gt; 99?
  ja .L11                       ; jump to b slow case if so
                                ; (falls through to...)
.L14:                           ; b fast case
  lea eax, [rsi+rsi]            ; double b
  add eax, r8d                  ; return 2*a + 2*b
  ret
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at &lt;code&gt;compute&lt;/code&gt;, we can see the benefits of this approach clearly: The simple range check and arithmetic (&lt;code&gt;cmp&lt;/code&gt;, &lt;code&gt;lea&lt;/code&gt;) are inlined directly, avoiding the function call overhead for the fast path. When a value is 100 or greater, it calls the outlined &lt;code&gt;process (.part.0)&lt;/code&gt; function for the more expensive computation.&lt;/p&gt;
&lt;p&gt;This is the best of both worlds: we get the performance benefit of inlining the lightweight check and simple arithmetic, whilst avoiding code bloat from duplicating the expensive computation&lt;a href="#fn:again"&gt;2&lt;/a&gt;. The original &lt;code&gt;process&lt;/code&gt; function remains intact and callable, so external callers still work correctly.&lt;/p&gt;
&lt;p&gt;Partial inlining lets the compiler make nuanced trade-offs about what to inline and what to keep shared. The compiler can outline portions of a function based on its heuristics about code size and performance&lt;a href="#fn:tradeoff"&gt;3&lt;/a&gt;, giving you benefits of inlining without necessarily paying the full code size cost. In this example, the simple check is duplicated whilst the complex computation stays shared.&lt;/p&gt;
&lt;p&gt;As with many optimisations, the compiler’s heuristics&lt;a href="#fn:clang"&gt;4&lt;/a&gt; usually make reasonable choices about when to apply partial inlining, but it’s worth checking your hot code paths to see if the compiler has made the decisions you expect. Taking a quick peek in &lt;a href="https://godbolt.org"&gt;Compiler Explorer&lt;/a&gt; is a good way to develop your intuition.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;See &lt;a href="https://youtu.be/STZb5K5sPDs"&gt;the video&lt;/a&gt; that accompanies this post.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;This post is day 18 of &lt;a href="https://xania.org/AoCO2025"&gt;Advent of Compiler Optimisations 2025&lt;/a&gt;,
a 25-day series exploring how compilers transform our code.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post was written by a human (&lt;a href="https://xania.org/MattGodbolt"&gt;Matt Godbolt&lt;/a&gt;) and reviewed and proof-read by LLMs and humans.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Support Compiler Explorer on &lt;a href="https://patreon.com/c/mattgodbolt"&gt;Patreon&lt;/a&gt;
or &lt;a href="https://github.com/sponsors/compiler-explorer"&gt;GitHub&lt;/a&gt;,
or by buying CE products in the &lt;a href="https://shop.compiler-explorer.com"&gt;Compiler Explorer Shop&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;


&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;I have had to cheat a little here to get the output I want: I’ve actually disabled GCC’s main inlining pass, otherwise it chooses to inline the whole of &lt;code&gt;process&lt;/code&gt;. With a larger, more complex “slow path” that would be unnecessary, but in order to demonstrate the effect of partial inlining without generating tons of code, I’m using this slight cheat. &lt;a href="#fnref:note"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Again, in this contrived example it probably &lt;em&gt;would&lt;/em&gt; be OK to inline &lt;code&gt;process&lt;/code&gt;, and the compiler really wants to, but for didactic purposes I’ve prevented that here. You can hopefully get the gist of this. &lt;a href="#fnref:again"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Of course, nothing is free - duplicating code still takes up instruction cache space. The compiler’s heuristics have to weigh the benefits against the costs, and different compilers make different choices. &lt;a href="#fnref:tradeoff"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Note that this varies substantially from compiler to compiler: I couldn’t trick clang into making similar partial inlining decisions to gcc using flags, so I couldn’t compare like with like. In my experience gcc and clang make quite different choices about inlining. &lt;a href="#fnref:clang"&gt;↩&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;/div&gt;</content:encoded>
      <guid isPermaLink="false">https://xania.org/202512/18-partial-inlining</guid>
      <category>Hacker News</category>
      <pubDate>Thu, 18 Dec 2025 13:39:41 +0000</pubDate>
    </item>
    <item>
      <title>Fifty problems with standard web APIs in 2025</title>
      <link>https://zerotrickpony.com/articles/browser-bugs/</link>
      <description>Recently, I made a free game .
It's a little mystery investigation game which I was inspired to write after enjoying games like Case of the Golden Idol , Roottrees are Dead , and Return of the Obra Dinn .
I thought my UX ideas were pretty simple, so I decided to implement it in HTML5 .</description>
      <content:encoded>&lt;article class="page"&gt;
&lt;h1&gt;Fifty problems with standard web APIs in 2025&lt;/h1&gt;
&lt;a href="https://messydesk.social/@zerotrickpony"&gt;Zero Trick Pony&lt;/a&gt; - December 2025
&lt;p&gt;&lt;a&gt;&lt;/a&gt;
Recently, I made a &lt;a href="https://intelligencegame.tech"&gt;free game&lt;/a&gt;.
It's a little mystery investigation game which I was inspired to write after enjoying games like
&lt;a href="https://en.wikipedia.org/wiki/The_Case_of_the_Golden_Idol"&gt;Case of the Golden Idol&lt;/a&gt;,
&lt;a href="https://en.wikipedia.org/wiki/The_Roottrees_are_Dead"&gt;Roottrees are Dead&lt;/a&gt;, and
&lt;a href="https://en.wikipedia.org/wiki/Return_of_the_Obra_Dinn"&gt;Return of the Obra Dinn&lt;/a&gt;.
I thought my UX ideas were pretty simple, so I decided to implement it in &lt;strong&gt;HTML5&lt;/strong&gt;.&lt;/p&gt;

&lt;a href="https://zerotrickpony.com/articles/browser-bugs/game-screenshot.jpg"&gt;
&lt;img src="https://zerotrickpony.com/articles/browser-bugs/game-screenshot.jpg"/&gt;
&lt;/a&gt;

&lt;p&gt;I know, I know: games should be made with game engines. But listen: The game is mostly text. It has
a dirt simple single-page ("SPA") type layout, static images, a few fonts, a few sounds, and that's it.
No need for a backing server, no 3D graphics, no complex animations, and no particularly novel interactions.
Just a single page load, and then clicking and reading.&lt;/p&gt;
&lt;p&gt;I figured it should be easy to make this game (app, really) work on multiple browsers and devices,
so that players could access it without a native install. The web has supported these basic functions for over
a decade. Surely in the year 2025, I thought, &lt;strong&gt;HTML5&lt;/strong&gt; is a good choice for these simple needs.
It's the future now!&lt;/p&gt;
&lt;p&gt;What really happened was, I hit &lt;strong&gt;over 50 surprising problems&lt;/strong&gt; related to gaps in web standards, requiring
me to &lt;strong&gt;spend over half of the total development time on rework&lt;/strong&gt; for cross-browser and cross-device
support. In this article I'd like to list the problems I hit, as an illustration of what a novice web developer
faces on the modern web today.
I'll give some simple advice on reducing rework costs, and conclude with some points on what
web standards in 2025 do and don't do for us.&lt;/p&gt;
&lt;h2&gt;Surely this is my fault&lt;/h2&gt;

&lt;img src="https://zerotrickpony.com/articles/browser-bugs/tombstone.jpg"/&gt;

&lt;p&gt;I know, I know: new features are always being added to browsers. There's always going to be some "wet paint" in
web standards. If I make a web project that depends on the newest features, it's not going to work everywhere.
You might be thinking that in order to hit 50+ cross-browser problems, I must have used the hottest, newest,
most experimental web APIs, and that was all my fault.&lt;/p&gt;
&lt;p&gt;The common wisdom is that if only I restrain myself to the "safe harbor" of the oldest, most time-tested parts of
the standard web, then I can rest assured that my web page will work on any "modern" browser and device.&lt;/p&gt;
&lt;p&gt;But sadly, no.&lt;/p&gt;
&lt;p&gt;Unfortunately some of the most buggy, glitchy, and/or divergent behaviors I found were in 20+ year old standard web features.
It's not (just) the new stuff. I was surprised to find &lt;strong&gt;no clear safe harbor feature set&lt;/strong&gt; for
building polished, interactive web-based projects, even if they are pretty simple.
Even with other projects that were barely interactive, I've hit fairly important platform and browser variances,
and needed at least some rework for multiple browsers.&lt;/p&gt;
&lt;p&gt;Even so, I imagine that an experienced web developer could read the list of problems below and nod to themselves knowingly:
"sure, these are all common pitfalls. That's why we have frameworks that polyfill many of these problems, and
experienced designers and frontend engineers who know all the best practices."&lt;/p&gt;
&lt;p&gt;Perhaps that's true, but my point is: should it be? If a "standard platform" requires a giant device testing lab and a
priesthood of finger-wagging frontend druids with trauma response for engineering intuition, is this "standard"
really helping us a lot? Even if web standards don't let us live the dream of "write once, run everywhere", shouldn't
it at least be predictable where the problems are going to be?&lt;/p&gt;
&lt;h2&gt;The novice web developer experience&lt;/h2&gt;
&lt;p&gt;The way I ended up hitting all these nasty surprises was not as naive as it may sound. I am not a novice
web developer; I am, unhappily, one of the druids. I did not naively blunder into cross-browser pitfalls,
I'm perfectly well aware that huge browser differences exist (spoiler: mobile) and need design consideration,
and testing.&lt;/p&gt;
&lt;p&gt;But I did accidentally simulate the naive web developer experience with my game project, because of
how I was prototyping. In game development, the core game mechanics have to be fun or else the rest of the game is
not worth making. So I whipped up a prototype wireframe in HTML5 to get a feel for core puzzle mechanics, purposely
disregarding cross platform considerations. I willfully ignored phones and tablets and Safari, and iterated just on
my own MacBook with only one browser.&lt;/p&gt;
&lt;p&gt;Only later, after the wireframe game mechanics had been refined with playtesting, did I decide to polish the
prototype into a cross-browser game that also worked well on mobile. If you work at a giant company you wouldn't
work like this; in fact you probably wouldn't get to design the UX &lt;em&gt;at all&lt;/em&gt;, because you'd receive the proposed
interactions from a paid UX designer.&lt;/p&gt;
&lt;p&gt;But a new developer working alone probably would do this? And why shouldn't they? It &lt;em&gt;should&lt;/em&gt; be reasonable to get
an idea working on one's own computer first, and not be surprised later by massive rework on a second device/browser.&lt;/p&gt;
&lt;p&gt;So, where are we on that in 2025? To find out, I compiled all the browser bugs and rework tasks from my game
project into this list.&lt;/p&gt;
&lt;h2&gt;&lt;a&gt;&lt;/a&gt;TLDR: buy an old iPhone and test with it daily&lt;/h2&gt;
&lt;p&gt;If you don't read the rest of this rant, I can sum up my advice as just this: if you're making a web project, even
a simple one, do your rapid, many-times-a-day iteration loop testing on an &lt;strong&gt;older iPhone&lt;/strong&gt; as your test mule.
Yes this is a pain, because none of us are programming on an iPhone soft keyboard. We're sitting at a computer
or laptop, and so that's the platform it's most natural to iterate on. Most frontend tools do not make it easy to
have a quick edit-and-reload cycle with a real mobile device.
So you'll have to either frequently push to a private web server, or use some
&lt;a href="https://apps.apple.com/us/app/ssh-tunnel-with-socks5-proxy/id1260223542"&gt;exotic ssh tunnel&lt;/a&gt; contraption,
to get it so that your test mule iPhone can view your test web project.&lt;/p&gt;
&lt;p&gt;This is not because iPhones are good, &lt;strong&gt;it's because they're bad.&lt;/strong&gt;
iPhones are more peculiar and less compliant than any other device I tried. I promise that if you get your
web project looking good and working smoothly on a crappy iPhone, your
residual costs to test and polish on all other platforms and browsers will be fairly low. (For extra bravery,
I recommend &lt;strong&gt;Firefox iOS&lt;/strong&gt; instead of Safari, because it is the most buggy, least compliant browser
I was able to find. If it works on Firefox iOS it's going to work anywhere. See below.)&lt;/p&gt;
&lt;p&gt;Yes all the desktop browsers have some form of "design for mobile" mode, and that's better than nothing.
But these tools will not reveal 80% of the problems I've described below. Not even the Safari responsive design
mode. Not even the XCode device simulator.&lt;/p&gt;
&lt;p&gt;If you'd like to hear more, then let's start with some gleeful indignation at one of the biggest culprits
in web development:&lt;/p&gt;
&lt;h1&gt;&lt;a&gt;&lt;/a&gt;Culprit #1: Apple has opinions&lt;/h1&gt;
&lt;p&gt;Writing this with fresh bruises from my iOS testing lab, I feel like it's fair to say that Apple's
mobile devices (iPhone, iPad) wilfully and unapologetically diverge from the rest of the web more than any other
platform. Safari has a few bugs and is the slowest to support any given web API. But this section is not about
Safari's &lt;strong&gt;bugs&lt;/strong&gt; and &lt;strong&gt;sandbagging&lt;/strong&gt;; more on that below.
This section is just about Safari's &lt;strong&gt;strong opinions&lt;/strong&gt;. Here are few issues I hit:&lt;/p&gt;
&lt;h2&gt;Can't use the whole screen&lt;/h2&gt;
&lt;p&gt;In a game, and arguably in any well designed UX, the application wants to use all the available screen space.
The design should neither waste space on unintended gutters or dead pixels, nor should it confuse the user
by letting important information fall below the fold where the user will have to scroll to get at it,
or will be confused because they won't notice it. I want to simply fill the whole canvas but not overspill it,
and this is comically difficult on iOS.&lt;/p&gt;

&lt;a href="https://zerotrickpony.com/articles/browser-bugs/browser-bar-resize.mp4"&gt;
&lt;img src="https://zerotrickpony.com/articles/browser-bugs/browser-bar-resize-screenshot.jpg"/&gt;
&lt;/a&gt;

&lt;p&gt;&lt;strong&gt;Mandatory automatic resizing:&lt;/strong&gt; First, the navigation bar at the top of the screen will appear and dissappear depending on the user's most recent
gesture. There is no event your application can receive to know this is happening, nor any measurement you can take
to detect it.
[surprising problem #1]&lt;/p&gt;
&lt;p&gt;The &lt;a href="https://caniuse.com/?search=vh"&gt;standard CSS features &lt;code&gt;vw&lt;/code&gt; and &lt;code&gt;vh&lt;/code&gt; units&lt;/a&gt; are broken by this
behavior, so trying to create a whole-page user experience will break on iOS Safari.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Broken CSS units:&lt;/strong&gt; Experienced web developers have &lt;a href="https://css-tricks.com/the-trick-to-viewport-units-on-mobile/"&gt;tried complicated tricks&lt;/a&gt;
to work around this resizing behavior. Later, &lt;a href="https://caniuse.com/?search=svh"&gt;new units were introduced&lt;/a&gt; to CSS to try to give
the web page more control over this. And although newer Safari iOS versions support them,
&lt;a href="https://github.com/mozilla-mobile/firefox-ios/issues/11574"&gt;Firefox iOS still doesn't.&lt;/a&gt;
[#2]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Anti-competitive non-standards:&lt;/strong&gt; Relatedly, there is a &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/requestFullscreen#browser_compatibility"&gt;Fullscreen API&lt;/a&gt; in the web standards, which every browser supports... except Safari iPhone.
[3]
The &lt;a href="https://developer.apple.com/forums/thread/133248"&gt;community hypothesizes that fullscreen is purposely hobbled&lt;/a&gt; on iOS
so that Apple can sell more native iOS games without web-based games being a viable competitor. When I considered
using the fullscreen web standard to give my game better use of the screen, I was thwarted by this.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Useless fullscreen behavior:&lt;/strong&gt; The Fullscreen API is
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Element/requestFullscreen#browser_compatibility"&gt;&lt;em&gt;supposed&lt;/em&gt; to work on iPad&lt;/a&gt;,
and I wasted time trying to offer it to my users. But it has
three ridiculous problems: First, it replaces the top of the screen with a black area and an irremovable "X"
which doesn't actually reclaim any more space than the address bar would have.
[4]&lt;/p&gt;
&lt;p&gt;Second, if the user &lt;em&gt;scrolls down&lt;/em&gt; in any element anywhere on the page, full-screen mode ends.
[5]&lt;/p&gt;

&lt;img src="https://zerotrickpony.com/articles/browser-bugs/ios-fullscreen-keyboard-error.jpg"/&gt;

&lt;p&gt;Third, Safari will &lt;em&gt;refuse to summon the soft keyboard&lt;/em&gt; if fullscreen is currently on.
Newer versions of Safari simply exit fullscreen, but in iOS 12 I encountered this hilarious error dialog informing the user
that Apple believes the web page is phishing them. (!)
[6]
Since my game had both scrolling elements and occasionally needed the keyboard,
I gave up in disgust so now I simply hide the fullscreen button on iOS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Workarounds:&lt;/strong&gt; My solutions were to (a) give up on the Fullscreen API on iOS, (b) use &lt;code&gt;position:fixed&lt;/code&gt; and some cleverness with
CSS transforms to fill the screen at least horizontally, and (c) to blindly add in some height fudge factors to try to stay below
the unknowable threshold of vertical scrolling on these browsers. My game now uses &lt;em&gt;almost&lt;/em&gt; the whole screen on iOS.&lt;/p&gt;
&lt;h2&gt;Touch screen problems&lt;/h2&gt;
&lt;p&gt;Apple's mobile browser is perfectly okay for scrolling to read articles and tapping hyperlinks. But for my
game I needed to design more interactive elements. Although I tried to keep it simple, I was still hit
by a number of Apple-specific surprises:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Dragging does what:&lt;/strong&gt; Dragging with the mouse on a desktop browser will drag any &lt;code&gt;draggable&lt;/code&gt; elements, or
do text selection otherwise. But on Safari iOS, dragging a finger will only scroll.
[7]
Even if the touched area isn't scrollable, and even if the finger lands on a &lt;code&gt;draggable&lt;/code&gt; element, swiping gestures only
scroll. If the user does a compound press-and-hold-and-then-drag gesture, then on Android this will drag
the &lt;code&gt;draggable&lt;/code&gt; element but on iOS it will select text instead.
[8]
I was able to fix this with a liberal sprinkling of &lt;code&gt;user-select:none&lt;/code&gt; styles on many more elements than Android needed.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is scrollable:&lt;/strong&gt; In the name of saving space and beautifying the display, Apple defaulted us all to
the "overlay" style of scroll bars. These elements are translucent, narrow, or entirely invisible for most
of their lifetime. The result looks simple and attractive, and next time I want to print out my phone's screen and
hang it on my wall as art, I'll thank them for that. The rest of the time, this makes it impossible for the
user to discern which areas of the screen are scrollable. This is probably a perfectly reasonable tradeoff
decision for when the browser is displaying a wikipedia article about raccoons. But for anything more interactive,
the inability for the user to discover what is scrollable is pretty bad. I had to add on-screen glinting elements
to draw the user's attention to the otherwise invisible scrolling areas.
[9]&lt;/p&gt;

&lt;a href="https://zerotrickpony.com/articles/browser-bugs/hittest_bug_ipad.mp4"&gt;
&lt;img src="https://zerotrickpony.com/articles/browser-bugs/tap-test-screenshot.jpg"/&gt;
&lt;/a&gt;

&lt;p&gt;&lt;strong&gt;Apple's finger location algorithm:&lt;/strong&gt; I assigned &lt;code&gt;click&lt;/code&gt; Event listeners to various on-screen objects, some of which were
&lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt; but many of which were &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; elements. My testing revealed that Android Chrome will deliver
a click event if the user's finger touches most/all of the area of the element. If the finger hits multiple
elements, Chrome Android delivers the event to the one closest to its own proprietary idea of the perceptual center
of the finger touch. When I tested my game board UX scaled &lt;em&gt;way&lt;/em&gt; down for a tiny mobile screen, I was pleasantly
surprised to find that the user can &lt;a href="https://zerotrickpony.com/articles/browser-bugs/hittest_bug_android.mp4"&gt;still tap them somewhat successfully&lt;/a&gt; even if they're visually small...
&lt;a href="https://zerotrickpony.com/articles/browser-bugs/hittest_bug_ipad.mp4"&gt;but not on iPad&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On Safari iOS with a scaled down UI, the user has to get the &lt;em&gt;center&lt;/em&gt; of their finger to hit
the element or else the click event won't be delivered. [10]
This made my game effectively unplayable on iOS because the playing field had 10px hit targets which were too
small to tap. I fixed it by creating a large invisible &lt;code&gt;&amp;lt;div&amp;gt;&lt;/code&gt; over every dot on the field, to catch touch input on iOS.&lt;/p&gt;
&lt;h2&gt;Can't play audio&lt;/h2&gt;
&lt;p&gt;My game has both sound effects and background music. Sound was exotic on the web in 2004, but it's long since been
standardized... supposedly. Not counting composing the sounds in Garage Band, I got these working
on my laptop's browser in under ten minutes. Then getting them to work on iPad and iPhone took me another
week of effort.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AudioContext always sounds silent:&lt;/strong&gt; My first try at sound effects used an &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext#browser_compatibility"&gt;AudioContext&lt;/a&gt; to wire up Gain and Oscillator nodes to play game beeps. These features are
"fully supported" on iOS, but no sound would be produced. [11]
I eventually learned that if you use these APIs
to make sound, &lt;a href="https://stackoverflow.com/questions/40789136/ios-ringer-switch-mutes-web-audio"&gt;iOS considers them to be "ringtones"&lt;/a&gt;
rather than "media", which means that the user's
media volume control will have no effect on the game's sounds. The user must enter their "Settings" app and
change their device's ring volume. The normal hard buttons for volume up and down on an iOS device control
media volume, not ring volume. I despaired of instructing any user to do this.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Audio tag play() does not function:&lt;/strong&gt; Next I moved to using &lt;code&gt;&amp;lt;audio/&amp;gt;&lt;/code&gt; tags to play pre-recorded sounds in response
to in-game events. I created six &lt;code&gt;HTMLAudioElement&lt;/code&gt; objects for my five kinds of sound effect, and one
more to play the background music. However, the &lt;code&gt;.play()&lt;/code&gt; method, which is marked on
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/play#browser_compatibility"&gt;MDN&lt;/a&gt;
as "fully supported" and "widely available", does not function at all on iOS.
[12]&lt;/p&gt;
&lt;p&gt;You see, Apple is of the opinion that &lt;code&gt;.play()&lt;/code&gt; method should only work if it's
&lt;a href="https://stackoverflow.com/questions/66300840/trying-to-play-an-mp3-via-js-on-ios-browsers"&gt;in response to a user action&lt;/a&gt;,
which they implement by checking if the user has tapped an element on the page. Since a game
has story events for the user to &lt;em&gt;react&lt;/em&gt; to, no such sound effects could work. I worked around it (see below)
but it made the system very complicated.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Audio tags skip the first 300ms of sound after the first play:&lt;/strong&gt; Safari will play MP3s through the &lt;code&gt;HTMLAudioElement&lt;/code&gt; ---
&lt;em&gt;once&lt;/em&gt;. But after each tag plays once, Safari aggressively unloads the media, I presume to save memory.
[13]
I think this is reasonable, &lt;em&gt;except&lt;/em&gt; that then when my sound effect plays a second time, the audio has
been unloaded and Safari plays silence until it can get the MP3 data back into its buffers again. I would
actually have been fine with this behavior if it were to wait to play until the audio was loaded, but it
doesn't do that. Safari is of the opinion that it's more important to keep up with the scheduled play
of the sound &lt;em&gt;than to hear it&lt;/em&gt;. So it non-deterministically jumps into the middle of the sound, cutting off the beginning.
This made all my sound effects seem glitchy and truncated.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Audio volume not controllable:&lt;/strong&gt; I created a volume control for both music and sound effects in the game,
in case the user wanted to mute them or make them quieter. I did this by setting the &lt;code&gt;.volume&lt;/code&gt; property
on the Audio tags, and this turned out to be broken on iOS.
[14]
(To their credit, MDN lists the &lt;code&gt;.volume&lt;/code&gt; property of media tags as
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/volume#browser_compatibility"&gt;"limited availability"&lt;/a&gt;.)
Apple simply says "volume is under the user's control",
and does not try to make the thing work. Apple &lt;a href="https://developer.apple.com/library/archive/documentation/AudioVideo/Conceptual/Using_HTML5_Audio_Video/Device-SpecificConsiderations/Device-SpecificConsiderations.html#//apple_ref/doc/uid/TP40009523-CH5-SW1"&gt;documents its behavior&lt;/a&gt;
like this:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Reading the volume property always returns 1&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;This would be a handy behavior to at least write some feature detection logic around, but sadly it's not true.
[15]
The actual behavior is that if you modify the &lt;code&gt;.volume&lt;/code&gt; property
of an &lt;code&gt;HTMLAudioElement&lt;/code&gt; then it &lt;em&gt;will&lt;/em&gt; seem to change, but (a) no actual volume change will occur, and
(b) at the next event loop idle, the volume value will be set back to &lt;code&gt;1&lt;/code&gt;. This wasted an hour of my time
to isolate the true behavior and write complicated feature detection logic to check that mutation of the &lt;code&gt;.volume&lt;/code&gt;
property survives past the next idle loop.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Workarounds:&lt;/strong&gt; The &lt;a href="https://stackoverflow.com/questions/31776548/why-cant-javascript-play-audio-files-on-iphone-safari"&gt;recommended workaround&lt;/a&gt;
for the anti-autoplay behavior is to create a little invisible farm of dummy &lt;code&gt;HTMLAudioElement&lt;/code&gt; objects
which play silent sounds when the user taps anything on the screen. I inserted a "start" screen into my
game when the page loads, which has no purpose except to provide the user with something to tap before
the game begins.&lt;/p&gt;
&lt;p&gt;Once the user taps, I can have the farm of elements play their silent sounds once. Then the programmer is
free to rewrite their &lt;code&gt;src&lt;/code&gt; attribute to play other media at any time.
This works because the constraint to play() from within a user action event handler apparently only pertains to the first
use of play on a per-tag basis.
[16]
So after writing about 200 lines of priming logic, I had a bank of
sound effects working. (And can I just say: if this workaround works for me, it works for bad actors too.
So Apple's mitigation adds complexity but doesn't actually protect users as intended. Awesome!)&lt;/p&gt;
&lt;p&gt;To work around the cut-off sound effect problem, I re-recorded all my sound effect MP3s in Garage Band to
start with 300ms of silence. This created an apparent lag in the responsiveness of the game, but at least the user
could hear the entire sound.&lt;/p&gt;
&lt;p&gt;To make mute work, I had to change my code to actually stop the audio instead of setting volume to zero.
I also had to write 20 lines of behavior probing code to detect the non-functioning &lt;code&gt;.volume&lt;/code&gt; property
and offer iOS users an "ON"/"OFF" switch without the gradiated volume controls.&lt;/p&gt;
&lt;h1&gt;&lt;a&gt;&lt;/a&gt;Culprit #2: Behaviors and bugs&lt;/h1&gt;
&lt;p&gt;Although a lot of the behavior differences I've described above are annoying opinions, there are definitely also some
more forgivable but still annoying variances in behavior within the standards. And also, good old browser bugs.&lt;/p&gt;
&lt;h2&gt;Layout problems&lt;/h2&gt;
&lt;h3&gt;Fonts vary by platform, even when they shouldn't&lt;/h3&gt;

&lt;a href="https://zerotrickpony.com/articles/browser-bugs/fonts-comparison.jpg"&gt;
&lt;img src="https://zerotrickpony.com/articles/browser-bugs/fonts-comparison.jpg"/&gt;
&lt;/a&gt;

&lt;p&gt;&lt;strong&gt;Font names aren't reliable:&lt;/strong&gt;
I had a lot of small layout glitches caused by browser differences in choice of font, even fonts that could easily be
exactly the same on all platforms like &lt;code&gt;Arial&lt;/code&gt; and &lt;code&gt;Courier&lt;/code&gt;.
[17]
I fixed these by using custom &lt;code&gt;woff2&lt;/code&gt; fonts loaded
at game start. In a normal web application I think it's arguable that the application should set a specific font,
but in a game where the fonts are part of the aesthetic, this is table stakes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Aside: woff2 is great:&lt;/strong&gt;
On the bright side, I was pleasantly surprised at how consistent layout can be across platforms when using &lt;code&gt;woff2&lt;/code&gt; fonts
to prevent font fallback.
(And &lt;code&gt;display:grid&lt;/code&gt; is also very consistent, more on that later.)
These were well supported even on my worst browser (Firefox iOS) and my second worst browser (Safari on an old iOS 12
device I had lying around). It is &lt;em&gt;almost&lt;/em&gt; attainable to have pixel-perfect consistency across platforms with just
these two features. I had not realized how much fonts (and localization, if your project has that) are such a large
source of layout ambiguity.&lt;/p&gt;
&lt;p&gt;(Yes yes, expecting pixel-accurate layout across devices is unreasonable. Yes yes make your designs responsive
so that they'll gracefully handle any shape and size of screen and font setting. But since I'm making a &lt;em&gt;game&lt;/em&gt;,
the interaction design had a hard requirement of certain things being on the same screen relative to each other.
The normal vaguaries of the web would result in broken interactions. My responsive compromise was to define
five specific layout sizes and snap to each of those based on font and zoom settings. This made it easier to
trust that a playtest of the game would work for a given size of screen.)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Incorrect ligature defaults on Safari iOS:&lt;/strong&gt;
I used Google's very clever &lt;a href="https://fonts.google.com/icons"&gt;Material design icons&lt;/a&gt; to save myself a lot of
time drawing and flowing simple icons in the app. It's implemented with a kooky abuse of the ligature feature
of custom font faces, which... weird! But okay! Unfortunately even when pasting the Google-provided code
snippet verbatim, Safari's defaults for the &lt;code&gt;font-ligature&lt;/code&gt; property are not to spec, so Google's icons don't
work on older Safari iOS.
[18]
I was able to fix this easily just by explicitly setting the property, but it
wasted about an hour of my time debugging that.&lt;/p&gt;
&lt;h3&gt;Safari iOS: late to every party&lt;/h3&gt;
&lt;p&gt;Although all the browsers adopt new features in their own time, it is my unscientific sense that Safari is
unusually slow. And it had a few more bugs, as well. To wit:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unsupported flex gaps:&lt;/strong&gt;
There are a lot of situations where I prefer the mental model of &lt;code&gt;display:flex&lt;/code&gt; over &lt;code&gt;display:grid&lt;/code&gt;, but this
caused a number of cross-browser unpleasant surprises. First, Safari was unreasonably late to the party on
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Properties/column-gap#browser_compatibility"&gt;correctly supporting &lt;code&gt;row-gap&lt;/code&gt; and &lt;code&gt;column-gap&lt;/code&gt; with &lt;code&gt;flex&lt;/code&gt;&lt;/a&gt;,
even though they do what you expect with &lt;code&gt;grid&lt;/code&gt; as far back as iOS 12.
[19]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Flex shrink problems:&lt;/strong&gt;
Safari chooses to aggressively shrink text in &lt;code&gt;flex&lt;/code&gt; layouts in situations where other browsers do
not. Specifically it seemed to be related to when a &lt;code&gt;flex-grow&lt;/code&gt; area was marked as scrollable. Other browsers
would let the elements before and after the scrollable item size naturally, but Safari truncates them.
[20]
So after a lot of layout testing I had to sprinkle &lt;code&gt;flex-shrink:0&lt;/code&gt; in a bunch of places. Ugh.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missing support for lh units:&lt;/strong&gt;
I had used the &lt;code&gt;lh&lt;/code&gt; length unit in some of my layouts, not realizing that Safari didn't add support for this
&lt;a href="https://caniuse.com/?search=lh+unit"&gt;until last year&lt;/a&gt;.
[21]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missing support for scale syntax:&lt;/strong&gt;
In all browsers I tested except Safari iOS 12, you can say &lt;code&gt;transform:scale(50%)&lt;/code&gt; but this does not work on
Safari. I had to change these to &lt;code&gt;transform:scale(0.5)&lt;/code&gt;.
[22]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Missing support for ResizeObserver:&lt;/strong&gt;
Safari iOS now supports &lt;code&gt;ResizeObserver&lt;/code&gt; for reacting to element size changes, but it was last to do so. To
support older browsers I had to write some nasty timer-based measurement code.
[23]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Bugs in CSS custom properties:&lt;/strong&gt;
I tried to set the &lt;code&gt;background-image&lt;/code&gt; of my game using a &lt;code&gt;var(--my-background-url)&lt;/code&gt; CSS custom property.
This seemed to mostly work, but in my testing I found that if the custom property changes, Safari will not
propagate it correctly to the &lt;code&gt;BODY:backdrop&lt;/code&gt; element and will cause a missing background bug in full screen.
(I was also able to reproduce this on Safari MacOS, but no other MacOS browsers.)
[24]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Late support for smooth scrolling:&lt;/strong&gt;
I had code in my game to programmatically scroll an element during the tutorial, to show the user that
it can be scrolled. I set the &lt;code&gt;scroll-behavior:smooth&lt;/code&gt; CSS property so that the user's attention would be
drawn to the animating motion of the scrolling area. Older versions of Safari iOS disregarded this directive,
making the element pop instantaneously instead of visibly scrolling. This doesn't seem like a failure,
but without it my tutorial failed to teach the user something important.
[25]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Button spacing:&lt;/strong&gt;
Safari, and only Safari, adds a bunch of padding to their &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt; elements which you have to style
away if you care how big your buttons are.
[26]
(Maybe they do this to compensate for their hit target choices?)
Although the agent stylesheet is allowed to contain anything
it wants, in practice this can disrupt the intended layout. I didn't catch it until I did cross-browser testing.&lt;/p&gt;
&lt;h3&gt;meta viewport incantations&lt;/h3&gt;

&lt;img src="https://zerotrickpony.com/articles/browser-bugs/metaviewport-differences.jpg"/&gt;

&lt;p&gt;Single-page application designs that want to work on mobile will need to sprinkle attributes into the &lt;code&gt;meta&lt;/code&gt;
header tag in order to persuade mobile browsers to scale elements predictably:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;meta name="viewport" content="width=device-width, height=device-height, initial-scale=1"&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Without these directives, browsers apply various opinionated fudge factors to try to guess what the web
page &lt;em&gt;intended&lt;/em&gt; while disregarding how the web page is actually styled.
Viewport control directives are
very useful and worth understanding... but without them, desktop browsers tend to do about the same thing,
and mobile browsers do quite different things.
[27]&lt;/p&gt;
&lt;h3&gt;Firefox iOS has no idea where the edges of the screen are&lt;/h3&gt;
&lt;p&gt;Firefox iOS wins the award for least competent browser in this area:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Broken CSS units:&lt;/strong&gt; Firefox iOS has a &lt;a href="https://github.com/mozilla-mobile/firefox-ios/issues/11574"&gt;bug&lt;/a&gt;
which prevents use of the special &lt;code&gt;svh&lt;/code&gt; and &lt;code&gt;lvh&lt;/code&gt; units which are themselves workarounds to the
self-hiding address bar behavior that all the mobile browsers have.
[28]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Occluded layout on iPhone:&lt;/strong&gt; Newer iOS devices lack a physical home button, instead consuming the
bottom edge of the touch screen with a line-shaped affordance which the user is supposed to know to
swipe or touch depending on their intention. Applications are supposed to either stay out of that area
or draw transparently behind it. Firefox does neither! It simply draws your web page with some of the
bottom edge cut off, but only on these newer iOS devices.
[29]
Safari doesn't have this problem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Crash on fullscreen:&lt;/strong&gt; Firefox iOS overrides the &lt;em&gt;requestFullScreen&lt;/em&gt; function with an agent script...
but that agent script has a &lt;a href="https://github.com/mozilla-mobile/firefox-ios/issues/30540"&gt;bug&lt;/a&gt;
so that if you call it, you just get a Javascript error. Cool.
[30]&lt;/p&gt;
&lt;h3&gt;Mobile browsers have crazy behavior when you pinch zoom&lt;/h3&gt;
&lt;p&gt;To try to fill the screen on all platforms I admittedly made a fragile choice: I used &lt;code&gt;transform:scale&lt;/code&gt;
to ensure that the main screen element was centered and sized. This worked like a charm on all the
desktop browsers. And it &lt;em&gt;almost&lt;/em&gt; worked on all the mobile browsers too. Except that if the user
used pinch zoom in and then out again, the browser would draw the screen with a few pixels at the top
missing.
[31]
The more times the user did this, the more pixels would be missing.
[32]
My application was not receiving any resize, drag, or scroll events when this happened, and the measurements of the screen
as reported by &lt;code&gt;offsetTop&lt;/code&gt;, &lt;code&gt;scrollTop&lt;/code&gt;, etc were all unchanged. I spent many hours trying to find
a cause or workaround for this problem.&lt;/p&gt;
&lt;p&gt;Eventually I created an isolated test case, and fixed the problem by adding a &lt;code&gt;position:fixed;top:0;left:0;&lt;/code&gt;
style to the root element. There is &lt;strong&gt;no&lt;/strong&gt; standards-based reason why that should have
fixed the problem, but it did.&lt;/p&gt;
&lt;h2&gt;Animation and graphics woes&lt;/h2&gt;
&lt;p&gt;Games need more precisely controlled animations and visuals than is typical for a Wikipedia page
about raccoons. This caused me more than a few problems:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Text selection styling:&lt;/strong&gt;
It is technically possible to style the selected text using the &lt;code&gt;::selection&lt;/code&gt; pseudoclass, and I tried
to use this to create an animating typewriter effect in my game. Sadly,
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Selectors/::selection#browser_compatibility"&gt;this is not supported on Safari iOS&lt;/a&gt;
so I had to rework the animation to work by modifying the DOM in a Javascript loop. Inelegant but functional.
[33]&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Blur bugs:&lt;/strong&gt;
I used &lt;code&gt;filter:blur()&lt;/code&gt; and &lt;code&gt;backdrop-filter:blur()&lt;/code&gt; CSS properties in various places to
create glow and frosted glass effects for the game's visuals. These &lt;em&gt;sometimes&lt;/em&gt; worked in Safari,
but were broken in certain situations, like on &lt;code&gt;&amp;lt;svg&amp;gt;&lt;/code&gt; elements.
[34]
Safari was also late to support this
and needed a &lt;code&gt;-webkit-backdrop-filter:blur()&lt;/code&gt; variation to get the visual effect to appear
on older tablets.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Sync animations:&lt;/strong&gt;
The &lt;code&gt;animation&lt;/code&gt; CSS property is surprisingly excellent, a much needed alternative to the often
useless &lt;code&gt;transition&lt;/code&gt; system, especially on browsers that don't yet support the just-added &lt;code&gt;content-visibility&lt;/code&gt;
property. (There, I said something nice about web standards.)
There's a &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Animation"&gt;Javascript API&lt;/a&gt;
to manipulate and restart animations so that (for example) blinking warning lights can be sync'd
up with each other. As usual my 2019 iPad was just old enough to not support this.
[35]
I didn't bother with any workaround, so on older tablets this remains a glitch.&lt;/p&gt;
&lt;h2&gt;Audio problems&lt;/h2&gt;
&lt;p&gt;Apple's audio opinions described above were the biggest problem with audio, but Apple wasn't the only culprit:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Error on play interruption:&lt;/strong&gt;
Chrome, and only Chrome, is of the opinion that it's a bug to &lt;code&gt;.pause()&lt;/code&gt; or assign &lt;code&gt;.currentTime&lt;/code&gt; on an audio
element while a previous &lt;code&gt;.play()&lt;/code&gt; request is "in progress", whatever that means. The other browsers will simply
fulfill your request, but not Chrome. Chrome generates an unhandled promise rejection which looks like a game
crash when the audio pauses.
[36]
So I had to write some complicated guarding logic to protect the audio widgets
from concurrent manipulation during their sensitive moments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Popping and skipping sounds:&lt;/strong&gt;
Firefox on both MacOS and Android cannot seem to just run an &lt;code&gt;OscillatorNode&lt;/code&gt; competently. Before I switched away from &lt;code&gt;AudioContext&lt;/code&gt;,
I found that although Chrome and Safari on MacOS could play my graph of sound effects smoothly, Firefox
introduced "pops" (audio artifacts caused by incorrectly reproducing a sound wave) and missing sounds.
[37]
I was able to mostly fix these by adding more attenuation ramps and silence at the start and end of sounds,
but I definitely shouldn't have to. Avoiding mathematical errors that cause popping sounds should be
table stakes for any piece of software that produces audio. You guys.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Safari iOS late to support AudioContext:&lt;/strong&gt;
&lt;code&gt;AudioContext&lt;/code&gt; is documented as &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext#browser_compatibility"&gt;fully supported&lt;/a&gt;
since forever, but you have to read the fine print! The function has been in Safari iOS
for many years, but only if you call it via the special &lt;code&gt;webkitAudioContext&lt;/code&gt;.
[38]
It was only renamed to match the other browsers a couple years ago. So that wasted a half hour of my
time to chase down.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;iPad GainNode timings inaccurate:&lt;/strong&gt; I found that Safari on iOS 12 does not honor linear gain ramps the way other browsers do.
[39]
So even once my sound effects were audible,
they sounded like strange whooping slide whistles on iPad even though they sounded correct on Android and MacOS.
I can't tell if this is a bug or an opinion, but either way, it was unacceptable. These two problems caused me
to abandon the &lt;code&gt;AudioContext&lt;/code&gt; API entirely. (My iOS 17 device doesn't have this behavior, so I guess Safari agreed
that it was a bug.)&lt;/p&gt;
&lt;h2&gt;Other interactions&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Drag and drop control:&lt;/strong&gt; My drag-and-drop Safari woes were not only caused by Apple's strong opinions. I found that I had quite
a few touch screen bugs caused by varying interpretations of CSS and HTML standards. For example, I was
using &lt;code&gt;inert=true&lt;/code&gt; to prevent interactions, but older Safari browsers ignore this attribute.
[40]
I had to also add &lt;code&gt;user-select:none; -webkit-user-select:none; pointer-events:none;&lt;/code&gt; in various places to get
Safari to stop showing my users unwanted text selection areas when dragging was wanted.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Draggable sprites:&lt;/strong&gt; I did get dragging to work on Safari iOS, but I found that if the &lt;code&gt;draggable&lt;/code&gt; element is a &lt;code&gt;&amp;lt;span&amp;gt;&lt;/code&gt;
which wraps to the next line, then Safari will garble the visual effect of the dragged sprite as
it moves on the screen.
[41]
I ended up reworking the draggable elements to ensure that they could never have a line break.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Clipboard API:&lt;/strong&gt; I used the clipboard API for a simple import/export game feature, since it is documented as
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/Clipboard#browser_compatibility"&gt;fully supported&lt;/a&gt;
on all major browsers. As usual Safari iOS was the last to add support, and I found that my old iPad
was &lt;em&gt;just&lt;/em&gt; old enough to fail with this API.
[42]&lt;/p&gt;
&lt;h2&gt;Microsoft Edge: copying Chrome's homework real hard&lt;/h2&gt;
&lt;p&gt;The only browser I tested which needed (almost) no rework was Microsoft Edge on Windows 10.&lt;/p&gt;

&lt;img src="https://zerotrickpony.com/articles/browser-bugs/scrollbar-unstyled.jpg"/&gt;

&lt;h3&gt;Styling for traditional scrollbars&lt;/h3&gt;
&lt;p&gt;The one problem I observed with Edge was scrollbar styling.
On Windows 10 the default scroll bar type is more likely to be "traditional" than
"overlay", so I happened to notice that glaring white scrollbars were shown in my dark-themed space game.
[43]
This situation can arise on any OS, not just Windows, because "always show scrollbars" is a user-facing accessibility setting on
several platforms.&lt;/p&gt;
&lt;p&gt;I fixed this by styling darker scrollbars for all browsers using the newly
available &lt;code&gt;scrollbar-color&lt;/code&gt; CSS property.
(Except for Safari, [44] which requires a &lt;code&gt;::-webkit-scrollbar&lt;/code&gt; pseudoclass, of course.)&lt;/p&gt;
&lt;p&gt;Other than this issue, Microsoft Edge was impressively trouble-free.
It passed my full test suite on the first try, and had no other platform-specific problems.
I attribute this not particularly to the skill of Microsoft, but that my game was already very well tested on
Chrome MacOS. Edge seems not to have diverged much at all from the Chrome ancestry from which was is forked.&lt;/p&gt;
&lt;h1&gt;&lt;a&gt;&lt;/a&gt;Culprit #3: Mobile Redesign&lt;/h1&gt;
&lt;p&gt;Zero web druids will be surprised to hear me say that the biggest source of pain with designing a polished,
interactive HTML5 application is the difference in browser behavior between &lt;strong&gt;phones and tablets&lt;/strong&gt; vs desktop computers.
Of course within the priesthood we consider "responsive design" to be table stakes. But taking a step back
from our craft for a moment: is it so crazy for a novice developer to expect that they could design a
web-based project on their laptop and see it work fine on a phone with no changes? Why can't this be a reality?&lt;/p&gt;
&lt;p&gt;Early on in the popularization of touch screens, manufacturers like Apple made some reasonable but aggressive
decisions to permanently fracture the desktop and mobile browsing experiences.
I don't think these were bad decisions! When a user has a small touch screen, the most efficient interactions for them aren't
the same as when they have a very large display, a mouse or trackpad, and a hard keyboard.
But it did double the size of the design space, and theoretically, this could have been avoided.&lt;/p&gt;
&lt;p&gt;Here are some mobile-specific snags I hit while cosplaying a novice web developer:&lt;/p&gt;
&lt;h2&gt;Tapping and touching&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Dragging does what, part 2:&lt;/strong&gt; You would think that dragging would work easily on touch screens,
and I did sort of expect that my game's drag-and-drop interactions would port nicely to mobile.
Except no! Because mobile browsers have reserved dragging for themselves. Vertical swipe,
edge-swipe, and other finger-drag type inputs
command the browser to scroll, navigate, and select text. Those events either don't reach the web
page's elements at all, or they are delivered as an overload with other interactions.
[45]
Various CSS hints like &lt;code&gt;pointer-events:none;&lt;/code&gt; and &lt;code&gt;user-select:none&lt;/code&gt; must be sprinkled into the page
to control these interactions more carefully.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Surprise zoom:&lt;/strong&gt; One silly example is double-tapping. The &lt;code&gt;&amp;lt;button&amp;gt;&lt;/code&gt; element which was designed to submit forms
to a server never needs to be repeatedly tapped. But in a game, the user may repeatedly tap to fire a weapon
or move a gamepiece. On mobile, these repeated taps will rather surprisingly zoom in on the
button.
[46]
These elements must be given the magical &lt;code&gt;touch-action:manipulation;&lt;/code&gt; CSS style to
hint that double-tapping should not be interpreted by the browser. One more thing to know.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What do you call it?&lt;/strong&gt; This is a very small thing, but induced a fair amount of rework for me so
I will mention it here: My game has on-screen instructions which tell the user how to play.
A web page about raccoons would not need to provide instructions saying, "here is how to scroll
down! Here is how to click hyperlinks!" ...but a game does need this! My original prototype
had a lot of "click the arrow to continue" type text, but the word "click" is not intuitive
language for someone using a touch screen. I could have left it in, figuring that most people
could make the deductive leap that anything that could be "clicked" with a mouse they didn't
have could also be "tapped" using their available fingers. Since I wanted the game to feel
as native as possible, I didn't want to leave this in. But I couldn't think of any single
verb that would feel equally intuitive to both mouse and touch users?
[47]
So I added complexity to the game to &lt;a href="https://peterscene.com/blog/detecting-touch-devices-2018-update/"&gt;detect the presence of a touch screen&lt;/a&gt;,
which is much harder than it sounds, and use the word "click" or "tap" depending on the device.&lt;/p&gt;
&lt;h2&gt;Hovering&lt;/h2&gt;
&lt;p&gt;Not because hovering is the most pivotal interaction, but it's a simple example of a willful divergence:
When the user places their mouse inside a region of the screen, that region's "hover" interactions will trigger.
This can be used for non-essential visual texture such as slightly brightening a button to cue its
interactivity. But it &lt;em&gt;could&lt;/em&gt; be (and is) used for anything else, like revealing a hidden sub-menu which
is critical to the user's task success.&lt;/p&gt;
&lt;p&gt;Arguably, mobile browsers &lt;em&gt;could have been&lt;/em&gt; designed to give touch screen users a way to use interfaces
designed for a mouse. As a strawman example, Safari for iPhone could show a little crosshair that you move around with
your finger. When the crosshair enters a region of the screen, that region's &lt;code&gt;:hover&lt;/code&gt; interaction could be
shown, giving the touch screen user the same experience as a mouse user.
But mobile browser designers &lt;em&gt;purposefully chose&lt;/em&gt; to take away the ability to easily express hovering. I'm not saying
this was a bad choice: interpreting finger motions as immediate actions saves the user time and dexterity
difficulties. Moving a crosshair around might be annoying and difficult.&lt;/p&gt;
&lt;p&gt;Apple probably set this standard by being the first to sell an extremely popular touch screen web browser,
so they made this decision for all of us. Right or wrong, this decision means that users can't experience hover
interactions on their iPad. If a developer creates an important hover-based interaction, then they have
introduced an &lt;strong&gt;unsolvable design flaw&lt;/strong&gt; into their user interface which they won't discover without a
mobile testing lab.&lt;/p&gt;
&lt;p&gt;Is &lt;code&gt;:hover&lt;/code&gt; a web standard? Supposedly yes.
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Selectors/:hover#browser_compatibility"&gt;MDN&lt;/a&gt; and
&lt;a href="https://caniuse.com/?search=hover"&gt;caniuse&lt;/a&gt; both list it as "widely available" and describe it as "fully supported"
on mobile browsers. Caniuse mentions an iOS Safari glitch, but doesn't say "this will basically never work on mobile"
even though it should.
[48]
MDN is better, with a blue callout warning the developer to consider "accessibility"
on "devices with limited hovering capabilities". This is technically true but undersells the case pretty significantly.
Here's what MDN &lt;em&gt;should&lt;/em&gt; say:&lt;/p&gt;
&lt;code&gt;
&lt;blockquote&gt;
&lt;p&gt;Hover is effectively unusable on the world's most popular browsers and devices.
Web projects which seek to work consistently for all users should &lt;strong&gt;refrain entirely&lt;/strong&gt; from using this feature.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/code&gt;
&lt;p&gt;The web standards don't say this because web standards aren't trying to create a consistent experience for all
users. There &lt;em&gt;is&lt;/em&gt; tribal knowledge amongst seasoned professional web developers that hover "shouldn't" be used for
any "critical" interactions like providing the user with instructions, or concealing interactive elements necessary
for primary task completion. But if our novice designer/developer created a hover-based interaction and it worked on their
computer, they will not discover until mobile testing that they have stepped outside the safe harbor, and now
need to majorly rework their design.&lt;/p&gt;
&lt;h2&gt;Soft keyboard&lt;/h2&gt;
&lt;p&gt;There's a bunch of completely reasonable interactions that a novice developer could build without
thinking about the fact that they depend upon the user having a physical keyboard. Most mobile users
have access to only a soft keyboard, which (a) lacks a few capabilities and (b) consumes an exhorbitant
amount of screen space. This screen space is almost always better allocated to something else, which is
why mobile browsers aggressively hide the soft keyboard. Here's some problems that are easy to hit:&lt;/p&gt;
&lt;h3&gt;Shift-click&lt;/h3&gt;
&lt;p&gt;An early prototype of my game accelerated certain interactions with shift-click. But shift-click is not
offered on a mobile device, so these interactions had to be redesigned for mobile.
[49]
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/MouseEvent/shiftKey"&gt;MDN&lt;/a&gt; lists the &lt;code&gt;shiftKey&lt;/code&gt;
property of MouseEvent as "widely supported", even though soft keyboards on mobile will &lt;strong&gt;NOT&lt;/strong&gt; deliver
this event with &lt;code&gt;shiftKey&lt;/code&gt; set to true, ever. Safari at least has the honesty to say that
it's &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/TouchEvent/shiftKey#browser_compatibility"&gt;unsupported on TouchEvent&lt;/a&gt;.
The rest of the browsers document it as "supported" even though this will 100% not do what
the developer intends.&lt;/p&gt;
&lt;p&gt;You could argue that MouseEvent is obviously unsafe on mobile because there is no mouse. But despite the
name, mobile browsers &lt;em&gt;do&lt;/em&gt; work hard to transparently support the "click" event when the user taps,
and they deliver a &lt;code&gt;MouseEvent&lt;/code&gt; when the touch happens. There was clearly some attempt to ensure that
&lt;code&gt;MouseEvent&lt;/code&gt; was part of the "safe harbor" we all wish existed, but it's not a complete attempt.&lt;/p&gt;
&lt;p&gt;I hope at this point you're yelling at your screen, "these are accessibility design problems! You can't
expect MDN to protect you from not designing properly!!!" And to that I say --- I hear you, but,
are we sure about that? Consider: One major reason why accessibility is so bad across modern computer interfaces is that
&lt;strong&gt;developers must do something extra to offer accessibility&lt;/strong&gt;. But these secondary quality characteristics
will always be, well, secondary. One way we could have ensured that designs are accessible is to
&lt;strong&gt;make it impossible to build anything else.&lt;/strong&gt; Instead, we've filled the standard web API with conditional features that
don't work for most people, and then we describe them as "widely supported". We are making this
problem worse when we could be making it better.&lt;/p&gt;
&lt;h3&gt;Text input&lt;/h3&gt;

&lt;img src="https://zerotrickpony.com/articles/browser-bugs/soft-keyboard-landscape.jpg"/&gt;

&lt;p&gt;The &lt;code&gt;&amp;lt;input&amp;gt;&lt;/code&gt; tag is like 30 years old, but that has apparently not been enough time for us to figure
out how to make it usable! My original game design had a good amount of typing in it, to let the user input their
guesses to solve a mystery. When I first tested this experience on mobile, I found that the soft keyboard's
consumption of the screen almost always covered up or reflowed an important clue that the user needed
to read as they typed their guess.
[50]
Worse, the game is wide-screen so the user would likely have their
phone tilted to landscape mode. In this orientation, the soft keyboard consumes much more than 50% of the
vertical screen space. What's left is almost entirely consumed by the text input area.
[51]&lt;/p&gt;
&lt;p&gt;This seemingly reasonable allotment of space leaves nothing for the clue context. This made the game
unplayable and required me to dramatically rework the design to eliminate typing. I spent more engineering
time on this rework than on any other single change for mobile. If I had prototyped on mobile first, I would
have realized this problem much sooner.&lt;/p&gt;
&lt;h3&gt;Input focus&lt;/h3&gt;
&lt;p&gt;With a hard keyboard device, calling &lt;code&gt;.focus()&lt;/code&gt; on a likely input element can be an incidental
convenience. It gives the user a very gentle hint at interactivity, and saves them a click if they would
like to start typing. But they can also easily ignore the focused element, and click something else on the
screen if they like.&lt;/p&gt;
&lt;p&gt;Soft and hard keyboards both need the unfortunate concept of keyboard focus, usually indicated
by some extra bold outlines and a blinking vertical line which users understand to be a "cursor".
Unlike on a laptop, a soft keyboard also needs a cue for when it is wanted. Showing the soft keyboard when
it is unwanted is an annoyance because of how much screen space it wastes. But &lt;em&gt;&lt;strong&gt;failing&lt;/strong&gt;&lt;/em&gt; to show
the soft keyboard when it is wanted fully prevents primary task completion. They need to type, and cannot.
Disaster.&lt;/p&gt;
&lt;p&gt;So I definitely sympathize with mobile browsers that show the soft keyboard on &lt;code&gt;.focus()&lt;/code&gt; of any input
element. But if any web page does focus an element, the soft keyboard will take over most of the screen.
[52]
The user will be &lt;em&gt;shut out of all other tasks&lt;/em&gt; until they dismiss the gigantic soft keyboard. This means
that calling &lt;code&gt;.focus()&lt;/code&gt; should only be done when the input is assured to be the primary task. It cannot
be used incidentally like it can on desktop.&lt;/p&gt;
&lt;h2&gt;Responsive layout: yes you have to&lt;/h2&gt;
&lt;p&gt;A lot of the documentation at large about designing for mobile will mention "responsive design". You could be
forgiven for thinking that the entirety of this concept is just learning how to set up the confusingly named
&lt;a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Guides/Media_queries/Using"&gt;media queries&lt;/a&gt; to conditionalize
a web page's layout. There is a lot of advice about responsive design out there, not all of it wise. So here's
what I think is the heart of it:&lt;/p&gt;
&lt;h3&gt;Design for mobile first&lt;/h3&gt;
&lt;p&gt;Unless your HTML5 project is a static list of raccoon facts shown in a single column of black text on a white
background, it is unlikely that a UX designed for a desktop browser will also be usable on a phone.
[53]
You're more likely to have a phone design look okay on desktop than the other way around. So if you really really don't
want to create two separate designs, you need to iterate your design on a mobile phone first. (Or at the very
least a mobile simulator like is integrated into Chrome and Firefox.)&lt;/p&gt;
&lt;h3&gt;You probably need at least two layouts&lt;/h3&gt;
&lt;p&gt;Web designers these days seem unable to resist cramming the margins of web pages with hamburger
menus, nav bars, chat bots, and ads. None of these will look right on a phone's tall, narrow screen.
[54]
So if you can't refrain
from multi-column layout, you will need to make at least two different layouts: a single-column
layout for phones and then a multi-column layout for desktop browsers.&lt;/p&gt;
&lt;h3&gt;No you can't control the real size of anything&lt;/h3&gt;
&lt;p&gt;CSS has a &lt;a href="https://developer.mozilla.org/en-US/docs/Learn_web_development/Core/Styling_basics/Values_and_units"&gt;wealth of units&lt;/a&gt;
which you might imagine can give you all the options you need to make text and controls the right size on
screens big and small. But these are all &lt;a href="https://developer.mozilla.org/en-US/docs/Learn_web_development/Core/Styling_basics/Values_and_units#numbers_lengths_and_percentages"&gt;lies&lt;/a&gt;, even the ones like &lt;code&gt;cm&lt;/code&gt; and &lt;code&gt;mm&lt;/code&gt; which sound like they
should, you know, be SI distances like we learned in school. Actually, a CSS &lt;code&gt;cm&lt;/code&gt; is defined as a certain number of
&lt;code&gt;px&lt;/code&gt;, and &lt;code&gt;px&lt;/code&gt; are defined as a certain number of &lt;code&gt;cm&lt;/code&gt;. How big is a &lt;code&gt;px&lt;/code&gt; really, then? &lt;strong&gt;You can't know.&lt;/strong&gt;
[55]&lt;/p&gt;
&lt;p&gt;The actual explanation I like best is buried in the fine print on MDN:&lt;/p&gt;
&lt;code&gt;
&lt;blockquote&gt;
&lt;p&gt;Note that 1px doesn't necessarily equal one physical device pixel.
On HD displays, it may span multiple physical pixels.
Similarly, 1cm in CSS often doesn't correspond to one hundredth of SI meter.
On a large TV screen, it typically is longer than that. The lengths are perceptual:
16px looks roughly the same on a phone, laptop, or TV screen at typical viewing distance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/code&gt;
&lt;p&gt;...the "perceptual" distances are determined by the device manufacturer, and then nudged by the
zoom fudge factor from the user's accessibility settings. So you'll have more luck reasoning about
the information density of "screenfuls" of your design, rather than trying to make a hit target the
"natural size" of a real-world object like a book or the size of a hit target for someone's fingertip.
(The latter is a sensible goal but purposely impossible on the web.)&lt;/p&gt;
&lt;p&gt;So for example, if you set your smallest readable font size to about &lt;code&gt;16px&lt;/code&gt; with a &lt;code&gt;line-height&lt;/code&gt; of &lt;code&gt;22px&lt;/code&gt;,
then you can (roughly) reason that about ten lines of text will fit on a &lt;code&gt;220px&lt;/code&gt; high area of the screen.
This is no help at all in determining the &lt;em&gt;size&lt;/em&gt; of the layout, but it will tell you roughly how much
the user can see at once on a mobile screen. Chrome and Firefox have "responsive design" modes in their
developer tools that you can use to get a sense of this.&lt;/p&gt;
&lt;h1&gt;&lt;a&gt;&lt;/a&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This exercise to write an HTML5 game has generated ample evidence that web standards are doing little to threaten
the thriving occupation of web druid in the year 2025. I realize building a game in vanilla.js is a strange
choice, but I think anyone would hit many of these surprises trying to build any single-page application
design which handled media or had any input interactions. And, I remind you, these were just the problems
that surprised &lt;em&gt;me&lt;/em&gt;, and I have been doing web development since the 1990s. How much worse would this
be for someone inexperienced?&lt;/p&gt;
&lt;p&gt;Blundering into a multi-browser interactive HTML5 project without any thought put towards best
practices, mobile design, or having a testing lab will not result in a functioning UX. For the dream
of "write once run anywhere", HTML5 seems another broken promise. May it rest with the likes of Electron,
Fluttr, Java, Flash, and all the failed abstractions that have come before and since.&lt;/p&gt;
&lt;p&gt;On the bright side, HTML5 has a lot to like as a development platform. And it's &lt;em&gt;much&lt;/em&gt; better than it was even just
5 years ago. No I didn't avoid the need for a testing lab. But it's tremendously helpful to have a &lt;em&gt;mostly&lt;/em&gt; consistent
set of concepts and documentation that can apply to all targeted platforms. Cross-browser and cross-device
development costs aren't &lt;em&gt;eliminated&lt;/em&gt;, no. But they are greatly reduced. (&lt;strong&gt;Especially&lt;/strong&gt; if you choose your primary
testing device wisely: an old iPhone.)
Compared to, say, the cost of developing a Swift app for iOS and then a Kotlin app for Android, and then
still needing desktop and Windows support after that... HTML5 is great.&lt;/p&gt;
&lt;p&gt;Browsers also remain a superior delivery platform vs. native installs for casual and untrusted content.
Users can (mostly) rest easy knowing that your web-based project is not risking their device or
stealing their stuff. And visiting a URL is still less friction than a native install. So HTML5 is
a great choice for projects where friction should be as low as possible.&lt;/p&gt;
&lt;h3&gt;&lt;a&gt;&lt;/a&gt;Footnote: Should I use HTML5 to make games?&lt;/h3&gt;
&lt;p&gt;Probably not? The above 50ish problems should give you a flavor of the costs and limitations of trying to
make a polished, interactive experience. A larger reason not to choose HTML5 for game-like
interactions is just that it isn't very capable. You can trick your way into doing a lot with animation
frameworks like &lt;a href="https://animejs.com/"&gt;animeJS&lt;/a&gt;, or you could do 3D with webGL. But a purpose-built
game framework like Unity would have polyfill to protect you from more of these layout and audio
problems. And unlike with information pages about raccoons, game players seem happy to
receive game applications through the various app stores (Apple, Android, Steam, Playstation)
they've decided to trust.&lt;/p&gt;
&lt;h3&gt;Footnote: How could this be better?&lt;/h3&gt;
&lt;p&gt;It's tempting to feel like a grand technical fix is needed. For the industry to keep developing ever-more
insulating polyfill frameworks which abstract away ever more of animation, media, layout, CSS, and all the
rest of the core web. But I think this is both overkill and unlikely to succeed, because so many have tried and failed at
this already. (Please stop making more frameworks!)&lt;/p&gt;
&lt;p&gt;The unglamorous answer is that this might be just a &lt;strong&gt;documentation problem&lt;/strong&gt;. &lt;a href="https://developer.mozilla.org/en-US/"&gt;MDN&lt;/a&gt;
is pretty good, even though Mozilla increasingly concerns me as a steward of the open web. What if
it were just a little better?&lt;/p&gt;
&lt;p&gt;One problem with MDN is that if you're trying to build a truly polished, consistent experience across many
browsers, there's almost more features to avoid than to use. What if you could tick a box in the upper
right corner of the documentation page saying "I want to support all these devices" and then the MDN pages
would change to hide features that won't work, show example code that's already tested on
all the devices you selected, and show you what percentage of users will have success with the set of browsers
you picked? Wouldn't that be nice? (The Android API docs and the Node.js docs have features that go toward this
idea, though they don't do it quite so thoroughly.)&lt;/p&gt;
&lt;h3&gt;Footnote: achieving a polished experience&lt;/h3&gt;
&lt;p&gt;Although I think there's good evidence for a lack of a "safe harbor" &lt;em&gt;feature set&lt;/em&gt; in HTML5, there &lt;em&gt;is&lt;/em&gt; a way to
enjoy low development costs and easily use HTML5 to support many devices and browsers:
simply &lt;strong&gt;don't care much about the user experience.&lt;/strong&gt; If you don't mind your users hitting glitches,
setbacks, and frustrations as they try to read your text, see your images, and fill out your input forms,
then HTML5 will be very affordable for your project.&lt;/p&gt;
&lt;p&gt;Browsers are designed to be the end user's self-service toolkit to combat our bad websites.
Users can override fonts, mute sounds, enlarge text, pinch-zoom in, open images in a separate tab, copy-and-paste, autofill rote form inputs,
switch to "simplified reading mode", search for the same information elsewhere, reload the page to reset Javascript bugs,
and even try a different browser to see if they happen to have the one on their computer that we bothered to test.&lt;/p&gt;
&lt;p&gt;The problem with my project was that I wanted to &lt;strong&gt;meet a high quality bar&lt;/strong&gt; for smoothness and polish in the resulting app.
Games are supposed to be fun, and frustration from glitches is not fun. As a result, games are some of the highest-quality
user experiences the software industry makes. Game developers &lt;strong&gt;care much more&lt;/strong&gt; than the average software team about the
consistency of look, feel, and smoothness of their UX. Polish was the real source of my high development costs.&lt;/p&gt;
&lt;h3&gt;Footnote: a damning case against vanilla.js?&lt;/h3&gt;
&lt;p&gt;I admit that all these snags made me a bit more pessimistic about using "bare" HTML5 for projects. But
counterpoint, there is no popular web framework that would have polyfilled &lt;em&gt;all&lt;/em&gt; these particular
issues away either. React, tailwind, bootstrap, Angular etc do not try to &lt;em&gt;entirely&lt;/em&gt; abstract things
like CSS, animations, text input, touch input, and media playback. Some of the widget library frameworks would have helped,
but I would still have had a lot of these problems. Unity and Godot might be better choices, but I have
no experience with them and I assume they only make sense for games.&lt;/p&gt;
&lt;p&gt;For my own web projects, I have an ever-growing proprietary polyfill library into which I encode best
practices. And I know from experience that large web shops do the same. Oh well.&lt;/p&gt;

Index
&lt;ul&gt;
&lt;li&gt;&lt;a href="#introduction"&gt;Introduction&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#tldr"&gt;tl;dr advice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#apple"&gt;Culprit 1: Apple's opinions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#bugs"&gt;Culprit 2: Behaviors &amp;amp; bugs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#mobile"&gt;Culprit 3: Mobile redesign&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#conclusion"&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#footnotes"&gt;Footnotes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;


&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://zerotrickpony.com/articles/browser-bugs/</guid>
      <category>Hacker News</category>
      <pubDate>Thu, 18 Dec 2025 04:55:18 +0000</pubDate>
    </item>
    <item>
      <title>Go-boot: bare metal Go UEFI boot manager</title>
      <link>https://github.com/usbarmory/go-boot</link>
      <description>The go-boot project is a TamaGo unikernel implementing a UEFI
Shell and OS loader for AMD64 platforms, allowing UEFI API interaction and OS
loading.</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;h1&gt;Introduction&lt;/h1&gt;&lt;a href="#introduction"&gt;&lt;/a&gt;
&lt;p&gt;The &lt;a href="https://github.com/usbarmory/go-boot"&gt;go-boot&lt;/a&gt; project is a
&lt;a href="https://github.com/usbarmory/tamago"&gt;TamaGo&lt;/a&gt; unikernel implementing a UEFI
Shell and OS loader for AMD64 platforms, allowing UEFI API interaction and OS
loading.&lt;/p&gt;
&lt;p&gt;The OS loading functionality supports launching of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;.&lt;/code&gt; EFI application images&lt;/li&gt;
&lt;li&gt;&lt;code&gt;l&lt;/code&gt; Linux kernels, with configuration parsed from Linux Userspace API (UAPI) &lt;a href="https://uapi-group.org/specifications/specs/boot_loader_specification/"&gt;boot loader entries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;w&lt;/code&gt; Windows UEFI boot manager&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The support of
&lt;a href="https://github.com/usbarmory/boot-transparency"&gt;boot-transparency&lt;/a&gt; is planned
for future releases.&lt;/p&gt;
&lt;h1&gt;Authors&lt;/h1&gt;&lt;a href="#authors"&gt;&lt;/a&gt;
&lt;p&gt;Andrea Barisani
&lt;a href="mailto:andrea@inversepath.com"&gt;andrea@inversepath.com&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Operation&lt;/h1&gt;&lt;a href="#operation"&gt;&lt;/a&gt;
&lt;p&gt;The default operation is to present an UEFI shell and its help, the ⏎ shortcut
(identically to &lt;code&gt;l&lt;/code&gt; or &lt;code&gt;linux&lt;/code&gt;) boots the default UAPI entry set at compile
time (see &lt;em&gt;Compiling&lt;/em&gt;).&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Shell&amp;gt; go-boot.efi

initializing EFI services
initializing console (text)

go-boot • tamago/amd64 (go1.24.1) • UEFI x64

.               &amp;lt;path&amp;gt;                   # load and start EFI image
build                                    # build information
cat             &amp;lt;path&amp;gt;                   # show file contents
clear                                    # clear screen
cpuid           &amp;lt;leaf&amp;gt; &amp;lt;subleaf&amp;gt;         # show CPU capabilities
date            (time in RFC339 format)? # show/change runtime date and time
efivar          (verbose)?               # list UEFI variables
dns             &amp;lt;host&amp;gt;                   # resolve domain
exit,quit                                # exit application
halt,shutdown                            # shutdown system
info                                     # runtime information
linux,l         (loader entry path)?     # boot Linux kernel image
linux,l,\r                               # `l \loader\entries\arch.conf`
log                                      # show runtime logs
ls              (path)?                  # list directory contents
lspci                                    # list PCI devices
memmap          (e820)?                  # show UEFI memory map
mode            &amp;lt;mode&amp;gt;                   # set screen mode
net             &amp;lt;ip&amp;gt; &amp;lt;mac&amp;gt; &amp;lt;gw&amp;gt; (debug)? # start UEFI networking
peek            &amp;lt;hex offset&amp;gt; &amp;lt;size&amp;gt;      # memory display (use with caution)
poke            &amp;lt;hex offset&amp;gt; &amp;lt;hex value&amp;gt; # memory write   (use with caution)
protocol        &amp;lt;registry format GUID&amp;gt;   # locate UEFI protocol
reset           (cold|warm)?             # reset system
stack                                    # goroutine stack trace (current)
stackall                                 # goroutine stack trace (all)
stat            &amp;lt;path&amp;gt;                   # show file information
uefi                                     # UEFI information
uptime                                   # show system running time
windows,win,w                            # launch Windows UEFI boot manager

&amp;gt; uefi
UEFI Revision ......: 2.70
Firmware Vendor ....: Lenovo
Firmware Revision ..: 0x1560
Runtime Services  ..: 0x90e2eb98
Boot Services ......: 0x6bd17690
Frame Buffer .......: 1920x1200 @ 0x4000000000
Configuration Tables: 0x8f426018
  ee4e5898-3914-4259-9d6e-dc7bd79403cf (0x8db6dc98)
  dcfa911d-26eb-469f-a220-38b7dc461220 (0x8b037018)
...

&amp;gt; memmap
Type Start            End              Pages            Attributes
02   0000000090000000 0000000090000fff 0000000000000001 000000000000000f
...

&amp;gt; linux \loader\entries\arch.conf
loading boot loader entry \loader\entries\arch.conf
go-boot exiting EFI boot services and jumping to kernel
Linux version 6.13.6-arch1-1 (linux@archlinux) (gcc (GCC) 14.2.1 20250207, GNU ld (GNU Binutils) 2.44)
...
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Package documentation&lt;/h1&gt;&lt;a href="#package-documentation"&gt;&lt;/a&gt;
&lt;p&gt;&lt;a href="https://pkg.go.dev/github.com/usbarmory/go-boot"&gt;&lt;img alt="Go Reference" src="https://camo.githubusercontent.com/1280be51cfaca015309656f9d1ca547200be57cb206155ba8b2f847901aa08d8/68747470733a2f2f706b672e676f2e6465762f62616467652f6769746875622e636f6d2f75736261726d6f72792f676f2d626f6f742e737667"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1&gt;Hardware Compatibility List&lt;/h1&gt;&lt;a href="#hardware-compatibility-list"&gt;&lt;/a&gt;
&lt;p&gt;The list of supported hardware is available in the
project wiki &lt;a href="https://github.com/usbarmory/go-boot/wiki#hardware-compatibility-list"&gt;HCL&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The list provides test &lt;code&gt;IMAGE_BASE&lt;/code&gt; values to pass while &lt;em&gt;Compiling&lt;/em&gt;.&lt;/p&gt;
&lt;h1&gt;Compiling&lt;/h1&gt;&lt;a href="#compiling"&gt;&lt;/a&gt;
&lt;p&gt;Build the &lt;a href="https://github.com/usbarmory/tamago-go"&gt;TamaGo compiler&lt;/a&gt;
(or use the &lt;a href="https://github.com/usbarmory/tamago-go/releases/latest"&gt;latest binary release&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget https://github.com/usbarmory/tamago-go/archive/refs/tags/latest.zip
unzip latest.zip
cd tamago-go-latest/src &amp;amp;&amp;amp; ./all.bash
cd ../bin &amp;amp;&amp;amp; export TAMAGO=`pwd`/go
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following environment variables configure the &lt;code&gt;go-boot.efi&lt;/code&gt; executable
build:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;IMAGE_BASE&lt;/code&gt;: must be set (in hex) within a memory range
available in the target UEFI environment for the unikernel allocation, the
&lt;a href="https://github.com/usbarmory/go-boot/wiki#hardware-compatibility-list"&gt;HCL&lt;/a&gt; or
&lt;code&gt;memmap&lt;/code&gt; command from an &lt;a href="https://github.com/pbatard/UEFI-Shell"&gt;UEFI Shell&lt;/a&gt;
can provide such value, when empty a common default value is set.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;DEFAULT_EFI_ENTRY&lt;/code&gt;: defines the &lt;code&gt;.&lt;/code&gt; shortcut entry path
for EFI image loading, it defaults to &lt;code&gt;\efi\boot\bootx64.efi&lt;/code&gt;
when unspecified.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;DEFAULT_LINUX_ENTRY&lt;/code&gt;: defines the &lt;code&gt;linux,l,\r&lt;/code&gt; shortcut loader entry path
for Linux kernel image booting, it defaults to &lt;code&gt;\loader\entries\arch.conf&lt;/code&gt;
when unspecified.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;CONSOLE&lt;/code&gt;: set to either &lt;code&gt;com1&lt;/code&gt; or &lt;code&gt;text&lt;/code&gt; (default) controls the output
console to either serial port or UEFI console.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;code&gt;NET&lt;/code&gt;: set to either &lt;code&gt;0&lt;/code&gt; (default) or &lt;code&gt;1&lt;/code&gt; controls enabling of UEFI
networking support (see &lt;em&gt;UEFI networking&lt;/em&gt;).&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Build the &lt;code&gt;go-boot.efi&lt;/code&gt; executable:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git clone https://github.com/usbarmory/go-boot &amp;amp;&amp;amp; cd go-boot
make efi IMAGE_BASE=10000000 CONSOLE=text
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Executing as UEFI application&lt;/h1&gt;&lt;a href="#executing-as-uefi-application"&gt;&lt;/a&gt;
&lt;p&gt;The &lt;code&gt;go-boot.efi&lt;/code&gt; application executable, built after &lt;em&gt;Compiling&lt;/em&gt;, can be
loaded from an &lt;a href="https://github.com/pbatard/UEFI-Shell"&gt;UEFI Shell&lt;/a&gt;
or boot manager, the following example shows an entry for
&lt;a href="https://www.freedesktop.org/wiki/Software/systemd/systemd-boot/"&gt;systemd-boot&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# /boot/loader/entries/go-boot.conf
title Go Boot
efi /EFI/Linux/go-boot.efi
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;UEFI boot manager entry&lt;/h1&gt;&lt;a href="#uefi-boot-manager-entry"&gt;&lt;/a&gt;
&lt;p&gt;The following example shows creation of an EFI boot entry using
&lt;a href="https://github.com/rhboot/efibootmgr"&gt;efibootmgr&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;efibootmgr -C -L "go-boot" -d $DISK -p $PART -l '\EFI\go-boot.efi'
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;UEFI networking&lt;/h1&gt;&lt;a href="#uefi-networking"&gt;&lt;/a&gt;
&lt;p&gt;With &lt;code&gt;NET=1&lt;/code&gt; passed in the environment builds include UEFI networking support
through the &lt;a href="https://uefi.org/specs/UEFI/2.10_A/24_Network_Protocols_SNP_PXE_BIS.html"&gt;Simple Network Protocol&lt;/a&gt;
(SNP) and &lt;a href="https://github.com/usbarmory/go-net"&gt;go-net&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;On such builds the &lt;code&gt;net&lt;/code&gt; and &lt;code&gt;dns&lt;/code&gt; commands become available and &lt;code&gt;make qemu&lt;/code&gt;
will require a tap0 interface.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;net&lt;/code&gt; command takes an IP address in CIDR notation, a fixed MAC address or
&lt;code&gt;:&lt;/code&gt; to automatically generate a random MAC, and a gateway IP address as
arguments.&lt;/p&gt;
&lt;p&gt;The optional &lt;code&gt;debug&lt;/code&gt; strings can be passed as final argument to &lt;code&gt;net&lt;/code&gt; to enable
Go &lt;a href="https://pkg.go.dev/net/http/pprof"&gt;profiling server&lt;/a&gt; and an unauthenticated
SSH console exposing the UEFI shell.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt; net 10.0.0.1/24 : 10.0.0.2 debug
starting debug servers:
        http://10.0.0.1:80/debug/pprof
        ssh://10.0.0.1:22
network initialized (10.0.0.1/24 da:e7:ac:e2:5e:05)

&amp;gt; dns golang.org
[142.251.209.17 2a00:1450:4002:410::2011]
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Emulated hardware with QEMU&lt;/h1&gt;&lt;a href="#emulated-hardware-with-qemu"&gt;&lt;/a&gt;
&lt;p&gt;QEMU supported targets can be executed under emulation, using the
&lt;a href="https://github.com/tianocore/tianocore.github.io/wiki/OVMF"&gt;Open Virtual Machine Firmware&lt;/a&gt;
as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;make qemu OVMFCODE=&amp;lt;path to OVMF_CODE.fd&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With &lt;code&gt;NET=1&lt;/code&gt; tap0 should be configured as follows (Linux example):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ip tuntap add dev tap0 mode tap group &amp;lt;your user group&amp;gt;
ip addr add 10.0.0.2/24 dev tap0
ip link set tap0 up
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;An emulated target can be &lt;a href="https://retrage.github.io/2019/12/05/debugging-ovmf-en.html/"&gt;debugged with GDB&lt;/a&gt;
using &lt;code&gt;make qemu-gdb&lt;/code&gt;, this will make qemu waiting for a GDB connection that
can be launched as follows:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gdb -ex "target remote 127.0.0.1:1234"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Breakpoints can be set in the usual way:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;b cpuinit
continue
&lt;/code&gt;&lt;/pre&gt;
&lt;h1&gt;Cloud deployments&lt;/h1&gt;&lt;a href="#cloud-deployments"&gt;&lt;/a&gt;
&lt;p&gt;The following example demonstrates how to create, and deploy, a UEFI-bootable
image for cloud deployments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/usbarmory/go-boot/wiki/Google-Compute-Engine"&gt;Google Compute Engine&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1&gt;License&lt;/h1&gt;&lt;a href="#license"&gt;&lt;/a&gt;
&lt;p&gt;go-boot | &lt;a href="https://github.com/usbarmory/go-boot"&gt;https://github.com/usbarmory/go-boot&lt;/a&gt;
Copyright (c) The go-boot authors. All Rights Reserved.&lt;/p&gt;
&lt;p&gt;These source files are distributed under the BSD-style license found in the
&lt;a href="https://github.com/usbarmory/go-boot/blob/main/LICENSE"&gt;LICENSE&lt;/a&gt; file.&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/usbarmory/go-boot</guid>
      <category>Hacker News</category>
      <pubDate>Thu, 18 Dec 2025 00:08:46 +0000</pubDate>
    </item>
    <item>
      <title>Learn Lisp/Fennel Programming Against Neovim</title>
      <link>https://github.com/humorless/fennel-fp-neovim</link>
      <description>A series of Neovim Plugin Development introduction articles, using Fennel as the programming language to explain Lisp, FP, and advanced programming ideas.</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;h1&gt;fennel-fp-neovim&lt;/h1&gt;&lt;a href="#fennel-fp-neovim"&gt;&lt;/a&gt;
&lt;p&gt;A series of Neovim Plugin Development introduction articles, using Fennel as the programming language to explain Lisp, FP, and advanced programming ideas.&lt;/p&gt;
&lt;h2&gt;Exploring Fennel and Functional Programming in Neovim&lt;/h2&gt;&lt;a href="#exploring-fennel-and-functional-programming-in-neovim"&gt;&lt;/a&gt;
&lt;p&gt;In the AI era, developers need to think about new development paradigms: "AI helps us quickly generate code, but debugging and verification still require active developer intervention." This series of articles will start with Neovim + Fennel, guiding readers into the new world of "Interactive Development" and "Functional Programming".&lt;/p&gt;
&lt;p&gt;Content includes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fennel Language: Syntax, commonly used libraries.&lt;/li&gt;
&lt;li&gt;Lisp Thinking: S-expression editing, interactive development.&lt;/li&gt;
&lt;li&gt;Functional Programming: Pure functions, practical techniques like map/filter/reduce.&lt;/li&gt;
&lt;li&gt;Neovim Plugin Development: From simple scripts to complete plugins.&lt;/li&gt;
&lt;li&gt;Patterns and Principles: The rules that guide us to success.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let's explore smarter and more elegant ways of program development together in the AI era.&lt;/p&gt;
&lt;h2&gt;Acknowledgments&lt;/h2&gt;&lt;a href="#acknowledgments"&gt;&lt;/a&gt;
&lt;p&gt;The completion of this article series is largely inspired by my work at &lt;a href="https://gaiwan.co/"&gt;Gaiwan&lt;/a&gt; and &lt;a href="https://lambdaisland.com/"&gt;LambdaIsland&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This series was first published in Taiwan, and then I translated the original &lt;a href="https://ithelp.ithome.com.tw/users/20161869/ironman/8497"&gt;Traditional Chinese version&lt;/a&gt; into English using &lt;a href="https://github.com/playcanvas/markdown-translator"&gt;markdown-translator&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you have any thoughts after reading this series, feel free to reach out to &lt;a href="https://replware.dev/"&gt;me&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Table of contents&lt;/h2&gt;&lt;a href="#table-of-contents"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day01.md"&gt;Preface: What Should You Learn After AI Accelerates Coding?&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Software Development in the AI Era&lt;/li&gt;
&lt;li&gt;Fennel Lowers the Entry Barrier for Interactive Development / Functional Programming&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day02.md"&gt;Fennel Brief History and Development Environment&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;From Individual to Community: The Birth of Fennel&lt;/li&gt;
&lt;li&gt;Development Environment - Installation&lt;/li&gt;
&lt;li&gt;Development Environment - Plugin Introduction&lt;/li&gt;
&lt;li&gt;Development Environment - Automatic Formatting&lt;/li&gt;
&lt;li&gt;Interactive Development&lt;/li&gt;
&lt;li&gt;S-expression Editing&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day03.md"&gt;Fennel Language Crash Course—Lisp Syntax&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Let's Talk About Syntax First&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day04.md"&gt;Fennel Language Crash Course—Core Syntax&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Functions&lt;/li&gt;
&lt;li&gt;Local Variables&lt;/li&gt;
&lt;li&gt;Numbers and Strings&lt;/li&gt;
&lt;li&gt;Containers&lt;/li&gt;
&lt;li&gt;Loops&lt;/li&gt;
&lt;li&gt;Iteration&lt;/li&gt;
&lt;li&gt;Conditional Statements&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day05.md"&gt;Fennel Language Crash Course—Lua&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Lua and Minimalism&lt;/li&gt;
&lt;li&gt;Lua Overview&lt;/li&gt;
&lt;li&gt;Other Uses of Lua's Table&lt;/li&gt;
&lt;li&gt;Fennel Syntax Extensions for Tables&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day06.md"&gt;Fennel Language Crash Course—LuaRocks&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;The Problem of Multiple Interpreters&lt;/li&gt;
&lt;li&gt;LuaRocks&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day07.md"&gt;Fennel Language Crash Course—nfnl Library&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;nfnl Examples&lt;/li&gt;
&lt;li&gt;Clojure-style Programming&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day08.md"&gt;Lisp In-depth—Interactive Development&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Other Commands for Interactive Development&lt;/li&gt;
&lt;li&gt;Leveraging Interactive Development&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day09.md"&gt;Lisp In-depth—S-expression Editing&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Parenthesis Pairing Issues&lt;/li&gt;
&lt;li&gt;Parenthesis Editing Issues&lt;/li&gt;
&lt;li&gt;Navigating and Editing within the Syntax Tree&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day10.md"&gt;Lisp In-depth—Macro&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;What Macros Does Lisp Provide?&lt;/li&gt;
&lt;li&gt;Fennel's Reader Macro&lt;/li&gt;
&lt;li&gt;Reconsidering Lisp Macros&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day11.md"&gt;Lisp In-depth—Data-Oriented Programming&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;The Troubles of Tree Traversal&lt;/li&gt;
&lt;li&gt;Clojure's Unique Flavor&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day12.md"&gt;Demystifying Functional Programming (FP)—High-Level Semantics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Why is FP considered a high-level semantic? Starting from Accounting&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day13.md"&gt;Demystifying Functional Programming (FP)—The Challenge of Definition&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;What is Functional Programming (FP)? What is its definition?&lt;/li&gt;
&lt;li&gt;Separating Concept from Implementation&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day14.md"&gt;Demystifying Functional Programming (FP)—Common Mechanisms&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Higher-Order Functions&lt;/li&gt;
&lt;li&gt;Value Copying&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day15.md"&gt;Demystifying Functional Programming (FP)—Advanced Topics&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Functional Programming Idioms (FP idioms)&lt;/li&gt;
&lt;li&gt;FP and Code Reuse (code reuse)&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day16.md"&gt;Neovim Plugin Development—Getting Started&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Why the Learning Failed&lt;/li&gt;
&lt;li&gt;A Relatively Reasonable Learning Strategy&lt;/li&gt;
&lt;li&gt;Neovim Runtime&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day17.md"&gt;Neovim Plugin Development—Hello World&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Hello World Plugin&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day18.md"&gt;Neovim Plugin Development—Standard Plugin&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Plugin Development&lt;/li&gt;
&lt;li&gt;Module Imports&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day19.md"&gt;Neovim Plugin Development—How to debug?&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Inspecting Internal State&lt;/li&gt;
&lt;li&gt;Internal Execution Order&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day20.md"&gt;Project Discussion—auto-conjure&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Problem Overview&lt;/li&gt;
&lt;li&gt;Solution Architecture&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day21.md"&gt;Project Discussion—Conjure Piglet Client&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Problem Overview&lt;/li&gt;
&lt;li&gt;Solution Architecture&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day22.md"&gt;Project Discussion—WebSocket&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Problem Overview&lt;/li&gt;
&lt;li&gt;Solution Architecture&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day23.md"&gt;Project Discussion—CBOR&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Problem Overview&lt;/li&gt;
&lt;li&gt;Solution Architecture&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day24.md"&gt;Project Discussion—Fennel's Jump to Definition&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Problem Overview&lt;/li&gt;
&lt;li&gt;Solution Architecture&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day25.md"&gt;Project Discussion—Tree-sitter Behind Jump to Definition&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Problem Overview&lt;/li&gt;
&lt;li&gt;Solution Architecture&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day26.md"&gt;Patterns and Principles—Bottlenecks and Improvements&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Theory of Constraints&lt;/li&gt;
&lt;li&gt;The Biggest Constraint in the Age of AI&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day27.md"&gt;Patterns and Principles—Uncertainty&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Ways to Respond&lt;/li&gt;
&lt;li&gt;Related Theory&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day28.md"&gt;Patterns and Principles—Complexity&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;The Way to Respond&lt;/li&gt;
&lt;li&gt;Related Theory&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day29.md"&gt;Patterns and Principles—Modification Propagation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;The Way to Respond&lt;/li&gt;
&lt;li&gt;Related Theories&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/humorless/fennel-fp-neovim/blob/main/day30.md"&gt;Patterns and Principles—Tacit Knowledge&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;The Way to Respond&lt;/li&gt;
&lt;li&gt;Related Theories&lt;/li&gt;
&lt;li&gt;Summary&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;License&lt;/h2&gt;&lt;a href="#license"&gt;&lt;/a&gt;
&lt;p&gt;Copyright @ Laurence Chen&lt;/p&gt;
&lt;p&gt;Licensed under the term of &lt;a href="https://creativecommons.org/licenses/by/4.0/"&gt;the Creative Commons Attribution 4.0 International License&lt;/a&gt;.&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/humorless/fennel-fp-neovim</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 17 Dec 2025 20:09:17 +0000</pubDate>
    </item>
    <item>
      <title>Show HN: Tonbo – an embedded database for serverless and edge runtimes</title>
      <link>https://github.com/tonbo-io/tonbo</link>
      <description>GitHub - tonbo-io/tonbo: Tonbo is an embedded database for serverless and edge runtimes.</description>
      <content:encoded>&lt;article class="markdown-body entry-content container-lg" itemprop="text"&gt;&lt;p&gt;
&lt;a href="https://tonbo.io"&gt;

&lt;img src="https://github.com/user-attachments/assets/f6949c40-012f-425e-8ad8-6b3fe11ce672"/&gt;

&lt;/a&gt;
&lt;/p&gt;
&lt;h1&gt;Tonbo&lt;/h1&gt;&lt;a href="#tonbo"&gt;&lt;/a&gt;
&lt;p&gt;&lt;a href="https://crates.io/crates/tonbo/"&gt;&lt;img alt="crates.io" src="https://camo.githubusercontent.com/c14411a490010d595763fe3a2ebfb97b816e8a802ad1e1474d8b43148e9ad000/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f762f746f6e626f2e737667"/&gt;&lt;/a&gt; &lt;a href="https://github.com/tonbo-io/tonbo/blob/main/LICENSE"&gt;&lt;img alt="crates.io" src="https://camo.githubusercontent.com/ede58c726b974969a2e04fd2bbc3437858fa6b437196fddfc844fb901eb143dd/68747470733a2f2f696d672e736869656c64732e696f2f6372617465732f6c2f746f6e626f"/&gt;&lt;/a&gt; &lt;a href="https://docs.rs/tonbo/0.4.0-a0/tonbo/"&gt;&lt;img alt="docs.rs" src="https://camo.githubusercontent.com/0186ede82c8aabaa6a22500cee55fa3fa8a3e23cb72bc23a0c73dbc2c8421013/68747470733a2f2f696d672e736869656c64732e696f2f646f637372732f746f6e626f"/&gt;&lt;/a&gt; &lt;a href="https://github.com/tonbo-io/tonbo/actions/workflows/rust.yml"&gt;&lt;img alt="ci" src="https://github.com/tonbo-io/tonbo/actions/workflows/rust.yml/badge.svg?branch=dev"/&gt;&lt;/a&gt; &lt;a href="https://discord.gg/j27XVFVmJM"&gt;&lt;img alt="discord" src="https://camo.githubusercontent.com/76271947c68a3b47c8afc156e0933b123f76f1a0c05b6b9daffabd0fe8b4c71a/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f313237303239343938373335353139373436303f6c6f676f3d646973636f7264"/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href="https://tonbo.io/"&gt;Website&lt;/a&gt; | &lt;a href="https://docs.rs/tonbo/0.4.0-a0/tonbo/"&gt;Rust Doc&lt;/a&gt; | &lt;a href="https://tonbo.io/blogs"&gt;Blog&lt;/a&gt; | &lt;a href="https://discord.gg/j27XVFVmJM"&gt;Community&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Tonbo is an embedded database for serverless and edge runtimes. Your data is stored as Parquet on S3, coordination happens through a manifest, and compute stays fully stateless.&lt;/p&gt;
&lt;h2&gt;Why Tonbo?&lt;/h2&gt;&lt;a href="#why-tonbo"&gt;&lt;/a&gt;
&lt;p&gt;Serverless compute is stateless, but your data isn't. Tonbo bridges this gap:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Async-first&lt;/strong&gt;: The entire storage and query engine is fully async, built for serverless and edge environments.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;No server to manage&lt;/strong&gt;: Data lives on S3, coordination via manifest, compute is stateless&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Arrow-native&lt;/strong&gt;: Define rich data type, declarative schemas, query with zero-copy &lt;code&gt;RecordBatch&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Runs anywhere&lt;/strong&gt;: Tokio, WASM, edge runtimes, or as a storage engine for building your own data infrastructure.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Open formats&lt;/strong&gt;: Standard Parquet files readable by any tool&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;When to use Tonbo?&lt;/h3&gt;&lt;a href="#when-to-use-tonbo"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;Build serverless or edge applications that need a durable state layer without running a database.&lt;/li&gt;
&lt;li&gt;Store append-heavy or event-like data directly in S3 and query it with low overhead.&lt;/li&gt;
&lt;li&gt;Embed a lightweight MVCC + Parquet storage engine inside your own data infrastructure.&lt;/li&gt;
&lt;li&gt;Run workloads in WASM or Cloudflare Workers that require structured persistence.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Quick Start&lt;/h2&gt;&lt;a href="#quick-start"&gt;&lt;/a&gt;
&lt;pre&gt;use tonbo::{db::{AwsCreds, ObjectSpec, S3Spec}, prelude::*};

#[derive(Record)]
struct User {
    #[metadata(k = "tonbo.key", v = "true")]
    id: String,
    name: String,
    score: Option&amp;lt;i64&amp;gt;,
}

// Open on S3
let s3 = S3Spec::new("my-bucket", "data/users", AwsCreds::from_env()?);
let db = DbBuilder::from_schema(User::schema())?
    .object_store(ObjectSpec::s3(s3))?.open().await?;

// Insert
let users = vec![User { id: "u1".into(), name: "Alice".into(), score: Some(100) }];
let mut builders = User::new_builders(users.len());
builders.append_rows(users);
db.ingest(builders.finish().into_record_batch()).await?;

// Query
let filter = Predicate::gt(ColumnRef::new("score"), ScalarValue::from(80_i64));
let results = db.scan().filter(filter).collect().await?;&lt;/pre&gt;
&lt;p&gt;For local development, use &lt;code&gt;.on_disk("/tmp/users")?&lt;/code&gt; instead. See &lt;a href="https://github.com/tonbo-io/tonbo/blob/dev/examples"&gt;&lt;code&gt;examples/&lt;/code&gt;&lt;/a&gt; for more.&lt;/p&gt;
&lt;h2&gt;Installation&lt;/h2&gt;&lt;a href="#installation"&gt;&lt;/a&gt;
&lt;pre&gt;cargo add tonbo@0.4.0-a0 tokio&lt;/pre&gt;
&lt;p&gt;Or add to &lt;code&gt;Cargo.toml&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;[dependencies]
tonbo = "0.4.0-a0"
tokio = { version = "1", features = ["rt-multi-thread", "macros"] }&lt;/pre&gt;
&lt;h2&gt;Examples&lt;/h2&gt;&lt;a href="#examples"&gt;&lt;/a&gt;
&lt;p&gt;Run with &lt;code&gt;cargo run --example &amp;lt;name&amp;gt;&lt;/code&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;01_basic&lt;/code&gt;: Define schema, insert, and query in 30 lines&lt;/li&gt;
&lt;li&gt;&lt;code&gt;02_transaction&lt;/code&gt;: MVCC transactions with upsert, delete, and read-your-writes&lt;/li&gt;
&lt;li&gt;&lt;code&gt;02b_snapshot&lt;/code&gt;: Consistent point-in-time reads while writes continue&lt;/li&gt;
&lt;li&gt;&lt;code&gt;03_filter&lt;/code&gt;: Predicates: eq, gt, in, is_null, and, or, not&lt;/li&gt;
&lt;li&gt;&lt;code&gt;04_s3&lt;/code&gt;: Store Parquet files on S3/R2/MinIO with zero server config&lt;/li&gt;
&lt;li&gt;&lt;code&gt;05_scan_options&lt;/code&gt;: Projection pushdown reads only the columns you need&lt;/li&gt;
&lt;li&gt;&lt;code&gt;06_composite_key&lt;/code&gt;: Multi-column keys for time-series and partitioned data&lt;/li&gt;
&lt;li&gt;&lt;code&gt;07_streaming&lt;/code&gt;: Process millions of rows without loading into memory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;08_nested_types&lt;/code&gt;: Deep struct nesting + Lists stored as Arrow StructArray&lt;/li&gt;
&lt;li&gt;&lt;code&gt;09_time_travel&lt;/code&gt;: Query historical snapshots via MVCC timestamps&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Architecture&lt;/h2&gt;&lt;a href="#architecture"&gt;&lt;/a&gt;
&lt;p&gt;Tonbo implements a merge-tree optimized for object storage: writes go to WAL → MemTable → Parquet SSTables, with MVCC for snapshot isolation and a manifest for coordination via compare-and-swap:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Stateless compute&lt;/strong&gt;: A worker only needs to read and update the manifest; no long-lived coordinator is required.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Object storage CAS&lt;/strong&gt;: The manifest is committed using compare-and-swap on S3, so any function can safely participate in commits.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Immutable data&lt;/strong&gt;: Data files are write-once Parquet SSTables, which matches the strengths of S3 and other object stores.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;See &lt;a href="https://github.com/tonbo-io/tonbo/blob/dev/docs/overview.md"&gt;docs/overview.md&lt;/a&gt; for the full design.&lt;/p&gt;
&lt;h2&gt;Documentation&lt;/h2&gt;&lt;a href="#documentation"&gt;&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;User Guide&lt;/strong&gt;: &lt;a href="https://tonbo.io/docs"&gt;tonbo.io/docs&lt;/a&gt;: tutorials and concepts&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;API Reference&lt;/strong&gt;: &lt;a href="https://docs.rs/tonbo"&gt;docs.rs/tonbo&lt;/a&gt;: full Rust API documentation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;RFCs&lt;/strong&gt;: &lt;a href="https://github.com/tonbo-io/tonbo/blob/dev/docs/rfcs"&gt;docs/rfcs/&lt;/a&gt;: design documents for contributors&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Development&lt;/h2&gt;&lt;a href="#development"&gt;&lt;/a&gt;
&lt;h3&gt;Coverage&lt;/h3&gt;&lt;a href="#coverage"&gt;&lt;/a&gt;
&lt;p&gt;Install coverage tooling once:&lt;/p&gt;
&lt;pre&gt;rustup component add llvm-tools-preview
cargo install cargo-llvm-cov --version 0.6.12 --locked&lt;/pre&gt;
&lt;p&gt;Run coverage locally:&lt;/p&gt;
&lt;pre&gt;cargo llvm-cov --workspace --lcov --output-path lcov.info --summary&lt;/pre&gt;
&lt;p&gt;Generate an HTML report:&lt;/p&gt;
&lt;pre&gt;cargo llvm-cov --workspace --html&lt;/pre&gt;
&lt;h3&gt;Project status&lt;/h3&gt;&lt;a href="#project-status"&gt;&lt;/a&gt;
&lt;p&gt;Tonbo is currently in &lt;strong&gt;alpha&lt;/strong&gt;. APIs may change, and we're actively iterating based on feedback.
We recommend starting with development and non-critical workloads before moving to production.&lt;/p&gt;
&lt;h2&gt;Features&lt;/h2&gt;&lt;a href="#features"&gt;&lt;/a&gt;
&lt;p&gt;&lt;strong&gt;Storage&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; Parquet files on object storage (S3, R2) or local filesystem&lt;/li&gt;
&lt;li&gt; Manifest-driven coordination (CAS commits, no server needed)&lt;/li&gt;
&lt;li&gt; (in-progress) Remote compaction (offload to serverless functions)&lt;/li&gt;
&lt;li&gt; (in-progress) Branching (git-like fork and merge for datasets)&lt;/li&gt;
&lt;li&gt; Time-window compaction strategy&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Schema &amp;amp; Query&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; Arrow-native schemas (&lt;code&gt;#[derive(Record)]&lt;/code&gt; or dynamic &lt;code&gt;Schema&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt; Projection pushdown (read only needed columns)&lt;/li&gt;
&lt;li&gt; Zero-copy reads via Arrow RecordBatch&lt;/li&gt;
&lt;li&gt; (in-progress) Filter pushdown (predicates evaluated at storage layer)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Backends&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; Local filesystem&lt;/li&gt;
&lt;li&gt; S3 / S3-compatible (R2, MinIO)&lt;/li&gt;
&lt;li&gt; (in-progress) OPFS (browser storage)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Runtime&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; Async-first (Tokio)&lt;/li&gt;
&lt;li&gt; Edge runtimes (Deno, Cloudflare Workers)&lt;/li&gt;
&lt;li&gt; WebAssembly&lt;/li&gt;
&lt;li&gt; (in-progress) io_uring&lt;/li&gt;
&lt;li&gt; (in-progress) Python async bindings&lt;/li&gt;
&lt;li&gt; JavaScript/TypeScript async bindings&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Integrations&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt; DataFusion TableProvider&lt;/li&gt;
&lt;li&gt; Postgres Foreign Data Wrapper&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;License&lt;/h2&gt;&lt;a href="#license"&gt;&lt;/a&gt;
&lt;p&gt;Apache License 2.0. See &lt;a href="https://github.com/tonbo-io/tonbo/blob/dev/LICENSE"&gt;LICENSE&lt;/a&gt; for details.&lt;/p&gt;
&lt;/article&gt;</content:encoded>
      <guid isPermaLink="false">https://github.com/tonbo-io/tonbo</guid>
      <category>Hacker News</category>
      <pubDate>Wed, 17 Dec 2025 18:41:40 +0000</pubDate>
    </item>
  </channel>
</rss>
